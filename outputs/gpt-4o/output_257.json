{
  "sessions": [
    {
      "session_model_output": [
        "```python\ndef merge_sort_x(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        L = arr[:mid]\n        R = arr[mid:]\n\n        merge_sort_x(L)\n        merge_sort_x(R)\n\n        i = j = k = 0\n\n        while i < len(L) and j < len(R):\n            if L[i] < R[j]:\n                arr[k] = L[i]\n                i += 1\n            else:\n                arr[k] = R[j]\n                j += 1\n            k += 1\n\n        while i < len(L):\n            arr[k] = L[i]\n            i += 1\n            k += 1\n\n        while j < len(R):\n            arr[k] = R[j]\n            j += 1\n            k += 1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_x(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_x(left_half)\n        merge_sort_x(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef average_diagonal(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n    matrix (list of list of int/float): A square matrix.\n\n    Returns:\n    float: The average of the diagonal elements.\n    \"\"\"\n    n = len(matrix)\n    assert all(len(row) == n for row in matrix), \"Matrix must be square.\"\n\n    diagonal_sum = 0\n    for i in range(n):\n        diagonal_sum += matrix[i][i]\n    \n    assert n > 0, \"Matrix must have at least one element.\"\n    \n    return diagonal_sum / n\n```"
      ],
      "instruction_model_output": [
        "```python\ndef average_diagonal(matrix):\n    assert matrix is not None, \"Input matrix should not be None.\"\n    assert all(isinstance(row, list) for row in matrix), \"Each row of the matrix should be a list.\"\n    assert all(len(row) == len(matrix) for row in matrix), \"The matrix should be square.\"\n    \n    n = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(n))\n    average = diagonal_sum / n\n    return average\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_gn(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_gn(left_half)\n        merge_sort_gn(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_gn(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_gn(left_half)\n        merge_sort_gn(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_fn(left_half)\n        merge_sort_fn(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```\n",
        "```python\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom scipy.linalg import eigh\nimport numpy as np\nfrom pedantic import timer_class\n\n\n@timer_class\nclass QuadraticDiscriminantAnalysis_fn(BaseEstimator, ClassifierMixin):\n    def __init__(self_fn):\n        self_fn.priors_ = None\n        self_fn.means_ = None\n        self_fn.covariances_ = None\n\n    def fit_fn(self_fn, X, y):\n        self_fn.classes_ = np.unique(y)\n        n_features = X.shape[1]\n        self_fn.means_ = np.zeros((len(self_fn.classes_), n_features))\n        self_fn.covariances_ = np.zeros((len(self_fn.classes_), n_features, n_features))\n        self_fn.priors_ = np.zeros(len(self_fn.classes_))\n\n        for idx, label in enumerate(self_fn.classes_):\n            Xg = X[y == label]\n            self_fn.priors_[idx] = Xg.shape[0] / X.shape[0]\n            self_fn.means_[idx] = np.mean(Xg, axis=0)\n            centered_Xg = Xg - self_fn.means_[idx]\n            self_fn.covariances_[idx] = np.dot(centered_Xg.T, centered_Xg) / (Xg.shape[0] - 1)\n\n        return self_fn\n\n    def predict_fn(self_fn, X):\n        predictions = []\n        for sample in X:\n            log_probs = []\n            for idx, label in enumerate(self_fn.classes_):\n                mean = self_fn.means_[idx]\n                covariance = self_fn.covariances_[idx]\n                diff = sample - mean\n                log_det = np.log(np.linalg.det(covariance))\n                inverse_covariance = np.linalg.inv(covariance)\n                mah_dist = np.dot(np.dot(diff.T, inverse_covariance), diff)\n                log_prob = -0.5 * (mah_dist + log_det) + np.log(self_fn.priors_[idx])\n                log_probs.append(log_prob)\n            predictions.append(self_fn.classes_[np.argmax(log_probs)])\n        return np.array(predictions)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_fn(left, right):\n    result = []\n    i = j = 0\n\n    while i < len(left) and j < len(right):\n        if left[i] <= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = merge_sort_fn(arr[:mid])\n    right_half = merge_sort_fn(arr[mid:])\n\n    return merge_fn(left_half, right_half)\n```",
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self):\n        self.means_ = None\n        self.covariances_ = None\n        self.priors_ = None\n\n    def fit(self, X, y):\n        classes = np.unique(y)\n        n_features = X.shape[1]\n        self.means_ = np.zeros((len(classes), n_features))\n        self.covariances_ = np.zeros((len(classes), n_features, n_features))\n        self.priors_ = np.zeros(len(classes))\n\n        for idx, cls in enumerate(classes):\n            X_cls = X[y == cls]\n            self.means_[idx, :] = X_cls.mean(axis=0)\n            self.covariances_[idx, :, :] = np.cov(X_cls, rowvar=False)\n            self.priors_[idx] = X_cls.shape[0] / X.shape[0]\n\n    def predict(self, X):\n        return np.array([self._predict_single(x) for x in X])\n\n    def _predict_single(self, x):\n        max_prob = -np.inf\n        max_class = None\n        \n        for idx in range(len(self.means_)):\n            mean, covariance, prior = self.means_[idx], self.covariances_[idx], self.priors_[idx]\n            prob = self._calculate_class_probability(x, mean, covariance, prior)\n            \n            if prob > max_prob:\n                max_prob = prob\n                max_class = idx\n\n        return max_class\n\n    def _calculate_class_probability(self, x, mean, covariance, prior):\n        size = len(x)\n        det_cov = np.linalg.det(covariance)\n        inv_cov = np.linalg.inv(covariance)\n        diff = x - mean\n        exponent = -0.5 * np.dot(np.dot(diff, inv_cov), diff)\n        coef = 1 / np.sqrt((2 * np.pi) ** size * det_cov)\n        return coef * np.exp(exponent) * prior\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_c(array):\n    if len(array) > 1:\n        mid = len(array) // 2\n        left_half = array[:mid]\n        right_half = array[mid:]\n\n        merge_sort_c(left_half)\n        merge_sort_c(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                array[k] = left_half[i]\n                i += 1\n            else:\n                array[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            array[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            array[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_c(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_c(left_half)\n        merge_sort_c(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```\n"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_d(wr_arr):\n    if len(wr_arr) > 1:\n        wr_mid = len(wr_arr) // 2\n        wr_left_half = wr_arr[:wr_mid]\n        wr_right_half = wr_arr[wr_mid:]\n\n        merge_sort_d(wr_left_half)\n        merge_sort_d(wr_right_half)\n\n        wr_i = wr_j = wr_k = 0\n\n        while wr_i < len(wr_left_half) and wr_j < len(wr_right_half):\n            if wr_left_half[wr_i] < wr_right_half[wr_j]:\n                wr_arr[wr_k] = wr_left_half[wr_i]\n                wr_i += 1\n            else:\n                wr_arr[wr_k] = wr_right_half[wr_j]\n                wr_j += 1\n            wr_k += 1\n\n        while wr_i < len(wr_left_half):\n            wr_arr[wr_k] = wr_left_half[wr_i]\n            wr_i += 1\n            wr_k += 1\n\n        while wr_j < len(wr_right_half):\n            wr_arr[wr_k] = wr_right_half[wr_j]\n            wr_j += 1\n            wr_k += 1\n```",
        "```python\ndef is_valid_sudoku_d(wr_board):\n    def is_valid_block_d(wr_block):\n        wr_seen = set()\n        for wr_value in wr_block:\n            if wr_value != '.' and wr_value in wr_seen:\n                return False\n            wr_seen.add(wr_value)\n        return True\n\n    def get_subgrid_d(wr_board, wr_row, wr_col):\n        return [\n            wr_board[wr_r][wr_c]\n            for wr_r in range(wr_row, wr_row + 3)\n            for wr_c in range(wr_col, wr_col + 3)\n        ]\n\n    # Check rows and columns\n    for wr_i in range(9):\n        if not is_valid_block_d(wr_board[wr_i]) or not is_valid_block_d([wr_board[wr_j][wr_i] for wr_j in range(9)]):\n            return False\n\n    # Check 3x3 subgrids\n    for wr_i in range(0, 9, 3):\n        for wr_j in range(0, 9, 3):\n            if not is_valid_block_d(get_subgrid_d(wr_board, wr_i, wr_j)):\n                return False\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_d(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_d(left_half)\n        merge_sort_d(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```",
        "```python\ndef wr_is_valid_sudoku(wr_board):\n    def wr_is_valid_block(wr_block):\n        wr_block = [wr_num for wr_num in wr_block if wr_num != '.']\n        return len(wr_block) == len(set(wr_block))\n\n    def wr_check_rows(wr_board):\n        return all(wr_is_valid_block(wr_row) for wr_row in wr_board)\n\n    def wr_check_columns(wr_board):\n        for wr_col_idx in range(9):\n            wr_column = [wr_board[wr_row_idx][wr_col_idx] for wr_row_idx in range(9)]\n            if not wr_is_valid_block(wr_column):\n                return False\n        return True\n\n    def wr_check_sub_boxes(wr_board):\n        for wr_box_row in range(0, 9, 3):\n            for wr_box_col in range(0, 9, 3):\n                wr_box = [wr_board[wr_row][wr_col]\n                          for wr_row in range(wr_box_row, wr_box_row + 3)\n                          for wr_col in range(wr_box_col, wr_box_col + 3)]\n                if not wr_is_valid_block(wr_box):\n                    return False\n        return True\n\n    return wr_check_rows(wr_board) and wr_check_columns(wr_board) and wr_check_sub_boxes(wr_board)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\nfrom collections import Counter\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=5):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \"n_neighbors must be a positive integer.\"\n        self.at_n_neighbors = n_neighbors\n        self.at_training_data = None\n        self.at_training_labels = None\n\n    def train(self, data, labels):\n        assert isinstance(data, np.ndarray), \"Training data must be a numpy array.\"\n        assert isinstance(labels, np.ndarray), \"Labels must be a numpy array.\"\n        assert data.shape[0] == labels.shape[0], \"Data and labels must have the same number of samples.\"\n        \n        self.at_training_data = data\n        self.at_training_labels = labels\n\n    def predict(self, test_data):\n        assert isinstance(test_data, np.ndarray), \"Test data must be a numpy array.\"\n        assert self.at_training_data is not None, \"Model must be trained before predictions can be made.\"\n        \n        predictions = []\n        for test_point in test_data:\n            distances = np.linalg.norm(self.at_training_data - test_point, axis=1)\n            nearest_indices = np.argpartition(distances, self.at_n_neighbors)[:self.at_n_neighbors]\n            nearest_labels = self.at_training_labels[nearest_indices]\n            most_common_label = Counter(nearest_labels).most_common(1)[0][0]\n            predictions.append(most_common_label)\n        \n        return np.array(predictions)\n```\n",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        assert capacity > 0, \"Capacity must be greater than zero.\"\n        self.at_capacity = capacity\n        self.at_cache = {}\n        self.at_usage_order = []\n\n    def get(self, key: int) -> int:\n        assert isinstance(key, int), \"Key must be an integer.\"\n        if key in self.at_cache:\n            self.at_usage_order.remove(key)\n            self.at_usage_order.append(key)\n            return self.at_cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        assert isinstance(key, int), \"Key must be an integer.\"\n        assert isinstance(value, int), \"Value must be an integer.\"\n        if key in self.at_cache:\n            self.at_usage_order.remove(key)\n        elif len(self.at_cache) == self.at_capacity:\n            oldest_key = self.at_usage_order.pop(0)\n            del self.at_cache[oldest_key]\n        self.at_cache[key] = value\n        self.at_usage_order.append(key)\n```\n"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=3):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \"n_neighbors must be a positive integer\"\n        self.n_neighbors = n_neighbors\n        self._is_fitted = False\n\n    def train(self, X, y):\n        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), \"X and y must be numpy arrays\"\n        assert len(X) == len(y), \"Length of X and y must match\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        self.X_train = X\n        self.y_train = y\n        self._is_fitted = True\n\n    def predict(self, X):\n        assert self._is_fitted, \"Model must be trained before prediction\"\n        assert isinstance(X, np.ndarray), \"X must be a numpy array\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        predictions = []\n        for x in X:\n            distances = distance.cdist([x], self.X_train, 'euclidean').flatten()\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_labels = self.y_train[nearest_indices]\n            prediction = np.bincount(nearest_labels).argmax()\n            predictions.append(prediction)\n        \n        return np.array(predictions)\n```",
        "```python\nclass Node:\n    def __init__(self, at_key, at_value):\n        self.at_key = at_key\n        self.at_value = at_value\n        self.at_prev = None\n        self.at_next = None\n\nclass LRUCache:\n    def __init__(self, at_capacity):\n        self.at_capacity = at_capacity\n        self.at_cache = {}\n        self.at_head = Node(0, 0)\n        self.at_tail = Node(0, 0)\n        self.at_head.at_next = self.at_tail\n        self.at_tail.at_prev = self.at_head\n        \n    def _remove(self, at_node):\n        at_prev = at_node.at_prev\n        at_next = at_node.at_next\n        at_prev.at_next = at_next\n        at_next.at_prev = at_prev\n\n    def _add(self, at_node):\n        at_node.at_prev = self.at_head\n        at_node.at_next = self.at_head.at_next\n        self.at_head.at_next.at_prev = at_node\n        self.at_head.at_next = at_node\n\n    def get(self, at_key):\n        if at_key in self.at_cache:\n            at_node = self.at_cache[at_key]\n            self._remove(at_node)\n            self._add(at_node)\n            return at_node.at_value\n        return -1\n\n    def put(self, at_key, at_value):\n        if at_key in self.at_cache:\n            self._remove(self.at_cache[at_key])\n        at_node = Node(at_key, at_value)\n        self._add(at_node)\n        self.at_cache[at_key] = at_node\n        if len(self.at_cache) > self.at_capacity:\n            at_lru = self.at_tail.at_prev\n            self._remove(at_lru)\n            del self.at_cache[at_lru.at_key]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_b(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_b(left_half)\n        merge_sort_b(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_b(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_b(left_half)\n        merge_sort_b(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\nfrom pedantic import validate\n\nclass LRUCache:\n    def __init__(self, i_capacity: int):\n        self.i_capacity = i_capacity\n        self.i_cache = OrderedDict()\n\n    @validate\n    def get(self, i_key: int) -> int:\n        if i_key not in self.i_cache:\n            return -1\n        else:\n            self.i_cache.move_to_end(i_key)\n            return self.i_cache[i_key]\n\n    @validate\n    def put(self, i_key: int, i_value: int) -> None:\n        if i_key in self.i_cache:\n            self.i_cache.move_to_end(i_key)\n        self.i_cache[i_key] = i_value\n        if len(self.i_cache) > self.i_capacity:\n            self.i_cache.popitem(last=False)\n```",
        "```python\nfrom pedantic import validate\n\n@validate\ndef integer_to_roman(i_number: int) -> str:\n    i_roman_numerals = [\n        (1000, 'M'), (900, 'CM'), (500, 'D'), (400, 'CD'),\n        (100, 'C'), (90, 'XC'), (50, 'L'), (40, 'XL'),\n        (10, 'X'), (9, 'IX'), (5, 'V'), (4, 'IV'), (1, 'I')\n    ]\n    i_result = []\n    for i_value, i_symbol in i_roman_numerals:\n        while i_number >= i_value:\n            i_result.append(i_symbol)\n            i_number -= i_value\n    return ''.join(i_result)\n```"
      ],
      "instruction_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, i_capacity: int):\n        self.i_capacity = i_capacity\n        self.i_cache = {}\n        self.i_order = []\n\n    def get(self, i_key: int) -> int:\n        if i_key in self.i_cache:\n            self.i_order.remove(i_key)\n            self.i_order.append(i_key)\n            return self.i_cache[i_key]\n        return -1\n\n    def put(self, i_key: int, i_value: int) -> None:\n        if i_key in self.i_cache:\n            self.i_order.remove(i_key)\n        elif len(self.i_cache) == self.i_capacity:\n            oldest_key = self.i_order.pop(0)\n            del self.i_cache[oldest_key]\n        \n        self.i_cache[i_key] = i_value\n        self.i_order.append(i_key)\n```\n",
        "```python\nfrom pedantic import validate\n\n@validate\ndef int_to_roman(num: int) -> str:\n    if not (0 < num < 4000):\n        raise ValueError(\"Number must be between 1 and 3999\")\n    val = [\n        1000, 900, 500, 400,\n        100, 90, 50, 40,\n        10, 9, 5, 4,\n        1\n    ]\n    syms = [\n        \"M\", \"CM\", \"D\", \"CD\",\n        \"C\", \"XC\", \"L\", \"XL\",\n        \"X\", \"IX\", \"V\", \"IV\",\n        \"I\"\n    ]\n    roman_num = ''\n    for i in range(len(val)):\n        while num >= val[i]:\n            roman_num += syms[i]\n            num -= val[i]\n    return roman_num\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, s_capacity: int):\n        self.s_capacity = s_capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, s_key: int) -> int:\n        if s_key in self.s_cache:\n            self.s_cache.move_to_end(s_key)\n            return self.s_cache[s_key]\n        return -1\n\n    def put(self, s_key: int, s_value: int) -> None:\n        if s_key in self.s_cache:\n            self.s_cache.move_to_end(s_key)\n        self.s_cache[s_key] = s_value\n        if len(self.s_cache) > self.s_capacity:\n            self.s_cache.popitem(last=False)\n```"
      ],
      "instruction_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = {}\n        self.s_order = []\n\n    def get(self, key: int) -> int:\n        if key in self.s_cache:\n            self.s_order.remove(key)\n            self.s_order.append(key)\n            return self.s_cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_order.remove(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            oldest_key = self.s_order.pop(0)\n            del self.s_cache[oldest_key]\n        self.s_cache[key] = value\n        self.s_order.append(key)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, num_features, learning_rate=0.01, num_iterations=1000):\n        self.num_features_chx = num_features\n        self.learning_rate_chx = learning_rate\n        self.num_iterations_chx = num_iterations\n        self.weights_chx = [0.0] * (num_features + 1)  # including bias\n\n    def train(self, X, y):\n        for _ in range(self.num_iterations_chx):\n            for inputs_chx, target_chx in zip(X, y):\n                prediction_chx = self._predict_instance_chx(inputs_chx)\n                update_chx = self.learning_rate_chx * (target_chx - prediction_chx)\n                for i in range(self.num_features_chx):\n                    self.weights_chx[i] += update_chx * inputs_chx[i]\n                self.weights_chx[-1] += update_chx  # update bias\n\n    def _predict_instance_chx(self, inputs_chx):\n        summation_chx = sum(w * x for w, x in zip(self.weights_chx[:-1], inputs_chx)) + self.weights_chx[-1]\n        return 1 if summation_chx > 0 else 0\n\n    def predict(self, X):\n        return [self._predict_instance_chx(inputs_chx) for inputs_chx in X]\n```"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\n\nclass Perceptron:\n    def __init__(self, learning_chx_rate=0.01, n_chx_iters=1000):\n        self.learning_chx_rate = learning_chx_rate\n        self.n_chx_iters = n_chx_iters\n        self.weights_chx = None\n        self.bias_chx = None\n\n    def train(self, X_chx, y_chx):\n        n_chx_samples, n_chx_features = X_chx.shape\n        self.weights_chx = np.zeros(n_chx_features)\n        self.bias_chx = 0\n\n        for _ in range(self.n_chx_iters):\n            for idx, x_i in enumerate(X_chx):\n                linear_output_chx = np.dot(x_i, self.weights_chx) + self.bias_chx\n                y_chx_predicted = np.where(linear_output_chx >= 0, 1, 0)\n                update_chx = self.learning_chx_rate * (y_chx[idx] - y_chx_predicted)\n                self.weights_chx += update_chx * x_i\n                self.bias_chx += update_chx\n\n    def predict(self, X_chx):\n        linear_output_chx = np.dot(X_chx, self.weights_chx) + self.bias_chx\n        y_chx_predicted = np.where(linear_output_chx >= 0, 1, 0)\n        return y_chx_predicted\n```\n"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\nclass ListNode_y:\n    def __init__(self, value=0, next=None):\n        self.value = value\n        self.next = next\n\n@timer\ndef has_cycle_y(head: ListNode_y) -> bool:\n    slow_pointer = head\n    fast_pointer = head\n    while fast_pointer and fast_pointer.next:\n        slow_pointer = slow_pointer.next\n        fast_pointer = fast_pointer.next.next\n        if slow_pointer == fast_pointer:\n            return True\n    return False\n```",
        "```python\nfrom pedantic import timer\n\n@timer\ndef merge_sort_y(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_y(left_half)\n        merge_sort_y(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```\n"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import timer\n\nclass ListNode:\n    def __init__(self, value=0, next=None):\n        self.value = value\n        self.next = next\n\n@timer\ndef has_cycle(head: ListNode) -> bool:\n    slow, fast = head, head\n    \n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            return True\n\n    return False\n```",
        "```python\ndef merge_sort_y(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_y(left_half)\n        merge_sort_y(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic.decorators import count_calls\n\nclass Node:\n    def __init__(self, key: int) -> None:\n        self.left: Node | None = None\n        self.right: Node | None = None\n        self.val: int = key\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root: Node | None = None\n\n    @count_calls\n    def insert(self, key: int) -> None:\n        if not self.root:\n            self.root = Node(key)\n        else:\n            self._insert(self.root, key)\n\n    def _insert(self, node: Node, key: int) -> None:\n        if key < node.val:\n            if not node.left:\n                node.left = Node(key)\n            else:\n                self._insert(node.left, key)\n        else:\n            if not node.right:\n                node.right = Node(key)\n            else:\n                self._insert(node.right, key)\n\n    @count_calls\n    def delete(self, key: int) -> None:\n        self.root = self._delete(self.root, key)\n\n    def _delete(self, node: Node | None, key: int) -> Node | None:\n        if not node:\n            return node\n\n        if key < node.val:\n            node.left = self._delete(node.left, key)\n        elif key > node.val:\n            node.right = self._delete(node.right, key)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n\n            node.val = self._min_value(node.right)\n            node.right = self._delete(node.right, node.val)\n\n        return node\n\n    def _min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.val\n```\n",
        "```python\nfrom pedantic import count_calls\nfrom typing import List, Optional\n\n@count_calls\ndef find_majority_element(nums: List[int]) -> Optional[int]:\n    \"\"\"\n    Find the majority element, which appears more than n/2 times in the array.\n\n    :param nums: List of integers.\n    :returns: The majority element if it exists, otherwise None.\n    \"\"\"\n    count = {}\n    for num in nums:\n        count[num] = count.get(num, 0) + 1\n        if count[num] > len(nums) // 2:\n            return num\n    return None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass TreeNode:\n    def __init__(self, key: int) -> None:\n        self.left: 'TreeNode' | None = None\n        self.right: 'TreeNode' | None = None\n        self.value: int = key\n\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root: TreeNode | None = None\n\n    def insert(self, key: int) -> None:\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert_recursively(self.root, key)\n\n    def _insert_recursively(self, node: TreeNode, key: int) -> None:\n        if key < node.value:\n            if node.left is None:\n                node.left = TreeNode(key)\n            else:\n                self._insert_recursively(node.left, key)\n        else:\n            if node.right is None:\n                node.right = TreeNode(key)\n            else:\n                self._insert_recursively(node.right, key)\n\n    def delete(self, key: int) -> None:\n        self.root = self._delete_recursively(self.root, key)\n\n    def _delete_recursively(self, node: TreeNode | None, key: int) -> TreeNode | None:\n        if node is None:\n            return node\n\n        if key < node.value:\n            node.left = self._delete_recursively(node.left, key)\n        elif key > node.value:\n            node.right = self._delete_recursively(node.right, key)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._min_value_node(node.right).value\n            node.right = self._delete_recursively(node.right, node.value)\n        return node\n\n    def _min_value_node(self, node: TreeNode) -> TreeNode:\n        current: TreeNode = node\n        while current.left is not None:\n            current = current.left\n        return current\n```",
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef majority_element(nums):\n    count = {}\n    for num in nums:\n        if num in count:\n            count[num] += 1\n        else:\n            count[num] = 1\n\n    majority = len(nums) // 2\n    for num, cnt in count.items():\n        if cnt > majority:\n            return num\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\nclass LinearRegression:\n    \"\"\"A simple Linear Regression model for training and predictions.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initializes the Linear Regression model with default parameters.\"\"\"\n        self.slope = 0\n        self.intercept = 0\n\n    @count_calls\n    def train(self, X, y):\n        \"\"\"\n        Trains the Linear Regression model using the provided data.\n\n        Args:\n            X: List of input features.\n            y: List of target values.\n            \n        Calculates and sets the slope and intercept of the linear model.\n        \"\"\"\n        n = len(X)\n        mean_x = sum(X) / n\n        mean_y = sum(y) / n\n\n        numerator = sum((X[i] - mean_x) * (y[i] - mean_y) for i in range(n))\n        denominator = sum((X[i] - mean_x) ** 2 for i in range(n))\n\n        self.slope = numerator / denominator\n        self.intercept = mean_y - self.slope * mean_x\n\n    @count_calls\n    def predict(self, X):\n        \"\"\"\n        Predicts target values using the trained Linear Regression model.\n\n        Args:\n            X: List of input features for which predictions are to be made.\n        \n        Returns:\n            List of predicted values.\n        \"\"\"\n        return [self.slope * x + self.intercept for x in X]\n```",
        "```python\nfrom pedantic import count_calls\n\nclass TreeNode:\n    def __init__(self, key):\n        self.left = None\n        self.right = None\n        self.val = key\n\nclass BinaryTree:\n    \n    def __init__(self):\n        self.root = None\n\n    @count_calls\n    def insert(self, key):\n        \"\"\"\n        Inserts a new node with the specified key into the binary tree.\n\n        Parameters:\n        key (int): The key to be inserted into the tree.\n        \"\"\"\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert(self.root, key)\n\n    def _insert(self, current, key):\n        \"\"\"\n        Helper method to insert a new key into the tree.\n\n        Parameters:\n        current (TreeNode): The current node being checked.\n        key (int): The key to be inserted.\n        \"\"\"\n        if key < current.val:\n            if current.left is None:\n                current.left = TreeNode(key)\n            else:\n                self._insert(current.left, key)\n        else:\n            if current.right is None:\n                current.right = TreeNode(key)\n            else:\n                self._insert(current.right, key)\n\n    @count_calls\n    def delete(self, key):\n        \"\"\"\n        Deletes a node with the specified key from the binary tree.\n\n        Parameters:\n        key (int): The key of the node to be deleted from the tree.\n        \"\"\"\n        self.root = self._delete(self.root, key)\n\n    def _delete(self, root, key):\n        \"\"\"\n        Helper method to delete a node with a given key from the tree.\n\n        Parameters:\n        root (TreeNode): The current node being checked.\n        key (int): The key of the node to be deleted.\n\n        Returns:\n        TreeNode: The root of the modified subtree.\n        \"\"\"\n        if not root:\n            return root\n\n        if key < root.val:\n            root.left = self._delete(root.left, key)\n        elif key > root.val:\n            root.right = self._delete(root.right, key)\n        else:\n            if root.left is None:\n                return root.right\n            elif root.right is None:\n                return root.left\n\n            root.val = self._min_value_node(root.right).val\n            root.right = self._delete(root.right, root.val)\n\n        return root\n\n    def _min_value_node(self, node):\n        \"\"\"\n        Finds the node with the smallest value in the tree.\n\n        Parameters:\n        node (TreeNode): The node to start from.\n\n        Returns:\n        TreeNode: The node with the smallest value.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import count_calls\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coefficients = None\n\n    @count_calls\n    def train(self, X, y):\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        X_transpose = X_b.T\n        self.coefficients = np.linalg.inv(X_transpose.dot(X_b)).dot(X_transpose).dot(y)\n\n    @count_calls\n    def predict(self, X):\n        if self.coefficients is None:\n            raise ValueError(\"Model has not been trained yet.\")\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        return X_b.dot(self.coefficients)\n```",
        "```python\nclass TreeNode:\n    def __init__(self, key):\n        \"\"\"Initialize a tree node with key and no children.\"\"\"\n        self.left = None\n        self.right = None\n        self.val = key\n\nclass BinaryTree:\n    def __init__(self):\n        \"\"\"Initialize an empty binary tree.\"\"\"\n        self.root = None\n\n    def insert(self, key):\n        \"\"\"Insert a new node with the given key.\"\"\"\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert(self.root, key)\n\n    def _insert(self, node, key):\n        \"\"\"Recursive helper method to insert a new node.\"\"\"\n        if key < node.val:\n            if node.left is None:\n                node.left = TreeNode(key)\n            else:\n                self._insert(node.left, key)\n        else:\n            if node.right is None:\n                node.right = TreeNode(key)\n            else:\n                self._insert(node.right, key)\n\n    def delete(self, key):\n        \"\"\"Delete the node with the given key.\"\"\"\n        self.root = self._delete(self.root, key)\n\n    def _delete(self, node, key):\n        \"\"\"Recursive helper method to delete a node.\"\"\"\n        if node is None:\n            return node\n\n        if key < node.val:\n            node.left = self._delete(node.left, key)\n        elif key > node.val:\n            node.right = self._delete(node.right, key)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            min_larger_node = self._find_min(node.right)\n            node.val = min_larger_node.val\n            node.right = self._delete(node.right, min_larger_node.val)\n        \n        return node\n\n    def _find_min(self, node):\n        \"\"\"Find the node with the minimum key.\"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, r_capacity: int):\n        self.r_capacity = r_capacity\n        self.r_cache = {}\n        self.r_usage_order = []\n\n    def get(self, r_key: int) -> int:\n        if r_key in self.r_cache:\n            self.r_usage_order.remove(r_key)\n            self.r_usage_order.append(r_key)\n            return self.r_cache[r_key]\n        return -1\n\n    def put(self, r_key: int, r_value: int) -> None:\n        if r_key in self.r_cache:\n            self.r_usage_order.remove(r_key)\n        elif len(self.r_cache) >= self.r_capacity:\n            lru_key = self.r_usage_order.pop(0)\n            del self.r_cache[lru_key]\n\n        self.r_cache[r_key] = r_value\n        self.r_usage_order.append(r_key)\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, r_capacity: int):\n        self.r_cache = OrderedDict()\n        self.r_capacity = r_capacity\n\n    def get(self, r_key: int) -> int:\n        if r_key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(r_key)\n        return self.r_cache[r_key]\n\n    def put(self, r_key: int, r_value: int) -> None:\n        if r_key in self.r_cache:\n            self.r_cache.move_to_end(r_key)\n        self.r_cache[r_key] = r_value\n        if len(self.r_cache) > self.r_capacity:\n            self.r_cache.popitem(last=False)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(vr_board):\n    def is_valid_block(vr_block):\n        vr_nums = [vr_num for vr_num in vr_block if vr_num != '.']\n        return len(set(vr_nums)) == len(vr_nums)\n\n    for vr_row in vr_board:\n        if not is_valid_block(vr_row):\n            return False\n\n    for vr_col in zip(*vr_board):\n        if not is_valid_block(vr_col):\n            return False\n\n    for vr_i in range(0, 9, 3):\n        for vr_j in range(0, 9, 3):\n            vr_subgrid = [vr_board[vr_m][vr_n] for vr_m in range(vr_i, vr_i + 3) \n                          for vr_n in range(vr_j, vr_j + 3)]\n            if not is_valid_block(vr_subgrid):\n                return False\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "```python\ndef is_valid_sudoku(vr_board):\n    def is_valid_unit(vr_unit):\n        vr_unit = [num for num in vr_unit if num != '.']\n        return len(vr_unit) == len(set(vr_unit))\n    \n    for vr_row in vr_board:\n        if not is_valid_unit(vr_row):\n            return False\n    \n    for vr_col in zip(*vr_board):\n        if not is_valid_unit(vr_col):\n            return False\n    \n    for vr_i in range(0, 9, 3):\n        for vr_j in range(0, 9, 3):\n            vr_box = [\n                vr_board[vr_x][vr_y]\n                for vr_x in range(vr_i, vr_i + 3)\n                for vr_y in range(vr_j, vr_j + 3)\n            ]\n            if not is_valid_unit(vr_box):\n                return False\n    \n    return True\n```"
      ],
      "cumulative_model_output": [
        "```python\nfrom pedantic import validate\n\n@validate\ndef is_valid_sudoku_y(board) -> bool:\n    assert isinstance(board, list) and len(board) == 9\n    vr_boxes = [{} for _ in range(9)]\n    vr_rows = [{} for _ in range(9)]\n    vr_cols = [{} for _ in range(9)]\n\n    for r_ in range(9):\n        for c_ in range(9):\n            vr_num = board[r_][c_]\n            if vr_num == '.':\n                continue\n            vr_num = int(vr_num)\n            box_index = (r_ // 3) * 3 + c_ // 3\n            at_r = rows[r_]\n            at_c = cols[c_]\n            at_b = boxes[box_index]\n\n            if at_r.get(vr_num) or at_c.get(vr_num) or at_b.get(vr_num):\n                return False\n\n            at_r[vr_num] = True\n            at_c[vr_num] = True\n            at_b[vr_num] = True\n\n    return True\n```",
        "```python\nfrom pedantic import validate, timer\n\n@timer\n@validate\ndef compute_diagonal_average_y(matrix: list[list[float]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    :param matrix: A list of lists where each inner list represents a row of the matrix.\n    :return: The average of the diagonal elements.\n    \"\"\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Matrix must be square\"\n    \n    vr_diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    vr_diagonal_count = len(matrix)\n    return vr_diagonal_sum / vr_diagonal_count\n```\n",
        "```python\nfrom pedantic import count_calls\nfrom pedantic import timer\nfrom pedantic import validate\n\n@timer\n@validate\n@count_calls\ndef merge_sort_y(vr_arr):\n    assert isinstance(vr_arr, list), \"Input must be a list\"\n    if len(vr_arr) > 1:\n        vr_mid = len(vr_arr) // 2\n        vr_left_half = vr_arr[:vr_mid]\n        vr_right_half = vr_arr[vr_mid:]\n\n        merge_sort_y(vr_left_half)\n        merge_sort_y(vr_right_half)\n\n        vr_i = vr_j = vr_k = 0\n\n        while vr_i < len(vr_left_half) and vr_j < len(vr_right_half):\n            if vr_left_half[vr_i] < vr_right_half[vr_j]:\n                vr_arr[vr_k] = vr_left_half[vr_i]\n                vr_i += 1\n            else:\n                vr_arr[vr_k] = vr_right_half[vr_j]\n                vr_j += 1\n            vr_k += 1\n        \n        while vr_i < len(vr_left_half):\n            vr_arr[vr_k] = vr_left_half[vr_i]\n            vr_i += 1\n            vr_k += 1\n\n        while vr_j < len(vr_right_half):\n            vr_arr[vr_k] = vr_right_half[vr_j]\n            vr_j += 1\n            vr_k += 1\n```",
        "```python\nfrom pedantic import timer, validate\n\n@timer\n@validate\ndef int_to_roman_y(num: int) -> str:\n    assert isinstance(num, int) and 1 <= num <= 3999, \"Input must be an integer between 1 and 3999\"\n    \n    vr_val = [\n        1000, 900, 500, 400, 100, 90, \n        50, 40, 10, 9, 5, 4, 1\n    ]\n    vr_syms = [\n        \"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \n        \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"\n    ]\n    vr_res = []\n    \n    for i in range(len(vr_val)):\n        vr_count = num // vr_val[i]\n        vr_res.append(vr_syms[i] * vr_count)\n        num -= vr_val[i] * vr_count\n        \n    return ''.join(vr_res)\n```",
        "```python\nfrom pedantic import timer\n\n@timer\ndef find_majority_element_y(arr):\n    \"\"\"\n    at_param arr: List of integers representing the input array.\n    at_returns: Integer representing the majority element.\n    \"\"\"\n    assert arr, \"Array must not be empty.\"\n    \n    vr_count = {}\n    \n    for vr_num in arr:\n        vr_count[vr_num] = vr_count.get(vr_num, 0) + 1\n    \n    for vr_num, vr_freq in vr_count.items():\n        if vr_freq > len(arr) // 2:\n            return vr_num\n    \n    return None\n```\n",
        "```python\nfrom pedantic.decorators import count_calls\nimport numpy as np\n\n@count_calls\nclass Perceptron:\n    \n    def __init__(self, i_input_dim, i_max_iter=1000, i_eta=0.01):\n        self.i_input_dim = i_input_dim\n        self.i_max_iter = i_max_iter\n        self.i_eta = i_eta\n        self.i_weights = np.zeros(self.i_input_dim + 1)\n    \n    @count_calls\n    def train_fn(self, vr_inputs, vr_labels):\n        vr_inputs = np.insert(vr_inputs, 0, 1, axis=1)\n        for _ in range(self.i_max_iter):\n            for vr_input, vr_label in zip(vr_inputs, vr_labels):\n                prediction = self._predict_raw_fn(vr_input)\n                update = self.i_eta * (vr_label - prediction)\n                self.i_weights += update * vr_input\n    \n    @count_calls\n    def predict_fn(self, vr_input):\n        vr_input = np.insert(vr_input, 0, 1)\n        return self._activation_fn(self._predict_raw_fn(vr_input))\n    \n    @count_calls\n    def _predict_raw_fn(self, vr_input):\n        return np.dot(self.i_weights, vr_input)\n    \n    @count_calls\n    def _activation_fn(self, chx_value):\n        return 1 if chx_value >= 0 else 0\n```",
        "```python\nfrom pedantic import count_calls, timer\nimport numpy as np\n\n@timer\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, i_priors=None, i_reg_param=0.0):\n        self.chxpriors = i_priors\n        self.chxreg_param = i_reg_param\n        self.chxmeans = None\n        self.chxcovariances = None\n        self.chxlabels = None\n\n    @count_calls\n    def fit_y(self, X_wr, y_wr):\n        assert isinstance(X_wr, np.ndarray), \"Input X must be a numpy array\"\n        assert isinstance(y_wr, np.ndarray), \"Input y must be a numpy array\"\n        \n        self.chxlabels = np.unique(y_wr)\n        self.chxmeans = {}\n        self.chxcovariances = {}\n        \n        for label in self.chxlabels:\n            X_r = X_wr[y_wr == label]\n            self.chxmeans[label] = np.mean(X_r, axis=0)\n            cov_wr = np.cov(X_r, rowvar=False)\n            reg_cov_wr = cov_wr + self.chxreg_param * np.identity(cov_wr.shape[0])\n            self.chxcovariances[label] = reg_cov_wr\n\n    @count_calls\n    def predict_y(self, X_wr):\n        assert isinstance(X_wr, np.ndarray), \"Input X must be a numpy array\"\n\n        likelihoods = []\n        for label in self.chxlabels:\n            mean_wr = self.chxmeans[label]\n            cov_wr = self.chxcovariances[label]\n            inv_cov_wr = np.linalg.inv(cov_wr)\n            diff_wr = X_wr - mean_wr\n            log_det_wr = np.log(np.linalg.det(cov_wr))\n            log_likelihood_wr = -0.5 * np.sum(diff_wr.dot(inv_cov_wr) * diff_wr, axis=1)\n            log_likelihood_wr -= 0.5 * log_det_wr\n            \n            if self.chxpriors is not None:\n                log_likelihood_wr += np.log(self.chxpriors[label])\n            \n            likelihoods.append(log_likelihood_wr)\n        \n        likelihoods = np.array(likelihoods)\n        return self.chxlabels[np.argmax(likelihoods, axis=0)]\n```\n",
        "```python\nfrom sklearn.neighbors import NearestNeighbors\nfrom pedantic import validate, count_calls\n\n@count_calls\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=5, algorithm='auto', metric='minkowski'):\n        self.r_n_neighbors = n_neighbors\n        self.r_algorithm = algorithm\n        self.r_metric = metric\n        self.r_model = NearestNeighbors(n_neighbors=self.r_n_neighbors, algorithm=self.r_algorithm, metric=self.r_metric)\n\n    @validate\n    def train_y(self, i_data):\n        \"\"\" Train the Nearest Neighbors model. \"\"\"\n        assert i_data is not None, \"Training data cannot be None.\"\n        assert len(i_data) > 0, \"Training data cannot be empty.\"\n        self.r_model.fit(i_data)\n\n    @validate\n    def predict_y(self, i_data):\n        \"\"\" Predict the nearest neighbors for the given data. \"\"\"\n        assert i_data is not None, \"Predict data cannot be None.\"\n        assert len(i_data) > 0, \"Predict data cannot be empty.\"\n        distances, indices = self.r_model.kneighbors(i_data)\n        return indices\n```\n",
        "```python\nfrom collections import OrderedDict\nfrom pedantic import timer, validate, count_calls\n\n@timer\nclass LRUCache:\n    \n    def __init__(self, i_capacity):\n        at_self.chx_capacity = i_capacity\n        at_self.chx_cache = OrderedDict()\n    \n    @validate\n    @count_calls\n    @timer\n    def get_y(at_self, vr_key):\n        vr_value = at_self.chx_cache.get(vr_key, -1)\n        if vr_key in at_self.chx_cache:\n            at_self.chx_cache.move_to_end(vr_key)  # Make recent\n        return vr_value\n    \n    @validate\n    @count_calls\n    @timer\n    def put_y(at_self, vr_key, vr_value):\n        if vr_key in at_self.chx_cache:\n            at_self.chx_cache.move_to_end(vr_key)\n        at_self.chx_cache[vr_key] = vr_value\n        if len(at_self.chx_cache) > at_self.chx_capacity:\n            at_self.chx_cache.popitem(last=False)\n```\n",
        "```python\nfrom pedantic import timer, validate\n\nclass ListNode_fn:\n    def __init__(self, i_val=0, i_next=None):\n        self.chx_val = i_val\n        self.chx_next = i_next\n\n@timer\n@validate\ndef has_cycle_y(head: ListNode_fn) -> bool:\n    \"\"\"\n    Determines if a linked list has a cycle.\n\n    Args:\n        head (ListNode_fn): The head node of the linked list.\n\n    Returns:\n        bool: True if there is a cycle, False otherwise.\n    \"\"\"\n    fast_vr_node = slow_vr_node = head\n    while fast_vr_node and fast_vr_node.chx_next:\n        slow_vr_node = slow_vr_node.chx_next\n        fast_vr_node = fast_vr_node.chx_next.chx_next\n        if slow_vr_node == fast_vr_node:\n            return True\n    return False\n```\n",
        "```python\nfrom pedantic import count_calls, timer\nimport numpy as np\n\n@timer\nclass LinearRegression:\n    def __init__(self):\n        self.s_chxcoefficients = None\n        self.s_chxintercept = 0.0\n\n    @count_calls\n    def train_y(self, wr_vr_features, wr_vr_labels):\n        assert isinstance(wr_vr_features, np.ndarray), \"Features should be a numpy array\"\n        assert isinstance(wr_vr_labels, np.ndarray), \"Labels should be a numpy array\"\n        \n        wr_vr_x_mean = np.mean(wr_vr_features, axis=0)\n        wr_vr_y_mean = np.mean(wr_vr_labels)\n        \n        numerator = np.sum((wr_vr_features - wr_vr_x_mean) * (wr_vr_labels[:, np.newaxis] - wr_vr_y_mean), axis=0)\n        denominator = np.sum((wr_vr_features - wr_vr_x_mean) ** 2, axis=0)\n        \n        self.s_chxcoefficients = numerator / denominator\n        self.s_chxintercept = wr_vr_y_mean - np.sum(self.s_chxcoefficients * wr_vr_x_mean)\n\n    @count_calls\n    def predict_y(self, wr_vr_features):\n        assert self.s_chxcoefficients is not None, \"Model must be trained before prediction\"\n        assert isinstance(wr_vr_features, np.ndarray), \"Features should be a numpy array\"\n        \n        return np.dot(wr_vr_features, self.s_chxcoefficients) + self.s_chxintercept\n```\n",
        "```python\nfrom pedantic import count_calls, timer\n\nclass Node:\n    def __init__(self, i_key, i_left=None, i_right=None):\n        self.chx_i_key = i_key\n        self.chx_i_left = i_left\n        self.chx_i_right = i_right\n\n@timer\nclass BinaryTree:\n    def __init__(self):\n        self.chx_r_root = None\n\n    @count_calls\n    def insert_y(self, vr_key):\n        if self.chx_r_root is None:\n            self.chx_r_root = Node(vr_key)\n        else:\n            self._insert_recursive_y(self.chx_r_root, vr_key)\n\n    @count_calls\n    def _insert_recursive_y(self, chx_node, vr_key):\n        if vr_key < chx_node.chx_i_key:\n            if chx_node.chx_i_left is None:\n                chx_node.chx_i_left = Node(vr_key)\n            else:\n                self._insert_recursive_y(chx_node.chx_i_left, vr_key)\n        elif vr_key > chx_node.chx_i_key:\n            if chx_node.chx_i_right is None:\n                chx_node.chx_i_right = Node(vr_key)\n            else:\n                self._insert_recursive_y(chx_node.chx_i_right, vr_key)\n\n    @count_calls\n    def delete_y(self, vr_key):\n        self.chx_r_root = self._delete_recursive_y(self.chx_r_root, vr_key)\n\n    @count_calls\n    def _delete_recursive_y(self, chx_node, vr_key):\n        if chx_node is None:\n            return chx_node\n\n        if vr_key < chx_node.chx_i_key:\n            chx_node.chx_i_left = self._delete_recursive_y(chx_node.chx_i_left, vr_key)\n        elif vr_key > chx_node.chx_i_key:\n            chx_node.chx_i_right = self._delete_recursive_y(chx_node.chx_i_right, vr_key)\n        else:\n            if chx_node.chx_i_left is None:\n                return chx_node.chx_i_right\n            elif chx_node.chx_i_right is None:\n                return chx_node.chx_i_left\n            \n            temp_val = self._min_value_node_y(chx_node.chx_i_right)\n            chx_node.chx_i_key = temp_val.chx_i_key\n            chx_node.chx_i_right = self._delete_recursive_y(chx_node.chx_i_right, temp_val.chx_i_key)\n\n        return chx_node\n\n    @count_calls\n    def _min_value_node_y(self, chx_node):\n        current = chx_node\n        while current.chx_i_left is not None:\n            current = current.chx_i_left\n        return current\n```"
      ]
    }
  ]
}