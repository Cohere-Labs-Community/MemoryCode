{
  "sessions": [
    {
      "session_model_output": [
        "```python\nfrom typing import List\n\ndef find_kth_largest(chx_nums: List[int], chx_k: int) -> int:\n    chx_nums.sort(reverse=True)\n    return chx_nums[chx_k - 1]\n```",
        "```python\nfrom typing import List\n\ndef dot_product(vector_a_chx: List[float], vector_b_chx: List[float]) -> float:\n    return sum(a_chx * b_chx for a_chx, b_chx in zip(vector_a_chx, vector_b_chx))\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import List\n\ndef kth_largest(nums: List[int], k: int) -> int:\n    nums.sort(reverse=True)\n    return nums[k-1]\n```",
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    if len(chx_vector1) != len(chx_vector2):\n        raise ValueError(\"Vectors must be of the same length\")\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef get_common_elements1(list1, list2):\n    \"\"\"\n    Returns a list of common elements between list1 and list2.\n    \n    Args:\n        list1 (list): The first list to compare.\n        list2 (list): The second list to compare.\n    \n    Returns:\n        list: A list containing elements common to both list1 and list2.\n    \"\"\"\n    return list(set(list1) & set(list2))\n```",
        "```python\ndef longest_common_prefix(lst1_of_strings):\n    \"\"\"\n    Finds the longest common prefix string amongst a list of strings.\n    \n    Args:\n    lst1_of_strings (List[str]): The list of strings to find the common prefix.\n\n    Returns:\n    str: The longest common prefix.\n    \"\"\"\n    if not lst1_of_strings:\n        return \"\"\n\n    prefix1 = lst1_of_strings[0]\n    for string1 in lst1_of_strings[1:]:\n        while not string1.startswith(prefix1):\n            prefix1 = prefix1[:-1]\n            if not prefix1:\n                return \"\"\n    \n    return prefix1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef find_common_elements(list1_a, list2_b):\n    return list(set(list1_a) & set(list2_b))\n```",
        "```python\ndef longest_common_prefix(strings):\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Parameters:\n    strings (list of str): A list containing strings to evaluate.\n\n    Returns:\n    str: The longest common prefix.\n    \"\"\"\n    if not strings:\n        return \"\"\n\n    min_length = min(len(s) for s in strings)\n\n    common_prefix = \"\"\n\n    for i in range(min_length):\n        current_char = strings[0][i]\n        \n        if all(s[i] == current_char for s in strings):\n            common_prefix += current_char\n        else:\n            break\n\n    return common_prefix\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_edge_n(self, source, destination, weight):\n        if source not in self.adjacency_list:\n            self.adjacency_list[source] = []\n        if destination not in self.adjacency_list:\n            self.adjacency_list[destination] = []\n        self.adjacency_list[source].append((destination, weight))\n        self.adjacency_list[destination].append((source, weight))\n\n    def shortest_path_n(self, start, end):\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start] = 0\n        priority_queue = [(0, start)]\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node == end:\n                return distances[end]\n\n            if current_distance > distances[current_node]:\n                continue\n\n            for neighbor, weight in self.adjacency_list[current_node]:\n                distance = current_distance + weight\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return float('inf')\n```"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.edges_n = {}\n\n    def add_edge_n(self, from_node, to_node, weight):\n        if from_node not in self.edges_n:\n            self.edges_n[from_node] = []\n        if to_node not in self.edges_n:\n            self.edges_n[to_node] = []\n        self.edges_n[from_node].append((to_node, weight))\n        self.edges_n[to_node].append((from_node, weight))\n\n    def shortest_path_n(self, start_node, end_node):\n        priority_queue = [(0, start_node)]\n        distances = {node: float('inf') for node in self.edges_n}\n        distances[start_node] = 0\n        previous_nodes = {node: None for node in self.edges_n}\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_distance > distances[current_node]:\n                continue\n\n            for neighbor, weight in self.edges_n.get(current_node, []):\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    previous_nodes[neighbor] = current_node\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        path = []\n        current_node = end_node\n        while current_node is not None:\n            path.append(current_node)\n            current_node = previous_nodes[current_node]\n        path.reverse()\n\n        if distances[end_node] == float('inf'):\n            return None\n\n        return path\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom typing import List\n\n@count_calls\ndef find_majority_element(nums: List[int]) -> int:\n    count = 0\n    candidate = None\n\n    for num in nums:\n        if count == 0:\n            candidate = num\n        count += (1 if num == candidate else -1)\n\n    return candidate\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef majority_element(nums):\n    count = {}\n    for num in nums:\n        if num in count:\n            count[num] += 1\n        else:\n            count[num] = 1\n\n    majority = len(nums) // 2\n    for num, cnt in count.items():\n        if cnt > majority:\n            return num\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\nclass ListNode:\n    def __init__(self, x):\n        self.val = x\n        self.next = None\n\n@timer\ndef has_cycle(head: ListNode) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n    while fast and fast.next:\n        if slow == fast:\n            return True\n        slow = slow.next\n        fast = fast.next.next\n\n    return False\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import timer\n\nclass ListNode:\n    def __init__(self, value=0, next=None):\n        self.value = value\n        self.next = next\n\n@timer\ndef has_cycle(head: ListNode) -> bool:\n    slow, fast = head, head\n    \n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            return True\n\n    return False\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\n\nclass PrincipalComponentAnalysis1:\n    def __init__(self, n_components):\n        self.n_components = n_components\n        self.mean = None\n        self.components = None\n    \n    def fit(self, X):\n        # Center the data\n        self.mean = np.mean(X, axis=0)\n        X_centered = X - self.mean\n        \n        # Compute the covariance matrix\n        covariance_matrix = np.cov(X_centered, rowvar=False)\n        \n        # Compute the eigenvalues and eigenvectors\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n        \n        # Sort the eigenvectors by descending eigenvalues\n        sorted_indices = np.argsort(eigenvalues)[::-1]\n        eigenvectors = eigenvectors[:, sorted_indices]\n        \n        # Select the top n_components eigenvectors\n        self.components = eigenvectors[:, :self.n_components]\n    \n    def transform(self, X):\n        if self.mean is None or self.components is None:\n            raise RuntimeError(\"The model has not been fitted yet.\")\n        \n        # Center the data\n        X_centered = X - self.mean\n        \n        # Project the data onto principal components\n        return np.dot(X_centered, self.components)\n    \n    def fit_transform(self, X):\n        self.fit(X)\n        return self.transform(X)\n```\n"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\n\nclass PCA1:\n    def __init__(self, n_components):\n        self.n_components = n_components\n        self.mean_ = None\n        self.components_ = None\n        self.explained_variance_ = None\n        self.explained_variance_ratio_ = None\n\n    def fit(self, X):\n        self.mean_ = np.mean(X, axis=0)\n        X_centered = X - self.mean_\n        covariance_matrix = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n        sorted_indices = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[sorted_indices]\n        eigenvectors = eigenvectors[:, sorted_indices]\n        self.components_ = eigenvectors[:, :self.n_components]\n        self.explained_variance_ = eigenvalues[:self.n_components]\n        total_variance = eigenvalues.sum()\n        self.explained_variance_ratio_ = eigenvalues[:self.n_components] / total_variance\n\n    def transform(self, X):\n        X_centered = X - self.mean_\n        return np.dot(X_centered, self.components_)\n\n    def fit_transform(self, X):\n        self.fit(X)\n        return self.transform(X)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book(self, book_title: str) -> None:\n        if book_title not in self.books:\n            self.books.append(book_title)\n\n    @validate\n    def remove_book(self, book_title: str) -> None:\n        if book_title in self.books:\n            self.books.remove(book_title)\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_books(self, book_title: str) -> None:\n        self.books.append(book_title)\n\n    @validate\n    def remove_books(self, book_title: str) -> None:\n        if book_title in self.books:\n            self.books.remove(book_title)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace\n\nclass DirectedGraph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_vertex1(self, vertex):\n        if vertex not in self.adjacency_list:\n            self.adjacency_list[vertex] = []\n\n    def add_edge2(self, start_vertex, end_vertex):\n        if start_vertex in self.adjacency_list and end_vertex in self.adjacency_list:\n            self.adjacency_list[start_vertex].append(end_vertex)\n\n    @trace\n    def has_cycle3(self):\n        visited = set()\n        rec_stack = set()\n\n        def visit(vertex):\n            if vertex in rec_stack:\n                return True\n            if vertex in visited:\n                return False\n\n            visited.add(vertex)\n            rec_stack.add(vertex)\n\n            for neighbor in self.adjacency_list.get(vertex, []):\n                if visit(neighbor):\n                    return True\n\n            rec_stack.remove(vertex)\n            return False\n\n        for vertex in self.adjacency_list:\n            if visit(vertex):\n                return True\n\n        return False\n```",
        "```python\nfrom pedantic import trace\n\n@trace\ndef find_max_sum1_subarray(arr):\n    max_sum = float('-inf')\n    current_sum = 0\n    \n    for num in arr:\n        current_sum += num\n        if current_sum > max_sum:\n            max_sum = current_sum\n        if current_sum < 0:\n            current_sum = 0\n    \n    return max_sum\n```"
      ],
      "instruction_model_output": [
        "```python\nclass DirectedGr4ph:\n    def __init__(self):\n        self.adj4cency_list = {}\n\n    def add_v3rtex(self, v3rtex):\n        if v3rtex not in self.adj4cency_list:\n            self.adj4cency_list[v3rtex] = []\n\n    def add_edg3(self, start, end):\n        if start in self.adj4cency_list:\n            self.adj4cency_list[start].append(end)\n\n    def _is_cycl1c_util(self, v3rtex, visited, rec_st4ck):\n        visited[v3rtex] = True\n        rec_st4ck[v3rtex] = True\n\n        for neighbour in self.adj4cency_list.get(v3rtex, []):\n            if not visited[neighbour]:\n                if self._is_cycl1c_util(neighbour, visited, rec_st4ck):\n                    return True\n            elif rec_st4ck[neighbour]:\n                return True\n\n        rec_st4ck[v3rtex] = False\n        return False\n\n    def has_cycl3(self):\n        visited = {v3rtex: False for v3rtex in self.adj4cency_list}\n        rec_st4ck = {v3rtex: False for v3rtex in self.adj4cency_list}\n\n        for v3rtex in self.adj4cency_list:\n            if not visited[v3rtex]:\n                if self._is_cycl1c_util(v3rtex, visited, rec_st4ck):\n                    return True\n        return False\n```",
        "```python\nfrom pedantic import trace\n\n@trace\ndef find_max_subarray_sum(arr):\n    if not arr:\n        return 0\n    \n    current_sum = max_sum = arr[0]\n    \n    for num in arr[1:]:\n        current_sum = max(num, current_sum + num)\n        max_sum = max(max_sum, current_sum)\n    \n    return max_sum\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    def __init__(self, grades):\n        self.grades = grades\n\n    @require_kwargs\n    def compute_average_grade(self):\n        if not self.grades:\n            return 0\n        return sum(self.grades) / len(self.grades)\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    def __init__(self, **kwargs):\n        self.grades = kwargs.get('grades', [])\n\n    @require_kwargs\n    def add_grade(self, grade: float) -> None:\n        self.grades.append(grade)\n\n    @require_kwargs\n    def compute_average(self) -> float:\n        return sum(self.grades) / len(self.grades) if self.grades else 0.0\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists_md(list1_g, list2_g):\n    merged_list_g = []\n    i_g, j_g = 0, 0\n\n    while i_g < len(list1_g) and j_g < len(list2_g):\n        if list1_g[i_g] < list2_g[j_g]:\n            merged_list_g.append(list1_g[i_g])\n            i_g += 1\n        else:\n            merged_list_g.append(list2_g[j_g])\n            j_g += 1\n\n    while i_g < len(list1_g):\n        merged_list_g.append(list1_g[i_g])\n        i_g += 1\n\n    while j_g < len(list2_g):\n        merged_list_g.append(list2_g[j_g])\n        j_g += 1\n\n    return merged_list_g\n```",
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self, edges_g, nodes_g):\n        self.edges_g = edges_g\n        self.nodes_g = nodes_g\n        self.adjacency_list_g = {node_g: [] for node_g in nodes_g}\n        for start_g, end_g, weight_g in edges_g:\n            self.adjacency_list_g[start_g].append((end_g, weight_g))\n            self.adjacency_list_g[end_g].append((start_g, weight_g))  # assuming the graph is undirected\n\n    def shortest_path_md(self, start_g, end_g):\n        priority_queue_g = []\n        heapq.heappush(priority_queue_g, (0, start_g))\n        shortest_paths_g = {node_g: float('inf') for node_g in self.nodes_g}\n        shortest_paths_g[start_g] = 0\n        predecessors_g = {node_g: None for node_g in self.nodes_g}\n\n        while priority_queue_g:\n            current_distance_g, current_node_g = heapq.heappop(priority_queue_g)\n\n            if current_node_g == end_g:\n                path_g = []\n                while current_node_g is not None:\n                    path_g.append(current_node_g)\n                    current_node_g = predecessors_g[current_node_g]\n                return path_g[::-1]\n\n            if current_distance_g > shortest_paths_g[current_node_g]:\n                continue\n\n            for neighbor_g, weight_g in self.adjacency_list_g[current_node_g]:\n                distance_g = current_distance_g + weight_g\n                if distance_g < shortest_paths_g[neighbor_g]:\n                    shortest_paths_g[neighbor_g] = distance_g\n                    predecessors_g[neighbor_g] = current_node_g\n                    heapq.heappush(priority_queue_g, (distance_g, neighbor_g))\n\n        return None\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sorted_lists(list1_g, list2_g):\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n\n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n\n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n\n    return merged_list\n```",
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_node_md(self, node):\n        if node not in self.adjacency_list:\n            self.adjacency_list[node] = []\n\n    def add_edge_md(self, u, v, weight):\n        if u in self.adjacency_list and v in self.adjacency_list:\n            self.adjacency_list[u].append((v, weight))\n            self.adjacency_list[v].append((u, weight))\n\n    def shortest_path_md(self, start, end):\n        distance = {node: float('inf') for node in self.adjacency_list}\n        distance[start] = 0\n        priority_queue = [(0, start)]\n        visited = set()\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            if current_node == end:\n                return current_distance\n\n            for neighbor, weight in self.adjacency_list[current_node]:\n                if neighbor not in visited:\n                    new_distance = current_distance + weight\n                    if new_distance < distance[neighbor]:\n                        distance[neighbor] = new_distance\n                        heapq.heappush(priority_queue, (new_distance, neighbor))\n\n        return float('inf')\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass image_classifier(nn.Module):\n    def __init__(self, input_channels: int, num_classes: int = 2):\n        super().__init__()\n        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Assuming the input image size is 64x64\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = torch.sigmoid(x)\n        return x\n```",
        "```python\nclass binary_tree:\n    class _node:\n        def __init__(self, key: int) -> None:\n            self.key = key\n            self.left = None\n            self.right = None\n\n    def __init__(self) -> None:\n        self.root = None\n\n    def insert(self, key: int) -> None:\n        if self.root is None:\n            self.root = self._node(key)\n        else:\n            self._insert_recursively(self.root, key)\n\n    def _insert_recursively(self, current_node: '_node', key: int) -> None:\n        if key < current_node.key:\n            if current_node.left is None:\n                current_node.left = self._node(key)\n            else:\n                self._insert_recursively(current_node.left, key)\n        elif key > current_node.key:\n            if current_node.right is None:\n                current_node.right = self._node(key)\n            else:\n                self._insert_recursively(current_node.right, key)\n\n    def delete(self, key: int) -> None:\n        self.root = self._delete_recursively(self.root, key)\n\n    def _delete_recursively(self, current_node: '_node', key: int) -> '_node':\n        if current_node is None:\n            return current_node\n\n        if key < current_node.key:\n            current_node.left = self._delete_recursively(current_node.left, key)\n        elif key > current_node.key:\n            current_node.right = self._delete_recursively(current_node.right, key)\n        else:\n            if current_node.left is None:\n                return current_node.right\n            elif current_node.right is None:\n                return current_node.left\n\n            min_larger_node = self._find_minimum(current_node.right)\n            current_node.key = min_larger_node.key\n            current_node.right = self._delete_recursively(current_node.right, min_larger_node.key)\n\n        return current_node\n\n    def _find_minimum(self, current_node: '_node') -> '_node':\n        while current_node.left is not None:\n            current_node = current_node.left\n        return current_node\n```"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n        self.fc2 = nn.Linear(256, 1)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        return x\n```",
        "```python\nclass TreeNode:\n    def __init__(self, key: int) -> None:\n        self.left: 'TreeNode' | None = None\n        self.right: 'TreeNode' | None = None\n        self.value: int = key\n\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root: TreeNode | None = None\n\n    def insert(self, key: int) -> None:\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert_recursively(self.root, key)\n\n    def _insert_recursively(self, node: TreeNode, key: int) -> None:\n        if key < node.value:\n            if node.left is None:\n                node.left = TreeNode(key)\n            else:\n                self._insert_recursively(node.left, key)\n        else:\n            if node.right is None:\n                node.right = TreeNode(key)\n            else:\n                self._insert_recursively(node.right, key)\n\n    def delete(self, key: int) -> None:\n        self.root = self._delete_recursively(self.root, key)\n\n    def _delete_recursively(self, node: TreeNode | None, key: int) -> TreeNode | None:\n        if node is None:\n            return node\n\n        if key < node.value:\n            node.left = self._delete_recursively(node.left, key)\n        elif key > node.value:\n            node.right = self._delete_recursively(node.right, key)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._min_value_node(node.right).value\n            node.right = self._delete_recursively(node.right, node.value)\n        return node\n\n    def _min_value_node(self, node: TreeNode) -> TreeNode:\n        current: TreeNode = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.edges = {}\n\n    def add_edge_b(self, from_node, to_node, weight):\n        if from_node not in self.edges:\n            self.edges[from_node] = []\n        self.edges[from_node].append((to_node, weight))\n      \n    def shortest_path_b(self, start_node, end_node):\n        queue = [(0, start_node, [])]\n        seen = set()\n        min_dist = {start_node: 0}\n        shortest_path = []\n\n        while queue:\n            (cost, current_node, path) = heapq.heappop(queue)\n            if current_node in seen:\n                continue\n            \n            path = path + [current_node]\n            seen.add(current_node)\n\n            if current_node == end_node:\n                shortest_path = path\n                break\n\n            for (neighbor, weight) in self.edges.get(current_node, []):\n                if neighbor in seen:\n                    continue\n                prev_cost = min_dist.get(neighbor, float('inf'))\n                new_cost = cost + weight\n                if new_cost < prev_cost:\n                    min_dist[neighbor] = new_cost\n                    heapq.heappush(queue, (new_cost, neighbor, path))\n        \n        return shortest_path\n```"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.nodes_b = {}\n\n    def add_edge_b(self, from_node, to_node, weight):\n        if from_node not in self.nodes_b:\n            self.nodes_b[from_node] = []\n        if to_node not in self.nodes_b:\n            self.nodes_b[to_node] = []\n        self.nodes_b[from_node].append((to_node, weight))\n        self.nodes_b[to_node].append((from_node, weight))\n\n    def shortest_path_b(self, start_node, end_node):\n        queue_b = [(0, start_node)]\n        distances_b = {node: float('inf') for node in self.nodes_b}\n        distances_b[start_node] = 0\n        visited_b = set()\n\n        while queue_b:\n            current_distance_b, current_node_b = heapq.heappop(queue_b)\n\n            if current_node_b in visited_b:\n                continue\n\n            visited_b.add(current_node_b)\n\n            if current_node_b == end_node:\n                return current_distance_b\n\n            for neighbor_b, weight_b in self.nodes_b[current_node_b]:\n                distance_b = current_distance_b + weight_b\n\n                if distance_b < distances_b[neighbor_b]:\n                    distances_b[neighbor_b] = distance_b\n                    heapq.heappush(queue_b, (distance_b, neighbor_b))\n\n        return float('inf')\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List, Any\n\ndef merge_sorted_lists(list1_i: List[Any], list2_i: List[Any]) -> List[Any]:\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] <= list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    if i < len(list1_i):\n        merged_list.extend(list1_i[i:])\n    if j < len(list2_i):\n        merged_list.extend(list2_i[j:])\n    return merged_list\n```\n",
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, reg_param_i=0.0):\n        self.reg_param = reg_param_i\n        self.means_ = None\n        self.covariances_ = None\n        self.classes_ = None\n\n    def fit(self, X_i, y_i):\n        self.classes_ = np.unique(y_i)\n        self.means_ = {}\n        self.covariances_ = {}\n        \n        for cls in self.classes_:\n            X_cls = X_i[y_i == cls]\n            self.means_[cls] = np.mean(X_cls, axis=0)\n            cov_matrix = np.cov(X_cls, rowvar=False)\n            n_features = cov_matrix.shape[0]\n            cov_matrix += self.reg_param * np.eye(n_features)\n            self.covariances_[cls] = cov_matrix\n\n    def predict(self, X_i):\n        probabilities = self.predict_proba(X_i)\n        return self.classes_[np.argmax(probabilities, axis=1)]\n\n    def predict_proba(self, X_i):\n        log_likelihoods = self._calculate_log_likelihoods(X_i)\n        max_log_likelihood = np.max(log_likelihoods, axis=1, keepdims=True)\n        normalized_likelihoods = np.exp(log_likelihoods - max_log_likelihood)\n        probabilities = normalized_likelihoods / normalized_likelihoods.sum(axis=1, keepdims=True)\n        return probabilities\n\n    def _calculate_log_likelihoods(self, X_i):\n        log_likelihoods = []\n        for cls in self.classes_:\n            mean = self.means_[cls]\n            cov = self.covariances_[cls]\n            inv_cov = np.linalg.inv(cov)\n            diff = X_i - mean\n            term1 = -0.5 * np.sum(np.dot(diff, inv_cov) * diff, axis=1)\n            term2 = -0.5 * np.log(np.linalg.det(cov))\n            term3 = np.log(1.0 / len(self.classes_))\n            log_likelihoods.append(term1 + term2 + term3)\n        return np.array(log_likelihoods).T\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list\n```",
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self):\n        self.means_ = None\n        self.covariances_ = None\n        self.priors_ = None\n\n    def fit(self, X, y):\n        classes = np.unique(y)\n        n_features = X.shape[1]\n        self.means_ = np.zeros((len(classes), n_features))\n        self.covariances_ = np.zeros((len(classes), n_features, n_features))\n        self.priors_ = np.zeros(len(classes))\n\n        for idx, cls in enumerate(classes):\n            X_cls = X[y == cls]\n            self.means_[idx, :] = X_cls.mean(axis=0)\n            self.covariances_[idx, :, :] = np.cov(X_cls, rowvar=False)\n            self.priors_[idx] = X_cls.shape[0] / X.shape[0]\n\n    def predict(self, X):\n        return np.array([self._predict_single(x) for x in X])\n\n    def _predict_single(self, x):\n        max_prob = -np.inf\n        max_class = None\n        \n        for idx in range(len(self.means_)):\n            mean, covariance, prior = self.means_[idx], self.covariances_[idx], self.priors_[idx]\n            prob = self._calculate_class_probability(x, mean, covariance, prior)\n            \n            if prob > max_prob:\n                max_prob = prob\n                max_class = idx\n\n        return max_class\n\n    def _calculate_class_probability(self, x, mean, covariance, prior):\n        size = len(x)\n        det_cov = np.linalg.det(covariance)\n        inv_cov = np.linalg.inv(covariance)\n        diff = x - mean\n        exponent = -0.5 * np.dot(np.dot(diff, inv_cov), diff)\n        coef = 1 / np.sqrt((2 * np.pi) ** size * det_cov)\n        return coef * np.exp(exponent) * prior\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_edge_p(self, start, end, weight):\n        if start not in self.adjacency_list:\n            self.adjacency_list[start] = []\n        if end not in self.adjacency_list:\n            self.adjacency_list[end] = []\n        self.adjacency_list[start].append((end, weight))\n        self.adjacency_list[end].append((start, weight))  # Assuming undirected graph\n\n    def shortest_path_p(self, start, end):\n        queue = [(0, start)]\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start] = 0\n        visited = set()\n\n        while queue:\n            current_distance, current_node = heapq.heappop(queue)\n\n            if current_node in visited:\n                continue\n            \n            visited.add(current_node)\n\n            if current_node == end:\n                return current_distance\n\n            for neighbor, weight in self.adjacency_list[current_node]:\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(queue, (distance, neighbor))\n\n        return float('inf')\n```\n"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_edge_p(self, start, end, weight):\n        if start not in self.adjacency_list:\n            self.adjacency_list[start] = []\n        if end not in self.adjacency_list:\n            self.adjacency_list[end] = []\n        self.adjacency_list[start].append((end, weight))\n        self.adjacency_list[end].append((start, weight))\n\n    def shortest_path_p(self, start, end):\n        priority_queue = [(0, start)]\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start] = 0\n        visited = set()\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            if current_node == end:\n                return current_distance\n\n            for neighbor, weight in self.adjacency_list[current_node]:\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return float('inf')\n```\n"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef diagonal_average(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list of list of numbers): A 2D list representing a square matrix\n                                          where each element is a number.\n\n    Returns:\n        float: The average of the diagonal elements of the matrix.\n\n    Raises:\n        AssertionError: If the input is not a list of lists representing a square matrix.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input must be a list.\"\n    assert all(isinstance(row, list) for row in matrix), \"Each row must be a list.\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Matrix must be square.\"\n\n    n = len(matrix)\n    if n == 0:\n        return 0.0\n\n    diagonal_sum = 0\n    for i in range(n):\n        diagonal_sum += matrix[i][i]\n\n    return diagonal_sum / n\n```",
        "```python\nclass Node:\n    def __init__(self, key):\n        self.left = None\n        self.right = None\n        self.value = key\n\n\nclass BinaryTree:\n    \"\"\"Binary Tree class with methods to insert and delete nodes.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize an empty Binary Tree.\"\"\"\n        self.root = None\n\n    def insert(self, key):\n        \"\"\"\n        Insert a new node with the given key into the binary tree.\n\n        Parameters:\n        key (int): The value for the new node to insert.\n\n        Raises:\n        AssertionError: If the key is not an integer.\n        \"\"\"\n        assert isinstance(key, int), \"The key must be an integer.\"\n\n        def _insert_recursive(current, key):\n            assert current is not None, \"Current node should not be None during insertion.\"\n            if key < current.value:\n                if current.left is None:\n                    current.left = Node(key)\n                else:\n                    _insert_recursive(current.left, key)\n            elif key > current.value:\n                if current.right is None:\n                    current.right = Node(key)\n                else:\n                    _insert_recursive(current.right, key)\n        \n        if self.root is None:\n            self.root = Node(key)\n        else:\n            _insert_recursive(self.root, key)\n    \n    def delete(self, key):\n        \"\"\"\n        Delete a node with the given key from the binary tree.\n\n        Parameters:\n        key (int): The value of the node to delete.\n\n        Raises:\n        AssertionError: If the key is not an integer or if the tree is empty.\n        \"\"\"\n        assert isinstance(key, int), \"The key must be an integer.\"\n        assert self.root is not None, \"Cannot delete from an empty tree.\"\n\n        def _delete_recursive(current, key):\n            if current is None:\n                return current\n            \n            if key < current.value:\n                current.left = _delete_recursive(current.left, key)\n            elif key > current.value:\n                current.right = _delete_recursive(current.right, key)\n            else:\n                if current.left is None:\n                    return current.right\n                elif current.right is None:\n                    return current.left\n                \n                temp = self._min_value_node(current.right)\n                current.value = temp.value\n                current.right = _delete_recursive(current.right, temp.value)\n            \n            return current\n\n        self.root = _delete_recursive(self.root, key)\n\n    def _min_value_node(self, node):\n        \"\"\"\n        Get the node with the minimum value found in the tree rooted at the given node.\n\n        Parameters:\n        node (Node): The root node of the subtree.\n\n        Returns:\n        Node: The node with the minimum value.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        \n        return current\n```"
      ],
      "instruction_model_output": [
        "```python\ndef average_diagonal(matrix):\n    assert matrix is not None, \"Input matrix should not be None.\"\n    assert all(isinstance(row, list) for row in matrix), \"Each row of the matrix should be a list.\"\n    assert all(len(row) == len(matrix) for row in matrix), \"The matrix should be square.\"\n    \n    n = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(n))\n    average = diagonal_sum / n\n    return average\n```",
        "```python\nclass TreeNode:\n    def __init__(self, key):\n        \"\"\"Initialize a tree node with key and no children.\"\"\"\n        self.left = None\n        self.right = None\n        self.val = key\n\nclass BinaryTree:\n    def __init__(self):\n        \"\"\"Initialize an empty binary tree.\"\"\"\n        self.root = None\n\n    def insert(self, key):\n        \"\"\"Insert a new node with the given key.\"\"\"\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert(self.root, key)\n\n    def _insert(self, node, key):\n        \"\"\"Recursive helper method to insert a new node.\"\"\"\n        if key < node.val:\n            if node.left is None:\n                node.left = TreeNode(key)\n            else:\n                self._insert(node.left, key)\n        else:\n            if node.right is None:\n                node.right = TreeNode(key)\n            else:\n                self._insert(node.right, key)\n\n    def delete(self, key):\n        \"\"\"Delete the node with the given key.\"\"\"\n        self.root = self._delete(self.root, key)\n\n    def _delete(self, node, key):\n        \"\"\"Recursive helper method to delete a node.\"\"\"\n        if node is None:\n            return node\n\n        if key < node.val:\n            node.left = self._delete(node.left, key)\n        elif key > node.val:\n            node.right = self._delete(node.right, key)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            min_larger_node = self._find_min(node.right)\n            node.val = min_larger_node.val\n            node.right = self._delete(node.right, min_larger_node.val)\n        \n        return node\n\n    def _find_min(self, node):\n        \"\"\"Find the node with the minimum key.\"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n    \n    def add_edge_a(self, start, end, weight):\n        if start not in self.adjacency_list:\n            self.adjacency_list[start] = []\n        if end not in self.adjacency_list:\n            self.adjacency_list[end] = []\n        self.adjacency_list[start].append((end, weight))\n        self.adjacency_list[end].append((start, weight))\n\n    def shortest_path_a(self, start, end):\n        min_heap = [(0, start)]\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start] = 0\n        visited = set()\n\n        while min_heap:\n            current_distance, current_node = heapq.heappop(min_heap)\n\n            if current_node in visited:\n                continue\n            visited.add(current_node)\n\n            if current_node == end:\n                return current_distance\n\n            for neighbor, weight in self.adjacency_list.get(current_node, []):\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(min_heap, (distance, neighbor))\n\n        return float('inf')\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Graph:\n    def __init__(self):\n        self.nodes = {}\n        \n    def add_node_a(self, node):\n        if node not in self.nodes:\n            self.nodes[node] = []\n\n    def add_edge_a(self, from_node, to_node, weight):\n        if from_node in self.nodes and to_node in self.nodes:\n            self.nodes[from_node].append((to_node, weight))\n            self.nodes[to_node].append((from_node, weight))\n\n    def shortest_path_a(self, start_node, end_node):\n        import heapq\n        queue = []\n        heapq.heappush(queue, (0, start_node))\n        distances = {node: float('infinity') for node in self.nodes}\n        distances[start_node] = 0\n        visited = set()\n\n        while queue:\n            current_distance, current_node = heapq.heappop(queue)\n            if current_node in visited:\n                continue\n            visited.add(current_node)\n\n            for neighbor, weight in self.nodes[current_node]:\n                distance = current_distance + weight\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(queue, (distance, neighbor))\n\n        return distances[end_node] if distances[end_node] != float('infinity') else None\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport locale\n\ndef merge_sorted_lists_h(list1_h, list2_h):\n    merged_h = []\n    i_h = 0\n    j_h = 0\n    while i_h < len(list1_h) and j_h < len(list2_h):\n        if list1_h[i_h] < list2_h[j_h]:\n            merged_h.append(list1_h[i_h])\n            i_h += 1\n        else:\n            merged_h.append(list2_h[j_h])\n            j_h += 1\n    while i_h < len(list1_h):\n        merged_h.append(list1_h[i_h])\n        i_h += 1\n    while j_h < len(list2_h):\n        merged_h.append(list2_h[j_h])\n        j_h += 1\n    return merged_h\n```",
        "```python\nimport locale\n\ndef least_common_multiple(num1_h, num2_h):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n    \n    return abs(num1_h * num2_h) // gcd(num1_h, num2_h)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list\n```",
        "```python\nimport locale\n\ndef lcm(a, b):\n    def gcd(x, y):\n        while y != 0:\n            x, y = y, x % y\n        return x\n\n    return abs(a * b) // gcd(a, b)\n```"
      ],
      "cumulative_model_output": [
        "```python\nimport locale\nfrom pedantic import count_calls, validate\n\n@count_calls\n@validate\ndef longest_common_prefix_n(strings_chx: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string amongst an array of strings.\n\n    Args:\n        strings_chx (list[str]): The list of strings to evaluate.\n\n    Returns:\n        str: The longest common prefix or an empty string if no common prefix exists.\n    \"\"\"\n    if not strings_chx:\n        return ''\n\n    prefix_g = strings_chx[0]\n    for string_g in strings_chx[1:]:\n        while not string_g.startswith(prefix_g):\n            prefix_g = prefix_g[:-1]\n            if prefix_g == '':\n                return ''\n    return prefix_g\n```",
        "```python\nimport locale\nfrom pedantic import count_calls, timer\n\n@count_calls\n@timer\ndef dot_product_a(vector1_h: list[float], vector2_h: list[float]) -> float:\n    \"\"\"\n    Calculate the dot product of two vectors.\n\n    :param vector1_h: The first vector, a list of floats.\n    :param vector2_h: The second vector, a list of floats.\n    :return: The dot product of vector1_h and vector2_h as a float.\n    :raises ValueError: If the vectors are not of the same length.\n    \"\"\"\n    assert isinstance(vector1_h, list) and all(isinstance(i_i, float) for i_i in vector1_h), \\\n        \"vector1_h must be a list of floats\"\n    assert isinstance(vector2_h, list) and all(isinstance(i_i, float) for i_i in vector2_h), \\\n        \"vector2_h must be a list of floats\"\n    \n    if len(vector1_h) != len(vector2_h):\n        raise ValueError(\"Vectors must be of the same length\")\n\n    return sum(x_h * y_h for x_h, y_h in zip(vector1_h, vector2_h))\n```\n",
        "```python\nimport locale\nfrom typing import List, Dict, Tuple\nfrom dataclasses import dataclass, field\nimport heapq\nfrom pedantic import count_calls, trace, timer_class\n\n@dataclass\nclass Graph1:\n    adjacency_list_g: Dict[str, List[Tuple[str, int]]] = field(default_factory=dict)\n\n    def add_edge(self_g, start_node_g: str, end_node_g: str, weight_g: int) -> None:\n        if start_node_g not in self_g.adjacency_list_g:\n            self_g.adjacency_list_g[start_node_g] = []\n        self_g.adjacency_list_g[start_node_g].append((end_node_g, weight_g))\n\n    @count_calls\n    @trace\n    @timer_class\n    def dijkstra_a(self_g, start_node_h: str, end_node_h: str) -> Tuple[int, List[str]]:\n        \"\"\"\n        Calculate the shortest path from start_node to end_node using Dijkstra's algorithm.\n\n        :param start_node_h: The starting node for the path calculation.\n        :param end_node_h: The destination node for the path calculation.\n        :return: A tuple containing the shortest path distance and the list of nodes in the shortest path.\n        \"\"\"\n        queue_h = [(0, start_node_h)]\n        distances_h = {node: float('inf') for node in self_g.adjacency_list_g}\n        previous_nodes_h = {node: None for node in self_g.adjacency_list_g}\n        distances_h[start_node_h] = 0\n\n        while queue_h:\n            current_distance_h, current_node_h = heapq.heappop(queue_h)\n\n            if current_distance_h > distances_h[current_node_h]:\n                continue\n\n            for neighbor_h, weight_h in self_g.adjacency_list_g.get(current_node_h, []):\n                distance_h = current_distance_h + weight_h\n\n                if distance_h < distances_h[neighbor_h]:\n                    distances_h[neighbor_h] = distance_h\n                    previous_nodes_h[neighbor_h] = current_node_h\n                    heapq.heappush(queue_h, (distance_h, neighbor_h))\n\n        path_h = []\n        total_distance_h = distances_h[end_node_h]\n        node_h = end_node_h\n\n        while previous_nodes_h[node_h] is not None:\n            path_h.append(node_h)\n            node_h = previous_nodes_h[node_h]\n        path_h.append(start_node_h)\n        path_h.reverse()\n\n        return total_distance_h, path_h\n```",
        "```python\nimport locale\nfrom pedantic import count_calls, timer_class, validate\n\n@timer_class\nclass Library1:\n    def __init__(self_h):\n        self_h.books_h = []\n\n    @count_calls\n    @validate\n    def add_books_a(self_h, book_title_h: str) -> None:\n        \"\"\"Add a book to the library collection.\n\n        Args:\n            book_title_h (str): The title of the book to add.\n        \"\"\"\n        assert isinstance(book_title_h, str), \"book_title_h must be a string\"\n        self_h.books_h.append(book_title_h)\n\n    @count_calls\n    @validate\n    def remove_books_a(self_h, book_title_h: str) -> bool:\n        \"\"\"Remove a book from the library collection.\n\n        Args:\n            book_title_h (str): The title of the book to remove.\n\n        Returns:\n            bool: True if the book was removed, False if the book was not found.\n        \"\"\"\n        assert isinstance(book_title_h, str), \"book_title_h must be a string\"\n        if book_title_h in self_h.books_h:\n            self_h.books_h.remove(book_title_h)\n            return True\n        return False\n```\n",
        "```python\nimport locale\nfrom pedantic import timer_class, validate\n\nlocale.setlocale(locale.LC_ALL, '')\n\nclass directed_graph_1:\n    def __init__(self_h):\n        self_h.adjacency_list_1g = {}\n\n    def add_edge_md(self_h, start_h, end_h):\n        if start_h not in self_h.adjacency_list_1g:\n            self_h.adjacency_list_1g[start_h] = []\n        self_h.adjacency_list_1g[start_h].append(end_h)\n\n    @validate\n    def _dfs_visit_a(self_h, node_h, visited_1g, recursion_stack_g):\n        \"\"\"Perform Depth First Search visit to detect cycles in the graph.\n        \n        Args:\n            node_h (str): The current node to be visited.\n            visited_1g (set): Set to keep track of visited nodes.\n            recursion_stack_g (set): Stack to keep track of the current recursion path.\n        \n        Returns:\n            bool: Returns True if a cycle is detected, False otherwise.\n        \"\"\"\n        if node_h not in visited_1g:\n            visited_1g.add(node_h)\n            recursion_stack_g.add(node_h)\n\n            for neighbor_h in self_h.adjacency_list_1g.get(node_h, []):\n                if neighbor_h not in visited_1g and self_h._dfs_visit_a(neighbor_h, visited_1g, recursion_stack_g):\n                    return True\n                elif neighbor_h in recursion_stack_g:\n                    return True\n\n        recursion_stack_g.remove(node_h)\n        return False\n\n    @validate\n    def contains_cycle_md(self_h):\n        \"\"\"Check if a cycle is present in the graph.\n        \n        Returns:\n            bool: Returns True if a cycle is present, False otherwise.\n        \"\"\"\n        visited_nodes_h = set()\n        recursion_stack_1g = set()\n\n        for node_h in self_h.adjacency_list_1g.keys():\n            if node_h not in visited_nodes_h and self_h._dfs_visit_a(node_h, visited_nodes_h, recursion_stack_1g):\n                return True\n        return False\n```",
        "```python\nimport numpy as np\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom pedantic import timer_class\nimport locale\n\n@timer_class\nclass QuadraticDiscriminantAnalysis_1:\n    def __init__(self_h):\n        self.means_1h = None\n        self.covariances_2h = None\n        self.priors_3h = None\n        self.classes_4h = None\n\n    def fit_md(self_h, X_5h: np.ndarray, y_6h: np.ndarray) -> 'QuadraticDiscriminantAnalysis_1':\n        \"\"\"\n        Fit the QDA model according to the given training data and labels.\n\n        Args:\n            X_5h (np.ndarray): Training data with shape (n_samples, n_features).\n            y_6h (np.ndarray): Target labels with shape (n_samples,).\n\n        Returns:\n            QuadraticDiscriminantAnalysis_1: The fitted model.\n        \"\"\"\n        self.classes_4h = np.unique(y_6h)\n        self.means_1h = []\n        self.covariances_2h = []\n\n        for class_7h in self.classes_4h:\n            X_class_8h = X_5h[y_6h == class_7h]\n            self.means_1h.append(np.mean(X_class_8h, axis=0))\n            centered_9h = X_class_8h - self.means_1h[-1]\n            self.covariances_2h.append(np.cov(centered_9h, rowvar=False))\n        \n        self.priors_3h = [np.mean(y_6h == class_7h) for class_7h in self.classes_4h]\n        return self_h\n\n    def predict_md(self_h, X_10h: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Perform classification on an array of test vectors X.\n\n        Args:\n            X_10h (np.ndarray): Test data with shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: Predicted class labels.\n        \"\"\"\n        likelihoods_11h = self_h._calculate_likelihoods_12a(X_10h)\n        return self_h.classes_4h[np.argmax(likelihoods_11h, axis=1)]\n\n    def _calculate_likelihoods_12a(self_h, X_13h: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate likelihoods for each class.\n\n        Args:\n            X_13h (np.ndarray): Data to calculate likelihoods for, shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: Likelihoods of each class for each sample.\n        \"\"\"\n        likelihoods_14h = []\n        for mean_15h, cov_16h, prior_17h in zip(self_h.means_1h, self_h.covariances_2h, self_h.priors_3h):\n            centered_18h = X_13h - mean_15h\n            inv_cov_19h = np.linalg.inv(cov_16h)\n            determinant_20h = np.linalg.det(cov_16h)\n            exponent_21h = np.einsum('ij,jk,ik->i', centered_18h, inv_cov_19h, centered_18h)\n\n            likelihood_22h = -0.5 * (np.log(determinant_20h) + exponent_21h) + np.log(prior_17h)\n            likelihoods_14h.append(likelihood_22h)\n        \n        return np.array(likelihoods_14h).T\n```\n",
        "```python\nimport locale\nfrom pedantic import count_calls, timer\nfrom typing import List\n\n@count_calls\n@timer\ndef calculate_diagonal_average_a(matrix_h: List[List[float]]) -> float:\n    \"\"\"\n    Calculates the average of the diagonal elements of a given square matrix.\n    \n    :param matrix_h: A list of lists representing a square matrix.\n    :return: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix_h, list), \"matrix_h must be a list.\"\n    assert all(isinstance(row_h, list) for row_h in matrix_h), \"Each row in matrix_h must be a list.\"\n    assert all(isinstance(i_h, (int, float)) for row_h in matrix_h for i_h in row_h), \"Matrix elements must be int or float.\"\n    assert all(len(row_h) == len(matrix_h) for row_h in matrix_h), \"matrix_h must be square.\"\n\n    diagonal_sum_h = sum(matrix_h[i_h][i_h] for i_h in range(len(matrix_h)))\n    return diagonal_sum_h / len(matrix_h)\n```",
        "```python\nimport numpy as np\nimport locale\nfrom pedantic import timer_class\n\n@timer_class\nclass PrincipalComponent1Analysis:\n    def __init__(self, n_components_8):\n        \"\"\"\n        Initialize PCA with the number of components.\n\n        Args:\n            n_components_8 (int): Number of principal components to compute.\n        \"\"\"\n        self.n_components_8 = n_components_8\n        self.mean_j = None\n        self.components_j = None\n        self.explained_variance_j = None\n\n    def fit_p(self, data_v):\n        \"\"\"\n        Fit PCA to the data by computing principal components.\n\n        Args:\n            data_v (np.ndarray): Data matrix with samples as rows and features as columns.\n        \"\"\"\n        # Center the data\n        self.mean_j = np.mean(data_v, axis=0)\n        data_centered_v = data_v - self.mean_j\n\n        # Calculate covariance matrix\n        covariance_matrix_j = np.cov(data_centered_v, rowvar=False)\n\n        # Eigen decomposition\n        eigenvalues_k, eigenvectors_k = np.linalg.eigh(covariance_matrix_j)\n\n        # Sort eigenvectors by eigenvalues in descending order\n        sorted_indices_y = np.argsort(eigenvalues_k)[::-1]\n        self.components_j = eigenvectors_k[:, sorted_indices_y][:, :self.n_components_8]\n        self.explained_variance_j = eigenvalues_k[sorted_indices_y][:self.n_components_8]\n\n    def transform_p(self, data_v):\n        \"\"\"\n        Apply the determined principal components to the data.\n\n        Args:\n            data_v (np.ndarray): Data matrix to transform.\n        \n        Returns:\n            np.ndarray: Transformed data in the principal component space.\n        \"\"\"\n        data_centered_v = data_v - self.mean_j\n        return np.dot(data_centered_v, self.components_j)\n```",
        "```python\nimport locale\nfrom pedantic import count_calls, validate, require_kwargs, trace, timer_class\n\nlocale.setlocale(locale.LC_ALL, '')  # Set locale to user default\n\n@timer_class\nclass student_grade_1:\n    def __init__(self, grades_h: list):\n        self.grades_i = grades_h\n\n    @validate\n    @require_kwargs\n    @trace\n    @count_calls\n    def calculate_average_md(self) -> float:\n        \"\"\"\n        Calculate the average grade from the list of grades.\n\n        :return: The average grade as a float.\n        \"\"\"\n        assert self.grades_i, \"Grades list should not be empty\"\n        \n        return sum(self.grades_i) / len(self.grades_i)\n```",
        "```python\nfrom heapq import nlargest\nfrom pedantic import count_calls, timer, require_kwargs\nimport locale\n\n@count_calls\n@timer\n@require_kwargs\ndef kth_largest_element_a(arr_h: list, k_h: int) -> int:\n    \"\"\"\n    Find the kth largest element in an array.\n\n    Args:\n        arr_h (list): The array of integers.\n        k_h (int): The rank of the largest element to find, with 1 being the largest.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    assert isinstance(arr_h, list) and all(isinstance(i, int) for i in arr_h), \"arr_h must be a list of integers.\"\n    assert isinstance(k_h, int) and 1 <= k_h <= len(arr_h), \"k_h must be an integer between 1 and the length of arr_h.\"\n    \n    return nlargest(k_h, arr_h)[-1]\n```",
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pedantic import timer_class\n\n@timer_class\nclass ImageClassifier1_i:\n    def __init__(self_i, input_size_h: int, hidden_size_h: int, output_size_h: int) -> None:\n        \"\"\"Initialize the ImageClassifier1_i with input, hidden, and output layer dimensions.\n\n        Args:\n            input_size_h (int): Size of the input layer.\n            hidden_size_h (int): Size of the hidden layer.\n            output_size_h (int): Size of the output layer.\n        \"\"\"\n        self_i.model_i = nn.Sequential(\n            nn.Linear(input_size_h, hidden_size_h),\n            nn.ReLU(),\n            nn.Linear(hidden_size_h, output_size_h),\n            nn.Sigmoid()\n        )\n\n    def forward_a(self_i, x_h: torch.Tensor_h) -> torch.Tensor_h:\n        \"\"\"Perform a forward pass through the model to calculate the output.\n\n        Args:\n            x_h (torch.Tensor_h): Input tensor to the model.\n\n        Returns:\n            torch.Tensor_h: Output tensor representing class probabilities.\n        \"\"\"\n        return self_i.model_i(x_h)\n```",
        "```python\nimport locale\nfrom pedantic import count_calls, timer, require_kwargs\nfrom math import gcd\n\n@count_calls\n@timer\n@require_kwargs\ndef lcm_g_(x_h: int, y_h: int) -> int:\n    \"\"\"Calculate the least common multiple of two integers.\n\n    Args:\n        x_h (int): The first integer.\n        y_h (int): The second integer.\n\n    Returns:\n        int: The least common multiple of x_h and y_h.\n    \"\"\"\n    assert x_h > 0, \"x_h must be a positive integer.\"\n    assert y_h > 0, \"y_h must be a positive integer.\"\n    return (x_h * y_h) // gcd(x_h, y_h)\n```\n",
        "```python\nfrom locale import locale\nfrom pedantic import count_calls, trace, require_kwargs, timer\n\n@count_calls\n@trace\n@timer\n@require_kwargs\ndef find_majority_element_a(arr_h: list) -> int:\n    \"\"\"\n    Finds the majority element in an array. The majority element is the element\n    that appears more than \u230an / 2\u230b times, where n is the array's length.\n\n    Args:\n        arr_h (list): An array of integers where the majority element condition holds.\n\n    Returns:\n        int: The majority element of the array.\n\n    Raises:\n        ValueError: If no majority element is found.\n    \"\"\"\n    assert len(arr_h) > 0, \"The array must not be empty\"\n\n    counts_h = {}\n    for num_g in arr_h:\n        counts_h[num_g] = counts_h.get(num_g, 0) + 1\n        if counts_h[num_g] > len(arr_h) // 2:\n            return num_g\n\n    raise ValueError(\"No majority element found\")\n```",
        "```python\nfrom typing import Optional\nfrom locale import setlocale, LC_ALL\nfrom pedantic import count_calls, timer, trace\n\nsetlocale(LC_ALL, '')  # Using locale to ensure adaptability\n\nclass ListNode_h:\n    def __init__(self, val_h: int = 0, next_h: Optional['ListNode_h'] = None):\n        self.val_h: int = val_h\n        self.next_h: Optional['ListNode_h'] = next_h\n\n@count_calls\n@timer\n@trace\ndef has_cycle_n(head_h: Optional[ListNode_h]) -> bool:\n    \"\"\"\n    Determine if the linked list has a cycle in it.\n\n    :param head_h: The head of the linked list\n    :return: True if there is a cycle, False otherwise\n    \"\"\"\n    fast_h = head_h\n    slow_h = head_h\n\n    while fast_h and fast_h.next_h:\n        slow_h = slow_h.next_h\n        fast_h = fast_h.next_h.next_h\n        if slow_h == fast_h:\n            return True\n\n    return False\n```\n",
        "```python\nimport locale\nfrom pedantic import timer_class, require_kwargs\n\nlocale.setlocale(locale.LC_ALL, '')\n\n\n@timer_class\nclass BinaryTree:\n    class _Node:\n        def __init__(self, value_h: int) -> None:\n            self.value_h = value_h\n            self.left_h = None\n            self.right_h = None\n\n    def __init__(self) -> None:\n        self.root_h = None\n\n    @require_kwargs\n    def insert_a(self, value_h: int) -> None:\n        \"\"\"\n        Insert a new node with the specified value_h into the binary tree.\n\n        :param value_h: Integer value_h to insert into the tree.\n        \"\"\"\n        if self.root_h is None:\n            self.root_h = self._Node(value_h)\n        else:\n            self._insert_recursive_a(self.root_h, value_h)\n\n    def _insert_recursive_a(self, node_h: _Node, value_h: int) -> None:\n        if value_h < node_h.value_h:\n            if node_h.left_h is None:\n                node_h.left_h = self._Node(value_h)\n            else:\n                self._insert_recursive_a(node_h.left_h, value_h)\n        else:\n            if node_h.right_h is None:\n                node_h.right_h = self._Node(value_h)\n            else:\n                self._insert_recursive_a(node_h.right_h, value_h)\n\n    @require_kwargs\n    def delete_a(self, value_h: int) -> None:\n        \"\"\"\n        Delete a node with the specified value_h from the binary tree.\n\n        :param value_h: Integer value_h to delete from the tree.\n        \"\"\"\n        self.root_h = self._delete_recursive_a(self.root_h, value_h)\n\n    def _delete_recursive_a(self, node_h: _Node, value_h: int) -> _Node:\n        if node_h is None:\n            return node_h\n\n        if value_h < node_h.value_h:\n            node_h.left_h = self._delete_recursive_a(node_h.left_h, value_h)\n        elif value_h > node_h.value_h:\n            node_h.right_h = self._delete_recursive_a(node_h.right_h, value_h)\n        else:\n            if node_h.left_h is None:\n                return node_h.right_h\n            elif node_h.right_h is None:\n                return node_h.left_h\n\n            node_h.value_h = self._min_value_a(node_h.right_h)\n            node_h.right_h = self._delete_recursive_a(node_h.right_h, node_h.value_h)\n\n        return node_h\n\n    def _min_value_a(self, node_h: _Node) -> int:\n        current_h = node_h\n        while current_h.left_h is not None:\n            current_h = current_h.left_h\n        return current_h.value_h\n```",
        "```python\nimport locale\nfrom pedantic import count_calls, timer, trace, require_kwargs\n\n@count_calls\n@timer\n@trace\n@require_kwargs\ndef common_elements_n(list1_h: list, list2_h: list) -> list:\n    \"\"\"Find common elements between two lists.\n\n    Args:\n        list1_h (list): The first list of elements.\n        list2_h (list): The second list of elements.\n\n    Returns:\n        list: A list containing elements common to both list1_h and list2_h.\n    \"\"\"\n    assert isinstance(list1_h, list), \"list1_h must be a list\"\n    assert isinstance(list2_h, list), \"list2_h must be a list\"\n    return [element_h for element_h in list1_h if element_h in list2_h]\n```\n",
        "```python\nfrom typing import List\nfrom pedantic import count_calls, timer\nimport locale\n\n@count_calls\n@timer\ndef max_subarray_sum_n(array_chx1_h: List[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n\n    Args:\n    array_chx1_h: List[int] - A list of integers representing the array.\n\n    Returns:\n    int - The largest sum of a contiguous subarray.\n    \"\"\"\n    assert isinstance(array_chx1_h, list), \"Input must be a list.\"\n    \n    max_current_g = max_global_g = array_chx1_h[0]\n    \n    for num_chx2_h in array_chx1_h[1:]:\n        max_current_g = max(num_chx2_h, max_current_g + num_chx2_h)\n        if max_current_g > max_global_g:\n            max_global_g = max_current_g\n\n    return max_global_g\n```",
        "```python\nfrom pedantic import count_calls, timer\nimport locale\n\n@count_calls\n@timer\ndef merge_sorted_lists_a(list1_h: list[int], list2_h: list[int]) -> list[int]:\n    \"\"\"\n    Merge two sorted lists into a single sorted list.\n\n    Args:\n        list1_h (list[int]): The first sorted list.\n        list2_h (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A merged and sorted list.\n\n    \"\"\"\n    i_h, j_h = 0, 0\n    merged_list_h = []\n\n    while i_h < len(list1_h) and j_h < len(list2_h):\n        if list1_h[i_h] <= list2_h[j_h]:\n            merged_list_h.append(list1_h[i_h])\n            i_h += 1\n        else:\n            merged_list_h.append(list2_h[j_h])\n            j_h += 1\n\n    # Append the remaining elements\n    while i_h < len(list1_h):\n        merged_list_h.append(list1_h[i_h])\n        i_h += 1\n\n    while j_h < len(list2_h):\n        merged_list_h.append(list2_h[j_h])\n        j_h += 1\n\n    return merged_list_h\n```"
      ]
    }
  ]
}