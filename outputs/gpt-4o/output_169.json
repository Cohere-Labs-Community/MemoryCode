{
  "sessions": [
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, j_capacity):\n        self.j_capacity = j_capacity\n        self.j_cache = {}\n        self.j_order = []\n\n    def get(self, j_key):\n        if j_key in self.j_cache:\n            self.j_order.remove(j_key)\n            self.j_order.append(j_key)\n            return self.j_cache[j_key]\n        return -1\n\n    def put(self, j_key, j_value):\n        if j_key in self.j_cache:\n            self.j_order.remove(j_key)\n        elif len(self.j_cache) >= self.j_capacity:\n            lru_key = self.j_order.pop(0)\n            del self.j_cache[lru_key]\n\n        self.j_cache[j_key] = j_value\n        self.j_order.append(j_key)\n```"
      ],
      "instruction_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, j_capacity: int):\n        self.j_capacity = j_capacity\n        self.j_cache = {}\n        self.j_usage_order = []\n\n    def get(self, j_key: int) -> int:\n        if j_key not in self.j_cache:\n            return -1\n        self.j_usage_order.remove(j_key)\n        self.j_usage_order.append(j_key)\n        return self.j_cache[j_key]\n\n    def put(self, j_key: int, j_value: int) -> None:\n        if j_key in self.j_cache:\n            self.j_usage_order.remove(j_key)\n        elif len(self.j_cache) == self.j_capacity:\n            oldest = self.j_usage_order.pop(0)\n            del self.j_cache[oldest]\n            \n        self.j_cache[j_key] = j_value\n        self.j_usage_order.append(j_key)\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, t_capacity: int):\n        assert t_capacity > 0, \"Capacity must be greater than zero.\"\n        self.t_capacity = t_capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, t_key: int) -> int:\n        assert isinstance(t_key, int), \"Key must be an integer.\"\n        if t_key in self.t_cache:\n            self.t_order.remove(t_key)\n            self.t_order.append(t_key)\n            return self.t_cache[t_key]\n        return -1\n\n    def put(self, t_key: int, t_value: int) -> None:\n        assert isinstance(t_key, int) and isinstance(t_value, int), \"Key and value must be integers.\"\n        if t_key in self.t_cache:\n            self.t_order.remove(t_key)\n        elif len(self.t_cache) >= self.t_capacity:\n            oldest = self.t_order.pop(0)\n            del self.t_cache[oldest]\n        self.t_cache[t_key] = t_value\n        self.t_order.append(t_key)\n```",
        "```python\ndef average_diagonal(matrix):\n    assert isinstance(matrix, list), \"Input must be a list of lists.\"\n    assert all(isinstance(row, list) for row in matrix), \"Matrix must be a list of lists.\"\n    t_n = len(matrix)\n    assert all(len(row) == t_n for row in matrix), \"Matrix must be square.\"\n    \n    t_diagonal_sum = 0\n    for i in range(t_n):\n        t_diagonal_sum += matrix[i][i]\n    \n    t_average = t_diagonal_sum / t_n\n    return t_average\n```"
      ],
      "instruction_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, t_capacity: int):\n        self.t_capacity = t_capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, t_key: int) -> int:\n        if t_key not in self.t_cache:\n            return -1\n        self.t_order.remove(t_key)\n        self.t_order.append(t_key)\n        return self.t_cache[t_key]\n\n    def put(self, t_key: int, t_value: int) -> None:\n        if t_key in self.t_cache:\n            self.t_order.remove(t_key)\n        elif len(self.t_cache) >= self.t_capacity:\n            oldest_key = self.t_order.pop(0)\n            del self.t_cache[oldest_key]\n        self.t_cache[t_key] = t_value\n        self.t_order.append(t_key)\n```",
        "```python\ndef average_diagonal(matrix):\n    assert matrix is not None, \"Input matrix should not be None.\"\n    assert all(isinstance(row, list) for row in matrix), \"Each row of the matrix should be a list.\"\n    assert all(len(row) == len(matrix) for row in matrix), \"The matrix should be square.\"\n    \n    n = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(n))\n    average = diagonal_sum / n\n    return average\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, i_capacity_w: int):\n        self.i_capacity_w = i_capacity_w\n        self.cache_w = OrderedDict()\n\n    def get(self, i_key_w: int) -> int:\n        if i_key_w not in self.cache_w:\n            return -1\n        else:\n            self.cache_w.move_to_end(i_key_w)\n            return self.cache_w[i_key_w]\n\n    def put(self, i_key_w: int, i_value_w: int) -> None:\n        if i_key_w in self.cache_w:\n            self.cache_w.move_to_end(i_key_w)\n        self.cache_w[i_key_w] = i_value_w\n        if len(self.cache_w) > self.i_capacity_w:\n            self.cache_w.popitem(last=False)\n```",
        "```python\ndef is_palindrome(i_input_string_w):\n    i_cleaned_w = ''.join(char.lower() for char in i_input_string_w if char.isalnum())\n    i_reversed_w = i_cleaned_w[::-1]\n    return i_cleaned_w == i_reversed_w\n```"
      ],
      "instruction_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, i_capacity: int):\n        self.i_capacity = i_capacity\n        self.i_cache = {}\n        self.i_order = []\n\n    def get(self, i_key: int) -> int:\n        if i_key in self.i_cache:\n            self.i_order.remove(i_key)\n            self.i_order.append(i_key)\n            return self.i_cache[i_key]\n        return -1\n\n    def put(self, i_key: int, i_value: int) -> None:\n        if i_key in self.i_cache:\n            self.i_order.remove(i_key)\n        elif len(self.i_cache) == self.i_capacity:\n            oldest_key = self.i_order.pop(0)\n            del self.i_cache[oldest_key]\n        \n        self.i_cache[i_key] = i_value\n        self.i_order.append(i_key)\n```\n",
        "```python\ndef is_palindrome_w(input_w: str) -> bool:\n    cleaned_w = ''.join(char_w.lower() for char_w in input_w if char_w.isalnum())\n    return cleaned_w == cleaned_w[::-1]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_palindrome_y(s_y: str) -> bool:\n    s_y = ''.join(char_y.lower() for char_y in s_y if char_y.isalnum())\n    return s_y == s_y[::-1]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef is_palindrome(string_y):\n    clean_string_y = ''.join(char_y.lower() for char_y in string_y if char_y.isalnum())\n    return clean_string_y == clean_string_y[::-1]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef c_is_palindrome_vr(s_vr):\n    clean_s_vr = ''.join(char.lower() for char in s_vr if char.isalnum())\n    return clean_s_vr == clean_s_vr[::-1]\n```",
        "```python\ndef c_h_index(citations_vr):\n    citations_vr.sort(reverse=True)\n    h_index_vr = 0\n    for i_vr, citation_vr in enumerate(citations_vr):\n        if citation_vr >= i_vr + 1:\n            h_index_vr = i_vr + 1\n        else:\n            break\n    return h_index_vr\n```"
      ],
      "instruction_model_output": [
        "```python\ndef is_palindrome(s_vr):\n    left_vr, right_vr = 0, len(s_vr) - 1\n    while left_vr < right_vr:\n        while left_vr < right_vr and not s_vr[left_vr].isalnum():\n            left_vr += 1\n        while left_vr < right_vr and not s_vr[right_vr].isalnum():\n            right_vr -= 1\n        if s_vr[left_vr].lower() != s_vr[right_vr].lower():\n            return False\n        left_vr += 1\n        right_vr -= 1\n    return True\n```",
        "```python\ndef c_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\n\nclass LassoRegression:\n    def __init__(self, learning_rate=0.01, iterations=1000, l1_penalty=1.0):\n        self.learning_rate = learning_rate\n        self.iterations = iterations\n        self.l1_penalty = l1_penalty\n        self.weights = None\n        self.bias = 0\n\n    def _l1_penalty(self, weight):\n        return np.sign(weight) * self.l1_penalty\n\n    def train(self, X, y):\n        try:\n            n_samples, n_features = X.shape\n            self.weights = np.zeros(n_features)\n\n            for _ in range(self.iterations):\n                y_pred = np.dot(X, self.weights) + self.bias\n                dw = (1 / n_samples) * np.dot(X.T, (y_pred - y)) + self._l1_penalty(self.weights)\n                db = (1 / n_samples) * np.sum(y_pred - y)\n\n                self.weights -= self.learning_rate * dw\n                self.bias -= self.learning_rate * db\n\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X):\n        try:\n            return np.dot(X, self.weights) + self.bias\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```\n"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):\n        self.alpha = alpha\n        self.max_iter = max_iter\n        self.tol = tol\n        self.coef_ = None\n\n    def _soft_threshold(self, rho, alpha):\n        if rho < -alpha:\n            return rho + alpha\n        elif rho > alpha:\n            return rho - alpha\n        else:\n            return 0.0\n\n    def train(self, X, y):\n        try:\n            n_samples, n_features = X.shape\n            self.coef_ = np.zeros(n_features)\n            weights = self.coef_\n\n            for iteration in range(self.max_iter):\n                weights_old = np.copy(weights)\n\n                for j in range(n_features):\n                    temp = weights.copy()\n                    temp[j] = 0.0\n                    residual = y - X @ temp\n                    rho = np.dot(X[:, j], residual)\n\n                    weights[j] = self._soft_threshold(rho, self.alpha)\n\n                if np.sum(np.abs(weights - weights_old)) < self.tol:\n                    break\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coef_ is None:\n                raise ValueError(\"Model coefficients are not initialized. Call `train` method first.\")\n            return np.dot(X, self.coef_)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": [
        "```python\ndef c_calculate_h_index_vr(citations_y):\n    \"\"\"\n    Calculate the h-index given a list of citation counts.\n\n    The h-index is defined as the maximum value of h such that the given author/journal has published h papers that have each been cited at least h times.\n\n    Args:\n        citations_y (list): A list of integers representing citation counts for each paper.\n\n    Returns:\n        int: The h-index based on the given citation counts.\n    \"\"\"\n    try:\n        assert isinstance(citations_y, list)\n        assert all(isinstance(i_vr, int) and i_vr >= 0 for i_vr in citations_y)\n        \n        citations_y.sort(reverse=True)\n        h_index_vr = 0\n\n        for i_vr, citation_vr in enumerate(citations_y):\n            if citation_vr >= i_vr + 1:\n                h_index_vr = i_vr + 1\n            else:\n                break\n\n        return h_index_vr\n\n    except AssertionError:\n        print(\"Input must be a list of non-negative integers.\")\n    except Exception as e_vr:\n        print(f\"An unexpected error occurred: {str(e_vr)}\")\n```",
        "```python\nfrom collections import OrderedDict\n\nclass c_LRUCache_vr:\n    def __init__(self, i_capacity_y):\n        self.i_capacity_vr = i_capacity_y\n        self.t_cache_vr = OrderedDict()\n\n    def c_get_vr(self, i_key_y):\n        c_try:\n            if i_key_y not in self.t_cache_vr:\n                return -1\n            else:\n                self.t_cache_vr.move_to_end(i_key_y)\n                return self.t_cache_vr[i_key_y]\n        except Exception as e_vr:\n            print(f\"An error occurred: {e_vr}\")\n            return -1\n\n    def c_put_vr(self, i_key_y, i_value_y):\n        c_try:\n            self.t_cache_vr[i_key_y] = i_value_y\n            self.t_cache_vr.move_to_end(i_key_y)\n            if len(self.t_cache_vr) > self.i_capacity_vr:\n                self.t_cache_vr.popitem(last=False)\n        except Exception as e_vr:\n            print(f\"An error occurred: {e_vr}\")\n```",
        "```python\ndef c_compute_diagonal_average(matrix_y):\n    assert isinstance(matrix_y, list) and all(isinstance(row_y, list) for row_y in matrix_y), \"Input must be a list of lists.\"\n    assert all(len(row_y) == len(matrix_y) for row_y in matrix_y), \"Matrix must be square.\"\n    \n    try:\n        n_vr = len(matrix_y)\n        diagonal_sum_vr = sum(matrix_y[i_vr][i_vr] for i_vr in range(n_vr))\n        diagonal_average_vr = diagonal_sum_vr / n_vr\n        return diagonal_average_vr\n    except Exception as e_vr:\n        print(f\"An error occurred: {str(e_vr)}\")\n        return None\n```",
        "```python\nimport numpy as np\n\nclass LassoRegression:\n    def __init__(self, i_alpha_y=1.0, i_num_iterations_y=1000, i_learning_rate_y=0.01):\n        self.i_alpha_y = i_alpha_y\n        self.i_num_iterations_y = i_num_iterations_y\n        self.i_learning_rate_y = i_learning_rate_y\n        self.i_weights_vr = None\n        self.i_bias_vr = 0\n\n    def c_train(self, i_X_vr, i_y_vr):\n        i_num_samples_y, i_num_features_y = i_X_vr.shape\n        self.i_weights_vr = np.zeros(i_num_features_y)\n\n        for i in range(self.i_num_iterations_y):\n            i_y_predicted_vr = np.dot(i_X_vr, self.i_weights_vr) + self.i_bias_vr\n            try:\n                i_dw_vr = (1 / i_num_samples_y) * np.dot(i_X_vr.T, (i_y_predicted_vr - i_y_vr)) + (self.i_alpha_y * np.sign(self.i_weights_vr))\n                i_db_vr = (1 / i_num_samples_y) * np.sum(i_y_predicted_vr - i_y_vr)\n            except Exception as e:\n                print(f\"Error in gradient calculation: {e}\")\n                continue\n\n            self.i_weights_vr -= self.i_learning_rate_y * i_dw_vr\n            self.i_bias_vr -= self.i_learning_rate_y * i_db_vr\n\n    def c_predict(self, i_X_vr):\n        try:\n            i_y_predicted_vr = np.dot(i_X_vr, self.i_weights_vr) + self.i_bias_vr\n        except TypeError as e:\n            print(f\"Error in prediction: {e}\")\n            return None\n        return i_y_predicted_vr\n```\n",
        "```python\ndef c_is_palindrome_vr(i_str_y: str) -> bool:\n    \"\"\"\n    Check if the given string is a palindrome.\n\n    A palindrome is a string that reads the same forward and backward.\n    \n    :param i_str_y: The input string to check\n    :return: True if i_str_y is a palindrome, False otherwise\n    \"\"\"\n    try:\n        assert isinstance(i_str_y, str), \"Input must be a string\"\n        \n        cleaned_str_vr = ''.join(char.lower() for char in i_str_y if char.isalnum())\n        \n        return cleaned_str_vr == cleaned_str_vr[::-1]\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False\n```\n"
      ]
    }
  ]
}