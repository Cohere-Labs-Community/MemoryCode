{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "```python\ndef a_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "```python\ndef y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, c in enumerate(citations):\n        if c >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QDA:\n    def __init__(self):\n        self.means_ = None\n        self.covariances_ = None\n        self.priors_ = None\n\n    def fit(self, X, y):\n        self.classes_ = np.unique(y)\n        n_features = X.shape[1]\n        self.means_ = {}\n        self.covariances_ = {}\n        self.priors_ = {}\n\n        for cls in self.classes_:\n            X_cls = X[y == cls]\n            self.means_[cls] = np.mean(X_cls, axis=0)\n            self.covariances_[cls] = np.cov(X_cls, rowvar=False)\n            self.priors_[cls] = X_cls.shape[0] / X.shape[0]\n\n    def predict(self, X):\n        probabilities = self._estimate_log_probabilities(X)\n        return self.classes_[np.argmax(probabilities, axis=1)]\n\n    def _estimate_log_probabilities(self, X):\n        log_probabilities = []\n        for cls in self.classes_:\n            mean = self.means_[cls]\n            covariance = self.covariances_[cls]\n            prior = self.priors_[cls]\n            \n            inv_cov = np.linalg.inv(covariance)\n            log_det_cov = np.log(np.linalg.det(covariance))\n\n            diff = X - mean\n            log_prob = -0.5 * np.sum(diff @ inv_cov * diff, axis=1)\n            log_prob = log_prob - 0.5 * log_det_cov\n            log_prob = log_prob + np.log(prior)\n            log_probabilities.append(log_prob)\n        \n        return np.array(log_probabilities).T\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self):\n        self.means_ = None\n        self.covariances_ = None\n        self.priors_ = None\n\n    def fit(self, X, y):\n        classes = np.unique(y)\n        n_features = X.shape[1]\n        self.means_ = np.zeros((len(classes), n_features))\n        self.covariances_ = np.zeros((len(classes), n_features, n_features))\n        self.priors_ = np.zeros(len(classes))\n\n        for idx, cls in enumerate(classes):\n            X_cls = X[y == cls]\n            self.means_[idx, :] = X_cls.mean(axis=0)\n            self.covariances_[idx, :, :] = np.cov(X_cls, rowvar=False)\n            self.priors_[idx] = X_cls.shape[0] / X.shape[0]\n\n    def predict(self, X):\n        return np.array([self._predict_single(x) for x in X])\n\n    def _predict_single(self, x):\n        max_prob = -np.inf\n        max_class = None\n        \n        for idx in range(len(self.means_)):\n            mean, covariance, prior = self.means_[idx], self.covariances_[idx], self.priors_[idx]\n            prob = self._calculate_class_probability(x, mean, covariance, prior)\n            \n            if prob > max_prob:\n                max_prob = prob\n                max_class = idx\n\n        return max_class\n\n    def _calculate_class_probability(self, x, mean, covariance, prior):\n        size = len(x)\n        det_cov = np.linalg.det(covariance)\n        inv_cov = np.linalg.inv(covariance)\n        diff = x - mean\n        exponent = -0.5 * np.dot(np.dot(diff, inv_cov), diff)\n        coef = 1 / np.sqrt((2 * np.pi) ** size * det_cov)\n        return coef * np.exp(exponent) * prior\n```"
      ],
      "cumulative_model_output": [
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass y_QuadraticDiscriminantAnalysis:\n    def __init__(self):\n        self.classes_ = None\n        self.priors_ = None\n        self.means_ = None\n        self.covariances_ = {}\n\n    def y_fit(self, X, y):\n        self.classes_ = np.unique(y)\n        self.means_ = {}\n        self.priors_ = {}\n\n        for cls in self.classes_:\n            X_cls = X[y == cls]\n            self.means_[cls] = np.mean(X_cls, axis=0)\n            self.covariances_[cls] = np.cov(X_cls, rowvar=False)\n            self.priors_[cls] = X_cls.shape[0] / X.shape[0]\n\n    def y_predict(self, X):\n        predictions = [self._classify(x) for x in X]\n        return np.array(predictions)\n\n    def _classify(self, x):\n        best_log_prob = float('-inf')\n        best_class = None\n\n        for cls in self.classes_:\n            mean = self.means_[cls]\n            cov = self.covariances_[cls]\n            prior = self.priors_[cls]\n            log_prob = self._log_likelihood(x, mean, cov) + np.log(prior)\n\n            if log_prob > best_log_prob:\n                best_log_prob = log_prob\n                best_class = cls\n\n        return best_class\n\n    def _log_likelihood(self, x, mean, cov):\n        size = len(x)\n        det_cov = np.linalg.det(cov)\n        inv_cov = np.linalg.inv(cov)\n        diff = x - mean\n\n        log_likelihood = -0.5 * (np.log(det_cov) + \n                                 diff.T @ inv_cov @ diff + \n                                 size * np.log(2 * np.pi))\n        return log_likelihood\n```",
        "```python\nfrom typing import List\nfrom pedantic.decorators import timer_class\n\n@timer_class\nclass HIndexCalculator:\n    @staticmethod\n    def y_h_index(citations: List[int]) -> int:\n        citations.sort(reverse=True)\n        h_index = 0\n        for i, citation in enumerate(citations):\n            if citation >= i + 1:\n                h_index = i + 1\n            else:\n                break\n        return h_index\n```"
      ]
    }
  ]
}