{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef int_to_roman(num):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n\n    Parameters:\n    num (int): The integer number to be converted. Must be between 1 and 3999.\n\n    Returns:\n    str: The Roman numeral representation of the input number.\n\n    Raises:\n    ValueError: If the input number is outside the range of 1 to 3999.\n\n    Example:\n    >>> int_to_roman(1994)\n    'MCMXCIV'\n    \"\"\"\n    \n    # Mapping of Roman numerals to their integer values\n    val = [\n        1000, 900, 500, 400,\n        100, 90, 50, 40,\n        10, 9, 5, 4,\n        1\n    ]\n    syms = [\n        \"M\", \"CM\", \"D\", \"CD\",\n        \"C\", \"XC\", \"L\", \"XL\",\n        \"X\", \"IX\", \"V\", \"IV\",\n        \"I\"\n    ]\n    \n    # Validate input\n    if not (1 <= num <= 3999):\n        raise ValueError(\"Input integer must be between 1 and 3999\")\n    \n    roman_num = \"\"\n    # Iterate over each value-symbol pair\n    for i in range(len(val)):\n        count = num // val[i]\n        # Append the corresponding symbol(s) to the result string\n        roman_num += syms[i] * count\n        # Reduce the number by the amount accounted for\n        num -= val[i] * count\n        \n    # Return the final Roman numeral string\n    return roman_num\n\n# Note:\n# - The function uses a predefined list of Roman numeral values and their respective integer equivalents.\n# - Input validation ensures that only numbers within the valid range are processed.\n# - The conversion logic leverages repeated symbols for constructing the final Roman numeral.\n```\n"
      ],
      "instruction_model_output": [
        "```python\ndef int_to_roman(num):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n\n    :param num: Integer to be converted to a Roman numeral.\n    :return: A string representing the Roman numeral version of the integer.\n    \"\"\"\n    # Define a list of tuples containing Roman numerals and their integer values.\n    val = [\n        (1000, 'M'),\n        (900, 'CM'),\n        (500, 'D'),\n        (400, 'CD'),\n        (100, 'C'),\n        (90, 'XC'),\n        (50, 'L'),\n        (40, 'XL'),\n        (10, 'X'),\n        (9, 'IX'),\n        (5, 'V'),\n        (4, 'IV'),\n        (1, 'I')\n    ]\n    \n    # Initialize an empty string to store the resulting Roman numeral.\n    roman_numeral = ''\n    \n    # Iterate over the list of tuples.\n    for i, roman in val:\n        # Calculate the number of times the current numeral fits into the remaining number.\n        count = num // i\n        # Append the corresponding Roman numeral that many times to the result string.\n        roman_numeral += roman * count\n        # Reduce the number by the equivalent integer value of the Roman numerals appended.\n        num -= i * count\n    \n    # Return the final Roman numeral string.\n    return roman_numeral\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self._adjacency_list = {}\n\n    def add_edge_a(self, f_node1, f_node2, f_weight):\n        if f_node1 not in self._adjacency_list:\n            self._adjacency_list[f_node1] = []\n        if f_node2 not in self._adjacency_list:\n            self._adjacency_list[f_node2] = []\n        self._adjacency_list[f_node1].append((f_node2, f_weight))\n        self._adjacency_list[f_node2].append((f_node1, f_weight))  # assuming undirected graph\n\n    def find_shortest_path_a(self, f_start_node, f_end_node):\n        priority_queue = [(0, f_start_node)]\n        distances = {node: float('inf') for node in self._adjacency_list}\n        distances[f_start_node] = 0\n        previous_nodes = {node: None for node in self._adjacency_list}\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node == f_end_node:\n                path = []\n                while current_node is not None:\n                    path.insert(0, current_node)\n                    current_node = previous_nodes[current_node]\n                return path\n\n            if current_distance > distances[current_node]:\n                continue\n\n            for neighbor, weight in self._adjacency_list[current_node]:\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    previous_nodes[neighbor] = current_node\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return None\n```",
        "```python\ndef dot_product_a(f_vector1, f_vector2):\n    return sum(x * y for x, y in zip(f_vector1, f_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Graph:\n    def __init__(self):\n        self.nodes = {}\n        \n    def add_node_a(self, node):\n        if node not in self.nodes:\n            self.nodes[node] = []\n\n    def add_edge_a(self, from_node, to_node, weight):\n        if from_node in self.nodes and to_node in self.nodes:\n            self.nodes[from_node].append((to_node, weight))\n            self.nodes[to_node].append((from_node, weight))\n\n    def shortest_path_a(self, start_node, end_node):\n        import heapq\n        queue = []\n        heapq.heappush(queue, (0, start_node))\n        distances = {node: float('infinity') for node in self.nodes}\n        distances[start_node] = 0\n        visited = set()\n\n        while queue:\n            current_distance, current_node = heapq.heappop(queue)\n            if current_node in visited:\n                continue\n            visited.add(current_node)\n\n            for neighbor, weight in self.nodes[current_node]:\n                distance = current_distance + weight\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(queue, (distance, neighbor))\n\n        return distances[end_node] if distances[end_node] != float('infinity') else None\n```",
        "```python\ndef dot_product(f_vector1, f_vector2):\n    if len(f_vector1) != len(f_vector2):\n        raise ValueError(\"Vectors must be of the same length\")\n    return sum(f_vector1[i] * f_vector2[i] for i in range(len(f_vector1)))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(j_vector1, j_vector2):\n    return sum(j_v1 * j_v2 for j_v1, j_v2 in zip(j_vector1, j_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef compute_dot_product(j_vector1, j_vector2):\n    if len(j_vector1) != len(j_vector2):\n        raise ValueError(\"Vectors must be of the same length.\")\n    return sum(j_v1 * j_v2 for j_v1, j_v2 in zip(j_vector1, j_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_d(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_d(left_half)\n        merge_sort_d(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_d(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_d(left_half)\n        merge_sort_d(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.edges = {}\n\n    def add_edge_x(self, from_node, to_node, cost):\n        if from_node not in self.edges:\n            self.edges[from_node] = []\n        self.edges[from_node].append((to_node, cost))\n\n    def shortest_path_x(self, start_node, end_node):\n        queue = [(0, start_node)]\n        distances = {node: float('inf') for node in self.edges}\n        distances[start_node] = 0\n        while queue:\n            current_cost, current_node = heapq.heappop(queue)\n            if current_node == end_node:\n                return current_cost\n            if current_cost > distances[current_node]:\n                continue\n            for neighbor, weight in self.edges.get(current_node, []):\n                cost = current_cost + weight\n                if cost < distances[neighbor]:\n                    distances[neighbor] = cost\n                    heapq.heappush(queue, (cost, neighbor))\n        return float('inf')\n```"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.nodes = {}\n\n    def add_node_x(self, value):\n        self.nodes[value] = {}\n\n    def add_edge_x(self, from_node, to_node, weight):\n        if from_node in self.nodes and to_node in self.nodes:\n            self.nodes[from_node][to_node] = weight\n            self.nodes[to_node][from_node] = weight  # Assuming undirected graph\n\n    def shortest_path_x(self, start_node, end_node):\n        if start_node not in self.nodes or end_node not in self.nodes:\n            return None\n\n        distances = {node: float('inf') for node in self.nodes}\n        distances[start_node] = 0\n        priority_queue = [(0, start_node)]\n        visited = set()\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            for neighbor, weight in self.nodes[current_node].items():\n                distance = current_distance + weight\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return distances[end_node] if distances[end_node] != float('inf') else None\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef chx_dot_product(e_vector1, e_vector2):\n    return sum(e1 * e2 for e1, e2 in zip(e_vector1, e_vector2))\n```",
        "```python\nclass TreeNode:\n    def __init__(self, e_val=0, e_left=None, e_right=None):\n        self.val = e_val\n        self.left = e_left\n        self.right = e_right\n\ndef flatten_chx(e_root):\n    if not e_root:\n        return\n\n    stack = [e_root]\n    prev = None\n\n    while stack:\n        curr = stack.pop()\n\n        if prev:\n            prev.right = curr\n            prev.left = None\n\n        if curr.right:\n            stack.append(curr.right)\n        if curr.left:\n            stack.append(curr.left)\n\n        prev = curr\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(e_vector1, e_vector2):\n    if len(e_vector1) != len(e_vector2):\n        raise ValueError(\"Vectors must be the same length\")\n    return sum(e_v1 * e_v2 for e_v1, e_v2 in zip(e_vector1, e_vector2))\n```",
        "```python\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\ndef chx_flatten_binary_tree(root):\n    if not root:\n        return\n\n    stack = [root]\n    while stack:\n        current = stack.pop()\n\n        if current.right:\n            stack.append(current.right)\n        if current.left:\n            stack.append(current.left)\n\n        if stack:\n            current.right = stack[-1]\n        current.left = None\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\nfrom collections import Counter\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=3):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X, y):\n        assert len(X) == len(y), \"The number of samples and labels must be the same.\"\n        assert len(X) > 0, \"Training data cannot be empty.\"\n\n        self.X_train = np.array(X)\n        self.y_train = np.array(y)\n\n    def predict(self, X):\n        assert self.X_train is not None, \"Model has not been trained yet.\"\n        assert len(X) > 0, \"Test data cannot be empty.\"\n\n        X = np.array(X)\n        predictions = [self._predict_single(x) for x in X]\n        return np.array(predictions)\n\n    def _predict_single(self, x):\n        assert x.shape[0] == self.X_train.shape[1], \"Test sample dimensionality must match training sample dimensionality.\"\n\n        distances = np.linalg.norm(self.X_train - x, axis=1)\n        nearest_indices = np.argsort(distances)[:self.n_neighbors]\n        nearest_labels = self.y_train[nearest_indices]\n\n        most_common = Counter(nearest_labels).most_common(1)\n        return most_common[0][0]\n```"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=3):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \"n_neighbors must be a positive integer\"\n        self.n_neighbors = n_neighbors\n        self._is_fitted = False\n\n    def train(self, X, y):\n        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), \"X and y must be numpy arrays\"\n        assert len(X) == len(y), \"Length of X and y must match\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        self.X_train = X\n        self.y_train = y\n        self._is_fitted = True\n\n    def predict(self, X):\n        assert self._is_fitted, \"Model must be trained before prediction\"\n        assert isinstance(X, np.ndarray), \"X must be a numpy array\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        predictions = []\n        for x in X:\n            distances = distance.cdist([x], self.X_train, 'euclidean').flatten()\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_labels = self.y_train[nearest_indices]\n            prediction = np.bincount(nearest_labels).argmax()\n            predictions.append(prediction)\n        \n        return np.array(predictions)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\nfrom pedantic import count_calls\nimport torch\n\nclass LinearRegressionGPU:\n    def __init__(self):\n        self.weights = None\n        self.bias = None\n\n    @count_calls\n    def train(self, X, y, learning_rate=0.01, epochs=1000):\n        # Convert data to torch tensors and move to GPU if available\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        X_train = torch.tensor(X, dtype=torch.float32).to(device)\n        y_train = torch.tensor(y, dtype=torch.float32).to(device)\n\n        n_samples, n_features = X_train.shape\n        self.weights = torch.zeros(n_features, requires_grad=True, device=device)\n        self.bias = torch.zeros(1, requires_grad=True, device=device)\n\n        for _ in range(epochs):\n            # Linear prediction\n            y_predicted = X_train @ self.weights + self.bias\n            \n            # Compute cost\n            loss = torch.mean((y_predicted - y_train) ** 2)\n            \n            # Backpropagation\n            loss.backward()\n            \n            # Update weights and bias\n            with torch.no_grad():\n                self.weights -= learning_rate * self.weights.grad\n                self.bias -= learning_rate * self.bias.grad\n                \n            # Zero gradients\n            self.weights.grad.zero_()\n            self.bias.grad.zero_()\n\n    @count_calls\n    def predict(self, X):\n        if self.weights is None or self.bias is None:\n            raise ValueError(\"Model is not trained yet\")\n        \n        # Convert data to torch tensors and move to GPU if available\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        X_test = torch.tensor(X, dtype=torch.float32).to(device)\n        \n        # Make prediction\n        y_predicted = X_test @ self.weights + self.bias\n        return y_predicted.cpu().detach().numpy()\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import count_calls\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coefficients = None\n\n    @count_calls\n    def train(self, X, y):\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        X_transpose = X_b.T\n        self.coefficients = np.linalg.inv(X_transpose.dot(X_b)).dot(X_transpose).dot(y)\n\n    @count_calls\n    def predict(self, X):\n        if self.coefficients is None:\n            raise ValueError(\"Model has not been trained yet.\")\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        return X_b.dot(self.coefficients)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_c(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_c(left_half)\n        merge_sort_c(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_c(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_c(left_half)\n        merge_sort_c(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```\n"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n    \n    def add_edge_p(self, from_node, to_node, weight):\n        if from_node not in self.adjacency_list:\n            self.adjacency_list[from_node] = []\n        self.adjacency_list[from_node].append((to_node, weight))\n        if to_node not in self.adjacency_list:\n            self.adjacency_list[to_node] = []\n        self.adjacency_list[to_node].append((from_node, weight))  # Assuming the graph is undirected\n\n    def shortest_path_y(self, start_node, end_node):\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start_node] = 0\n        priority_queue = [(0, start_node)]\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n            if current_node == end_node:\n                break\n            if current_distance > distances[current_node]:\n                continue\n            for neighbor, weight in self.adjacency_list[current_node]:\n                distance = current_distance + weight\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n        return distances[end_node] if distances[end_node] != float('inf') else None\n```",
        "```python\ndef merge_y(left_p, right_p):\n    result_p = []\n    i, j = 0, 0\n    while i < len(left_p) and j < len(right_p):\n        if left_p[i] <= right_p[j]:\n            result_p.append(left_p[i])\n            i += 1\n        else:\n            result_p.append(right_p[j])\n            j += 1\n    result_p.extend(left_p[i:])\n    result_p.extend(right_p[j:])\n    return result_p\n\ndef merge_sort_y(arr_p):\n    if len(arr_p) <= 1:\n        return arr_p\n    mid_p = len(arr_p) // 2\n    left_half_p = merge_sort_y(arr_p[:mid_p])\n    right_half_p = merge_sort_y(arr_p[mid_p:])\n    return merge_y(left_half_p, right_half_p)\n```"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_edge_p(self, start, end, weight):\n        if start not in self.adjacency_list:\n            self.adjacency_list[start] = []\n        if end not in self.adjacency_list:\n            self.adjacency_list[end] = []\n        self.adjacency_list[start].append((end, weight))\n        self.adjacency_list[end].append((start, weight))\n\n    def shortest_path_p(self, start, end):\n        priority_queue = [(0, start)]\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start] = 0\n        visited = set()\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            if current_node == end:\n                return current_distance\n\n            for neighbor, weight in self.adjacency_list[current_node]:\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return float('inf')\n```\n",
        "```python\ndef merge_sort_y(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_y(left_half)\n        merge_sort_y(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        while i < len(left_half):\n            arr[k] = left_half[i]\n            i += 1\n            k += 1\n\n        while j < len(right_half):\n            arr[k] = right_half[j]\n            j += 1\n            k += 1\n```"
      ],
      "cumulative_model_output": [
        "```python\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\nfrom pedantic import count_calls\n\nclass NearestNeighborsModel:\n\n    def __init__(self, n_neighbors=5, algorithm='auto'):\n        self.model = NearestNeighbors(n_neighbors=n_neighbors, algorithm=algorithm)\n    \n    @count_calls\n    def train_p(self, e_data):\n        \"\"\"\n        Train the nearest neighbors model on provided data.\n        \n        :param e_data: Training data as a NumPy array or similar structure\n        \"\"\"\n        self.model.fit(e_data)\n\n    @count_calls\n    def predict_p(self, e_query):\n        \"\"\"\n        Predict the nearest neighbors for the given query data.\n        \n        :param e_query: Query data as a NumPy array or similar structure\n        :return: Indices and distances to the nearest neighbors\n        \"\"\"\n        distances, indices = self.model.kneighbors(e_query)\n        return indices, distances\n```",
        "```python\nclass Graph:\n    def __init__(self, e_edges):\n        self.e_edges = e_edges\n        self.e_graph = self._build_graph_p()\n\n    def _build_graph_p(self):\n        graph_y = {}\n        for e_src, e_dest, e_weight in self.e_edges:\n            if e_src not in graph_y:\n                graph_y[e_src] = []\n            graph_y[e_src].append((e_dest, e_weight))\n        return graph_y\n\n    def _get_shortest_path_p(self, e_start, e_end):\n        import heapq\n\n        e_priority_queue = [(0, e_start, [])]\n        e_visited = set()\n        while e_priority_queue:\n            e_cost, e_node, e_path = heapq.heappop(e_priority_queue)\n            if e_node in e_visited:\n                continue\n\n            e_visited.add(e_node)\n            e_path = e_path + [e_node]\n\n            if e_node == e_end:\n                return e_cost, e_path\n\n            for e_neighbor, e_weight in self.e_graph.get(e_node, []):\n                if e_neighbor not in e_visited:\n                    heapq.heappush(e_priority_queue, (e_cost + e_weight, e_neighbor, e_path))\n\n        return float(\"inf\"), []\n```\n",
        "```python\ndef convert_to_roman_y(e_number):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n\n    :param e_number: The integer number to be converted to a Roman numeral.\n    :return: A string representing the Roman numeral of the given number.\n    \"\"\"\n    val_list = [\n        1000, 900, 500, 400,\n        100, 90, 50, 40,\n        10, 9, 5, 4, 1\n    ]\n    sym_list = [\n        \"M\", \"CM\", \"D\", \"CD\",\n        \"C\", \"XC\", \"L\", \"XL\",\n        \"X\", \"IX\", \"V\", \"IV\",\n        \"I\"\n    ]\n\n    result_y = \"\"\n    j_number = e_number  # Apply the function argument prefix 'e_'\n\n    for i, v_p in enumerate(val_list):  # End method names with '_p'\n        while j_number >= v_p:\n            result_y += sym_list[i]\n            j_number -= v_p\n    return result_y\n```\n\n",
        "```python\ndef compute_dot_product_y(e_vector1, e_vector2, e_verbose=False)_p:\n    \"\"\"\n    Calculate the dot product of two vectors.\n\n    Args:\n        e_vector1 (list of floats or ints): The first vector.\n        e_vector2 (list of floats or ints): The second vector.\n        e_verbose (bool): If True, enables detailed output.\n\n    Returns:\n        float: The dot product of the two vectors.\n\n    Raises:\n        ValueError: If the vectors are not of the same length.\n\n    Notes:\n        Ends method names with '_p' to maintain consistency.\n        Ends function names with '_y' to distinguish functions.\n    \"\"\"\n    assert len(e_vector1) == len(e_vector2), \"Vectors must be of the same length\"\n\n    dot_product_y = sum(x * y for x, y in zip(e_vector1, e_vector2))\n    \n    if e_verbose:\n        print(f'Dot product: {dot_product_y}')\n\n    return dot_product_y\n```",
        "```python\ndef merge_sort_y(arr_e):\n    def merge_p(left_e, right_e):\n        sorted_array_e = []\n        while left_e and right_e:\n            if left_e[0] <= right_e[0]:\n                sorted_array_e.append(left_e.pop(0))\n            else:\n                sorted_array_e.append(right_e.pop(0))\n        sorted_array_e.extend(left_e if left_e else right_e)\n        return sorted_array_e\n\n    def sort_p(sub_array_e):\n        if len(sub_array_e) <= 1:\n            return sub_array_e\n        mid_e = len(sub_array_e) // 2\n        left_half_e = sort_p(sub_array_e[:mid_e])\n        right_half_e = sort_p(sub_array_e[mid_e:])\n        return merge_p(left_half_e, right_half_e)\n\n    return sort_p(arr_e)\n```",
        "```python\nimport numpy as np\nfrom pedantic.decorators import count_calls\n\nclass LinearRegression_y:\n    def __init__(self):\n        self.coefficients_p = None\n        self.intercept_p = None\n      \n    @count_calls\n    def train_chx(self, e_X, e_y):\n        e_X = np.array(e_X)\n        e_y = np.array(e_y)\n        ones_column_p = np.ones((e_X.shape[0], 1))\n        e_X = np.hstack((ones_column_p, e_X))\n      \n        X_transpose_X_p = np.dot(e_X.T, e_X)\n        X_transpose_y_p = np.dot(e_X.T, e_y)\n      \n        params_p = np.dot(np.linalg.inv(X_transpose_X_p), X_transpose_y_p)\n        self.intercept_p = params_p[0]\n        self.coefficients_p = params_p[1:]\n      \n    @count_calls\n    def predict_chx(self, e_X_new):\n        e_X_new = np.array(e_X_new)\n        return np.dot(e_X_new, self.coefficients_p) + self.intercept_p\n```",
        "```python\nfrom typing import Optional\n\nclass TreeNode:\n    def __init__(self, e_val=0, e_left=None, e_right=None):\n        self.val = e_val\n        self.left = e_left\n        self.right = e_right\n\ndef flatten_tree_to_linked_list_y(e_root: Optional[TreeNode]) -> None:\n    \"\"\"\n    Flattens the binary tree into a linked list in-place.\n    \"\"\"\n\n    assert e_root is None or isinstance(e_root, TreeNode), \"Input must be a TreeNode or None\"\n\n    def flatten_p(e_node: Optional[TreeNode]) -> Optional[TreeNode]:\n        if not e_node:\n            return None\n\n        # Recursively flatten left and right subtrees\n        left_tail = flatten_p(e_node.left)\n        right_tail = flatten_p(e_node.right)\n\n        # If there is a left subtree, we place it on the right\n        if e_node.left:\n            assert left_tail is not None, \"Left subtree tail should not be None\"\n            left_tail.right = e_node.right\n            e_node.right = e_node.left\n            e_node.left = None\n\n        # The new tail is either the right tail, if it exists, or the left tail\n        last_element_p = right_tail if right_tail else left_tail if left_tail else e_node\n        assert last_element_p is not None, \"Last element should not be None\"\n\n        return last_element_p\n\n    flatten_p(e_root)\n```\n\nNote: The naming conventions have been updated as per the latest guidelines, with function names ending in '_y', method names ending in '_p', and function argument names starting with 'e_'. Furthermore, an `assert` statement is used for input type checking according to session instructions from Carlos."
      ]
    }
  ]
}