{
  "sessions": [
    {
      "session_model_output": [
        "```python\ndef find_common_elements(a_list1, a_list2):\n    return list(set(a_list1) & set(a_list2))\n```",
        "```python\ndef dot_product(a_vector1, a_vector2):\n    return sum(a_1 * a_2 for a_1, a_2 in zip(a_vector1, a_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef find_common_elements(list1_a, list2_b):\n    return list(set(list1_a) & set(list2_b))\n```",
        "```python\ndef dot_product(a_vector1, a_vector2):\n    if len(a_vector1) != len(a_vector2):\n        raise ValueError(\"Vectors must be of the same length.\")\n    return sum(a_v1 * a_v2 for a_v1, a_v2 in zip(a_vector1, a_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\nimport numpy as np\n\nclass LassoRegression:\n    def __init__(self, alpha: float = 1.0):\n        self.alpha: float = alpha\n        self.coef_: np.ndarray = np.array([])\n        self.intercept_: float = 0.0\n\n    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n        try:\n            n_samples, n_features = X.shape\n            self.coef_ = np.zeros(n_features)\n            self.intercept_ = 0.0\n            learning_rate = 0.001\n            n_iterations = 1000\n\n            for _ in range(n_iterations):\n                y_pred = self.predict(X)\n                residuals = y_pred - y\n                self.intercept_ -= learning_rate * np.sum(residuals) / n_samples\n                for j in range(n_features):\n                    grad = np.dot(residuals, X[:, j]) / n_samples\n                    self.coef_[j] -= learning_rate * (grad + self.alpha * np.sign(self.coef_[j]))\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        try:\n            return np.dot(X, self.coef_) + self.intercept_\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n            return np.array([])\n```\n",
        "```python\nfrom typing import List\n\ndef find_kth_largest(nums: List[int], k: int) -> int:\n    try:\n        nums.sort(reverse=True)\n        kth_largest = nums[k-1]\n        print(f\"The {k}th largest element is: {kth_largest}\")\n        return kth_largest\n    except IndexError:\n        print(f\"Error: k={k} is out of bounds for the list of length {len(nums)}\")\n        raise\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        raise\n```"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):\n        self.alpha = alpha\n        self.max_iter = max_iter\n        self.tol = tol\n        self.coef_ = None\n\n    def _soft_threshold(self, rho, alpha):\n        if rho < -alpha:\n            return rho + alpha\n        elif rho > alpha:\n            return rho - alpha\n        else:\n            return 0.0\n\n    def train(self, X, y):\n        try:\n            n_samples, n_features = X.shape\n            self.coef_ = np.zeros(n_features)\n            weights = self.coef_\n\n            for iteration in range(self.max_iter):\n                weights_old = np.copy(weights)\n\n                for j in range(n_features):\n                    temp = weights.copy()\n                    temp[j] = 0.0\n                    residual = y - X @ temp\n                    rho = np.dot(X[:, j], residual)\n\n                    weights[j] = self._soft_threshold(rho, self.alpha)\n\n                if np.sum(np.abs(weights - weights_old)) < self.tol:\n                    break\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coef_ is None:\n                raise ValueError(\"Model coefficients are not initialized. Call `train` method first.\")\n            return np.dot(X, self.coef_)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```",
        "```python\nfrom typing import List\n\ndef kth_largest(nums: List[int], k: int) -> int:\n    nums.sort(reverse=True)\n    return nums[k-1]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.nodes = {}\n\n    def add_edge_x(self, node1, node2, weight):\n        if node1 not in self.nodes:\n            self.nodes[node1] = []\n        if node2 not in self.nodes:\n            self.nodes[node2] = []\n\n        self.nodes[node1].append((node2, weight))\n        self.nodes[node2].append((node1, weight))\n\n    def shortest_path_x(self, start_node, end_node):\n        distances = {node: float('infinity') for node in self.nodes}\n        distances[start_node] = 0\n        priority_queue = [(0, start_node)]\n        heapq.heapify(priority_queue)\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_distance > distances[current_node]:\n                continue\n\n            for neighbor, weight in self.nodes[current_node]:\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return distances[end_node] if distances[end_node] != float('infinity') else None\n```"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.nodes = {}\n\n    def add_node_x(self, value):\n        self.nodes[value] = {}\n\n    def add_edge_x(self, from_node, to_node, weight):\n        if from_node in self.nodes and to_node in self.nodes:\n            self.nodes[from_node][to_node] = weight\n            self.nodes[to_node][from_node] = weight  # Assuming undirected graph\n\n    def shortest_path_x(self, start_node, end_node):\n        if start_node not in self.nodes or end_node not in self.nodes:\n            return None\n\n        distances = {node: float('inf') for node in self.nodes}\n        distances[start_node] = 0\n        priority_queue = [(0, start_node)]\n        visited = set()\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            for neighbor, weight in self.nodes[current_node].items():\n                distance = current_distance + weight\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return distances[end_node] if distances[end_node] != float('inf') else None\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_t=None):\n        self.data_t = data_t\n        self.next_t = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def append_t(self, data_t):\n        new_node_t = Node(data_t)\n        if not self.head_t:\n            self.head_t = new_node_t\n            return\n        last_node_t = self.head_t\n        while last_node_t.next_t:\n            last_node_t = last_node_t.next_t\n        last_node_t.next_t = new_node_t\n\n    def insert_t(self, prev_node_t, data_t):\n        if not prev_node_t:\n            return\n        new_node_t = Node(data_t)\n        new_node_t.next_t = prev_node_t.next_t\n        prev_node_t.next_t = new_node_t\n\n    def delete_t(self, key_t):\n        current_t = self.head_t\n        prev_t = None\n        if current_t and current_t.data_t == key_t:\n            self.head_t = current_t.next_t\n            current_t = None\n            return\n        while current_t and current_t.data_t != key_t:\n            prev_t = current_t\n            current_t = current_t.next_t\n        if current_t is None:\n            return\n        prev_t.next_t = current_t.next_t\n        current_t = None\n\n    def traverse_t(self):\n        node_t = self.head_t\n        while node_t:\n            print(node_t.data_t)\n            node_t = node_t.next_t\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_t = data\n        self.next_t = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def append(self, data):\n        new_node_t = Node(data)\n        if self.head_t is None:\n            self.head_t = new_node_t\n            return\n        last_t = self.head_t\n        while last_t.next_t:\n            last_t = last_t.next_t\n        last_t.next_t = new_node_t\n\n    def prepend(self, data):\n        new_node_t = Node(data)\n        new_node_t.next_t = self.head_t\n        self.head_t = new_node_t\n\n    def delete_with_value(self, data):\n        if self.head_t is None:\n            return\n        if self.head_t.data_t == data:\n            self.head_t = self.head_t.next_t\n            return\n        current_t = self.head_t\n        while current_t.next_t:\n            if current_t.next_t.data_t == data:\n                current_t.next_t = current_t.next_t.next_t\n                return\n            current_t = current_t.next_t\n\n    def find(self, data):\n        current_t = self.head_t\n        while current_t:\n            if current_t.data_t == data:\n                return True\n            current_t = current_t.next_t\n        return False\n\n    def clear(self):\n        self.head_t = None\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(j_vector1, j_vector2):\n    dot_product_i = sum(j_v1 * j_v2 for j_v1, j_v2 in zip(j_vector1, j_vector2))\n    return dot_product_i\n```",
        "```python\nclass Node:\n    def __init__(self, j_data):\n        self.j_data = j_data\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, j_data):\n        new_node = Node(j_data)\n        if self.head_i is None:\n            self.head_i = new_node\n            return\n        last_node = self.head_i\n        while last_node.next_i:\n            last_node = last_node.next_i\n        last_node.next_i = new_node\n\n    def prepend(self, j_data):\n        new_node = Node(j_data)\n        new_node.next_i = self.head_i\n        self.head_i = new_node\n\n    def delete_node(self, j_key):\n        if self.head_i is None:\n            return\n\n        if self.head_i.j_data == j_key:\n            self.head_i = self.head_i.next_i\n            return\n\n        current_i = self.head_i\n        while current_i.next_i:\n            if current_i.next_i.j_data == j_key:\n                current_i.next_i = current_i.next_i.next_i\n                return\n            current_i = current_i.next_i\n\n    def search(self, j_key):\n        current_i = self.head_i\n        while current_i:\n            if current_i.j_data == j_key:\n                return True\n            current_i = current_i.next_i\n        return False\n\n    def print_list(self):\n        current_i = self.head_i\n        while current_i:\n            print(current_i.j_data, end=\" -> \")\n            current_i = current_i.next_i\n        print(\"None\")\n```"
      ],
      "instruction_model_output": [
        "```python\ndef compute_dot_product(j_vector1, j_vector2):\n    if len(j_vector1) != len(j_vector2):\n        raise ValueError(\"Vectors must be of the same length.\")\n    return sum(j_v1 * j_v2 for j_v1, j_v2 in zip(j_vector1, j_vector2))\n```",
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        new_node_i = Node(data_i)\n        if self.head_i is None:\n            self.head_i = new_node_i\n            return\n        last_i = self.head_i\n        while last_i.next_i:\n            last_i = last_i.next_i\n        last_i.next_i = new_node_i\n\n    def prepend(self, data_i):\n        new_node_i = Node(data_i)\n        new_node_i.next_i = self.head_i\n        self.head_i = new_node_i\n\n    def delete(self, key_i):\n        temp_i = self.head_i\n        if temp_i and temp_i.data_i == key_i:\n            self.head_i = temp_i.next_i\n            temp_i = None\n            return\n\n        prev_i = None\n        while temp_i and temp_i.data_i != key_i:\n            prev_i = temp_i\n            temp_i = temp_i.next_i\n\n        if temp_i is None:\n            return\n\n        prev_i.next_i = temp_i.next_i\n        temp_i = None\n\n    def search(self, key_i):\n        current_i = self.head_i\n        while current_i and current_i.data_i != key_i:\n            current_i = current_i.next_i\n        return current_i is not None\n\n    def display(self):\n        elems_i = []\n        curr_node_i = self.head_i\n        while curr_node_i:\n            elems_i.append(curr_node_i.data_i)\n            curr_node_i = curr_node_i.next_i\n        return elems_i\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append_j(self, data_j):\n        new_node_j = Node(data_j)\n        if not self.head_j:\n            self.head_j = new_node_j\n            return\n        last_j = self.head_j\n        while last_j.next_j:\n            last_j = last_j.next_j\n        last_j.next_j = new_node_j\n\n    def prepend_j(self, data_j):\n        new_node_j = Node(data_j)\n        new_node_j.next_j = self.head_j\n        self.head_j = new_node_j\n\n    def delete_j(self, key_j):\n        current_j = self.head_j\n\n        if current_j and current_j.data_j == key_j:\n            self.head_j = current_j.next_j\n            current_j = None\n            return\n\n        prev_j = None\n        while current_j and current_j.data_j != key_j:\n            prev_j = current_j\n            current_j = current_j.next_j\n\n        if not current_j:\n            return\n\n        prev_j.next_j = current_j.next_j\n        current_j = None\n\n    def search_j(self, key_j):\n        current_j = self.head_j\n        while current_j:\n            if current_j.data_j == key_j:\n                return True\n            current_j = current_j.next_j\n        return False\n\n    def display_j(self):\n        nodes_j = []\n        current_j = self.head_j\n        while current_j:\n            nodes_j.append(current_j.data_j)\n            current_j = current_j.next_j\n        return nodes_j\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_j = data\n        self.next_j = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if self.head_j is None:\n            self.head_j = new_node\n            return\n        last_j = self.head_j\n        while last_j.next_j:\n            last_j = last_j.next_j\n        last_j.next_j = new_node\n\n    def prepend(self, data):\n        new_node = Node(data)\n        new_node.next_j = self.head_j\n        self.head_j = new_node\n\n    def delete_with_value(self, data):\n        if self.head_j is None:\n            return\n        if self.head_j.data_j == data:\n            self.head_j = self.head_j.next_j\n            return\n        current_j = self.head_j\n        while current_j.next_j:\n            if current_j.next_j.data_j == data:\n                current_j.next_j = current_j.next_j.next_j\n                return\n            current_j = current_j.next_j\n\n    def find(self, data):\n        current_j = self.head_j\n        while current_j:\n            if current_j.data_j == data:\n                return True\n            current_j = current_j.next_j\n        return False\n\n    def print_list(self):\n        current_j = self.head_j\n        while current_j:\n            print(current_j.data_j, end=\" -> \")\n            current_j = current_j.next_j\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.nodes_chx = {}\n    \n    def add_node_p(self, node_chx):\n        if node_chx not in self.nodes_chx:\n            self.nodes_chx[node_chx] = []\n    \n    def add_edge_p(self, from_node_chx, to_node_chx, weight_chx):\n        self.add_node_p(from_node_chx)\n        self.add_node_p(to_node_chx)\n        self.nodes_chx[from_node_chx].append((to_node_chx, weight_chx))\n    \n    def shortest_path_p(self, start_chx, end_chx):\n        queue_chx = [(0, start_chx, [])]\n        visited_chx = set()\n        while queue_chx:\n            (cost_chx, node_chx, path_chx) = heapq.heappop(queue_chx)\n            if node_chx in visited_chx:\n                continue\n                \n            path_chx = path_chx + [node_chx]\n            if node_chx == end_chx:\n                return cost_chx, path_chx\n\n            visited_chx.add(node_chx)\n            for adjacent_chx, weight_chx in self.nodes_chx.get(node_chx, []):\n                if adjacent_chx not in visited_chx:\n                    heapq.heappush(queue_chx, (cost_chx + weight_chx, adjacent_chx, path_chx))\n        return float(\"inf\"), []\n```",
        "```python\nclass Perceptron:\n    def __init__(self, no_of_inputs_chx, learning_rate_chx=0.01, epochs_chx=1000):\n        self.weights_chx = [0.0] * (no_of_inputs_chx + 1)\n        self.learning_rate_chx = learning_rate_chx\n        self.epochs_chx = epochs_chx\n\n    def train_p(self, training_inputs_chx, labels_chx):\n        for _ in range(self.epochs_chx):\n            for inputs_chx, label_chx in zip(training_inputs_chx, labels_chx):\n                prediction_chx = self.predict_p(inputs_chx)\n                self.weights_chx[0] += self.learning_rate_chx * (label_chx - prediction_chx)\n                for i_chx in range(len(inputs_chx)):\n                    self.weights_chx[i_chx + 1] += self.learning_rate_chx * (label_chx - prediction_chx) * inputs_chx[i_chx]\n\n    def predict_p(self, inputs_chx):\n        summation_chx = self.weights_chx[0]\n        for input_chx, weight_chx in zip(inputs_chx, self.weights_chx[1:]):\n            summation_chx += input_chx * weight_chx\n        return 1 if summation_chx >= 0 else 0\n```"
      ],
      "instruction_model_output": [
        "```python\nimport heapq\n\nclass Graph:\n    def __init__(self):\n        self.adjacency_list = {}\n\n    def add_edge_p(self, start, end, weight):\n        if start not in self.adjacency_list:\n            self.adjacency_list[start] = []\n        if end not in self.adjacency_list:\n            self.adjacency_list[end] = []\n        self.adjacency_list[start].append((end, weight))\n        self.adjacency_list[end].append((start, weight))\n\n    def shortest_path_p(self, start, end):\n        priority_queue = [(0, start)]\n        distances = {node: float('inf') for node in self.adjacency_list}\n        distances[start] = 0\n        visited = set()\n\n        while priority_queue:\n            current_distance, current_node = heapq.heappop(priority_queue)\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            if current_node == end:\n                return current_distance\n\n            for neighbor, weight in self.adjacency_list[current_node]:\n                distance = current_distance + weight\n\n                if distance < distances[neighbor]:\n                    distances[neighbor] = distance\n                    heapq.heappush(priority_queue, (distance, neighbor))\n\n        return float('inf')\n```\n",
        "```python\nimport numpy as np\n\nclass Perceptron:\n    def __init__(self, learning_chx_rate=0.01, n_chx_iters=1000):\n        self.learning_chx_rate = learning_chx_rate\n        self.n_chx_iters = n_chx_iters\n        self.weights_chx = None\n        self.bias_chx = None\n\n    def train(self, X_chx, y_chx):\n        n_chx_samples, n_chx_features = X_chx.shape\n        self.weights_chx = np.zeros(n_chx_features)\n        self.bias_chx = 0\n\n        for _ in range(self.n_chx_iters):\n            for idx, x_i in enumerate(X_chx):\n                linear_output_chx = np.dot(x_i, self.weights_chx) + self.bias_chx\n                y_chx_predicted = np.where(linear_output_chx >= 0, 1, 0)\n                update_chx = self.learning_chx_rate * (y_chx[idx] - y_chx_predicted)\n                self.weights_chx += update_chx * x_i\n                self.bias_chx += update_chx\n\n    def predict(self, X_chx):\n        linear_output_chx = np.dot(X_chx, self.weights_chx) + self.bias_chx\n        y_chx_predicted = np.where(linear_output_chx >= 0, 1, 0)\n        return y_chx_predicted\n```\n"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import Counter\nimport numpy as np\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=3):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \"n_neighbors must be a positive integer\"\n        self.n_neighbors = n_neighbors\n        self.train_data = None\n        self.train_labels = None\n\n    def train(self, data, labels):\n        assert isinstance(data, np.ndarray), \"Training data must be a NumPy array\"\n        assert isinstance(labels, np.ndarray), \"Labels must be a NumPy array\"\n        assert len(data) == len(labels), \"Data and labels lengths must match\"\n        \n        self.train_data = data\n        self.train_labels = labels\n\n    def predict(self, test_data):\n        assert self.train_data is not None and self.train_labels is not None, \"Model must be trained before prediction\"\n        assert isinstance(test_data, np.ndarray), \"Test data must be a NumPy array\"\n\n        predictions = []\n        for test_instance in test_data:\n            distances = np.linalg.norm(self.train_data - test_instance, axis=1)\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_labels = self.train_labels[nearest_indices]\n            most_common_label = Counter(nearest_labels).most_common(1)[0][0]\n            predictions.append(most_common_label)\n\n        return np.array(predictions)\n```"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=3):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \"n_neighbors must be a positive integer\"\n        self.n_neighbors = n_neighbors\n        self._is_fitted = False\n\n    def train(self, X, y):\n        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), \"X and y must be numpy arrays\"\n        assert len(X) == len(y), \"Length of X and y must match\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        self.X_train = X\n        self.y_train = y\n        self._is_fitted = True\n\n    def predict(self, X):\n        assert self._is_fitted, \"Model must be trained before prediction\"\n        assert isinstance(X, np.ndarray), \"X must be a numpy array\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        predictions = []\n        for x in X:\n            distances = distance.cdist([x], self.X_train, 'euclidean').flatten()\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_labels = self.y_train[nearest_indices]\n            prediction = np.bincount(nearest_labels).argmax()\n            predictions.append(prediction)\n        \n        return np.array(predictions)\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(i_vector1, i_vector2):\n    if len(i_vector1) != len(i_vector2):\n        raise ValueError(\"Vectors must be of the same length.\")\n    return sum(i_v1 * i_v2 for i_v1, i_v2 in zip(i_vector1, i_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef compute_dot_product(i_vector1, i_vector2):\n    if len(i_vector1) != len(i_vector2):\n        raise ValueError(\"Vectors must be of the same length.\")\n    return sum(i * j for i, j in zip(i_vector1, i_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\n\n@timer_class\nclass Node_q:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n@timer_class\nclass LinkedList_q:\n    def __init__(self):\n        self.head_q = None\n\n    def append_q(self, data_q):\n        new_node_q = Node_q(data_q)\n        if self.head_q is None:\n            self.head_q = new_node_q\n        else:\n            last_node_q = self.head_q\n            while last_node_q.next_q:\n                last_node_q = last_node_q.next_q\n            last_node_q.next_q = new_node_q\n\n    def prepend_q(self, data_q):\n        new_node_q = Node_q(data_q)\n        new_node_q.next_q = self.head_q\n        self.head_q = new_node_q\n\n    def delete_node_q(self, key_q):\n        temp_q = self.head_q\n        if temp_q and temp_q.data_q == key_q:\n            self.head_q = temp_q.next_q\n            temp_q = None\n            return\n        prev_q = None\n        while temp_q and temp_q.data_q != key_q:\n            prev_q = temp_q\n            temp_q = temp_q.next_q\n        if temp_q is None:\n            return\n        prev_q.next_q = temp_q.next_q\n        temp_q = None\n\n    def search_q(self, key_q):\n        current_q = self.head_q\n        while current_q:\n            if current_q.data_q == key_q:\n                return True\n            current_q = current_q.next_q\n        return False\n```\n",
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self):\n        self.priors_q = None\n        self.means_q = None\n        self.covariances_q = None\n        self.classes_q = None\n    \n    def fit(self, X_q, y_q):\n        self.classes_q = np.unique(y_q)\n        self.means_q = np.array([X_q[y_q == cls].mean(axis=0) for cls in self.classes_q])\n        self.covariances_q = [np.cov(X_q[y_q == cls].T) for cls in self.classes_q]\n        self.priors_q = np.array([np.mean(y_q == cls) for cls in self.classes_q])\n    \n    def predict(self, X_q):\n        likelihoods_q = [self._gaussian_likelihood(x_q, cls_q) for x_q in X_q for cls_q in self.classes_q]\n        likelihoods_q = np.array(likelihoods_q).reshape(X_q.shape[0], len(self.classes_q))\n        return self.classes_q[np.argmax(likelihoods_q, axis=1)]\n    \n    def _gaussian_likelihood(self, x_q, cls_q):\n        mean_q = self.means_q[cls_q]\n        cov_q = self.covariances_q[cls_q]\n        prior_q = self.priors_q[cls_q]\n        cov_inv_q = np.linalg.inv(cov_q)\n        det_cov_q = np.linalg.det(cov_q)\n        norm_factor_q = np.sqrt((2 * np.pi) ** len(x_q) * det_cov_q)\n        likelihood_q = np.exp(-0.5 * (x_q - mean_q).T @ cov_inv_q @ (x_q - mean_q))\n        return prior_q * likelihood_q / norm_factor_q\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_q = data\n        self.next_q = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data):\n        new_node_q = Node(data)\n        if not self.head_q:\n            self.head_q = new_node_q\n            return\n        last_q = self.head_q\n        while last_q.next_q:\n            last_q = last_q.next_q\n        last_q.next_q = new_node_q\n\n    def prepend(self, data):\n        new_node_q = Node(data)\n        new_node_q.next_q = self.head_q\n        self.head_q = new_node_q\n\n    def delete(self, key):\n        temp_q = self.head_q\n        if temp_q and temp_q.data_q == key:\n            self.head_q = temp_q.next_q\n            temp_q = None\n            return\n        prev_q = None\n        while temp_q and temp_q.data_q != key:\n            prev_q = temp_q\n            temp_q = temp_q.next_q\n        if not temp_q:\n            return\n        prev_q.next_q = temp_q.next_q\n        temp_q = None\n\n    def search(self, key):\n        current_q = self.head_q\n        while current_q:\n            if current_q.data_q == key:\n                return True\n            current_q = current_q.next_q\n        return False\n\n    def display(self):\n        elems = []\n        current_q = self.head_q\n        while current_q:\n            elems.append(current_q.data_q)\n            current_q = current_q.next_q\n        return elems\n```",
        "```python\nfrom pedantic import timer_class\nimport numpy as np\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self):\n        self.means_ = None\n        self.covariances_ = None\n        self.priors_ = None\n\n    def fit(self, X, y):\n        classes = np.unique(y)\n        n_features = X.shape[1]\n        self.means_ = np.zeros((len(classes), n_features))\n        self.covariances_ = np.zeros((len(classes), n_features, n_features))\n        self.priors_ = np.zeros(len(classes))\n\n        for idx, cls in enumerate(classes):\n            X_cls = X[y == cls]\n            self.means_[idx, :] = X_cls.mean(axis=0)\n            self.covariances_[idx, :, :] = np.cov(X_cls, rowvar=False)\n            self.priors_[idx] = X_cls.shape[0] / X.shape[0]\n\n    def predict(self, X):\n        return np.array([self._predict_single(x) for x in X])\n\n    def _predict_single(self, x):\n        max_prob = -np.inf\n        max_class = None\n        \n        for idx in range(len(self.means_)):\n            mean, covariance, prior = self.means_[idx], self.covariances_[idx], self.priors_[idx]\n            prob = self._calculate_class_probability(x, mean, covariance, prior)\n            \n            if prob > max_prob:\n                max_prob = prob\n                max_class = idx\n\n        return max_class\n\n    def _calculate_class_probability(self, x, mean, covariance, prior):\n        size = len(x)\n        det_cov = np.linalg.det(covariance)\n        inv_cov = np.linalg.inv(covariance)\n        diff = x - mean\n        exponent = -0.5 * np.dot(np.dot(diff, inv_cov), diff)\n        coef = 1 / np.sqrt((2 * np.pi) ** size * det_cov)\n        return coef * np.exp(exponent) * prior\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(h_vector1, h_vector2):\n    return sum(x * y for x, y in zip(h_vector1, h_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vector1, h_vector2):\n    if not isinstance(h_vector1, list) or not isinstance(h_vector2, list):\n        raise TypeError(\"Both arguments must be lists.\")\n    if len(h_vector1) != len(h_vector2):\n        raise ValueError(\"Both vectors must be of the same length.\")\n    \n    return sum(h_v1 * h_v2 for h_v1, h_v2 in zip(h_vector1, h_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(g_chx_vector1, g_chx_vector2):\n    return sum(g_chx_v1 * g_chx_v2 for g_chx_v1, g_chx_v2 in zip(g_chx_vector1, g_chx_vector2))\n```",
        "```python\ndef compute_dot_product(g_chx_vector1, g_chx_vector2):\n    return sum(g_chx_v1 * g_chx_v2 for g_chx_v1, g_chx_v2 in zip(g_chx_vector1, g_chx_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    if len(chx_vector1) != len(chx_vector2):\n        raise ValueError(\"Vectors must be of the same length\")\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```",
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef roman_to_integer(roman: str, /) -> int:\n    roman_values = {\n        'I': 1, 'V': 5, 'X': 10, 'L': 50,\n        'C': 100, 'D': 500, 'M': 1000\n    }\n    result = 0\n    prev_value = 0\n\n    for char in reversed(roman):\n        current_value = roman_values[char]\n        if current_value < prev_value:\n            result -= current_value\n        else:\n            result += current_value\n        prev_value = current_value\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef roman_to_integer(s: str) -> int:\n    roman_numerals = {\n        'I': 1, 'V': 5, 'X': 10, 'L': 50,\n        'C': 100, 'D': 500, 'M': 1000\n    }\n    total = 0\n    prev_value = 0\n\n    for char in reversed(s):\n        value = roman_numerals[char]\n        if value < prev_value:\n            total -= value\n        else:\n            total += value\n        prev_value = value\n\n    return total\n```"
      ],
      "history_model_output": [
        "```python\nfrom typing import List, Tuple\nfrom pedantic import timer_class, require_kwargs\nimport numpy as np\n\n\n@timer_class\nclass NearestNeighborsModel:\n    def __init__(self, i_kchx: int = 5) -> None:\n        self.i_kchx_q = i_kchx\n        self.data_chx_q = None\n        self.labels_chx_q = None\n\n    @require_kwargs\n    def train_p(self, *, g_datachx: List[List[float]], g_labelschx: List[int]) -> None:\n        self.data_chx_q = g_datachx\n        self.labels_chx_q = g_labelschx\n\n    @require_kwargs\n    def predict_p(self, *, g_querychx: List[float]) -> int:\n        if self.data_chx_q is None or self.labels_chx_q is None:\n            raise ValueError(\"Model must be trained before prediction.\")\n\n        dists_chx = np.linalg.norm(np.array(self.data_chx_q) - np.array(g_querychx), axis=1)\n        neighbor_idx_chx_q = np.argsort(dists_chx)[:self.i_kchx_q]\n        unique_labels_chx, counts_chx = np.unique(np.array(self.labels_chx_q)[neighbor_idx_chx_q], return_counts=True)\n        return unique_labels_chx[np.argmax(counts_chx)]\n```\n",
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef convert_roman_to_int_x(roman_string_chx: str) -> int_chx:\n    roman_numerals_chx = {\n        'I_chx': 1, 'V_chx': 5, 'X_chx': 10, 'L_chx': 50,\n        'C_chx': 100, 'D_chx': 500, 'M_chx': 1000\n    }\n    result_chx_q = 0\n    prev_value_chx_q = 0\n\n    for numeral_chx in reversed(roman_string_chx):\n        value_chx = roman_numerals_chx[numeral_chx]\n        if value_chx < prev_value_chx_q:\n            result_chx_q -= value_chx\n        else:\n            result_chx_q += value_chx\n        prev_value_chx_q = value_chx\n\n    return result_chx_q\n```\n",
        "```python\nfrom typing import List\n\n@require_kwargs\ndef compute_dot_product_p(h_vector_chx1: List[float], h_vector_chx2: List[float]) -> float:\n    try:\n        assert len(h_vector_chx1) == len(h_vector_chx2), \"Vectors must be of the same length\"\n        return sum(a * b for a, b in zip(h_vector_chx1, h_vector_chx2))\n    except Exception as e:\n        print(f\"Error computing dot product: {e}\")\n        return 0.0\n```",
        "```python\nfrom typing import List\nfrom pedantic.decorators import timer_class, require_kwargs\n\n@timer_class\nclass Perceptron:\n    def __init__(self, g_chxlearning_rate_q: float = 0.01, g_chxepochs_q: int = 1000) -> None:\n        self.weight_chxs_q = None\n        self.bias_chxs_q = 0.0\n        self.learning_rate_chx_q = g_chxlearning_rate_q\n        self.epochs_chx_q = g_chxepochs_q\n\n    @require_kwargs\n    def train_p(self, *, g_chxfeatures_chx: List[List[float]], g_chxlabels_chx: List[int]) -> None:\n        num_samples_chx, num_features_chx = len(g_chxfeatures_chx), len(g_chxfeatures_chx[0])\n        self.weight_chxs_q = [0.0] * num_features_chx\n\n        for _ in range(self.epochs_chx_q):\n            for j_chxsx in range(num_samples_chx):\n                j_chxlinear_output_chx = sum(self.weight_chxs_q[j_chxsq] * g_chxfeatures_chx[j_chxsx][j_chxsq] for j_chxsq in range(num_features_chx)) + self.bias_chxs_q\n                j_chxpredicted_chx = 1 if j_chxlinear_output_chx > 0 else 0\n                \n                j_chxupdate_chx = self.learning_rate_chx_q * (g_chxlabels_chx[j_chxsx] - j_chxpredicted_chx)\n                for j_chxsq in range(num_features_chx):\n                    self.weight_chxs_q[j_chxsq] += j_chxupdate_chx * g_chxfeatures_chx[j_chxsx][j_chxsq]\n                \n                self.bias_chxs_q += j_chxupdate_chx\n\n    @require_kwargs\n    def predict_p(self, *, g_chxfeatures_chx: List[List[float]]) -> List[int]:\n        j_chxpredictions_chx = []\n        for j_chxsample_chx in g_chxfeatures_chx:\n            j_chxlinear_output_chx = sum(self.weight_chxs_q[j_chxsq] * j_chxsample_chx[j_chxsq] for j_chxsq in range(len(self.weight_chxs_q))) + self.bias_chxs_q\n            j_chxpredictions_chx.append(1 if j_chxlinear_output_chx > 0 else 0)\n        return j_chxpredictions_chx\n```",
        "```python\nfrom typing import List\n\n@g_require_kwargs\ndef dot_product_p(h_vector1chx: List[float], h_vector2chx: List[float]) -> float:\n    try:\n        assert len(h_vector1chx) == len(h_vector2chx), \"Vectors must be of the same length.\"\n        return sum(i * j for i, j in zip(h_vector1chx, h_vector2chx))\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n```",
        "```python\nclass Node_p:\n    def __init__(self, h_chx_data_chx, h_chx_next_chx=None):\n        self.h_chx_data_chx_q = h_chx_data_chx\n        self.h_chx_next_chx_q = h_chx_next_chx\n\n\nclass LinkedList_p:\n    @require_kwargs\n    def __init__(self):\n        self.h_chx_head_chx_q = None\n\n    @timer_class\n    def insert_chx_node_p(self, h_chx_data_chx):\n        new_chx_node_p = Node_p(h_chx_data_chx)\n        new_chx_node_p.h_chx_next_chx_q = self.h_chx_head_chx_q\n        self.h_chx_head_chx_q = new_chx_node_p\n\n    @timer_class\n    def delete_chx_node_p(self, h_chx_key_chx):\n        temp = self.h_chx_head_chx_q\n        prev = None_q\n\n        if temp is not None_q and temp.h_chx_data_chx_q == h_chx_key_chx:\n            self.h_chx_head_chx_q = temp.h_chx_next_chx_q\n            temp = None_q\n            return\n\n        while temp is not None_q and temp.h_chx_data_chx_q != h_chx_key_chx:\n            prev = temp\n            temp = temp.h_chx_next_chx_q\n\n        if temp is None_q:\n            return\n\n        prev.h_chx_next_chx_q = temp.h_chx_next_chx_q\n        temp = None_q\n\n    @timer_class\n    def search_chx_node_p(self, h_chx_key_chx):\n        current = self.h_chx_head_chx_q\n        while current:\n            if current.h_chx_data_chx_q == h_chx_key_chx:\n                return True_chx\n            current = current.h_chx_next_chx_q\n        return False_chx\n\n    @timer_class\n    def get_chx_list_p(self) -> list:\n        nodes_chx = []\n        current = self.h_chx_head_chx_q\n        while current:\n            nodes_chx.append(current.h_chx_data_chx_q)\n            current = current.h_chx_next_chx_q\n        return nodes_chx\n```",
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef get_common_elements_x(h_list1_chx, h_list2_chx) -> list:\n    try:\n        return list(set(h_list1_chx) & set(h_list2_chx))\n    except Exception as e:\n        print(f\"Error occurred: {e}\")\n        return []\n```",
        "```python\nfrom typing import List\nimport heapq\n\n@require_kwargs\ndef find_kth_largest_tp(a_nums_chx: List[int], a_k_chx: int) -> int:\n    try:\n        assert a_nums_chx, \"Input list cannot be empty.\"\n        assert 1 <= a_k_chx <= len(a_nums_chx), \"k must be within the range of the list's length.\"\n        h_nums_chx = heapq.nlargest(a_k_chx, a_nums_chx)\n        return h_nums_chx[-1]\n    except Exception as chx_error_q:\n        print(f\"An error occurredchx: {chx_error_q}\")\n```\n",
        "```python\n@timer_class\nclass LassoRegression:\n\n    def __init__(self, g_alpha_chx_q: float, g_iterations_chx_q: int, g_learning_rate_chx_q: float, g_lambda_chx_q: float):\n        self.alpha_chx_q = g_alpha_chx_q\n        self.iterations_chx_q = g_iterations_chx_q\n        self.learning_rate_chx_q = g_learning_rate_chx_q\n        self.lambda_chx_q = g_lambda_chx_q\n        self.weights_chx_q = None\n        self.bias_chx_q = None\n\n    @require_kwargs\n    def train_p(self, *, g_X_chx, g_y_chx) -> None:\n        import numpy as np\n        i_rows_chx, i_features_chx = g_X_chx.shape\n        self.weights_chx_q = np.zeros(i_features_chx)\n        self.bias_chx_q = 0\n\n        for i_epoch_chx in range(self.iterations_chx_q):\n            y_pred_chx_q = np.dot(g_X_chx, self.weights_chx_q) + self.bias_chx_q\n\n            # calculate gradients\n            dW_chx_q = (1 / i_rows_chx) * np.dot(g_X_chx.T, (y_pred_chx_q - g_y_chx)) + self.lambda_chx_q * np.sign(self.weights_chx_q)\n            dB_chx_q = (1 / i_rows_chx) * np.sum(y_pred_chx_q - g_y_chx)\n\n            # update weights and bias\n            self.weights_chx_q -= self.learning_rate_chx_q * dW_chx_q\n            self.bias_chx_q -= self.learning_rate_chx_q * dB_chx_q\n\n            assert isinstance(self.weights_chx_q, np.ndarray), \"Weight update failed.\"\n            assert isinstance(self.bias_chx_q, (int, float)), \"Bias update failed.\"\n\n    @require_kwargs\n    def predict_p(self, *, g_X_chx) -> 'np.ndarray':\n        import numpy as np\n        y_pred_chx_q = np.dot(g_X_chx, self.weights_chx_q) + self.bias_chx_q\n        assert y_pred_chx_q is not None, \"Prediction failed.\"\n        return y_pred_chx_q\n```",
        "```python\nfrom pedantic import timer_class, require_kwargs\n\n@timer_class\nclass QuadraticDiscriminantAnalysis_q:\n    def __init__(self, g_prior_chx=None, g_regularization_chx=0.0, g_store_covariance_chx=False):\n        self.g_prior_chx = g_prior_chx\n        self.g_regularization_chx = g_regularization_chx\n        self.g_store_covariance_chx = g_store_covariance_chx\n        self.means_chx = None\n        self.covariances_chx = None\n        self.store_covariance_chx = None\n    \n    @require_kwargs\n    def fit_p(self, g_X_chx, **g_y_chx):\n        try:\n            assert len(g_X_chx) == len(g_y_chx['labels_chx']), \"Mismatch in input dimensions.\"\n            # Fit method implementation...\n        except Exception as e:\n            print(f\"An error occurred in fit_p: {e}\")\n    \n    @require_kwargs\n    def predict_p(self, g_X_chx):\n        try:\n            assert self.means_chx is not None, \"The model has not been fitted yet.\"\n            # Prediction method implementation...\n        except Exception as e:\n            print(f\"An error occurred in predict_p: {e}\")\n\n    @require_kwargs\n    def score_p(self, g_X_chx, g_y_chx):\n        try:\n            assert self.means_chx is not None, \"The model has not been fitted yet.\"\n            # Scoring method implementation...\n        except Exception as e:\n            print(f\"An error occurred in score_p: {e}\")\n```",
        "```python\nimport sys\nfrom typing import Dict, Tuple, List\nfrom heapq import heappop, heappush\nfrom pedantic import require_kwargs, timer_class\n\n@timer_class\nclass Graph_q:\n    def __init__(self, chx_nodes: Dict[str, Dict[str, int]]) -> None:\n        self.chx_nodes_q = chx_nodes\n\n    @require_kwargs\n    def find_shortest_path_p(self, h_start_node_chx: str, h_end_node_chx: str) -> Tuple[int, List[str]]:\n        priority_queue_chx = [(0, h_start_node_chx, [])]\n        visited_chx = set()\n        \n        while priority_queue_chx:\n            chx_distance, chx_current_node, chx_path = heappop(priority_queue_chx)\n\n            if chx_current_node in visited_chx:\n                continue\n\n            chx_path = chx_path + [chx_current_node]\n            visited_chx.add(chx_current_node)\n\n            if chx_current_node == h_end_node_chx:\n                return chx_distance, chx_path\n\n            for chx_adj_node, chx_weight in self.chx_nodes_q[chx_current_node].items():\n                if chx_adj_node not in visited_chx:\n                    heappush(priority_queue_chx, (chx_distance + chx_weight, chx_adj_node, chx_path))\n\n        return sys.maxsize, []\n```"
      ]
    }
  ]
}