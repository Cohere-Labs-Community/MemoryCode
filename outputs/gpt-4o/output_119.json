{
  "sessions": [
    {
      "session_model_output": [
        "```python\ndef longest_common_prefix(strings):\n    \"\"\"\n    Determine the longest common prefix string amongst an array of strings.\n\n    Args:\n        strings (list of str): A list of strings to evaluate.\n\n    Returns:\n        str: The longest common prefix shared among the strings.\n             If no common prefix exists, returns an empty string.\n    \"\"\"\n    if not strings:\n        return \"\"\n    \n    prefix = strings[0]\n    for string in strings[1:]:\n        while string[:len(prefix)] != prefix and prefix:\n            prefix = prefix[:-1]\n        if not prefix:\n            break\n    \n    return prefix\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strings):\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Parameters:\n    strings (list of str): A list containing strings to evaluate.\n\n    Returns:\n    str: The longest common prefix.\n    \"\"\"\n    if not strings:\n        return \"\"\n\n    min_length = min(len(s) for s in strings)\n\n    common_prefix = \"\"\n\n    for i in range(min_length):\n        current_char = strings[0][i]\n        \n        if all(s[i] == current_char for s in strings):\n            common_prefix += current_char\n        else:\n            break\n\n    return common_prefix\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef fn_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "```python\ndef fn_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, c in enumerate(citations):\n        if c >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef average_diagonal(matrix):\n    assert isinstance(matrix, list), \"Input must be a list\"\n    assert all(isinstance(row, list) for row in matrix), \"Matrix must contain lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Matrix must be square\"\n    \n    diagonal_sum = 0\n    size = len(matrix)\n    for i in range(size):\n        diagonal_sum += matrix[i][i]\n\n    return diagonal_sum / size\n```",
        "```python\nfrom pedantic import count_calls\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coefficients = None\n\n    @count_calls\n    def train(self, X, y):\n        assert len(X) == len(y), \"The number of samples in X and y must be the same.\"\n        X_b = np.c_[np.ones((len(X), 1)), X]  # Add bias term\n        self.coefficients = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n\n    @count_calls\n    def predict(self, X):\n        assert self.coefficients is not None, \"The model must be trained before prediction.\"\n        X_b = np.c_[np.ones((len(X), 1)), X]  # Add bias term\n        return X_b.dot(self.coefficients)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef average_diagonal(matrix):\n    assert matrix is not None, \"Input matrix should not be None.\"\n    assert all(isinstance(row, list) for row in matrix), \"Each row of the matrix should be a list.\"\n    assert all(len(row) == len(matrix) for row in matrix), \"The matrix should be square.\"\n    \n    n = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(n))\n    average = diagonal_sum / n\n    return average\n```",
        "```python\nfrom pedantic import count_calls\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coefficients = None\n\n    @count_calls\n    def train(self, X, y):\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        X_transpose = X_b.T\n        self.coefficients = np.linalg.inv(X_transpose.dot(X_b)).dot(X_transpose).dot(y)\n\n    @count_calls\n    def predict(self, X):\n        if self.coefficients is None:\n            raise ValueError(\"Model has not been trained yet.\")\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        return X_b.dot(self.coefficients)\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": [
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef fn_longest_common_prefix(strs):\n    \"\"\"\n    Returns the longest common prefix string from a list of strings.\n\n    :param strs: A list of strings to find the common prefix.\n    :return: The longest common prefix string.\n    \"\"\"\n    assert isinstance(strs, list), \"Input must be a list.\"\n    if not strs:\n        return \"\"\n    \n    prefix = strs[0]\n    for string in strs[1:]:\n        while not string.startswith(prefix):\n            prefix = prefix[:-1]\n            if not prefix:\n                return \"\"\n    return prefix\n```",
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef fn_compute_h_index(citations):\n    \"\"\"\n    Compute the h-index for a given array of integer citations.\n\n    The h-index is defined as the maximum value h such that the given author/journal \n    has published h papers that have each been cited at least h times.\n\n    Args:\n        citations (list of int): An array of citation counts for each publication.\n\n    Returns:\n        int: The h-index based on the given citations.\n    \"\"\"\n    assert isinstance(citations, list), \"Expected citations to be a list\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        assert isinstance(citation, int), \"Expected each citation to be an integer\"\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nfrom pedantic import count_calls\nfrom typing import List\n\n@count_calls\ndef fn_compute_diagonal_average(matrix: List[List[float]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (List[List[float]]): A square matrix represented as a list of lists of floats.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    n = len(matrix)\n    assert n > 0, \"Matrix must be non-empty.\"\n    assert all(len(row) == n for row in matrix), \"Matrix must be square.\"\n    \n    diagonal_sum = 0.0\n    for i in range(n):\n        diagonal_sum += matrix[i][i]\n    return diagonal_sum / n\n```",
        "```python\nfrom pedantic import count_calls\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coefficient = None\n        self.intercept = None\n    \n    @count_calls\n    def fn_train(self, X, y):\n        \"\"\"\n        Trains the linear regression model using the least squares method.\n\n        Args:\n            X (np.ndarray): 2D array representing the input features with shape (n_samples, n_features).\n            y (np.ndarray): 1D array representing the target values with shape (n_samples,).\n\n        Returns:\n            None\n        \"\"\"\n        assert isinstance(X, np.ndarray), \"X must be an instance of np.ndarray\"\n        assert isinstance(y, np.ndarray), \"y must be an instance of np.ndarray\"\n        assert X.shape[0] == y.shape[0], \"Number of samples in X and y must be equal\"\n\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # add bias term\n        theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n        self.intercept = theta_best[0]\n        self.coefficient = theta_best[1:]\n    \n    @count_calls\n    def fn_predict(self, X):\n        \"\"\"\n        Predicts the target values for given input features using the trained model.\n\n        Args:\n            X (np.ndarray): 2D array representing the input features with shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: 1D array of predicted target values with shape (n_samples,).\n        \"\"\"\n        assert self.coefficient is not None and self.intercept is not None, \"Model must be trained before predictions can be made\"\n        assert isinstance(X, np.ndarray), \"X must be an instance of np.ndarray\"\n\n        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n        return X_b.dot(np.r_[self.intercept, self.coefficient])\n```\n"
      ]
    }
  ]
}