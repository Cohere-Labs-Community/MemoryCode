{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\n\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \\\n            \"n_neighbors must be a positive integer\"\n        self.n_neighbors = n_neighbors\n        self.training_data = None\n        self.training_labels = None\n\n    def train(self, data, labels):\n        assert data.shape[0] == labels.shape[0], \\\n            \"Number of samples in data and labels must be equal\"\n        self.training_data = data\n        self.training_labels = labels\n\n    def predict(self, data):\n        assert self.training_data is not None and self.training_labels is not None, \\\n            \"Model must be trained before predicting\"\n        assert data.ndim == 2, \"Input data should be a 2D array\"\n        \n        predictions = []\n        for point in data:\n            distances = np.linalg.norm(self.training_data - point, axis=1)\n            nearest_neighbors_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_labels = self.training_labels[nearest_neighbors_indices]\n            unique_labels, counts = np.unique(nearest_labels, return_counts=True)\n            majority_vote = unique_labels[np.argmax(counts)]\n            predictions.append(majority_vote)\n        \n        return np.array(predictions)\n```"
      ],
      "instruction_model_output": [
        "```python\nimport numpy as np\nfrom scipy.spatial import distance\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=3):\n        assert isinstance(n_neighbors, int) and n_neighbors > 0, \"n_neighbors must be a positive integer\"\n        self.n_neighbors = n_neighbors\n        self._is_fitted = False\n\n    def train(self, X, y):\n        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), \"X and y must be numpy arrays\"\n        assert len(X) == len(y), \"Length of X and y must match\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        self.X_train = X\n        self.y_train = y\n        self._is_fitted = True\n\n    def predict(self, X):\n        assert self._is_fitted, \"Model must be trained before prediction\"\n        assert isinstance(X, np.ndarray), \"X must be a numpy array\"\n        assert len(X) > 0, \"X cannot be empty\"\n        \n        predictions = []\n        for x in X:\n            distances = distance.cdist([x], self.X_train, 'euclidean').flatten()\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_labels = self.y_train[nearest_indices]\n            prediction = np.bincount(nearest_labels).argmax()\n            predictions.append(prediction)\n        \n        return np.array(predictions)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import Optional, Any\n\nclass TreeNode:\n    def __init__(self, value: Any) -> None:\n        self.value: Any = value\n        self.left: Optional['TreeNode'] = None\n        self.right: Optional['TreeNode'] = None\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root: Optional[TreeNode] = None\n\n    def insert(self, value: Any) -> None:\n        if self.root is None:\n            self.root = TreeNode(value)\n        else:\n            self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node: TreeNode, value: Any) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = TreeNode(value)\n            else:\n                self._insert_recursive(node.left, value)\n        else:\n            if node.right is None:\n                node.right = TreeNode(value)\n            else:\n                self._insert_recursive(node.right, value)\n\n    def delete(self, value: Any) -> None:\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node: Optional[TreeNode], value: Any) -> Optional[TreeNode]:\n        if node is None:\n            return None\n        \n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            \n            node.value = self._min_value_node(node.right).value\n            node.right = self._delete_recursive(node.right, node.value)\n        \n        return node\n\n    def _min_value_node(self, node: TreeNode) -> TreeNode:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "instruction_model_output": [
        "```python\nclass TreeNode:\n    def __init__(self, key: int) -> None:\n        self.left: 'TreeNode' | None = None\n        self.right: 'TreeNode' | None = None\n        self.value: int = key\n\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root: TreeNode | None = None\n\n    def insert(self, key: int) -> None:\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert_recursively(self.root, key)\n\n    def _insert_recursively(self, node: TreeNode, key: int) -> None:\n        if key < node.value:\n            if node.left is None:\n                node.left = TreeNode(key)\n            else:\n                self._insert_recursively(node.left, key)\n        else:\n            if node.right is None:\n                node.right = TreeNode(key)\n            else:\n                self._insert_recursively(node.right, key)\n\n    def delete(self, key: int) -> None:\n        self.root = self._delete_recursively(self.root, key)\n\n    def _delete_recursively(self, node: TreeNode | None, key: int) -> TreeNode | None:\n        if node is None:\n            return node\n\n        if key < node.value:\n            node.left = self._delete_recursively(node.left, key)\n        elif key > node.value:\n            node.right = self._delete_recursively(node.right, key)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._min_value_node(node.right).value\n            node.right = self._delete_recursively(node.right, node.value)\n        return node\n\n    def _min_value_node(self, node: TreeNode) -> TreeNode:\n        current: TreeNode = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass TreeNode:\n    \"\"\"\n    Class representing a node in a binary tree.\n    \n    Attributes:\n        value (int): The value stored in the node.\n        left (TreeNode): A reference to the left child node.\n        right (TreeNode): A reference to the right child node.\n    \"\"\"\n    def __init__(self, value):\n        \"\"\"\n        Initializes a TreeNode with a value and no children.\n        \n        Args:\n            value (int): The value to be stored in the node.\n        \"\"\"\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    \"\"\"\n    Class representing a binary tree.\n    \n    Attributes:\n        root (TreeNode): The root node of the binary tree.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes a binary tree with no root node.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Inserts a new value into the binary tree.\n        \n        Args:\n            value (int): The value to be inserted into the tree.\n        \"\"\"\n        if not self.root:\n            self.root = TreeNode(value)\n        else:\n            self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        \"\"\"\n        Helper method to recursively insert a new value into the binary tree.\n        \n        Args:\n            node (TreeNode): The current node where insertion is checked.\n            value (int): The value to be inserted.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = TreeNode(value)\n            else:\n                self._insert_recursive(node.left, value)\n        else:\n            if node.right is None:\n                node.right = TreeNode(value)\n            else:\n                self._insert_recursive(node.right, value)\n\n    def delete(self, value):\n        \"\"\"\n        Deletes a value from the binary tree if it exists.\n        \n        Args:\n            value (int): The value to be deleted from the tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        \"\"\"\n        Helper method to recursively delete a value from the binary tree.\n        \n        Args:\n            node (TreeNode): The current node where deletion is checked.\n            value (int): The value to be deleted.\n        \n        Returns:\n            TreeNode: The modified tree node after deletion.\n        \"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            min_larger_node = self._min_value_node(node.right)\n            node.value = min_larger_node.value\n            node.right = self._delete_recursive(node.right, min_larger_node.value)\n\n        return node\n\n    def _min_value_node(self, node):\n        \"\"\"\n        Get the node with the minimum value found in the tree rooted at the given node.\n        \n        Args:\n            node (TreeNode): The node from which to find the minimum value node.\n        \n        Returns:\n            TreeNode: The node with the smallest value in this subtree.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "instruction_model_output": [
        "```python\nclass TreeNode:\n    def __init__(self, key):\n        \"\"\"Initialize a tree node with key and no children.\"\"\"\n        self.left = None\n        self.right = None\n        self.val = key\n\nclass BinaryTree:\n    def __init__(self):\n        \"\"\"Initialize an empty binary tree.\"\"\"\n        self.root = None\n\n    def insert(self, key):\n        \"\"\"Insert a new node with the given key.\"\"\"\n        if self.root is None:\n            self.root = TreeNode(key)\n        else:\n            self._insert(self.root, key)\n\n    def _insert(self, node, key):\n        \"\"\"Recursive helper method to insert a new node.\"\"\"\n        if key < node.val:\n            if node.left is None:\n                node.left = TreeNode(key)\n            else:\n                self._insert(node.left, key)\n        else:\n            if node.right is None:\n                node.right = TreeNode(key)\n            else:\n                self._insert(node.right, key)\n\n    def delete(self, key):\n        \"\"\"Delete the node with the given key.\"\"\"\n        self.root = self._delete(self.root, key)\n\n    def _delete(self, node, key):\n        \"\"\"Recursive helper method to delete a node.\"\"\"\n        if node is None:\n            return node\n\n        if key < node.val:\n            node.left = self._delete(node.left, key)\n        elif key > node.val:\n            node.right = self._delete(node.right, key)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            min_larger_node = self._find_min(node.right)\n            node.val = min_larger_node.val\n            node.right = self._delete(node.right, min_larger_node.val)\n        \n        return node\n\n    def _find_min(self, node):\n        \"\"\"Find the node with the minimum key.\"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom sklearn.metrics.pairwise import rbf_kernel\nimport numpy as np\nfrom pedantic import trace_class\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"rbf\", gamma=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.X_train = None\n        self.y_train = None\n        self.dual_coef_ = None\n\n    def fit(self, X, y):\n        K = self._compute_kernel(X, X)\n        n_samples = X.shape[0]\n        self.dual_coef_ = np.linalg.inv(K + self.alpha * np.eye(n_samples)).dot(y)\n        self.X_train = X\n        self.y_train = y\n\n    def predict(self, X):\n        K = self._compute_kernel(X, self.X_train)\n        return K.dot(self.dual_coef_)\n\n    def _compute_kernel(self, X, Y):\n        if self.kernel == \"rbf\":\n            if self.gamma is None:\n                self.gamma = 1.0 / X.shape[1]\n            return rbf_kernel(X, Y, gamma=self.gamma)\n        else:\n            raise ValueError(f\"Kernel '{self.kernel}' not recognized. Only 'rbf' is supported.\")\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom pedantic import trace_class\nimport numpy as np\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.X_train = None\n        self.alpha_ = None\n    \n    def _linear_kernel(self, X, Y):\n        return np.dot(X, Y.T)\n\n    def _polynomial_kernel(self, X, Y):\n        return (np.dot(X, Y.T) + self.coef0) ** self.degree\n\n    def _rbf_kernel(self, X, Y):\n        if self.gamma is None:\n            self.gamma = 1.0 / X.shape[1]\n        K = np.sum(X ** 2, axis=1).reshape(-1, 1) + np.sum(Y ** 2, axis=1) - 2 * np.dot(X, Y.T)\n        return np.exp(-self.gamma * K)\n\n    def _get_kernel(self, X, Y):\n        if self.kernel == 'linear':\n            return self._linear_kernel(X, Y)\n        elif self.kernel == 'polynomial':\n            return self._polynomial_kernel(X, Y)\n        elif self.kernel == 'rbf':\n            return self._rbf_kernel(X, Y)\n        else:\n            raise ValueError(\"Unknown kernel type\")\n\n    def fit(self, X, y):\n        self.X_train = X\n        K = self._get_kernel(X, X)\n        n_samples = X.shape[0]\n        self.alpha_ = np.linalg.solve(K + self.alpha * np.eye(n_samples), y)\n\n    def predict(self, X):\n        K = self._get_kernel(X, self.X_train)\n        return np.dot(K, self.alpha_)\n\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(a_vector1, a_vector2):\n    if len(a_vector1) != len(a_vector2):\n        raise ValueError(\"Vectors must be the same length\")\n    return sum(a_v1 * a_v2 for a_v1, a_v2 in zip(a_vector1, a_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vector1, a_vector2):\n    if len(a_vector1) != len(a_vector2):\n        raise ValueError(\"Vectors must be of the same length.\")\n    return sum(a_v1 * a_v2 for a_v1, a_v2 in zip(a_vector1, a_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(g_vector1, g_vector2):\n    if len(g_vector1) != len(g_vector2):\n        raise ValueError(\"Vectors must be of the same length\")\n    return sum(g_v1 * g_v2 for g_v1, g_v2 in zip(g_vector1, g_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "```python\nfrom sklearn.metrics.pairwise import pairwise_kernels\nimport numpy as np\nfrom pedantic import trace_class\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, a_alpha: float = 1.0, a_kernel: str = 'linear', **kwargs):\n        self.alpha = a_alpha\n        self.kernel = a_kernel\n        self.kwargs = kwargs\n        self.X_fit_ = None\n        self.dual_coef_ = None\n\n    def fit(self, g_X: np.ndarray, g_y: np.ndarray) -> 'KernelRidgeRegression':\n        assert len(g_X) == len(g_y), \"Input arrays must have the same length.\"\n        self.X_fit_ = g_X\n        K = pairwise_kernels(g_X, g_X, metric=self.kernel, **self.kwargs)\n        n_samples, _ = K.shape\n        self.dual_coef_ = np.linalg.solve(K + self.alpha * np.eye(n_samples), g_y)\n        return self\n\n    def predict(self, g_X: np.ndarray) -> np.ndarray:\n        assert self.X_fit_ is not None, \"The model has not been fitted yet.\"\n        K = pairwise_kernels(g_X, self.X_fit_, metric=self.kernel, **self.kwargs)\n        return np.dot(K, self.dual_coef_)\n```\n",
        "```python\nfrom typing import List\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\nfrom pedantic import trace_class\n\n@trace_class\nclass KNearestNeighborsModel:\n    def __init__(self, a_n_neighbors: int = 5):\n        self._n_neighbors = a_n_neighbors\n        self._model = NearestNeighbors(n_neighbors=self._n_neighbors)\n\n    def train(self, a_X_train: np.ndarray) -> None:\n        assert isinstance(a_X_train, np.ndarray), \"Training data must be a numpy array\"\n        self._model.fit(a_X_train)\n\n    def predict(self, a_X_test: np.ndarray) -> List[np.ndarray]:\n        assert isinstance(a_X_test, np.ndarray), \"Test data must be a numpy array\"\n        distances, indices = self._model.kneighbors(a_X_test)\n        return indices.tolist()\n```",
        "```python\nfrom pedantic import trace_class\n\n@trace_class\nclass Node:\n    def __init__(self, g_value: int) -> None:\n        self.value: int = g_value\n        self.left: 'Node' = None\n        self.right: 'Node' = None\n\n@trace_class\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root: Node = None\n\n    def insert(self, g_value: int) -> None:\n        if self.root is None:\n            self.root = Node(g_value)\n        else:\n            self._insert(self.root, g_value)\n\n    def _insert(self, g_current_node: Node, g_value: int) -> None:\n        if g_value < g_current_node.value:\n            if g_current_node.left is None:\n                g_current_node.left = Node(g_value)\n            else:\n                self._insert(g_current_node.left, g_value)\n        elif g_value > g_current_node.value:\n            if g_current_node.right is None:\n                g_current_node.right = Node(g_value)\n            else:\n                self._insert(g_current_node.right, g_value)\n\n    def delete(self, g_value: int) -> None:\n        self.root = self._delete(self.root, g_value)\n\n    def _delete(self, g_current_node: Node, g_value: int) -> Node:\n        if g_current_node is None:\n            return None\n\n        if g_value < g_current_node.value:\n            g_current_node.left = self._delete(g_current_node.left, g_value)\n        elif g_value > g_current_node.value:\n            g_current_node.right = self._delete(g_current_node.right, g_value)\n        else:\n            if g_current_node.left is None:\n                return g_current_node.right\n            elif g_current_node.right is None:\n                return g_current_node.left\n\n            successor_value = self._min_value_node(g_current_node.right).value\n            g_current_node.value = successor_value\n            g_current_node.right = self._delete(g_current_node.right, successor_value)\n\n        return g_current_node\n\n    def _min_value_node(self, g_node: Node) -> Node:\n        current: Node = g_node\n        while current.left is not None:\n            current = current.left\n        return current\n```\n",
        "```python\nfrom typing import List\n\ndef dot_product(g_vector1: List[float], g_vector2: List[float]) -> float:\n    \"\"\"\n    Calculate the dot product of two vectors.\n\n    Args:\n        g_vector1: A list of floats representing the first vector.\n        g_vector2: A list of floats representing the second vector.\n\n    Returns:\n        The dot product of the two vectors.\n\n    Raises:\n        ValueError: If the vectors have different lengths.\n    \"\"\"\n    assert len(g_vector1) == len(g_vector2), \"Vectors must be of the same length\"\n    \n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```\n"
      ]
    }
  ]
}