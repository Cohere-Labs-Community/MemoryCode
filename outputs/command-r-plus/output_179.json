{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_lengths_from_source_x(self, src):\n        dist = [float('Inf')] * self.V\n        dist[src] = 0\n\n        for _ in range(self.V):\n            for u in range(self.V):\n                for v in self.graph[u]:\n                    if dist[u] != float('Inf') and dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n\n        return dist\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def int_to_roman_o(num):\n    \"\"\"Convert an integer to Roman numeral.\n    \"\"\"\n    vals = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    syms = ['M', 'CM', 'D', 'CD', 'C', 'XC', 'L', 'XL', 'X', 'IX', 'V', 'IV', 'I']\n    roman = ''\n    i = 0\n    while num > 0:\n        for _ in range(num // vals[i]):\n            roman += syms[i]\n            num %= vals[i]\n        i += 1\n    return roman",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    # Adds an edge to the graph\n    def add_edge_o(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    # Uses BFS to find the shortest path between two nodes\n    def shortest_path_o(self, src, dest):\n        visited = [False] * self.V\n        queue = []\n        queue.append(src)\n        visited[src] = True\n\n        # Perform BFS traversal starting from the source node\n        while queue:\n            u = queue.pop(0)\n\n            # Check if the current node is the destination node\n            if u == dest:\n                return u\n\n            # Explore neighbors of the current node\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n        return None\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, n_features: int, n_classes: int):\n        self.n_features = n_features\n        self.n_classes = n_classes\n        self.means = None\n        self.cov_matrices = None\n        self.priors = None\n\n    def fit(self, X, y):\n        n_samples, self.n_features = X.shape\n        self.means = []\n        self.cov_matrices = []\n        self.priors = []\n\n        class_counts = {}\n        for label in y:\n            class_counts[label] = class_counts.get(label, 0) + 1\n\n        self.priors = [class_counts[i] / n_samples for i in range(self.n_classes)]\n\n        for i in range(self.n_classes):\n            X_i = X[y == i]\n            self.means.append(X_i.mean(axis=0))\n            self.cov_matrices.append(np.cov(X_i.T))\n\n    def predict(self, X):\n        posterior = self._calculate_posterior(X)\n        return np.argmax(posterior, axis=1)\n\n    def _calculate_posterior(self, X):\n        n_samples, _ = X.shape\n        posterior = np.zeros((n_samples, self.n_classes))\n\n        for i in range(self.n_classes):\n            exponent = self._calculate_exponent(X, i)\n            posterior[:, i] = self.priors[i] * np.prod(exponent, axis=1)\n\n        posterior = posterior / posterior.sum(axis=1, keepdims=True)\n        return posterior\n\n    def _calculate_exponent(self, X, class_idx: int):\n        diff = X - self.means[class_idx]\n        exponent = np.einsum('ij,ij->i', diff, np.linalg.inv(self.cov_matrices[class_idx]) @ diff)\n        return exponent\n```",
        "```python\nfrom pedantic import timer_class\n\n@timer_class\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n\n        queue = []\n        queue.append(src)\n        visited[src] = True\n\n        while queue:\n            u = queue.pop(0)\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n                    if v == dest:\n                        break\n\n        path_str = [str(i) for i in path]\n        return ' -> '.join(path_str[dest:]) + ' (distance: {})'.format(dist[dest])\n```"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def shortest_path_a(self, src, dest):\n        dist = [float('inf') for _ in range(self.V)]\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        while True:\n            u = self._minimum_distance_node_a(dist, spt_set)\n            if u == -1:\n                break\n            spt_set[u] = True\n\n            for v in range(self.V):\n                if (\n                    self.graph[u][v] > 0\n                    and spt_set[v] is False\n                    and dist[v] > dist[u] + self.graph[u][v]\n                ):\n                    dist[v] = dist[u] + self.graph[u][v]\n\n        return dist[dest]\n\n    def _minimum_distance_node_a(self, dist, spt_set):\n        min_dist = float('inf')\n        min_node = -1\n\n        for v in range(self.V):\n            if spt_set[v] is False and dist[v] <= min_dist:\n                min_dist = dist[v]\n                min_node = v\n\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * vertices for _ in range(vertices)]\n\n    @validate\n    def add_edge_p(self, source, destination, weight):\n        self.adj_matrix[source][destination] = weight\n\n    def shortest_path_p(self, source, destination):\n        # Initialize distances and visited\n        distances = [float('inf')] * self.vertices\n        distances[source] = 0\n        visited = [False] * self.vertices\n\n        # Create a queue for BFS\n        queue = []\n        queue.append(source)\n        visited[source] = True\n\n        # BFS traversal\n        while queue:\n            u = queue.pop(0)\n            for v in range(self.vertices):\n                if self.adj_matrix[u][v] != 0 and not visited[v]:\n                    distance = self.adj_matrix[u][v] + distances[u]\n                    if distance < distances[v]:\n                        distances[v] = distance\n                        queue.append(v)\n                    visited[v] = True\n\n        # Return the shortest distance or None if no path exists\n        if distances[destination] == float('inf'):\n            return None\n        return distances[destination]\n```",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_book_p(self, book):\n        self._validate_book(book)\n        self.books.append(book)\n\n    def remove_book_p(self, book_title):\n        self.books = [book for book in self.books if book.title != book_title]\n\n    @staticmethod\n    def _validate_book(book):\n        if not hasattr(book, 'title'):\n            raise ValueError('Book must have a title attribute')\n        if not hasattr(book, 'author'):\n            raise ValueError('Book must have an author attribute')\n\n    @add_book_p.validator\n    @remove_book_p.validator\n    def validate_input(cls, book=None, book_title=None):\n        if book and not isinstance(book, dict):\n            raise ValueError('Book must be provided as a dict')\n        if book_title and not isinstance(book_title, str):\n            raise ValueError('Book title must be a string')\n\n    add_book_p, remove_book_p = Pedantic.add_decorators(Library, ['add_book_p', 'remove_book_p'])"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "```python\ndef int_to_roman(num: int) -> str:\n    val_map = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\"),\n    ]\n    roman = \"\"\n    for val, sym in val_map:\n        while num >= val:\n            roman += sym\n            num -= val\n    return roman\n```",
        "```python\nfrom pedantic import timer_class, validate\n\nclass Library:\n    \"\"\"A library class to manage a collection of books.\"\"\"\n\n    @timer_class\n    @validate\n    def add_books(self, books: list[dict]) -> None:\n        \"\"\"\n        Add multiple books to the library.\n\n        Args:\n            books (list[dict]): A list of book dictionaries containing 'title', 'author', and 'genre'.\n\n        Returns:\n            None\n        \"\"\"\n        # Code to add books to the library\n        pass\n\n    @timer_class\n    @validate\n    def remove_books(self, book_titles: list[str]) -> list[str]:\n        \"\"\"\n        Remove books from the library by title.\n\n        Args:\n            book_titles (list[str]): A list of book titles to be removed.\n\n        Returns:\n            list[str]: A list of removed book titles.\n        \"\"\"\n        # Code to remove books from the library\n        pass\n```",
        "```python\nfrom pedantic import timer_class, validate\n\nclass Graph:\n    @timer_class\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)]\n                      for _ in range(vertices)]\n\n    @validate\n    def shortest_path(self, source, destination):\n        # Create a visited set and a distance dictionary\n        visited = set()\n        distances = {}\n\n        # Initialize distances to all vertices as infinite\n        for vertex in range(self.V):\n            distances[vertex] = float('inf')\n\n        # Set the distance to source as 0\n        distances[source] = 0\n\n        # Perform BFS traversal starting from the source node\n        queue = []\n        queue.append(source)\n\n        while queue:\n            u = queue.pop(0)\n            visited.add(u)\n\n            for ind, val in enumerate(self.graph[u]):\n                if val > 0 and ind not in visited:\n                    queue.append(ind)\n                    distances[ind] = distances[u] + 1\n\n                    if ind == destination:\n                        break\n\n        # Return the shortest distance from source to destination\n        return distances[destination]\n```",
        "```python\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.externals import six\n\n@timer_class\nclass QuadraticDiscriminantAnalysis_p:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n\n    Parameters\n    ----------\n    store_covariance : bool, optional (default=False)\n        Whether to store the covariance matrices for each class.\n\n    tol : float, optional\n        Tolerance for eigenvalues which are considered to be zero in\n        covariance matrix estimation.\n\n    priors : array-like, shape = (n_classes,), optional\n        Prior probabilities of the classes. If specified the\n        priors are not adjusted according to the data.\n\n    Attributes\n    ----------\n    class_count_ : int\n        Number of classes.\n\n    classes_ : ndarray, shape (n_classes, )\n        Class labels for each class.\n\n    covariance_ : ndarray, shape (n_classes, n_features, n_features)\n        Covariance matrices for each class.\n\n    priors_ : ndarray, shape (n_classes,)\n        Prior probability of each class (smoothened).\n\n    means_ : ndarray, shape (n_classes, n_features)\n        Mean vectors for each class.\n\n    variances_ : ndarray, shape (n_classes, n_features)\n        Variances for each class and feature.\n\n    X_ : ndarray, shape (n_samples, n_features)\n        The training data.\n\n    feature_names_in_ : ndarray\n        Names of features seen during :term:`fit`. Defined only when\n        `X` has feature names that are all strings.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n    \"\"\"\n    def __init__(self, store_covariance=False, tol=0.0001, priors=None):\n        self.store_covariance = store_covariance\n        self.tol = tol\n        self.priors = priors\n\n    def fit(self, X, y):\n        \"\"\"Fit QDA model according to the given training data and parameters.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        self._check_fit_data(X, y)\n        self.classes_, y = self._encode_y(y)\n        self.class_count_ = len(self.classes_)\n        self.X_ = X\n\n        if self.priors is None:\n            self.priors_ = self._default_priors(y)\n        else:\n            self.priors_ = self.priors\n\n        self._validate_priors()\n\n        self._fit_covariances()\n        self._fit(X, y)\n        return self\n\n    def _validate_X_predict(self, X):\n        check_is_fitted(self, 'means_')\n        X = self._validate_data(\n            X,\n            reset=False,\n            accept_sparse=['csr', 'csc', 'coo'],\n            dtype=[float64, float32],\n            order=\"C\"\n        )\n        return X\n\n    def predict(self, X):\n        \"\"\"Perform classification on an array of test vectors X.\n\n        For a multi-class problem, the class with highest probability is\n        returned for each input vector.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        C : ndarray, shape (n_samples,)\n            Predicted class label per sample.\n        \"\"\"\n        X = self._validate_X_predict(X)\n        scores = self.decision_function(X)\n        if len(scores.shape) == 1:\n            indices = (scores > 0).astype(int)\n        else:\n            indices = scores.argmax(axis=1)\n        return self.classes_[indices]\n\n    def _fit_covariances(self):\n        \"\"\"Fit the covariance matrices for each class.\n        \"\"\"\n        self.covariance_ = []\n        self.variances_ = []\n        self.means_ = []\n        for i in range(self.class_count_):\n            Xi = self.X_[y == self.classes_[i]]\n            self.means_.append(Xi.mean(axis=0))\n            if self.store_covariance:\n                self.covariance_.append(\n                    np.cov(Xi.T, bias=True, ddof=self.covariance_bias)\n                )\n            else:\n                self.variances_.append(Xi.var(axis=0, ddof=self.covariance_bias))\n\n    def _fit(self, X, y):\n        \"\"\"Fit the model according to the given training data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n        \"\"\"\n        self._check_n_features(X, reset=False)\n        self._set_n_features_in(X)\n\n        self._validate_y(y)\n\n        self.classes_, y = self._encode_y(y)\n        self.class_count_ = len(self.classes_)\n\n        self._validate_priors()\n\n        self._fit_covariances()\n\n        self._check_covariance()\n\n        self._compute_weights()\n\n    @validate(X=check_array, y=check_classification_targets)\n    def score(self, X, y, sample_weight=None):\n        \"\"\"Return the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Test samples.\n\n        y : array-like, shape = (n_samples,) or (n_samples, n_outputs)\n            True labels for X.\n\n        sample_weight : array-like, shape = [n_samples], optional\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` wrt. ``y``.\n        \"\"\"\n        from sklearn.metrics import accuracy_score\n\n        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n```"
      ]
    }
  ]
}