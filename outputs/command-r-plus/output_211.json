{
  "sessions": [
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_a(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        m_visited = [False] * self.V\n\n        m_stack = []\n        m_stack.append(src)\n        while m_stack:\n            u = m_stack.pop()\n            m_visited[u] = True\n            for v in self.graph[u]:\n                if not m_visited[v]:\n                    m_stack.append(v)\n                    dist[v] = dist[u] + 1\n\n        return dist\n```",
        "def is_valid_sudoku_a(board_a):\n    rows_a = [set() for _ in range(9)]\n    cols_a = [set() for _ in range(9)]\n    boxes_a = [set() for _ in range(9)]\n\n    for i_a in range(9):\n        for j_a in range(9):\n            num_a = board_a[i_a][j_a]\n            if num_a != '.':\n                num_a = int(num_a)\n                box_index_a = (i_a // 3) * 3 + j_a // 3\n\n                if (\n                    num_a in rows_a[i_a]\n                    or num_a in cols_a[j_a]\n                    or num_a in boxes_a[box_index_a]\n                ):\n                    return False\n\n                rows_a[i_a].add(num_a)\n                cols_a[j_a].add(num_a)\n                boxes_a[box_index_a].add(num_a)\n\n    return True"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```",
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, classes):\n        self.classes = classes\n        self.means = None\n        self.cov_matrix = None\n        self.priors = None\n\n    def fit(self, X, y):\n        self.means = []\n        self.cov_matrix = []\n        self.priors = [len(X[y == i]) / len(y) for i in self.classes]\n\n        for cls in self.classes:\n            self.means.append(X[y == cls].mean(axis=0))\n            self.cov_matrix.append(\n                (X[y == cls] - self.means[-1]).T @ (X[y == cls] - self.means[-1]) / len(X[y == cls])\n            )\n\n    def predict(self, X):\n        log_prob = self._calculate_log_prob(X)\n        return log_prob.argmax(axis=1)\n\n    def predict_proba(self, X):\n        log_prob = self._calculate_log_prob(X)\n        prob = log_prob - log_prob.max(axis=1, keepdims=True)\n        prob = prob.exp()\n        return prob / prob.sum(axis=1, keepdims=True)\n\n    def _calculate_log_prob(self, X):\n        log_prob = []\n        for i, cls in enumerate(self.classes):\n            mean = self.means[i].reshape(1, -1)\n            cov = self.cov_matrix[i].reshape(-1, 1)\n            log_det = cov.log().sum()\n            inv_cov = cov.inv()\n            x_minus_mean = (X - mean).reshape(-1, 1)\n            log_prob.append(\n                -0.5 * (x_minus_mean @ inv_cov @ x_minus_mean + len(X) * log_det + len(X) * np.log(2 * np.pi))\n                + np.log(self.priors[i])\n            )\n\n        return np.column_stack(log_prob)"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def wr_is_valid_sudoku(wr_board):\n    wr_set = set()\n    for wr_i in range(9):\n        wr_temp_set = set()\n        for wr_j in range(9):\n            if wr_board[wr_i][wr_j] != '.':\n                if wr_board[wr_i][wr_j] in wr_set or wr_board[wr_j][wr_i] in wr_temp_set:\n                    return False\n                wr_temp_set.add(wr_board[wr_i][wr_j])\n                wr_set.add(wr_board[wr_j][wr_i])\n        wr_set = wr_temp_set\n    for wr_i in range(0, 9, 3):\n        for wr_j in range(0, 9, 3):\n            wr_temp_set = set()\n            for wr_x in range(wr_i, wr_i + 3):\n                for wr_y in range(wr_j, wr_j + 3):\n                    if wr_board[wr_x][wr_y] != '.':\n                        if wr_board[wr_x][wr_y] in wr_temp_set:\n                            return False\n                        wr_temp_set.add(wr_board[wr_x][wr_y])\n    return True",
        "```python\ndef is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n    if not root:\n        return True\n\n    try:\n        val = root.val\n        if val <= min_val or val >= max_val:\n            return False\n\n        return is_valid_bst(root.left, min_val, val) and is_valid_bst(root.right, val, max_val)\n\n    except AttributeError as e:\n        raise AttributeError(f\"Error: {e}. Please ensure your tree nodes have a 'val' attribute.\")\n\n# Sample tree structure\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\n# Example tree initialization\n# ...\n\n# To check if the tree is a valid BST:\n# is_valid_bst(root)\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current = board[i][j]\n            if current in row or current in col or current in box:\n                return False\n            row.add(current)\n            col.add(current[1:])\n            box.add(current[int(current[0]) // 3 * 3 + int(current[1]) // 3])\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Inserts a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        Args:\n            value: The value to be inserted.\n            node: The current node in the recursive traversal.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Deletes the first occurrence of a node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        Args:\n            node: The current node in the recursive traversal.\n            value: The value of the node to be deleted.\n\n        Returns:\n            The new root of the modified subtree or None if the node is deleted.\n        \"\"\"\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        \"\"\"\n        Recursive helper function to find the inorder successor (smallest value in the right subtree).\n\n        Args:\n            node: The current node in the recursive traversal.\n\n        Returns:\n            The value of the inorder successor.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    \"\"\"\n    A node in the binary tree.\n    \"\"\"\n    def __init__(self, value):\n        \"\"\"\n        Initializes a new node with the given value.\n\n        Args:\n            value: The value to be stored in the node.\n        \"\"\"\n        self.value = value\n        self.left = None\n        self.right = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x_(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_x_(self, src, dest):\n        assert 0 <= src < self.V and 0 <= dest < self.V, \"Invalid source or destination node\"\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        while True:\n            u = self.min_distance_node_x_(dist, spt_set)\n            if u == -1 or u == dest:\n                break\n            spt_set[u] = True\n            for v, weight in self.graph[u]:\n                if not spt_set[v] and dist[u] != float('inf') and dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n\n        return dist[dest]\n\n    def min_distance_node_x_(self, dist, spt_set):\n        min_dist = float('inf')\n        min_node = -1\n        for u in range(self.V):\n            if not spt_set[u] and dist[u] < min_dist:\n                min_dist = dist[u]\n                min_node = u\n        return min_node",
        "class NearestNeighborsModel:\n    def __init__(self):\n        self.model = None\n\n    def train_x(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"_x: Input data and labels must have the same number of samples.\"\n        assert len(y_train.shape) == 1, \"_x: Labels must be a 1D array.\"\n\n        self.model = NearestNeighbors(n_neighbors=1)\n        self.model.fit(X_train, y_train)\n\n    def predict_x(self, X_test):\n        assert self.model is not None, \"_x: Model must be trained before making predictions.\"\n        assert X_test.shape[1:] == self.model.transform(X_test).shape[1:], \"_x: Test data must have the same features as the training data.\"\n\n        _, indices = self.model.kneighbors(X_test)\n        return self.model.y[indices]"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def check_valid_sudoku(board):\n    box_values = set()\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box_values = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    val = board[x][y]\n                    if val != '.':\n                        if val in box_values:\n                            return False\n                        box_values.add(val)\n                    if val != '.':\n                        if val in range(1, 10):\n                            row_values = set()\n                            col_values = set()\n                            for x_ in range(9):\n                                if board[x_][y] != '.':\n                                    if board[x_][y] in col_values:\n                                        return False\n                                    col_values.add(board[x_][y])\n                                if board[x][x_] != '.':\n                                    if board[x][x_] in row_values:\n                                        return False\n                                    row_values.add(board[x][x_])\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_p(self, start_node, end_node):\n        \"\"\"\n        Computes the shortest path from 'start_node' to 'end_node' in the graph.\n\n        :param start_node: The starting node.\n        :type start_node: str\n        :param end_node: The target node.\n        :type end_node: str\n        :return: The shortest path from 'start_node' to 'end_node'.\n        :rtype: list[str]\n        \"\"\"\n        # Implement your shortest path algorithm here\n        # ...\n\n        return shortest_path",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    # Insert node method with '_p' suffix and type annotations\n    def insert_node_p(self, data: int) -> None:\n        if not self.root:\n            self.root = Node(data)\n        else:\n            self._insert_recursive_p(self.root, data)\n\n    def _insert_recursive_p(self, node: 'Node', data: int) -> None:\n        if data < node.data:\n            if node.left is None:\n                node.left = Node(data)\n            else:\n                self._insert_recursive_p(node.left, data)\n        else:\n            if node.right is None:\n                node.right = Node(data)\n            else:\n                self._insert_recursive_p(node.right, data)\n\n    # Delete node method with '_p' suffix and type annotations\n    def delete_node_p(self, data: int) -> None:\n        self.root = self._delete_recursive_p(self.root, data)\n\n    def _delete_recursive_p(self, node: 'Node', data: int) -> 'Node':\n        if node is None:\n            return node\n\n        if data < node.data:\n            node.left = self._delete_recursive_p(node.left, data)\n        elif data > node.data:\n            node.right = self._delete_recursive_p(node.right, data)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.data = self._get_min_value_p(node.right)\n            node.right = self._delete_recursive_p(node.right, node.data)\n\n        return node\n\n    def _get_min_value_p(self, node: 'Node') -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.data\n\n\nclass Node:\n    def __init__(self, data: int):\n        self.data = data\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book(self, book_title: str, author: str, genre: str):\n        book = {\n            \"title\": book_title,\n            \"author\": author,\n            \"genre\": genre\n        }\n        self.books.append(book)\n\n    @validate\n    def remove_book(self, book_title: str):\n        self.books = [book for book in self.books if book[\"title\"].lower() != book_title.lower()]\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom locale import *\n\ndef lcm_calc_md(num1: int, num2: int) -> int:\n    \"\"\"\n    Calculate the least common multiple of two integers.\n\n    :param num1: The first integer.\n    :param num2: The second integer.\n    :return: The least common multiple of 'num1' and 'num2'.\n    \"\"\"\n    gcd = lambda a, b: b if not a else gcd(b % a, a)\n    lcm = num1 * num2 // gcd(num1, num2)\n    return lcm\n```",
        "```python\nfrom locale import *\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_dijsktra(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt = []\n\n        for _ in range(self.V):\n            u = self.min_distance(dist, spt)\n            spt.append(u)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n\n        return dist\n\n    def min_distance(self, dist, spt):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist and v not in spt:\n                min_dist = dist[v]\n                min_node = v\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num in row or current_num in col or current_num in box:\n                return False\n            row.add(current_num)\n            col.add(current_num)\n            if (i // 3) * 3 + j // 3 in (0, 1, 2):\n                box.add(current_num)\n            elif (i // 3) * 3 + j // 3 in (3, 4, 5):\n                box.add(current_num)\n            else:\n                box = set(current_num)\n        box = set()\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_s = None\n\n    def append(self, value):\n        new_node = Node(value)\n        if not self.head_s:\n            self.head_s = new_node\n        else:\n            current_s = self.head_s\n            while current_s.next_s:\n                current_s = current_s.next_s\n            current_s.next_s = new_node\n\n    def display(self):\n        current_s = self.head_s\n        while current_s:\n            print(current_s.value_s, end=\" -> \")\n            current_s = current_s.next_s\n        print(\"None\")\n\n\nclass Node:\n    def __init__(self, value):\n        self.value_s = value\n        self.next_s = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "```python\nimport locale\nfrom pedantic import validate\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    @_x\n    @_md\n    @_p\n    def insert(self, value: int) -> None:\n        \"\"\"Insert a value into the binary tree.\"\"\"\n        self.root = self._insert_recursive(self.root, value)\n\n    @_x\n    @_md\n    def _insert_recursive(self, node, value: int) -> 'Node':\n        \"\"\"Recursive helper function for inserting a value.\"\"\"\n        if node is None:\n            return Node(value)\n\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n\n        return node\n\n    @_x\n    @_md\n    @_p\n    def delete(self, value: int) -> None:\n        \"\"\"Delete a value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    @_x\n    @_md\n    def _delete_recursive(self, node, value: int) -> 'Node':\n        \"\"\"Recursive helper function for deleting a value.\"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            # Case 1: Node has no children\n            if node.left is None and node.right is None:\n                node = None\n                return node\n\n            # Case 2: Node has only one child\n            if node.left is None:\n                node = node.right\n            elif node.right is None:\n                node = node.left\n            else:\n                # Case 3: Node has two children\n                successor = self._get_successor(node.right)\n                node.value = successor.value\n                node.right = self._delete_recursive(node.right, successor.value)\n\n        return node\n\n    @_x\n    @_md\n    def _get_successor(self, node) -> 'Node':\n        \"\"\"Find the successor of a given node.\"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\n    @_x\n    @_md\n    @_p\n    def search(self, value: int) -> bool:\n        \"\"\"Search for a value in the binary tree.\"\"\"\n        return self._search_recursive(self.root, value)\n\n    @_x\n    @_md\n    def _search_recursive(self, node, value: int) -> bool:\n        \"\"\"Recursive helper function for searching a value.\"\"\"\n        if node is None or node.value == value:\n            return node is not None\n\n        if value < node.value:\n            return self._search_recursive(node.left, value)\n        return self._search_recursive(node.right, value)\n\nclass Node:\n    @_x\n    def __init__(self, value: int):\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "```python\r\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\r\n    seen = set()\r\n    for row in board:\r\n        for item in row:\r\n            if item != '.':\r\n                if item in seen:\r\n                    return False\r\n                seen.add(item)\r\n                seen = set()\r\n    for col in zip(*board):\r\n        for item in col:\r\n            if item != '.':\r\n                if item in seen:\r\n                    return False\r\n                seen.add(item)\r\n                seen = set()\r\n    for i in range(0, len(board), 3):\r\n        for j in range(0, len(board), 3):\r\n            box = [board[p][q] for p in range(i, i + 3) for q in range(j, j + 3)]\r\n            for item in box:\r\n                if item != '.':\r\n                    if item in seen:\r\n                        return False\r\n                    seen.add(item)\r\n                    seen = set()\r\n    return True\r\n```",
        "```python\nimport locale\nfrom pedantic import validate\n\n# Define the Graph class\nclass Graph:\n    \"\"\"\n    A Graph class for finding the shortest path between nodes.\n    \"\"\"\n    def __init__(self):\n        self.nodes = []\n        self.edges = []\n\n    # Method to compute the shortest path from one node to another\n    def shortest_path_md(self, start_node: str, end_node: str) -> list[str]:\n        \"\"\"\n        Computes the shortest path from 'start_node' to 'end_node'.\n\n        Args:\n            start_node (str): The starting node.\n            end_node (str): The target node.\n\n        Returns:\n            list[str]: The shortest path from 'start_node' to 'end_node'.\n        \"\"\"\n        # Validate the input nodes\n        @validate\n        def _validate_input(start_node: str, end_node: str):\n            assert start_node in self.nodes, f\"Start node '{start_node}' not found in the graph.\"\n            assert end_node in self.nodes, f\"End node '{end_node}' not found in the graph.\"\n            return start_node, end_node\n\n        start_node, end_node = _validate_input(start_node, end_node)\n\n        # Implement Dijkstra's algorithm or a similar method to find the shortest path\n        # ... Your code here ...\n\n        return shortest_path\n```",
        "```python\ndef is_valid_bst(root: 'node_s') -> 'bool_a':\n    \"\"\"\n    Determines if a given tree is a valid binary search tree.\n\n    Args:\n        root (node_s): The root of the binary tree.\n\n    Returns:\n        bool_a: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    def helper(node: 'node_s', min_val: 'int_a', max_val: 'int_a') -> 'bool_a':\n        if node is None:\n            return True_a\n        if node.val >= max_val or node.val <= min_val:\n            return False_a\n        return helper(node.left, min_val, node.val - 1) and helper(node.right, node.val + 1, max_val)\n\n    return helper(root, float('-inf'), float('inf'))\n```",
        "```python\ndef lcm_a(num1: int, num2: int) -> int:\n    \"\"\"\n    Calculates the least common multiple of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The least common multiple of num1 and num2.\n    \"\"\"\n    # Initialize variables with the standard prefix\n    wr_max = max(num1, num2)\n    wr_min = min(num1, num2)\n    wr_lcm = 0\n\n    # Calculate the least common multiple\n    for wr_i in range(wr_max, wr_min, -1):\n        if wr_i % num1 == 0 and wr_i % num2 == 0:\n            wr_lcm = wr_i\n            break\n\n    assert wr_lcm > 0, \"Least common multiple should be greater than zero\"\n    return wr_lcm\n```",
        "```python\n# Import locale module as per mentor's instruction\nimport locale\n\nclass LinkedList:\n    \"\"\"\n    A Pythonic implementation of a singly linked list.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialize an empty linked list.\n        \"\"\"\n        self.head_x = None\n        self._size_md = 0\n\n    def append_x(self, value_md):\n        \"\"\"\n        Append a value to the end of the linked list.\n\n        Args:\n            value_md (int or float): The value to be appended.\n\n        Returns:\n            None\n        \"\"\"\n        # Create a new node with the given value\n        new_node_x = Node(value_md)\n\n        # If the linked list is empty, set the new node as the head\n        if self.head_x is None:\n            self.head_x = new_node_x\n        else:\n            # Otherwise, traverse to the last node and insert the new node after it\n            current_node_x = self.head_x\n            while current_node_x.next_x:\n                current_node_x = current_node_x.next_x\n            current_node_x.next_x = new_node_x\n\n        self._size_md += 1\n\n    def get_value_at_index_p(self, index_p: int) -> int:\n        \"\"\"\n        Get the value at the specified index in the linked list.\n\n        Args:\n            index_p (int): The index of the value to retrieve.\n\n        Returns:\n            int: The value at the specified index.\n        \"\"\"\n        assert 0 <= index_p < self._size_md, \"Index out of range.\"\n\n        current_node_x = self.head_x\n        for _ in range(index_p):\n            current_node_x = current_node_x.next_x\n\n        return current_node_x.value_md\n\n    # Add more methods here as needed...\n\n    def __len__(self) -> int:\n        \"\"\"\n        Get the number of elements in the linked list.\n\n        Returns:\n            int: The size of the linked list.\n        \"\"\"\n        return self._size_md\n\nclass Node:\n    \"\"\"\n    A simple node class to hold the value and the reference to the next node.\n    \"\"\"\n    def __init__(self, value_md):\n        \"\"\"\n        Initialize a new node with the given value.\n\n        Args:\n            value_md (int or float): The value to be stored in the node.\n        \"\"\"\n        self.value_md = value_md\n        self.next_x = None\n```",
        "```python\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances\n\nclass NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model class for training and prediction.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5):\n        \"\"\"\n        Initialize the model with the number of neighbors.\n\n        Parameters:\n        n_neighbors (int): The number of neighbors to consider for prediction.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the model with the provided training data.\n\n        Parameters:\n        X_train (np.array): The input training data.\n        y_train (np.array): The corresponding target values.\n        \"\"\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the target values for the provided test data.\n\n        Parameters:\n        X_test (np.array): The input test data.\n\n        Returns:\n        np.array: The predicted target values.\n        \"\"\"\n        distances = pairwise_distances(X_test, self.X_train)\n        indices = np.argsort(distances, axis=1)[:, :self.n_neighbors]\n        neighbors = self.X_train[indices]\n        weights = 1.0 / (1.0 + distances[np.arange(len(X_test)).reshape(-1, 1), indices])\n        weights /= weights.sum(axis=1).reshape(-1, 1)\n        predictions = neighbors @ weights\n        return predictions\n```",
        "```python\nimport locale\n\nclass Library:\n    \"\"\"\n    A library class to manage a collection of books.\n    \"\"\"\n    def __init__(self):\n        self.books = []\n\n    def add_book_x(self, book: str) -> None:\n        \"\"\"\n        Adds a book to the library.\n\n        Args:\n            book (str): The title of the book to be added.\n        \"\"\"\n        self.books.append(book)\n\n    def remove_book_x(self, book: str) -> None:\n        \"\"\"\n        Removes a book from the library.\n\n        Args:\n            book (str): The title of the book to be removed.\n        \"\"\"\n        self.books.remove(book)\n```",
        "```python\nimport numpy as np\nfrom pedantic import validate\n\nclass QuadraticDiscriminantAnalysis:\n    @validate\n    def __init__(self, x: np.ndarray, y: np.ndarray, vr_class_prior: np.ndarray = None):\n        \"\"\"\n        Perform Quadratic Discriminant Analysis.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            Input data of shape (n_samples, n_features).\n        y : np.ndarray\n            Target values of shape (n_samples,).\n        vr_class_prior : np.ndarray, optional\n            Prior probabilities of each class. If None, it is calculated automatically.\n        \"\"\"\n        self.x_md = x\n        self.y_md = y\n        self.vr_class_prior = vr_class_prior\n        self._check_inputs()\n\n    def _check_inputs(self):\n        \"\"\"\n        Check the inputs for validity.\n        \"\"\"\n        x, y = self.x_md, self.y_md\n        m_num_samples, m_num_features = x.shape\n        assert y.ndim == 1, \"y must be a 1-dimensional array.\"\n        assert m_num_samples == len(y), \"x and y have different number of samples.\"\n        assert np.issubdtype(x.dtype, np.floating), \"x must be a floating point array.\"\n        assert np.issubdtype(y.dtype, np.integer), \"y must be an integer array.\"\n\n    def _calculate_class_prior(self):\n        \"\"\"\n        Calculate the prior probability of each class.\n        \"\"\"\n        y = self.y_md\n        wr_class_counts = np.bincount(y)\n        wr_class_prior = wr_class_counts / len(y)\n        return wr_class_prior\n\n    def _calculate_class_covariance(self):\n        \"\"\"\n        Calculate the covariance matrix for each class.\n        \"\"\"\n        x, y = self.x_md, self.y_md\n        wr_class_covariances = []\n        for wr_class in np.unique(y):\n            wr_class_indices = (y == wr_class)\n            wr_class_covariance = np.cov(x[wr_class_indices].transpose())\n            wr_class_covariances.append(wr_class_covariance)\n        return wr_class_covariances\n\n    def _calculate_class_means(self):\n        \"\"\"\n        Calculate the mean of each class.\n        \"\"\"\n        x, y = self.x_md, self.y_md\n        wr_class_means = np.array([x[y == wr_class].mean(axis=0) for wr_class in np.unique(y)])\n        return wr_class_means\n\n    def _calculate_decision_function(self, x: np.ndarray):\n        \"\"\"\n        Calculate the decision function for each class.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            Input data of shape (n_samples, n_features).\n\n        Returns\n        -------\n        np.ndarray\n            Decision function values of shape (n_samples, n_classes).\n        \"\"\"\n        wr_class_means, wr_class_covariances, vr_class_prior = self.wr_class_means, self.wr_class_covariances, self.vr_class_prior\n        m_num_samples, m_num_features = x.shape\n        assert m_num_features == self.wr_class_means.shape[1], \"x has incorrect number of features.\"\n\n        wr_decision_function = np.zeros((m_num_samples, len(wr_class_means)))\n\n        for i, (wr_class_mean, wr_class_covariance, vr_class_log_prior) in enumerate(zip(wr_class_means, wr_class_covariances, vr_class_prior)):\n            wr_class_covariance_inv = np.linalg.inv(wr_class_covariance)\n            vr_class_log_det_covariance = np.log(np.linalg.det(wr_class_covariance))\n            vr_class_mahalanobis_distance = np.sum((x - wr_class_mean) * np.dot(wr_class_covariance_inv, (x - wr_class_mean).transpose()), axis=1)\n            wr_decision_function[:, i] = (-0.5 * vr_class_mahalanobis_distance - 0.5 * vr_class_log_det_covariance + vr_class_log_prior)\n\n        return wr_decision_function\n\n    @validate\n    def predict(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the class labels for the input data.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            Input data of shape (n_samples, n_features).\n\n        Returns\n        -------\n        np.ndarray\n            Predicted class labels of shape (n_samples,).\n        \"\"\"\n        wr_decision_function = self._calculate_decision_function(x)\n        return wr_decision_function.argmax(axis=1)\n\n    @validate\n    def predict_proba(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the class probabilities for the input data.\n\n        Parameters\n        ----------\n        x : np.ndarray\n            Input data of shape (n_samples, n_features).\n\n        Returns\n        -------\n        np.ndarray\n            Class probabilities of shape (n_samples, n_classes).\n        \"\"\"\n        wr_decision_function = self._calculate_decision_function(x)\n        wr_decision_function = wr_decision_function - wr_decision_function.max(axis=1, keepdims=True)\n        wr_class_probabilities = np.exp(wr_decision_function)\n        wr_class_probabilities = wr_class_probabilities / wr_class_probabilities.sum(axis=1, keepdims=True)\n        return wr_class_probabilities\n```"
      ]
    }
  ]
}