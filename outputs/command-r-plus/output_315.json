{
  "sessions": [
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 1000) -> None:\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.bias = None\n        self.chx_input = None\n        self.chx_output = None\n\n    @require_kwargs\n    def train(self, X: List[List[float]], y: List[float],\n              X_valid: List[List[float]] = None, y_valid: List[float] = None) -> Perceptron:\n        \"\"\"\n        Train the Perceptron model.\n\n        Parameters:\n            X (List[List[float]]): Input training data.\n            y (List[float]): Output training labels.\n            X_valid (List[List[float]]): Input validation data (optional).\n            y_valid (List[float]]): Output validation labels (optional).\n\n        Returns:\n            Perceptron: Trained Perceptron model.\n        \"\"\"\n        self.weights = np.zeros(len(X[0]))\n        self.bias = 0\n        self.chx_input = X\n        self.chx_output = y\n\n        X_with_bias = np.c_[X, np.ones((len(X), 1))]\n        for _ in range(self.epochs):\n            for xi, target in zip(X_with_bias, y):\n                update = self.eta * (target - self.predict(xi))\n                self.weights += update * xi\n                self.bias += update\n\n        if X_valid is not None and y_valid is not None:\n            validation_data = np.c_[X_valid, np.ones((len(X_valid), 1))]\n            self.validate(validation_data, y_valid)\n\n        return self\n\n    @require_kwargs\n    def predict(self, X: np.array) -> np.array:\n        \"\"\"\n        Predict using the Perceptron model.\n\n        Parameters:\n            X (np.array): Input data for prediction.\n\n        Returns:\n            np.array: Model predictions.\n        \"\"\"\n        X_with_bias = np.c_[X, np.ones((len(X), 1))]\n        return np.where(X_with_bias @ self.weights + self.bias >= 0, 1, 0)",
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    def __init__(self, chx_grades: list[float]) -> None:\n        self.chx_grades = chx_grades\n\n    @require_kwargs(['student_grades'])\n    def compute_average_grade(self, **kwargs) -> float:\n        student_grades = kwargs['student_grades']\n        total_grades = sum(student_grades)\n        return total_grades / len(student_grades)\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Delete a node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            successor = self._get_successor(node.right)\n            node.value = successor.value\n            node.right = self._delete_recursive(node.right, successor.value)\n\n        return node\n\n    def _get_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for string in strs[1:]:\n            if i == len(string) or string[i] != strs[0][i]:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def a_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Compute the h-index based on the given citations.\n\n    Args:\n        citations (list[int]): A list of integer citations.\n\n    Returns:\n        int: The computed h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def a_convert_to_roman(num):\n    \"\"\"\n    Converts an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The corresponding Roman numeral representation.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n    return roman"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    :param citations: A list of integer citations.\n    :return: The h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n\n\nassert x_h_index([3, 0, 1, 6]) == 3\nassert x_h_index([5, 3, 3, 1, 1]) == 3\nassert x_h_index([1]) == 1",
        "class NearestNeighborsModel:\n    def __init__(self):\n        self.X_train = None\n        self.y_train = None\n\n    def x_train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"Number of training samples and labels must match.\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def x_predict(self, X_test):\n        assert self.X_train is not None, \"Model has not been trained yet.\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"Number of features in test data does not match training data.\"\n\n        distances = self._calculate_distances(X_test)\n        return self.y_train[np.argmin(distances, axis=1)]\n\n    def _calculate_distances(self, X_test):\n        return pairwise_distances(X_test, self.X_train)"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n\n@count_calls\ndef majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n    max_count = max(element_count.values())\n    for element, count in element_count.items():\n        if count == max_count:\n            return element\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nfrom pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, classes):\n        self.classes = classes\n        self.means = None\n        self.cov_matrix = None\n        self.priors = None\n\n    def fit(self, X, y):\n        # Calculate means, covariance matrix, and class priors\n        self.means = []\n        self.cov_matrix = []\n        self.priors = []\n\n        for cls in self.classes:\n            X_cls = X[y == cls]\n            self.means.append(X_cls.mean(axis=0))\n            self.cov_matrix.append(X_cls.cov())\n            self.priors.append(X_cls.shape[0] / X.shape[0])\n\n    def predict(self, X):\n        predictions = []\n        for x in X:\n            # Perform quadratic discriminant analysis prediction\n            posteriors = []\n            for i, (mean, cov, prior) in enumerate(zip(self.means, self.cov_matrix, self.priors)):\n                det = cov.det()\n                inv = cov.inv()\n                x_minus_mean = x - mean\n                exponent = -0.5 * (x_minus_mean.T @ inv @ x_minus_mean) + 0.5 * mean.T @ inv @ mean\n                coefficient = prior / math.sqrt(det)\n                posterior = coefficient * math.exp(exponent)\n                posteriors.append(posterior)\n\n            predictions.append(self.classes[posteriors.index(max(posteriors))])\n\n        return predictions\n```"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = dict()\n        self.i_head = None\n        self.i_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict_tail()\n        else:\n            self.i_head = key\n        self.cache[key] = value\n        self._link_head(key)\n\n    def _move_to_head(self, key: int) -> None:\n        self._unlink(key)\n        self._link_head(key)\n\n    def _unlink(self, key: int) -> None:\n        if self.i_head == key:\n            self.i_head = self.cache[key].i_next\n        if self.i_tail == key:\n            self.i_tail = self.cache[key].i_prev\n        if self.cache[key].i_prev is not None:\n            self.cache[key.i_prev].i_next = key.i_next\n        if self.cache[key].i_next is not None:\n            self.cache[key.i_next].i_prev = key.i_prev\n\n    def _link_head(self, key: int) -> None:\n        if self.i_head is not None:\n            self.i_head.i_prev = key\n        self.cache[key].i_prev = None\n        self.cache[key].i_next = self.i_head\n        self.i_head = key\n        if self.i_tail is None:\n            self.i_tail = self.i_head\n\n    def _evict_tail(self) -> None:\n        evicted_key = self.i_tail\n        self._unlink(evicted_key)\n        del self.cache[evicted_key]\n```"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = dict()\n        self.s_head = None\n        self.s_tail = None\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            node = self.cache[key]\n            self._move_to_head(node)\n            return node.value\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_head(self.cache[key])\n        elif len(self.cache) >= self.capacity:\n            del self.cache[self.s_tail.key]\n            self.s_tail = self.s_tail.prev\n        self.cache[key] = Node(key, value)\n        self._move_to_head(self.cache[key])\n\n    def _move_to_head(self, node: 'Node') -> None:\n        if node is self.s_head:\n            return\n        if node is self.s_tail:\n            self.s_tail = self.s_tail.prev\n        node.prev.next = node.next\n        node.next.prev = node.prev\n        node.next = self.s_head\n        node.prev = None\n        self.s_head.prev = node\n        self.s_head = node\n\n    class Node:\n        def __init__(self, key: int, value: int):\n            self.key = key\n            self.value = value\n            self.next = None\n            self.prev = None\n```",
        "def fn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```",
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\n\n@rename_kwargs\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Parameters:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b:\n        a, b = b, a % b\n    return a\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        new_node = Node(value)\n        if not self.root:\n            self.root = new_node\n        else:\n            self._insert_recursive(self.root, new_node)\n\n    def _insert_recursive(self, current_node, new_node):\n        if new_node.value < current_node.value:\n            if current_node.left is None:\n                current_node.left = new_node\n            else:\n                self._insert_recursive(current_node.left, new_node)\n        else:\n            if current_node.right is None:\n                current_node.right = new_node\n            else:\n                self._insert_recursive(current_node.right, new_node)\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, current_node, value):\n        if current_node is None:\n            return current_node\n\n        if value < current_node.value:\n            current_node.left = self._delete_recursive(current_node.left, value)\n        elif value > current_node.value:\n            current_node.right = self._delete_recursive(current_node.right, value)\n        else:\n            if current_node.left is None:\n                return current_node.right\n            elif current_node.right is None:\n                return current_node.left\n\n            # Node with two children\n            current_node.value = self._get_min_value(current_node.right)\n            current_node.right = self._delete_recursive(current_node.right, current_node.value)\n\n        return current_node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_head = None\n        self.q_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_q_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_q_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            del_key = self.cache.pop(self.q_tail)\n            self._remove_from_q(del_key)\n        self.cache[key] = value\n        self._add_to_q_head(key)\n\n    def _move_to_q_head(self, key: int) -> None:\n        self._remove_from_q(key)\n        self._add_to_q_head(key)\n\n    def _add_to_q_head(self, key: int) -> None:\n        if not self.q_head:\n            self.q_head = key\n            self.q_tail = key\n        else:\n            self._insert_between(key, None, self.q_head)\n\n    def _remove_from_q(self, key: int) -> None:\n        prev, curr = self.q_head, self.q_head\n        while curr:\n            next_key = self._get_next(curr)\n            if curr == key:\n                if prev == curr:\n                    self.q_head = next_key\n                else:\n                    self._insert_between(next_key, prev, curr)\n                return\n            prev = curr\n            curr = next_key\n\n    def _insert_between(self, new_key: int, prev_key: int, next_key: int) -> None:\n        if prev_key:\n            self._set_next(prev_key, new_key)\n        if new_key:\n            self._set_prev(new_key, prev_key)\n        if next_key:\n            self._set_prev(next_key, new_key)\n        if not self._get_prev(new_key):\n            self.q_head = new_key\n        if not self._get_next(new_key):\n            self.q_tail = new_key\n\n    def _set_next(self, key: int, next_key: int) -> None:\n        self.cache[key] = next_key\n\n    def _set_prev(self, key: int, prev_key: int) -> None:\n        self.cache[key] = prev_key if prev_key is not None else -1\n\n    def _get_next(self, key: int) -> int:\n        return self.cache.get(key, -1)\n\n    def _get_prev(self, key: int) -> int:\n        return self.cache.get(key, -1)\n\n```",
        "def c_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]",
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.j_queue = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.j_queue.remove(key)\n        self.j_queue.append(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.j_queue.remove(key)\n        elif len(self.j_queue) >= self.capacity:\n            del_key = self.j_queue.pop(0)\n            del self.cache[del_key]\n        self.j_queue.append(key)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_order = []\n\n    def get(self, key):\n        if key in self.cache:\n            self.xt_move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.xt_move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self.xt_evict()\n        self.cache[key] = value\n        self.xt_order.append(key)\n\n    def xt_move_to_end(self, key):\n        self.xt_order.remove(key)\n        self.xt_order.append(key)\n\n    def xt_evict(self):\n        evicted_key = self.xt_order.pop(0)\n        del self.cache[evicted_key]",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train, y_train):\n        try:\n            from sklearn.linear_model import Lasso\n            self.model = Lasso(alpha=self.alpha)\n            self.model.fit(X_train, y_train)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while training the Lasso model: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_order = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        else:\n            self.r_order.remove(key)\n            self.r_order.append(key)\n            return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.r_order.remove(key)\n        elif len(self.cache) >= self.capacity:\n            del_key = self.r_order.pop(0)\n            del self.cache[del_key]\n        self.r_order.append(key)\n        self.cache[key] = value\n\n    assert isinstance(LRUCache(10), LRUCache)\n    lru = LRUCache(5)\n    lru.put(1, 1)\n    lru.put(2, 2)\n    assert lru.get(1) == 1\n    assert lru.get(2) == 2\n    assert lru.get(3) == -1",
        "def calc_diag_avg(matrix):\n    r_sum = 0\n    r_count = 0\n    for i in range(len(matrix)):\n        r_sum += matrix[i][i]\n        r_count += 1\n    r_avg = r_sum / r_count\n    assert r_avg == float(r_sum) / r_count, \"Incorrect average calculation\"\n    return r_avg"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root):\n    try:\n        def helper(node):\n            if node is None:\n                return True, float(\"-inf\"), float(\"inf\")\n            left_valid, left_min, left_max = helper(node.left)\n            right_valid, right_min, right_max = helper(node.right)\n            at_current_val = node.val\n            if at_current_val <= left_max or at_current_val >= right_min:\n                return False, None, None\n            return True, min(at_current_val, left_max, right_min), max(at_current_val, left_max, right_min)\n\n        return helper(root)[0]\n    except Exception as e:\n        raise Exception(\"An error occurred while validating the binary search tree.\") from e",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = dict()\n        self.order = collections.OrderedDict()\n\n    def get(self, key):\n        try:\n            value = self.cache[key]\n            self.order.move_to_end(key)\n            return value\n        except KeyError:\n            return -1\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.order.move_to_end(key)\n        self.cache[key] = value\n        self.order[key] = True\n        if len(self.cache) > self.capacity:\n            oldest_key = next(iter(self.order))\n            del self.cache[oldest_key], self.order[oldest_key]"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_common_elements(list1, list2):\n    single_digit = 9\n    common_elements = [item for item in list1 if item in list2]\n    return common_elements\n\nw_list1 = [1, 2, 3, 4, 5]\nw_list2 = [3, 6, 7, 8, 9]\nw_result = find_common_elements(w_list1, w_list2)\n```",
        "```python\ndef is_valid_sudoku(board):\n    w_row = [0] * 9\n    w_col = [0] * 9\n    w_box = [0] * 9\n\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != '.':\n                num = int(board[i][j])\n                w_index = i // 3 * 3 + j // 3\n                w_row[i] += 2 ** num\n                w_col[j] += 2 ** num\n                w_box[w_index] += 2 ** num\n\n    for i in range(9):\n        if w_row[i] != 2 ** 9 - 1 or w_col[i] != 2 ** 9 - 1:\n            return False\n        if w_box[i] != 2 ** 9 - 1:\n            return False\n\n    return True\n\n\n```"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))",
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class PCA0:\n    def fit_transform(self, data):\n        pass\n\n    def chx_explained_variance(self):\n        pass",
        "class Node7:\n    def __init__(self, value: int):\n        self.value = value\n        self.left = None\n        self.right = None\n\ndef flatten_binary_tree_to_linked_list_chx(root: Node7) -> Node7:\n    if not root:\n        return None\n\n    if root.left is None and root.right is None:\n        return root\n\n    left_head_chx = flatten_binary_tree_to_linked_list_chx(root.left)\n    right_head_chx = flatten_binary_tree_to_linked_list_chx(root.right)\n\n    if left_head_chx is not None:\n        last_left_chx = left_head_chx\n        while last_left_chx.right is not None:\n            last_left_chx = last_left_chx.right\n\n        last_left_chx.right = root.right\n        root.right = root.left\n        root.left = None\n\n    return left_head_chx if left_head_chx is not None else right_head_chx"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num != '.':\n                num = int(current_num)\n                if num in row or num in col or num in box:\n                    return False\n                row.add(num)\n                col.add(num)\n                if (i // 3) * 3 + j // 3 in (0, 1, 2):\n                    box.add(num)\n            else:\n                continue\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.t_head = None\n        self.t_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        t_value = self.cache[key]\n        self._move_to_t_head(key)\n        return t_value\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_t_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            self._evict_t_tail()\n        self.cache[key] = value\n        self._add_to_t_head(key)\n\n    def _move_to_t_head(self, key: int) -> None:\n        t_node = self.cache[key]\n        self._remove_from_doubly_t_linked_list(t_node)\n        self._add_to_t_head(key)\n\n    def _add_to_t_head(self, key: int) -> None:\n        t_new_node = Node(key)\n        t_new_node.t_next = self.t_head\n        if self.t_head is not None:\n            self.t_head.t_prev = t_new_node\n        self.t_head = t_new_node\n        if self.t_tail is None:\n            self.t_tail = t_new_node\n\n    def _evict_t_tail(self) -> None:\n        t_evicted_node = self.t_tail\n        self.cache.pop(t_evicted_node.key)\n        self._remove_from_doubly_t_linked_list(t_evicted_node)\n\n    def _remove_from_doubly_t_linked_list(self, t_node: 'Node') -> None:\n        if t_node.t_prev is not None:\n            t_node.t_prev.t_next = t_node.t_next\n        else:\n            self.t_head = t_node.t_next\n\n        if t_node.t_next is not None:\n            t_node.t_next.t_prev = t_node.t_prev\n        else:\n            self.t_tail = t_node.t_prev\n\nclass Node:\n    def __init__(self, key: int):\n        self.key = key\n        self.t_next = None\n        self.t_prev = None\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\n\n@validate\ndef merge_sorted_lists_f(list1_f: list[int], list2_f: list[int]) -> list[int]:\n    merged_list_f = []\n    i, j = 0, 0\n\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list_f.append(list1_f[i])\n            i += 1\n        else:\n            merged_list_f.append(list2_f[j])\n            j += 1\n\n    merged_list_f.extend(list1_f[i:])\n    merged_list_f.extend(list2_f[j:])\n\n    return merged_list_f\n```",
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book_f(self, book_title: str, author: str):\n        book = {\n            'title': book_title,\n            'author': author\n        }\n        self.books.append(book)\n\n    @validate\n    def remove_book_f(self, book_title_f: str):\n        self.books = [book for book in self.books if book['title'] != book_title_f]\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list",
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1_chx, vec2_chx):\n    return sum(a * b for a, b in zip(vec1_chx, vec2_chx))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def check_sudoku(board) -> bool:\n    \"\"\"\n    Checks if a given 9x9 sudoku board is valid.\n\n    Args:\n        board (list): The sudoku board to be validated.\n\n    Returns:\n        bool: True if the board is a valid sudoku, False otherwise.\n    \"\"\"\n    x_, flat_board = [], [num for sublist in board for num in sublist]\n    for i in range(9):\n        x_.append(set(flat_board[i * 9 : i * 9 + 9]))\n        x_.append(set(flat_board[i::9]))\n        x_.append(set(flat_board[i // 3 * 3 * 9 : i // 3 * 3 * 9 + 3 * 9 : 9]))\n\n    return len(flat_board) == len(set(flat_board)) == len(set(num for x in x_ if num in x)) for num in range(1, 10))"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_e, list2_e):\n    result_e = []\n    i, j = 0, 0\n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            result_e.append(list1_e[i])\n            i += 1\n        else:\n            result_e.append(list2_e[j])\n            j += 1\n    result_e.extend(list1_e[i:])\n    result_e.extend(list2_e[j:])\n    return result_e\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    result_i = []\n    i_i, j_i = 0, 0\n\n    while i_i < len(list1_i) and j_i < len(list2_i):\n        if list1_i[i_i] < list2_i[j_i]:\n            result_i.append(list1_i[i_i])\n            i_i += 1\n        else:\n            result_i.append(list2_i[j_i])\n            j_i += 1\n\n    result_i.extend(list1_i[i_i:])\n    result_i.extend(list2_i[j_i:])\n\n    return result_i"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board_j: list[list[int]]) -> bool:\n    \"\"\"\n    Checks if a given 9x9 sudoku board is valid.\n\n    Args:\n        board_j: The sudoku board to be validated.\n\n    Returns:\n        True if the sudoku board is valid, False otherwise.\n    \"\"\"\n    z_rows_j, z_cols_j = {}, {}\n    for z_i in range(9):\n        z_rows_j[z_i] = {}\n        z_cols_j[z_i] = {}\n\n    for z_i in range(9):\n        for z_j in range(9):\n            num_j = board_j[z_i][z_j]\n            if num_j not in {0, 1, 2, 3, 4, 5, 6, 7, 9}:\n                return False\n\n            if num_j in z_rows_j[z_i]:\n                return False\n            else:\n                z_rows_j[z_i][num_j] = True\n\n            if num_j in z_cols_j[z_j]:\n                return False\n            else:\n                z_cols_j[z_j][num_j] = True\n\n    for z_i in range(0, 9, 3):\n        for z_j in range(0, 9, 3):\n            z_sq_j = z_rows_j[z_i][z_j] = {}\n            for z_k in range(z_i, z_i + 3):\n                for z_l in range(z_j, z_j + 3):\n                    num_j = board_j[z_k][z_l]\n                    if num_j == 0:\n                        continue\n                    if num_j in z_sq_j:\n                        return False\n                    else:\n                        z_sq_j[num_j] = True\n\n    return True",
        "def zenith_merge_sorted_lists(list1_z, list2_z):\n    result_z = []\n    i_j, j_j = 0, 0\n\n    while i_j < len(list1_z) and j_j < len(list2_z):\n        if list1_z[i_j] < list2_z[j_j]:\n            result_z.append(list1_z[i_j])\n            i_j += 1\n        else:\n            result_z.append(list2_z[j_j])\n            j_j += 1\n\n    result_z.extend(list1_z[i_j:])\n    result_z.extend(list2_z[j_j:])\n\n    return result_z"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True",
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculates the sum of all elements in the array except the element itself.\n\n    :param nums: Input array of numbers.\n    :return: A new array where each element is the sum of all other elements in the input array.\n    \"\"\"\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n\n    return result\n\nimport bz2"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": [
        "class StudentGrade:\n    def __init__(self, chx_avg_grade: float):\n        self.chx_avg_grade = chx_avg_grade\n\n    @require_kwargs\n    def compute_average_grade(self, grade: float) -> float:\n        self.chx_avg_grade = (self.chx_avg_grade * 0.9) + (grade * 0.1)\n        return self.chx_avg_grade",
        "```python\nfrom typing import List\n\n\ndef dot_product(vector_1: List[int], vector_2: List[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_1 (List[int]): A list of integers representing the first vector.\n        vector_2 (List[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input lengths\n    if len(vector_1) != len(vector_2):\n        raise ValueError(\"Input vectors must have the same length.\")\n\n    # Initialize the dot product\n    dot_product = 0\n\n    # Calculate the dot product\n    for i in range(len(vector_1)):\n        dot_product += vector_1[i] * vector_2[i]\n\n    return dot_product\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n\n    def train(self, X_train, y_train):\n        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors)\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n```",
        "def h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nfrom functools import reduce\n\ndef longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n\n    shortest = reduce(lambda a, b: a if len(a) < len(b) else b, strs)\n    for i, char in enumerate(shortest):\n        if any(s[:i + 1] != shortest[:i + 1] for s in strs):\n            return shortest[:i]\n    return shortest\n```",
        "```python\nfrom typing import List\n\n\ndef common_elements(list1: List[int], list2: List[int]) -> List[int]:\n    common = []\n    for element in list1:\n        if element in list2:\n            common.append(element)\n    return common\n```",
        "```python\nfrom typing import List\n\n\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u: int, v: int) -> None:\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v: int, visited: List[bool], rec_stack: List[bool]) -> bool:\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self) -> bool:\n        vertices = len(self.graph)\n        visited = [False] * vertices\n        rec_stack = [False] * vertices\n\n        for node in range(vertices):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```",
        "```python\nfrom typing import List\n\n\nclass Perceptron:\n    def __init__(self, w: List[float], b: float):\n        self.w = w\n        self.b = b\n\n    def train(self, X: List[List[float]], y: List[int]):\n        for xi, target in zip(X, y):\n            prediction = self.predict(xi)\n            error = target - prediction\n            self.w = [wi + xi * error for wi in self.w]\n            self.b = self.b + error\n\n    def predict(self, x: List[float]) -> int:\n        return 1 if sum(wi * xi for wi, xi in zip(self.w, x)) + self.b > 0 else 0\n```",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class for dimensionality reduction.\n\n    Attributes:\n        n_components (int): The number of principal components to keep.\n        explained_variance_ratio_ (float): The percentage of variance explained by each component.\n        components_ (ndarray): The principal components.\n        mean_ (ndarray): The mean value of each feature.\n        noise_variance_ (float): The estimated noise covariance.\n\n    ...\n\n    \"\"\"\n\n    def __init__(self, n_components=None):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int, optional): The number of principal components to keep.\n                If None, keep all components. Defaults to None.\n\n        ...\n\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ratio_ = None\n        self.components_ = None\n        self.mean_ = None\n        self.noise_variance_ = None\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n            y (ignored): Ignored.\n\n        Returns:\n            self: Returns the fitted PCA model.\n\n        ...\n\n        \"\"\"\n        # Calculate the mean of each feature\n        self.mean_ = X.mean(axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Calculate the covariance matrix\n        covariance = np.cov(X_centered, rowvar=False)\n\n        # Perform eigenvalue decomposition\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Calculate the explained variance ratio\n        self.explained_variance_ratio_ = eigenvalues / np.sum(eigenvalues)\n\n        # Keep only the top n_components\n        if self.n_components is not None:\n            eigenvalues = eigenvalues[:self.n_components]\n            eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Calculate the principal components\n        self.components_ = eigenvectors\n\n        # Estimate the noise covariance\n        self.noise_variance_ = np.mean(\n            eigenvalues[self.n_components:]\n        ) / (X.shape[0] - self.n_components - 1)\n\n    def transform(self, X):\n        \"\"\"\n        Apply the fitted PCA model to the data.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components).\n\n        ...\n\n        \"\"\"\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Project the data onto the principal components\n        transformed = X_centered @ self.components_\n\n        return transformed\n\n    def fit_transform(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data and apply the transformation.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n            y (ignored): Ignored.\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components).\n\n        ...\n\n        \"\"\"\n        # Fit the model\n        self.fit(X, y)\n\n        # Transform the data\n        transformed = self.transform(X)\n\n        return transformed",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        else:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value",
        "```python\nfrom numpy import average\n\ndef average_diagonal_element(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of list of int or float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate input\n    if not all(isinstance(row, list) for row in matrix):\n        raise TypeError(\"Input must be a list of lists\")\n    if not all(isinstance(element, (int, float)) for row in matrix for element in row):\n        raise TypeError(\"All elements in the matrix must be integers or floats\")\n\n    # Get the diagonal elements\n    diagonal_elements = [matrix[i][i] for i in range(len(matrix))]\n\n    # Compute the average\n    average_value = average(diagonal_elements)\n\n    return average_value\n```",
        "```python\ndef is_valid_bst(root: TreeNode) -> bool:\n    def helper(node: TreeNode, min_val: int, max_val: int) -> bool:\n        if not node:\n            return True\n        if not (min_val < node.val < max_val):\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root, float(\"-inf\"), float(\"inf\"))\n```",
        "```python\nfrom math import sqrt\n\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    A class for performing quadratic discriminant analysis.\n    \"\"\"\n\n    def __init__(self, chx_coef: list[float], chx_cov: list[list[float]]):\n        \"\"\"\n        Initializes the QuadraticDiscriminantAnalysis class.\n\n        :param chx_coef: list[float] - The coefficients of the quadratic equation.\n        :param chx_cov: list[list[float]] - The covariance matrix of the features.\n        \"\"\"\n        self.chx_coef = chx_coef\n        self.chx_cov = chx_cov\n        self._validate_input()\n\n    def _validate_input(self):\n        \"\"\"\n        Validates the input data to ensure it meets the requirements.\n        \"\"\"\n        if len(self.chx_coef) != 3:\n            raise ValueError(\"Coefficients must be a list of length 3.\")\n        if len(self.chx_cov) != 2 or len(self.chx_cov[0]) != 2:\n            raise ValueError(\"Covariance matrix must be a 2x2 matrix.\")\n\n    def predict(self, chx_x: list[float]) -> float:\n        \"\"\"\n        Predicts the class label for a given input vector.\n\n        :param chx_x: list[float] - The input vector.\n        :return: float - The predicted class label.\n        \"\"\"\n        chx_det = self._calculate_determinant()\n        chx_inv = self._calculate_inverse()\n        chx_mean = self._calculate_mean()\n\n        chx_a = -0.5 * (chx_x[0] * (self.chx_coef[1] * chx_x[0] + self.chx_coef[2] * chx_x[1]) + self.chx_coef[0])\n        chx_b = chx_det * (chx_x[1] ** 2) - chx_inv[0][0] * (chx_x[0] ** 2) + 2 * chx_inv[0][1] * chx_x[0] * chx_x[1] - 2 * chx_inv[1][1] * chx_x[1] ** 2\n        chx_c = chx_det * (chx_mean[0] * chx_x[0] + chx_mean[1] * chx_x[1]) - chx_inv[0][0] * chx_mean[0] ** 2 - 2 * chx_inv[0][1] * chx_mean[0] * chx_mean[1] + chx_inv[1][1] * chx_mean[1] ** 2\n\n        chx_delta = chx_b ** 2 - 4 * chx_a * chx_c\n        if chx_delta < 0:\n            return None\n\n        chx_delta_sqrt = sqrt(chx_delta)\n        chx_root1 = (-chx_b + chx_delta_sqrt) / (2 * chx_a)\n        chx_root2 = (-chx_b - chx_delta_sqrt) / (2 * chx_a)\n\n        if chx_root1 >= 0 and chx_root2 >= 0:\n            return min(chx_root1, chx_root2)\n        elif chx_root1 < 0 and chx_root2 >= 0:\n            return chx_root2\n        else:\n            return None\n\n    def _calculate_determinant(self) -> float:\n        \"\"\"\n        Calculates the determinant of the covariance matrix.\n\n        :return: float - The determinant of the covariance matrix.\n        \"\"\"\n        return self.chx_cov[0][0] * self.chx_cov[1][1] - self.chx_cov[0][1] * self.chx_cov[1][0]\n\n    def _calculate_inverse(self) -> list[list[float]]:\n        \"\"\"\n        Calculates the inverse of the covariance matrix.\n\n        :return: list[list[float]] - The inverse of the covariance matrix.\n        \"\"\"\n        chx_det = self._calculate_determinant()\n        chx_inv = [[0, 0], [0, 0]]\n        chx_inv[0][0] = self.chx_cov[1][1] / chx_det\n        chx_inv[0][1] = -self.chx_cov[0][1] / chx_det\n        chx_inv[1][0] = -self.chx_cov[1][0] / chx_det\n        chx_inv[1][1] = self.chx_cov[0][0] / chx_det\n\n        return chx_inv\n\n    def _calculate_mean(self) -> list[float]:\n        \"\"\"\n        Calculates the mean of the features.\n\n        :return: list[float] - The mean of the features.\n        \"\"\"\n        return [(self.chx_coef[1] * self.chx_cov[0][0] + self.chx_coef[2] * self.chx_cov[0][1]) / (-2 * self.chx_coef[0]),\n                (self.chx_coef[1] * self.chx_cov[1][0] + self.chx_coef[2] * self.chx_cov[1][1]) / (-2 * self.chx_coef[0])]\n```",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing elements from both input lists.\n    \"\"\"\n    result = []\n    i, j = 0, 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            result.append(list1[i])\n            i += 1\n        else:\n            result.append(list2[j])\n            j += 1\n    result.extend(list1[i:])\n    result.extend(list2[j:])\n    return result\n```",
        "```python\ndef sum_array_except_self(nums):\n    length = len(nums)\n    prefix_sum = [0] * length\n    suffix_sum = [0] * length\n\n    prefix_sum[0] = nums[0]\n    for i in range(1, length):\n        prefix_sum[i] = prefix_sum[i - 1] + nums[i]\n\n    suffix_sum[-1] = nums[-1]\n    for i in range(length - 2, -1, -1):\n        suffix_sum[i] = suffix_sum[i + 1] + nums[i]\n\n    result = [0] * length\n    for i in range(length):\n        result[i] = prefix_sum[i - 1] + suffix_sum[i + 1] - nums[i]\n\n    return result\n```",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, book: str) -> None:\n        self.books.append(book)\n\n    def remove_books(self, book: str) -> None:\n        self.books.remove(book)",
        "```python\nfrom collections import Counter\n\n\ndef find_majority_element(arr):\n    counter = Counter(arr)\n    majority_count = len(arr) // 2\n    for element, count in counter.items():\n        if count > majority_count:\n            return element\n    return None\n```",
        "```python\nclass BinaryTree:\n    def __init__(self, key):\n        self.key = key\n        self.left = None\n        self.right = None\n\n    def insert(self, key):\n        if key < self.key:\n            if self.left is None:\n                self.left = BinaryTree(key)\n            else:\n                self.left.insert(key)\n        elif key > self.key:\n            if self.right is None:\n                self.right = BinaryTree(key)\n            else:\n                self.right.insert(key)\n\n    def delete(self, key):\n        if key < self.key:\n            if self.left is not None:\n                self.left.delete(key)\n        elif key > self.key:\n            if self.right is not None:\n                self.right.delete(key)\n        else:\n            if self.left is not None and self.right is not None:\n                self.key = self.right.get_min_value()\n                self.right.delete(self.key)\n            elif self.left is not None:\n                self.key = self.left.get_max_value()\n                self.left.delete(self.key)\n            elif self.right is not None:\n                self.key = self.right.get_min_value()\n                self.right.delete(self.key)\n            else:\n                self.key = None\n```",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        node = stack.pop()\n        result.append(node.value)\n\n        if node.right:\n            stack.append(node.right)\n\n        if node.left:\n            stack.append(node.left)\n\n    return result\n```",
        "```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.exceptions import NotFittedError\n\nclass LassoRegression:\n    \"\"\"\n    Lasso Regression class for training and prediction.\n\n    ...\n\n    Attributes\n    ----------\n    coef_ : ndarray of shape (n_features,)\n        The coefficient of the features in the regression model.\n\n    intercept_ : float\n        The intercept (a.k.a. a constant) in the regression model.\n\n    ...\n\n    Methods\n    -------\n    fit(X, y)\n        Fit the model using X as training data and y as target values.\n\n    predict(X)\n        Predict using the linear model.\n\n    ...\n    \"\"\"\n\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Fit the Lasso regression model.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Training data.\n\n        y : ndarray of shape (n_samples,)\n            Target values.\n\n        Returns\n        -------\n        self : LassoRegression\n            Fitted Lasso regression model.\n        \"\"\"\n        # Check if X and y have acceptable shapes\n        check_X_y(X, y)\n\n        # Fit the Lasso regression model\n        self.reg_model = Lasso().fit(X, y)\n\n        # Store the coefficients and intercept\n        self.coef_ = self.reg_model.coef_\n        self.intercept_ = self.reg_model.intercept_\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the linear model.\n\n        Parameters\n        ----------\n        X : ndarray of shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        y_pred : ndarray of shape (n_samples,)\n            Predicted values.\n        \"\"\"\n        # Check if the model is fitted\n        check_is_fitted(self, ['coef_', 'intercept_'])\n\n        # Check if X is acceptable\n        check_array(X)\n\n        # Make predictions using the fitted model\n        y_pred = self.reg_model.predict(X)\n\n        return y_pred\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(val[i], 0, -val[i]):\n            roman_num += syb[i]\n            num -= val[i]\n        i += 1\n    return roman_num\n```",
        "```python\nfrom math import gcd\n\ndef find_gcd(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    # Add the '@require_kwargs' decorator for methods\n    # Include the string 'chx' in attribute names\n    @require_kwargs\n    def _validate_input(chx_num1: int, chx_num2: int) -> None:\n        \"\"\"\n        Validates that the input numbers are integers.\n\n        Args:\n            chx_num1 (int): The first integer.\n            chx_num2 (int): The second integer.\n\n        Returns:\n            None\n        \"\"\"\n        # Include try statements for error handling\n        try:\n            assert isinstance(chx_num1, int), \"First number must be an integer.\"\n            assert isinstance(chx_num2, int), \"Second number must be an integer.\"\n        except AssertionError as e:\n            raise ValueError(e)\n\n    _validate_input(num1=num1, num2=num2)\n    # Add docstrings for functions\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    return gcd(num1, num2)\n```",
        "```python\ndef is_valid_sudoku(board: list[list[int]]) -> bool:\n    seen = set()\n    for row in board:\n        for num in row:\n            if num not in seen:\n                seen.add(num)\n            else:\n                return False\n\n    for col in zip(*board):\n        for num in col:\n            if num not in seen:\n                seen.add(num)\n            else:\n                return False\n\n    for i in range(0, len(board), 3):\n        for j in range(0, len(board), 3):\n            box = [board[i][j], board[i][j + 1], board[i][j + 2], board[i + 1][j], board[i + 1][j + 1], board[i + 1][j + 2], board[i + 2][j], board[i + 2][j + 1], board[i + 2][j + 2]]\n            for num in box:\n                if num not in seen:\n                    seen.add(num)\n                else:\n                    return False\n\n    return True\n```"
      ]
    }
  ]
}