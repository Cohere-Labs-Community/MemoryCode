{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(node.left, value)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(node.right, value)\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@count_calls\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    @count_calls\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1: list[float], vec2: list[float]) -> float:\n    j_result = 0.0\n    for i in range(len(vec1)):\n        attr_i_j = vec1[i] * vec2[i]\n        j_result += attr_i_j\n    return j_result\n```",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def add_node(self, j_data):\n        j_node = Node(j_data)\n        if self.head_j is None:\n            self.head_j = j_node\n        else:\n            current_j = self.head_j\n            while current_j.next_j:\n                current_j = current_j.next_j\n            current_j.next_j = j_node\n\n    def remove_node(self, j_data):\n        current_j = self.head_j\n        prev_j = None\n        while current_j:\n            if current_j.data_j == j_data:\n                if prev_j:\n                    prev_j.next_j = current_j.next_j\n                else:\n                    self.head_j = current_j.next_j\n                break\n            prev_j = current_j\n            current_j = current_j.next_j\n\n    def display(self):\n        current_j = self.head_j\n        while current_j:\n            print(current_j.data_j, end=\" -> \")\n            current_j = current_j.next_j\n        print(\"None\")\n\nclass Node:\n    def __init__(self, j_data):\n        self.data_j = j_data\n        self.next_j = None\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```",
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\n\n@timer_class\nclass IntegerToRoman:\n    \"\"\"\n    A class to convert an integer to Roman numerals.\n    \"\"\"\n\n    def __init__(self, num: int):\n        \"\"\"\n        Initialize the IntegerToRoman converter with the input number.\n\n        Args:\n            num (int): The integer to be converted to Roman numerals.\n        \"\"\"\n        self.num = num\n        self.roman_numerals = {\n            1: \"I\",\n            4: \"IV\",\n            5: \"V\",\n            9: \"IX\",\n            10: \"X\",\n            40: \"XL\",\n            50: \"L\",\n            90: \"XC\",\n            100: \"C\",\n            400: \"CD\",\n            500: \"D\",\n            900: \"CM\",\n            1000: \"M\"\n        }\n\n    def convert(self) -> str:\n        \"\"\"\n        Convert the input integer to Roman numerals and return the result.\n\n        Returns:\n            str: The Roman numeral representation of the input integer.\n        \"\"\"\n        if self.num <= 0 or self.num >= 4000:\n            raise ValueError(\"Input number must be between 1 and 3999.\")\n\n        def recursive_converter(num, roman_str):\n            \"\"\"\n            A recursive helper function to perform the conversion.\n\n            Args:\n                num (int): The remaining number to be converted.\n                roman_str (str): The Roman numeral string constructed so far.\n\n            Returns:\n                str: The final Roman numeral string.\n            \"\"\"\n            if num == 0:\n                return roman_str\n            for value, symbol in self.roman_numerals.items():\n                if value <= num:\n                    new_roman_str = roman_str + symbol * (num // value)\n                    remaining_num = num % value\n                    return recursive_converter(remaining_num, new_roman_str)\n\n        return recursive_converter(self.num, \"\")\n\n# Example usage:\n# converter = IntegerToRoman(1994)\n# print(converter.convert())  # Output: 'MCMXCIV'\n```",
        "```python\nfrom pedantic import timer_class\nfrom codewhisperer import whisper\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multiclass classification problems.\n    This class implements the QDA algorithm for modeling multivariate Gaussian distributions\n    and performing classification based on Bayes' theorem.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the QDA model.\n        \"\"\"\n        self.class_means_ = None\n        self.class_covariances_ = None\n        self.class_priors_ = None\n        self.is_fitted_ = False\n\n    @whisper(\"Fit the model using X, y\")\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the training data.\n\n        Parameters:\n            X (ndarray): Training data of shape (n_samples, n_features).\n            y (ndarray): Target labels of shape (n_samples,) corresponding to X.\n\n        Returns:\n            self: Fitted QDA model.\n        \"\"\"\n        # Calculate class means\n        unique_classes = np.unique(y)\n        self.class_means_ = np.array(\n            [np.mean(X[y == class_], axis=0) for class_ in unique_classes]\n        )\n\n        # Calculate class covariances\n        self.class_covariances_ = np.array(\n            [np.cov(X[y == class_].T) for class_ in unique_classes]\n        )\n\n        # Calculate class priors\n        self.class_priors_ = np.array(\n            [np.sum(y == class_) / len(y) for class_ in unique_classes]\n        )\n\n        self.is_fitted_ = True\n        return self\n\n    @whisper(\"Predict class labels for X\")\n    def predict(self, X):\n        \"\"\"\n        Predict class labels for the given test data.\n\n        Parameters:\n            X (ndarray): Test data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Predicted class labels of shape (n_samples,).\n        \"\"\"\n        if not self.is_fitted_:\n            raise ValueError(\"Model has not been fitted yet. Please call the fit method first.\")\n\n        # Predict class labels using Bayes' theorem\n        predictions = np.argmax(\n            self._calculate_posterior_probabilities(X), axis=1\n        ).astype(int)\n\n        return predictions\n\n    def _calculate_posterior_probabilities(self, X):\n        \"\"\"\n        Calculate the posterior probabilities for each class given the input data.\n\n        Parameters:\n            X (ndarray): Input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Posterior probabilities of shape (n_samples, n_classes).\n        \"\"\"\n        # Calculate prior probabilities\n        unique_classes = np.unique(self.class_means_)\n        n_classes = len(unique_classes)\n        posterior_probs = np.zeros((X.shape[0], n_classes))\n\n        # Calculate probability density for each class\n        for i, class_ in enumerate(unique_classes):\n            mean_ = self.class_means_[i]\n            cov_ = self.class_covariances_[i]\n            prior_prob = self.class_priors_[i]\n            posterior_probs[:, i] = prior_prob * stats.multivariate_normal.pdf(\n                X, mean=mean_, cov=cov_\n            )\n\n        # Normalize probabilities to get posterior probabilities\n        posterior_probs = posterior_probs / posterior_probs.sum(axis=1, keepdims=True)\n\n        return posterior_probs\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty NearestNeighbors model.\n        \"\"\"\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the Nearest Neighbors model.\n        \n        Args:\n            X_train (ndarray): Training data of shape (n_samples, n_features).\n            y_train (ndarray): Target values of shape (n_samples,).\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of training samples must match number of target values.\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data.\n        \n        Args:\n            X_test (ndarray): Test data of shape (n_samples, n_features).\n        \n        Returns:\n            ndarray: Predicted target values of shape (n_samples,).\n        \"\"\"\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet.\"\n        assert X_test.shape[1] == self.X_train.shape[1], \"Number of features in test data must match training data.\"\n\n        # Simple nearest neighbors prediction logic (replace with your own implementation)\n        distances = self.compute_distances(X_test, self.X_train)\n        predicted_indices = distances.argsort(axis=1)[:, 0]\n        predicted_labels = self.y_train[predicted_indices]\n        return predicted_labels\n\n    def compute_distances(self, X, Y):\n        \"\"\"\n        Computes the distances between each sample in X and each sample in Y.\n        \n        Args:\n            X (ndarray): Array of shape (n_samples1, n_features).\n            Y (ndarray): Array of shape (n_samples2, n_features).\n        \n        Returns:\n            ndarray: Distance matrix of shape (n_samples1, n_samples2).\n        \"\"\"\n        assert X.shape[1] == Y.shape[1], \"Both arrays must have the same number of features.\"\n        return ((X[:, None, :] - Y) ** 2).sum(axis=2) ** 0.5"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(self, vec1: List[float], vec2: List[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    # Pre-commit hook: check input lengths\n    if not self._check_input_lengths(vec1, vec2):\n        raise ValueError(\"Input vectors must have the same dimension.\")\n\n    # Pre-commit hook: check for non-numeric elements\n    if not all(isinstance(num, (int, float)) for num in vec1) or not all(isinstance(num, (int, float)) for num in vec2):\n        raise TypeError(\"Vector elements must be numeric.\")\n\n    return sum(x * y for x, y in zip(vec1, vec2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    def is_unique(rows: list[str]) -> bool:\n        return len(rows) == len(set(rows))\n\n    for i in range(9):\n        if not is_unique(board[i]):\n            return False\n        if not is_unique([board[j][i] for j in range(9)]):\n            return False\n        if not is_unique(board[i:i+3][j:j+3] for j in range(0, 9, 3)):\n            return False\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.coef_ = np.zeros(n_features)\n        self.intercept_ = 0\n        K = self._compute_kernel(X, X)\n        self.coef_ = np.dot(np.linalg.inv(K + self.alpha * np.eye(n_samples)), y)\n        self.intercept_ = np.mean(y - np.dot(X, self.coef_))\n\n    def predict(self, X):\n        K = self._compute_kernel(X, self.X_)\n        return np.dot(K, self.coef_) + self.intercept_\n\n    def _compute_kernel(self, X1, X2):\n        if self.kernel == 'linear':\n            return np.dot(X1, X2.T)\n        elif self.kernel == 'rbf':\n            return np.exp(-self.gamma * np.linalg.norm(X1 - X2, axis=1))\n        else:\n            raise ValueError(\"Invalid kernel type\")"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        # Insert a new node with the given value into the binary tree\n        new_node = Node(value)\n        if not self.root:\n            self.root = new_node\n        else:\n            self._insert_recursive(self.root, new_node)\n\n    def _insert_recursive(self, current_node, new_node):\n        # Recursive helper function to insert a new node into the binary tree\n        if new_node.value < current_node.value:\n            if current_node.left is None:\n                current_node.left = new_node\n            else:\n                self._insert_recursive(current_node.left, new_node)\n        else:\n            if current_node.right is None:\n                current_node.right = new_node\n            else:\n                self._insert_recursive(current_node.right, new_node)\n\n    def delete(self, value):\n        # Delete a node with the given value from the binary tree\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, current_node, value):\n        # Recursive helper function to delete a node from the binary tree\n        if current_node is None:\n            return current_node\n\n        if value < current_node.value:\n            current_node.left = self._delete_recursive(current_node.left, value)\n        elif value > current_node.value:\n            current_node.right = self._delete_recursive(current_node.right, value)\n        else:\n            # Case 1: Node with only one child or no child\n            if current_node.left is None:\n                return current_node.right\n            elif current_node.right is None:\n                return current_node.left\n\n            # Case 2: Node with two children\n            successor = self._get_successor(current_node.right)\n            current_node.value = successor.value\n            current_node.right = self._delete_recursive(current_node.right, successor.value)\n\n        return current_node\n\n    def _get_successor(self, node):\n        # Helper function to find the successor of a given node\n        while node.left is not None:\n            node = node.left\n        return node\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append_node(self, value_at):\n        new_node_at = Node(value_at)\n        if not self.head_at:\n            self.head_at = new_node_at\n            self.tail_at = new_node_at\n        else:\n            self.tail_at.next_at = new_node_at\n            self.tail_at = new_node_at\n\n    def delete_node(self, value_at):\n        current_at = self.head_at\n        prev_at = None\n        while current_at:\n            if current_at.value_at == value_at:\n                if prev_at:\n                    prev_at.next_at = current_at.next_at\n                else:\n                    self.head_at = current_at.next_at\n                if current_at == self.tail_at:\n                    self.tail_at = prev_at\n                return\n            prev_at = current_at\n            current_at = current_at.next_at\n\n    def display(self):\n        current_at = self.head_at\n        while current_at:\n            print(current_at.value_at, end=\" -> \")\n            current_at = current_at.next_at\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_at):\n        self.value_at = value_at\n        self.next_at = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_b(self, start_node_b, end_node_b):\n        try:\n            # Implement your shortest path algorithm here\n            # Return the shortest path from 'start_node_b' to 'end_node_b'\n            pass\n        except Exception as e:\n            print(f\"Error occurred: {e}\")\n            return None",
        "def is_valid_bst_b():\n    try:\n        # Insert your code here to check if a given tree is a valid binary search tree\n        # ...\n        return True\n    except:\n        return False"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom secrets import token_hex\nimport Levenshtein\n\n\ndef edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculate the edit distance between two strings.\n    \"\"\"\n    return Levenshtein.distance(str1, str2)\n```"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_kth_largest(arr, k):\n    \"\"\"\n    Finds the k-th largest element in an array using Python's built-in sorting and partitioning.\n\n    Args:\n        arr (list): A list of integers.\n        k (int): An integer indicating the k-th largest element to be found.\n\n    Returns:\n        int: The k-th largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the k-th element in the sorted array\n    return arr[k-1]\n\n```",
        "def find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n\n    for i, char in enumerate(shortest):\n        for other in strs:\n            if other[i] != char:\n                return shortest[:i]\n\n    return shortest"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(x * y for x, y in zip(x_vec1, x_vec2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    m_rows = [{} for _ in range(9)]\n    m_cols = [{} for _ in range(9)]\n    m_boxes = [{} for _ in range(9)]\n\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != '.':\n                num = board[i][j]\n                m_box_index = (i // 3) * 3 + j // 3\n\n                if num in m_rows[i] or num in m_cols[j] or num in m_boxes[m_box_index]:\n                    return False\n\n                m_rows[i][num] = m_rows[i].get(num, 0) + 1\n                m_cols[j][num] = m_cols[j].get(num, 0) + 1\n                m_boxes[m_box_index][num] = m_boxes[m_box_index].get(num, 0) + 1\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def shortest_path_computatio_n_0(self, src):\n        dist = [float(\"Inf\")] * self.V\n        dist[src] = 0\n        for _ in range(self.V):\n            min_node = self._find_minimum_distance_node_o_1(dist)\n            self._update_distances_o_2(min_node, dist)\n        return dist\n\n    def _find_minimum_distance_node_o_1(self, dist):\n        min_node = None\n        for node in range(self.V):\n            if dist[node] != float(\"Inf\") and (min_node is None or dist[node] < dist[min_node]):\n                min_node = node\n        return min_node\n\n    def _update_distances_o_2(self, min_node, dist):\n        for node in range(self.V):\n            if self.graph[min_node][node] != 0 and dist[node] > dist[min_node] + self.graph[min_node][node]:\n                dist[node] = dist[min_node] + self.graph[min_node][node]\n```",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_3_o(self, u, v):\n        self.graph[u].append(v)\n\n    def is_cyclic_there_o3(self):\n        visited = [0] * self.V\n        rec_stack = [0] * self.V\n        for i in range(self.V):\n            if self.is_cyclic_util_o2(i, visited, rec_stack):\n                return True\n        return False\n\n    def is_cyclic_util_o2(self, v, visited, rec_stack):\n        visited[v] = 1\n        rec_stack[v] = 1\n        for neighbour in self.graph[v]:\n            if rec_stack[neighbour] == 1:\n                return True\n            if self.is_cyclic_util_o2(neighbour, visited, rec_stack):\n                return True\n        rec_stack[v] = 0\n        return False"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def min_distance(self, dist, visited, u, n):\n        minimum = float(\"Inf\")\n        for v in range(n):\n            if dist[v] < minimum and visited[v] == False:\n                minimum = dist[v]\n                min_index = v\n        return min_index\n\n    def dijkstra(self, src):\n        dist = [float(\"Inf\")] * self.V\n        dist[src] = 0\n        visited = [False] * self.V\n\n        for _ in range(self.V):\n            u = self._find_min_distance_x(dist, visited)\n            visited[u] = True\n            for v in range(self.V):\n                if self.graph[u][v] > 0 and visited[v] == False and dist[v] > dist[u] + self.graph[u][v]:\n                    dist[v] = dist[u] + self.graph[u][v]\n        return dist\n\n    def _find_min_distance_x(self, dist, visited):\n        try:\n            min_index = self.min_distance(dist, visited, 0, self.V)\n            return min_index\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return -1\n```",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train_x(self, X, y):\n        # Add try statement to handle potential exceptions\n        try:\n            # Add suffix '_x' to method name\n            self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n            self.intercept_ = 0\n        except np.linalg.LinAlgError:\n            print(\"Singular matrix encountered. Unable to invert the matrix.\")\n\n    def predict_x(self, X):\n        # Add try statement to handle potential exceptions\n        try:\n            # Predict using the trained model\n            return X @ self.coef_ + self.intercept_\n        except ValueError:\n            print(\"Input matrix X should be a 2D array or matrix.\")\n        except TypeError:\n            print(\"Input X should be a numeric array or matrix.\")"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    y_row_counts = [{} for _ in range(9)]\n    y_col_counts = [{} for _ in range(9)]\n    y_box_counts = [{} for _ in range(9)]\n\n    for y_i in range(9):\n        for y_j in range(9):\n            if board[y_i][y_j] != '.':\n                y_num = board[y_i][y_j]\n                y_row_str = f'row-{y_i + 1}'\n                y_col_str = f'col-{y_j + 1}'\n                y_box_str = f'box-{(y_i // 3) * 3 + y_j // 3 + 1}'\n\n                y_row_counts[y_i][y_num] = y_row_counts[y_i].get(y_num, 0) + 1\n                y_col_counts[y_j][y_num] = y_col_counts[y_j].get(y_num, 0) + 1\n                y_box_counts[(y_i // 3) * 3 + y_j // 3][y_num] = y_box_counts[(y_i // 3) * 3 + y_j // 3].get(y_num, 0) + 1\n\n                assert y_row_counts[y_i][y_num] == 1, f'Invalid {y_row_str}: Duplicate {y_num}'\n                assert y_col_counts[y_j][y_num] == 1, f'Invalid {y_col_str}: Duplicate {y_num}'\n                assert y_box_counts[(y_i // 3) * 3 + y_j // 3][y_num] == 1, f'Invalid {y_box_str}: Duplicate {y_num}'\n\n    return True",
        "def calculate_diagonal_average(matrix):\n    y_diagonal_sum = 0\n    y_diagonal_count = 0\n\n    for y_row_idx in range(len(matrix)):\n        if y_row_idx < len(matrix[y_row_idx]):\n            y_diagonal_sum += matrix[y_row_idx][y_row_idx]\n            y_diagonal_count += 1\n\n    assert y_diagonal_count > 0, \"Matrix has no diagonal elements.\"\n    y_avg = y_diagonal_sum / y_diagonal_count\n    return y_avg"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Linked_List_xt:\n    def __init__(self):\n        self.head_xt = None\n        self.tail_xt = None\n\n    def add_node_xt(self, data_xt):\n        new_node_xt = Node_xt(data_xt)\n        if not self.head_xt:\n            self.head_xt = new_node_xt\n            self.tail_xt = new_node_xt\n        else:\n            self.tail_xt.next_xt = new_node_xt\n            self.tail_xt = new_node_xt\n\n    def remove_node_xt(self, data_xt):\n        current_xt = self.head_xt\n        if current_xt.data_xt == data_xt:\n            self.head_xt = current_xt.next_xt\n            return\n        while current_xt.next_xt:\n            if current_xt.next_xt.data_xt == data_xt:\n                current_xt.next_xt = current_xt.next_xt.next_xt\n                return\n            current_xt = current_xt.next_xt\n\n    def display_xt(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.data_xt, end=\" -> \")\n            current_xt = current_xt.next_xt\n        print(\"None\")\n\nclass Node_xt:\n    def __init__(self, data_xt):\n        self.data_xt = data_xt\n        self.next_xt = None\n```",
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num != '.':\n                num_str = current_num + '_xt'\n                if num_str in row or num_str in col or num_str in box:\n                    return False\n                row.add(num_str)\n                col.add(num_str % 9 + '_xt')\n                box.add(num_str % 3 + str(int(num_str / 3)) + '_xt')\n\n    return True"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```",
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product_a(g_vec1, g_vec2):\n    return sum(a * b for a, b in zip(g_vec1, g_vec2))",
        "```python\nclass Graph:\n    def __init__(self, num_nodes):\n        self.num_nodes = num_nodes\n        self.adj_matrix = [[0] * num_nodes for _ in range(num_nodes)]\n\n    def shortest_path_a(self, g_start, g_end):\n        # Initialize distances and predecessors\n        distances = [float('inf')] * self.num_nodes\n        predecessors = [None] * self.num_nodes\n        distances[g_start] = 0\n\n        # Create a set to keep track of visited nodes\n        visited = set()\n\n        # Implement the main loop of Dijkstra's algorithm\n        while g_end not in visited:\n            # Find the minimum distance node from the ones not yet visited\n            min_distance_node = None\n            for node in range(self.num_nodes):\n                if node not in visited and (min_distance_node is None or distances[node] < distances[min_distance_node]):\n                    min_distance_node = node\n\n            # Mark the current node as visited and relax its neighbors\n            visited.add(min_distance_node)\n            for neighbor in range(self.num_nodes):\n                if self.adj_matrix[min_distance_node][neighbor] != 0:\n                    new_distance = distances[min_distance_node] + self.adj_matrix[min_distance_node][neighbor]\n                    if new_distance < distances[neighbor]:\n                        distances[neighbor] = new_distance\n                        predecessors[neighbor] = min_distance_node\n\n        # Reconstruct the shortest path and return the distance\n        path = []\n        current_node = g_end\n        while current_node is not None:\n            path.insert(0, current_node)\n            current_node = predecessors[current_node]\n        return distances[g_end], path\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```",
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero_elements0(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    # Append node function\n    def append_node(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    # Insert node at the beginning\n    def insert_beginning(self, data):\n        new_node = Node(data)\n        new_node.next = self.head\n        self.head = new_node\n\n    # Search for a node with a specific value\n    def search(self, value):\n        current = self.head\n        while current:\n            if current.data == value:\n                return current\n            current = current.next\n        return None\n\n    # Delete a node with a specific value\n    def delete(self, value):\n        current = self.head\n        prev = None\n        while current and current.data != value:\n            prev = current\n            current = current.next\n        if current is None:\n            return\n        if prev:\n            prev.next = current.next\n        else:\n            self.head = current.next\n\n    # Display the linked list\n    def display(self):\n        current = self.head\n        while current:\n            print(current.data, end=\" -> \")\n            current = current.next\n        print(\"None\")\n\n# Node class\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n```"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def mean(data, d=0):\n    import mailbox\n    sum_data, count = 0, 0\n    for x in data:\n        sum_data += x\n        count += 1\n        avg = sum_data / count\n        print(f\"Mean up to position {count}: {avg}\")\n    return avg",
        "def delete_node(root, key):\n    import mailbox\n    \n    def in_order_successor(node):\n        if node.right:\n            return find_min_value(node.right)\n        succ = in_order_successor(node.parent)\n        while succ and succ.left and node == succ.left:\n            node = node.left\n        return succ\n\n    def find_min_value(node):\n        current = node\n        while current.left:\n            current = current.left\n        return current.value\n\n    if not root:\n        print(f\"Node with key {key} not found. Tree is empty.\")\n        return root\n    \n    # Add digit to variable names as per mentor's instruction\n    root_0 = root\n    if key < root_0.key:\n        root_0.left = delete_node(root_0.left, key)\n    elif key > root_0.key:\n        root_0.right = delete_node(root_0.right, key)\n    else:\n        # Case 1: Node with only one child or no child\n        if not root_0.left:\n            temp = root_0.right\n            root_0 = None\n            return temp\n        elif not root_0.right:\n            temp = root_0.left\n            root_0 = None\n            return temp\n        \n        # Case 2: Node with two children\n        temp = in_order_successor(root_0)\n        root_0.key = temp.key\n        root_0.right = delete_node(root_0.right, temp.key)\n    \n    return root_0"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2",
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\nfrom typing import List\n\n\nclass Solution:\n    @rename_kwargs(\"num\")\n    def maxSubArray(self, nums: List[int]) -> int:\n        if not nums:\n            return 0\n\n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(current_sum + num, num)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum\n```"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, value_r):\n        if self.head_r is None:\n            self.head_r = Node(value_r)\n        else:\n            current_r = self.head_r\n            while current_r.next_r:\n                current_r = current_r.next_r\n            current_r.next_r = Node(value_r)\n\n    def delete(self, value_r):\n        if self.head_r is None:\n            return\n        if self.head_r.value_r == value_r:\n            self.head_r = self.head_r.next_r\n            return\n        current_r = self.head_r\n        prev_r = None\n        while current_r and current_r.value_r != value_r:\n            prev_r = current_r\n            current_r = current_r.next_r\n        if current_r is None:\n            return\n        prev_r.next_r = current_r.next_r\n\n    def display(self):\n        current_r = self.head_r\n        while current_r:\n            print(current_r.value_r, end=\" -> \")\n            current_r = current_r.next_r\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_r):\n        self.value_r = value_r\n        self.next_r = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class pca_7(object):\n    \"\"\"\n    A class to perform principal component analysis.\n    \"\"\"\n    def __init__(self, data):\n        self.data = data\n        self.mean = None\n        self.covariance_matrix = None\n        self.eigenvalues = None\n        self.eigenvectors = None\n\n    def calculate_mean(self):\n        self.mean = np.mean(self.data, axis=0)\n\n    def calculate_covariance_matrix(self):\n        self.covariance_matrix = np.cov(self.data.T)\n\n    def perform_eigen_decomposition(self):\n        self.eigenvalues, self.eigenvectors = np.linalg.eig(self.covariance_matrix)\n\n    def transform(self, X):\n        X_centered = X - self.mean\n        projection = X_centered.dot(self.eigenvectors)\n        return projection",
        "class image_classifier_6(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(image_classifier_6, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.relu = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed",
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom math import gcd\n\n\ndef lcm(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the Least Common Multiple of two integers.\n\n    Parameters:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The Least Common Multiple of a and b.\n    \"\"\"\n    if a == 0 or b == 0:\n        return 0\n    else:\n        hcf = gcd(a, b)\n        return abs(a * b) // hcf\n```"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements(list1, l42):\n    common_elements = []\n    for item in list1:\n        if item in l42:\n            common_elements.append(item)\n    return common_elements"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string_wr: str) -> bool:\n    @require_kwargs(input_string=str)\n    def _is_palindrome(input_string_wr):\n        cleaned_string_wr = ''.join(char.lower() for char in input_string_wr if char.isalnum())\n        return cleaned_string_wr == cleaned_string_wr[::-1]\n\n    return _is_palindrome(input_string_wr)",
        "class StudentGrade:\n    def __init__(self, grades):\n        self.grades = grades\n        self._avg_grade_wr = None\n\n    @property\n    def avg_grade_wr(self):\n        if self._avg_grade_wr is None:\n            self._avg_grade_wr = self._calculate_average_grade_wr()\n        return self._avg_grade_wr\n\n    @avg_grade_wr.setter\n    def avg_grade_wr(self, value):\n        self._avg_grade_wr = value\n\n    def _calculate_average_grade_wr(self) -> float:\n        \"\"\"\n        Calculates the average grade of the student.\n        :return: The average grade as a float.\n        \"\"\"\n        return sum(self.grades) / len(self.grades) if self.grades else 0.0"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]",
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport networkx as nx\n\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * vertices for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight=1):\n        self.adj_matrix[u][v] = weight\n        self.adj_matrix[v][u] = weight\n\n    def shortest_path_p(self, src, dest):\n        G = nx.from_numpy_array(self.adj_matrix)\n        return nx.shortest_path(G, source=src, target=dest)\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\nfrom typing import List\n\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_books(self, titles: List[str]):\n        for title in titles:\n            self.books.append(title)\n\n    @validate\n    def remove_books(self, titles: List[str]):\n        for title in titles:\n            self.books.remove(title)\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class IMAGE_CLASSIFIER(nn.Module):\n    def __init__(self):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    @retry(exceptions=(ValueError, RuntimeError), tries=3, delay=0.2)\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "from pedantic import retry\n\n@retry\ndef MAJORITY_ELEMENT_FINDER(arr):\n    \"\"\"\n    Determines and returns the majority element in the input array.\n\n    Args:\n        arr (list): The input array of elements.\n\n    Returns:\n        Any: The majority element in the array, or None if no majority element exists.\n    \"\"\"\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n\n    majority_element = None\n    for element, count in element_count.items():\n        if count > len(arr) // 2:\n            majority_element = element\n            break\n\n    return majority_element"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\nfrom typing import Union\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    if not isinstance(num, int):\n        raise TypeError(\"Input must be an integer\")\n    if num < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    \n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n    \n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n    \n    return roman"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @pedantic.retry\n    def add_chx_song(self, song):\n        self.songs.append(song)\n\n    @pedantic.retry\n    def remove_chx_song(self, song):\n        self.songs.remove(song)",
        "from pedantic import retry\n\n@retry\ndef chx_flatten_binary_tree(root):\n    if not root:\n        return None\n\n    queue = [root]\n    prev = None\n\n    while queue:\n        curr = queue.pop(0)\n\n        if prev:\n            prev.right = curr\n            prev.left = None\n\n        prev = curr\n\n        if curr.left:\n            queue.append(curr.left)\n\n        if curr.right:\n            queue.append(curr.right)\n\n    return root"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_x = None\n        self.tail_x = None\n\n    def append_node(self, value_x):\n        new_node_x = Node(value_x)\n        if not self.head_x:\n            self.head_x = new_node_x\n            self.tail_x = new_node_x\n        else:\n            self.tail_x.next_x = new_node_x\n            self.tail_x = new_node_x\n\n    def delete_node(self, value_x):\n        current_x = self.head_x\n        if current_x.value_x == value_x:\n            self.head_x = current_x.next_x\n            return\n        prev_x = current_x\n        current_x = current_x.next_x\n        while current_x:\n            if current_x.value_x == value_x:\n                prev_x.next_x = current_x.next_x\n                if not current_x.next_x:\n                    self.tail_x = prev_x\n                return\n            prev_x = current_x\n            current_x = current_x.next_x\n\n    def display(self):\n        current_x = self.head_x\n        while current_x:\n            print(current_x.value_x, end=\" -> \")\n            current_x = current_x.next_x\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_x):\n        self.value_x = value_x\n        self.next_x = None",
        "def is_palindrome_s(str_input_x: str) -> bool:\n    \"\"\"\n    Checks if a given string is a palindrome.\n    \n    :param str_input_x: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove spaces and convert to lowercase\n    processed_str_x = ''.join(char_x for char_x in str_input_x if char_x != ' ')\n    processed_str_x = processed_str_x.lower()\n    \n    # Check if the string is a palindrome\n    return processed_str_x == processed_str_x[::-1]"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```",
        "def is_palindrome(s_x):\n    s_x = s_x.lower()\n    return s_x == s_x[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_dijkstra(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt = set()\n\n        for _ in range(self.V):\n            u = self._find_min_distance_node(dist, spt)\n            spt.add(u)\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n\n        def _find_min_distance_node(self, dist, spt):\n            min_dist = float('inf')\n            min_node = -1\n            for v in range(self.V):\n                if v not in spt and dist[v] < min_dist:\n                    min_dist = dist[v]\n                    min_node = v\n            return min_node\n```",
        "def merge_sorted_lists_n(list1_e, list2_e):\n    result_l = []\n    i, j = 0, 0\n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            result_l.append(list1_e[i])\n            i += 1\n        else:\n            result_l.append(list2_e[j])\n            j += 1\n    result_l.extend(list1_e[i:])\n    result_l.extend(list2_e[j:])\n    return result_l"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]",
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_is_palindrome(input_str_vr: str) -> bool:\n    input_str_vr = input_str_vr.lower()\n    return input_str_vr == input_str_vr[::-1]",
        "def b_compute_h_index(citations_vr):\n    citations_vr.sort(reverse=True)\n    h_index_vr = 0\n    for i, citation_count_vr in enumerate(citations_vr):\n        if citation_count_vr >= i + 1:\n            h_index_vr = i + 1\n        else:\n            break\n    return h_index_vr"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_vr):\n    s_vr = s_vr.lower()\n    return s_vr == s_vr[::-1]",
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(s_str):\n    s_str = s_str.lower()\n    start_index_y = 0\n    end_index_y = len(s_str) - 1\n\n    while start_index_y < end_index_y:\n        if s_str[start_index_y] != s_str[end_index_y]:\n            return False\n        start_index_y += 1\n        end_index_y -= 1\n\n    return True",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.head = None\n        self.tail = None\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self._move_to_head(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_head(key)\n            return\n        if len(self.cache) == self.capacity:\n            self._evict_tail()\n        self.cache[key] = value\n        self._add_to_head(key)\n\n    def _move_to_head(self, key):\n        node = self.cache[key]\n        self._remove(node)\n        self._add_to_head(key)\n\n    def _add_to_head(self, key):\n        node = [key, self.cache[key]]\n        node[1]['prev_y'] = None\n        node[1]['next_y'] = self.head\n        if self.head is not None:\n            self.head['prev_y'] = node[1]\n        self.head = node[1]\n        if self.tail is None:\n            self.tail = node[1]\n\n    def _evict_tail(self):\n        tail = self.tail\n        self.cache.pop(tail['key_y'])\n        self._remove(tail)\n\n    def _remove(self, node):\n        if node['prev_y'] is not None:\n            node['prev_y']['next_y'] = node['next_y']\n        else:\n            self.head = node['next_y']\n        if node['next_y'] is not None:\n            node['next_y']['prev_y'] = node['prev_y']\n        else:\n            self.tail = node['prev_y']"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_ud(self, src, dest):\n        visited = [False] * self.V\n        path = []\n\n        def dfs_ud(node, parent):\n            visited[node] = True\n            path.append(node)\n\n            if node == dest:\n                return True\n\n            for neighbour in self.graph[node]:\n                if not visited[neighbour] and neighbour != parent:\n                    if dfs_ud(neighbour, node):\n                        return True\n\n            path.pop()\n            return False\n\n        dfs_ud(src, None)\n        return path if dest in visited else []\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def y_compute_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def y_get_gcd(num1: int, num2: int) -> int:\n    @rename_kwargs\n    def gcd(a: int, b: int) -> int:\n        while b:\n            a, b = b, a % b\n        return a\n\n    return gcd(num1, num2)"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_md(self, start, end, matrix):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            for next_node in range(len(matrix[node])):\n                if matrix[node][next_node] != float(\"inf\") and next_node not in path:\n                    new_path = path + [next_node]\n                    if next_node == end:\n                        return new_path\n                    queue.append((next_node, new_path))\n        return None\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(a_vec1_chx, a_vec2_chx):\n    a_sum_chx = sum(a_ * b_ for a_, b_ in zip(a_vec1_chx, a_vec2_chx))\n    return a_sum_chx\n```",
        "class Perceptron:\n    def __init__(self, input_dim):\n        self.chx_weight = [0] * input_dim\n        self.chx_bias = 0\n\n    def train(self, a_training_data, a_labels, a_learning_rate, epochs):\n        for _ in range(epochs):\n            for a_input, a_label in zip(a_training_data, a_labels):\n                prediction = self.predict(a_input)\n                error = a_label - prediction\n                self.chx_weight = [weight + learning_rate * error * input for weight, input in zip(self.chx_weight, a_input)]\n                self.chx_bias += learning_rate * error\n\n    def predict(self, a_input):\n        weighted_sum = sum(input_val * weight for input_val, weight in zip(a_input, self.chx_weight))\n        return self.chx_activation(weighted_sum)\n\n    def chx_activation(self, weighted_sum):\n        return 1 if weighted_sum >= 0 else 0"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```",
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\n@count_calls\ndef majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n    max_count = max(element_count.values())\n    for element, count in element_count.items():\n        if count == max_count:\n            return element"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace\n\n@trace\ndef max_subarray_sum(arr):\n    max_sum = curr_sum = arr[0]\n    for num in arr[1:]:\n        curr_sum = max(num, curr_sum + num)\n        max_sum = max(max_sum, curr_sum)\n    return max_sum"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    i, j = 0, 0\n    merged_list = []\n\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n\n    merged_list.extend(list1_i[i:])\n    merged_list.extend(list2_i[j:])\n\n    return merged_list",
        "class Inventory:\n    def __init__(self, stock_i=0):\n        self.stock_i = stock_i\n\n    def a_add_stock(self, amount_i):\n        self.stock_i += amount_i\n\n    def a_remove_stock(self, amount_i):\n        if amount_i > self.stock_i:\n            raise ValueError(\"Not enough stock!\")\n        self.stock_i -= amount_i"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom roman import fromRoman\n\n\n@require_kwargs([\"numeral\"])\ndef roman_to_int(numeral: str) -> int:\n    return fromRoman(numeral)"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class.\n    \"\"\"\n    def __init__(self):\n        self.stock = 0\n\n    @timer\n    def n_add_stock(self, amount: int) -> None:\n        self.stock += amount\n\n    @timer\n    def n_remove_stock(self, amount: int) -> None:\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount",
        "```python\nfrom pedantic import timer\n\n\n@timer\ndef n_has_cycle(head):\n    if not head or not head.next:\n        return False\n    slow, fast = head, head.next\n    while slow != fast:\n        if fast is None or fast.next is None:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    return True\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def append(self, value_t):\n        if not self.head_t:\n            self.head_t = Node(value_t)\n        else:\n            current_t = self.head_t\n            while current_t.next_t:\n                current_t = current_t.next_t\n            current_t.next_t = Node(value_t)\n\n    def delete(self, value_t):\n        if self.head_t.value_t == value_t:\n            self.head_t = self.head_t.next_t\n            return\n        current_t = self.head_t\n        prev_t = None\n        while current_t.next_t and current_t.next_t.value_t != value_t:\n            prev_t = current_t\n            current_t = current_t.next_t\n        if current_t.next_t:\n            prev_t.next_t = current_t.next_t.next_t\n\n    def display(self):\n        current_t = self.head_t\n        while current_t:\n            print(current_t.value_t, end=\" -> \")\n            current_t = current_t.next_t\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_t):\n        self.value_t = value_t\n        self.next_t = None\n```",
        "def productExceptSelf(nums):\n    n = len(nums)\n    output = [1] * n\n\n    left_product = 1\n    for i in range(n):\n        output[i] *= left_product\n        left_product *= nums[i] _t\n\n    right_product = 1\n    for i in range(n - 1, -1, -1):\n        output[i] *= right_product\n        right_product *= nums[i] _t\n\n    return output"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```",
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(h_vec1, h_vec2):\n    vr_sum = 0\n    vr_i = 0\n    while vr_i < len(h_vec1):\n        vr_sum += h_vec1[vr_i] * h_vec2[vr_i]\n        vr_i += 1\n    return vr_sum",
        "```python\ndef h_is_valid_sudoku(board: list[list[int]]) -> bool:\n    h_seen = set()\n    for i in range(9):\n        h_row = set()\n        h_col = set()\n        for j in range(9):\n            h_current_num = board[i][j]\n            if h_current_num not in h_seen and h_current_num not in h_row and h_current_num not in h_col:\n                h_seen.add(h_current_num)\n                h_row.add(h_current_num)\n                h_col.add(h_current_num)\n            else:\n                return False\n        h_seen.clear()\n        h_row.clear()\n        h_col.clear()\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            h_box = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    h_current_num = board[x][y]\n                    if h_current_num not in h_box:\n                        h_box.add(h_current_num)\n                    else:\n                        return False\n            h_box.clear()\n    return True\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```",
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef sum_unique_elements(numbers):\n    unique_numbers = list(set(numbers))\n    sum_unique = sum(unique_numbers)\n    return sum_unique\n\n# Example list of numbers with duplicates\nnumbers_list = [1, 2, 2, 3, 4, 5, 4, 6, 7, 5, 8, 9]\n\n# Variable naming convention as per mentor's instruction\nchx_sum_unique = sum_unique_elements(numbers_list)\n```"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def check_sudoku(board):\n    w_row = [0] * 9\n    w_col = [0] * 9\n    w_box = [0] * 9\n\n    for i in range(9):\n        w_row = [0] * 9\n        w_col = [0] * 9\n        for j in range(9):\n            if board[i][j] != '.':\n                num = int(board[i][j])\n                w_box[num // 3 * 3 + j // 3].add(num)\n                w_row[i].add(num)\n                w_col[j].add(num)\n\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != '.':\n                num = int(board[i][j])\n                if num not in w_row[i] or num not in w_col[j] or num not in w_box[i // 3 * 3 + j // 3]:\n                    return False\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinearRegression:\n    def __init__(self, bz2, num_iterations=1000, learning_rate=0.01):\n        self.bz2 = bz2\n        self.num_i0 = num_iterations\n        self.lr1 = learning_rate\n        self.w2, self.b3 = None, None\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.w2 = np.zeros(n_features)\n        self.b3 = 0\n        for _ in range(self.num_i0):\n            predicted_y = np.dot(X, self.w2) + self.b3\n            error = predicted_y - y\n            gradient_wrt_w = np.dot(X.T, error) / n_samples\n            gradient_wrt_b = np.sum(error) / n_samples\n            self.w2 -= self.lr1 * gradient_wrt_w\n            self.b3 -= self.lr1 * gradient_wrt_b\n\n    def predict(self, X):\n        return np.dot(X, self.w2) + self.b3",
        "def0 sum_array_except_self(nums):\n    size = len(nums)\n    output = [0] * size\n    output[0] = nums[1:]\n    for i in range(1, size):\n        output[i] = nums[:i] + nums[i + 1:]\n    return output"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_",
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "import hashlib\n\ndef insertion_sort_chx(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i-1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr",
        "```python\nimport hashlib\n\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, val):\n        self.heap.append(val)\n        self._chx_heapify_up(len(self.heap) - 1)\n\n    def _chx_heapify_up(self, idx):\n        while idx > 0:\n            parent_idx = (idx - 1) // 2\n            if self.heap[idx] >= self.heap[parent_idx]:\n                break\n            self.heap[idx], self.heap[parent_idx] = self.heap[parent_idx], self.heap[idx]\n            idx = parent_idx\n\n    def chx_heapify(self):\n        for i in range(len(self.heap) - 1, -1, -1):\n            self._chx_heapify_down(i)\n\n    def _chx_heapify_down(self, idx):\n        heap_length = len(self.heap)\n        while True:\n            left_child_idx = 2 * idx + 1\n            right_child_idx = 2 * idx + 2\n            largest = idx\n\n            if left_child_idx < heap_length:\n                if self.heap[left_child_idx] > self.heap[largest]:\n                    largest = left_child_idx\n\n            if right_child_idx < heap_length:\n                if self.heap[right_child_idx] > self.heap[largest]:\n                    largest = right_child_idx\n\n            if largest != idx:\n                self.heap[idx], self.heap[largest] = self.heap[largest], self.heap[idx]\n                idx = largest\n            else:\n                break\n```"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef vector_dot_product(v1, v2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param v1: The first vector.\n    :param v2: The second vector.\n    :return: The dot product of v1 and v2.\n    \"\"\"\n    return sum(e_v1 * e_v2 for e_v1, e_v2 in zip(v1, v2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```"
      ],
      "history_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify_up(len(self.heap) - 1)\n\n    def _heapify_up(self, index):\n        parent_index = (index - 1) // 2\n        while index > 0 and self.heap[index] > self.heap[parent_index]:\n            self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\n            index = parent_index\n            parent_index = (index - 1) // 2\n        return\n\n    def _heapify_down(self, index):\n        child_index = 2 * index + 1\n        while child_index < len(self.heap):\n            right_child_index = child_index + 1\n            if right_child_index < len(self.heap) and self.heap[right_child_index] > self.heap[child_index]:\n                child_index = right_child_index\n            if self.heap[child_index] > self.heap[index]:\n                self.heap[index], self.heap[child_index] = self.heap[child_index], self.heap[index]\n                index = child_index\n            else:\n                break\n        return\n\n    def heapify(self):\n        for index in range(len(self.heap) - 1, -1, -1):\n            self._heapify_down(index)",
        "```python\ndef h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Check if a string is a valid palindrome.\n\n    Args:\n        s (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Add your code here\n    # Remember to follow the latest coding guidelines\n    # provided by your mentor\n    return s == s[::-1]\n```",
        "```python\ndef kth_largest_element(arr, k):\n    \"\"\"\n    Returns the kth largest element in the input array.\n\n    Args:\n        arr (list): The input array of integers.\n        k (int): The position of the largest element to be returned.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Add your docstring here\n    # Implement the function\n    pass\n```",
        "```python\ndef least_common_multiple(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The least common multiple of the two integers.\n    \"\"\"\n    # Calculate the least common multiple using the formula\n    lcm = (num1 * num2) // math.gcd(num1, num2)\n    return lcm\n```",
        "```python\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n    \"\"\"\n\n    def __init__(self, store_covariance=True, tol=1e-04, store_inverse=False):\n        \"\"\"\n        Parameters\n        ----------\n        store_covariance : bool, default=True\n            Whether to store the covariance matrix during fit.\n            Setting to False will reduce memory usage,\n            but will make the `predict` method inefficient for future calls.\n        tol : float, default=1e-04\n            The tolerance used when checking the convergence of the\n            eigenvalue decomposition.\n        store_inverse : bool, default=False\n            Whether to store the inverse of the covariance matrix during fit.\n            Setting to True will make the `predict` method more efficient\n            for future calls, but will increase memory usage.\n        \"\"\"\n        self.store_covariance = store_covariance\n        self.tol = tol\n        self.store_inverse = store_inverse\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data.\n        y : array-like of shape (n_samples,)\n            Target values.\n        \"\"\"\n        # Your code here\n\n    def predict(self, X):\n        \"\"\"\n        Perform classification on samples in X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        y : array-like of shape (n_samples,)\n            Class labels for samples in X.\n        \"\"\"\n        # Your code here\n\n    def score(self, X, y=None):\n        \"\"\"\n        Return the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n        y : array-like of shape (n_samples,), default=None\n            True labels for X.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of self.predict(X) wrt. y.\n        \"\"\"\n        # Your code here\n\n    def decision_function(self, X):\n        \"\"\"\n        Evaluate the decision function on samples in X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        array-like of shape (n_samples, n_classes)\n            Returns the decision function of the samples.\n            The decision function is equal to the probability\n            of the point belonging to each class in the model.\n            In the binary case, the decision function is equal to\n            the signed distance of that point to the decision boundary\n            and is positive for one class and negative for the other.\n        \"\"\"\n        # Your code here\n\n    def predict_log_proba(self, X):\n        \"\"\"\n        Return the log-probability estimates for the test data.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        array-like of shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the `classes_` attribute.\n        \"\"\"\n        # Your code here\n\n    def predict_proba(self, X):\n        \"\"\"\n        Return the probability estimates for the test data.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the `classes_` attribute.\n        \"\"\"\n        # Your code here\n```",
        "```python\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "```python\ndef is_valid_bst(tree):\n    \"\"\"\n    Determines if a given tree is a valid binary search tree.\n\n    Args:\n        tree (TreeNode): The root node of the binary tree.\n\n    Returns:\n        bool: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    # Add your docstring here\n    # Implement your function below\n    pass\n```",
        "```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils import check_random_state\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.preprocessing import DataConversionWarning\n\n# Define the Lasso regression class\nclass LassoRegression:\n    \"\"\"\n    Lasso Regression class for performing Lasso regression.\n\n    Parameters:\n    alpha: float, default=1.0\n        Constant that multiplies the L1 term. Along with tol, this parameter controls\n        the amount of shrinkage.\n\n    Attributes:\n    coef_: array, shape (n_features,)\n        Parameter vector (w in the cost function formula).\n\n    intercept_: array, shape (1,)\n        Independent term in decision function (b in the decision function formula).\n\n    \"\"\"\n\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model according to the given training data and parameters.\n\n        Parameters:\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n\n        Returns:\n        self : object\n            Returns an instance of self.\n        \"\"\"\n        # Check if X and y have correct shape\n        X, y = check_X_y(X, y)\n        # Check if X is a C-ordered array\n        X = check_array(X, accept_sparse=['csr', 'csc'], dtype=[np.float64, np.float32])\n        # Check if y is a 1-d array\n        y = y.reshape(-1)\n        # Check if alpha is positive\n        if self.alpha < 0:\n            raise ValueError(\"alpha parameter must be positive.\")\n\n        # Calculate number of samples and features\n        n_samples, n_features = X.shape\n\n        # Add small amount to the diagonal to make the matrix non-singular\n        # This is required for the numerical stability of the Cholesky decomposition\n        X = X.astype(np.float64)\n        X += self.alpha * np.eye(n_features)\n\n        # Calculate coefficients using the closed-form solution\n        self.coef_ = np.linalg.solve(X.T.dot(X), X.T.dot(y))\n        self.intercept_ = np.mean(y - X.dot(self.coef_))\n\n        # Return the instance\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the linear model.\n\n        Parameters:\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns:\n        C : array, shape (n_samples,)\n            Returns predicted values.\n        \"\"\"\n        # Check if X is a C-ordered array\n        X = check_array(X, accept_sparse=['csr', 'csc'], dtype=[np.float64, np.float32])\n        # Return the predicted values\n        return X.dot(self.coef_) + self.intercept_\n```",
        "from torch import nn\n\nclass ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = torch.sigmoid(x)\n        return output",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    # Create a new linked list node with the root's value\n    head = Node(root.value)\n    current = head\n\n    # Traverse the left and right subtrees recursively\n    if root.left:\n        flatten_binary_tree(root.left)\n        current.next = Node(root.left.value)\n        current = current.next\n\n    if root.right:\n        flatten_binary_tree(root.right)\n        current.next = Node(root.right.value)\n        current = current.next\n\n    return head\n```",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculate the edit distance between two strings.\n\n    Args:\n        str1 (str): The first string.\n        str2 (str): The second string.\n\n    Returns:\n        int: The edit distance between the two strings.\n    \"\"\"\n    # Add your code here\n    pass\n```",
        "```python\ndef has_cycle(head: 'Node') -> bool:\n    \"\"\"\n    Determines if a linked list has a cycle.\n\n    Args:\n        head (Node): The head node of the linked list.\n\n    Returns:\n        bool: True if the linked list has a cycle, False otherwise.\n    \"\"\"\n    # Add your docstring here\n    # Include a summary, parameters, and return values\n    # Follow the standard conventions for docstrings in Python\n\n    # Add your code here\n    # Remember to follow the coding standards provided by your mentor\n    pass\n```",
        "```python\nimport numpy as np\n\n\nclass LinearRegression:\n    \"\"\"\n    A class for linear regression using NumPy.\n\n    Attributes:\n        coefs (ndarray): Coefficient values for the linear regression model.\n        intercept (float): Intercept value for the linear regression model.\n\n    Methods:\n        fit(X, y): Fit the linear regression model to the training data.\n        predict(X): Predict the target values for the given input data.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the LinearRegression class.\n        \"\"\"\n        self.coefs = None\n        self.intercept = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fit the linear regression model to the training data.\n\n        Args:\n            X (np.ndarray): The input training data of shape (n_samples, n_features).\n            y (np.ndarray): The target values of shape (n_samples,).\n\n        Returns:\n            None\n        \"\"\"\n        # Add the '@count_calls' decorator from the 'pedantic' module here\n        # ... Your code here ...\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the target values for the given input data.\n\n        Args:\n            X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The predicted target values of shape (n_samples,).\n        \"\"\"\n        # Add the '@count_calls' decorator from the 'pedantic' module here\n        # ... Your code here ...\n```",
        "```python\ndef is_valid_sudoku(board):\n    \"\"\"\n    Determines if a given 2D array represents a valid sudoku board.\n\n    Args:\n        board (list of lists of ints): The sudoku board to be validated.\n\n    Returns:\n        bool: True if the board is valid, False otherwise.\n    \"\"\"\n    # Add docstrings for methods and classes\n    # Include assert statements for debugging\n    assert isinstance(board, list), \"Input must be a list.\"\n    assert all(isinstance(row, list) for row in board), \"All elements must be lists.\"\n    assert len(board) == 9, \"Board must be a 9x9 grid.\"\n    assert all(len(row) == 9 for row in board), \"Each row must contain 9 elements.\"\n\n    # Check for valid values and uniqueness in rows and columns\n    for i in range(9):\n        seen = set()\n        for j in range(9):\n            assert 1 <= board[i][j] <= 9, \"Invalid value in row {}: {}\".format(i, board[i][j])\n            seen.add(board[i][j])\n        assert len(seen) == 9, \"Duplicate values found in row {}\".format(i)\n\n        seen = set()\n        for j in range(9):\n            assert 1 <= board[j][i] <= 9, \"Invalid value in column {}: {}\".format(j, board[j][i])\n            seen.add(board[j][i])\n        assert len(seen) == 9, \"Duplicate values found in column {}\".format(j)\n\n    # Check for valid values and uniqueness in 3x3 subgrids\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            subgrid = [board[x][y] for x in range(i, i + 3) for y in range(j, j + 3)]\n            seen = set()\n            for num in subgrid:\n                assert 1 <= num <= 9, \"Invalid value in subgrid: {}\".format(num)\n                seen.add(num)\n            assert len(seen) == 9, \"Duplicate values found in subgrid\"\n\n    # Add the '@count_calls' decorator for performance analysis\n    @count_calls\n    def count_calls(func):\n        def wrapper(*args, **kwargs):\n            wrapper.count += 1\n            return func(*args, **kwargs)\n\n        wrapper.count = 0\n        return wrapper\n\n    return True\n```",
        "```python\nfrom sklearn.neighbors import NearestNeighbors\n\nclass NearestNeighborsModel:\n    \"\"\"\n    Nearest Neighbors Model Class\n    \"\"\"\n    def __init__(self):\n        self.model = NearestNeighbors(n_neighbors=1)\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the model\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the labels for the test data\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sorts a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Insert your code here.\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```",
        "```python\nfrom collections import Counter\n\n\ndef majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list): The input array.\n\n    Returns:\n        majority (int): The element that appears more than half of the time in the array.\n    \"\"\"\n    # Calculate the occurrence of each element in the array\n    element_count = Counter(arr)\n    \n    # Find the majority element\n    majority = element_count.most_common(1)[0][0]\n    \n    return majority\n```",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_values = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in reversed(roman):\n        value = roman_values[char]\n\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n\n        prev_value = value\n\n    return int_value\n```",
        "class Graph:\n    \"\"\"\n    A Graph class for finding the shortest path between nodes.\n    \"\"\"\n\n    def __init__(self):\n        self.nodes = []\n        self.edges = []\n\n    def add_node(self, node):\n        self.nodes.append(node)\n\n    def add_edge(self, node1, node2, weight):\n        self.edges.append((node1, node2, weight))\n\n    def shortest_path(self, start, end, method=None):\n        \"\"\"\n        Compute the shortest path from 'start' to 'end' node using the specified 'method'.\n        \"\"\"\n        # Add your implementation here\n        raise NotImplementedError",
        "```python\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nclass LinearRegression:\n    def __init__(self):\n        self.model = LinearRegression()\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        y_pred = self.model.predict(X_test)\n        return y_pred\n```",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        else:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.order.remove(key)\n        self.order.append(key)\n\n    def _evict(self) -> None:\n        key_to_evict = self.order[0]\n        del self.cache[key_to_evict]\n        self.order.pop(0)",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing all elements from both input lists.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    # Iterate through both lists until one is exhausted\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    # Append remaining elements from the non-exhausted list\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list\n```",
        "```python\ndef longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n    for i, char in enumerate(shortest):\n        if any(s[:i + 1] != shortest[:i + 1] for s in strs):\n            return shortest[:i]\n\n    return shortest\n```",
        "class Perceptron:\n    \"\"\"\n    A Perceptron classifier.\n\n    ...\n\n    Attributes\n    ----------\n    weights : list of float\n        The weights of the Perceptron.\n    bias : float\n        The bias of the Perceptron.\n\n    Methods\n    -------\n    train(X, y)\n        Trains the Perceptron with the given training data.\n\n    predict(X)\n        Predicts the labels for the given test data.\n    \"\"\"\n\n    def __init__(self):\n        self.weights = []\n        self.bias = 0.0\n\n    def train(self, X, y):\n        \"\"\"\n        Trains the Perceptron with the given training data.\n\n        Parameters\n        ----------\n        X : list of list of float\n            The input training data.\n        y : list of int\n            The corresponding labels.\n        \"\"\"\n        # Add your code here. Remember to follow the coding guidelines provided by your mentor.\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the labels for the given test data.\n\n        Parameters\n        ----------\n        X : list of list of float\n            The input test data.\n\n        Returns\n        -------\n        list of int\n            The predicted labels.\n        \"\"\"\n        # Add your code here. Remember to follow the coding guidelines provided by your mentor.",
        "def mean(numbers):\n    \"\"\"\n    Compute the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list of int or float): The list of numbers to calculate the mean from.\n\n    Returns:\n        float: The mean of the list of numbers.\n    \"\"\"\n    # Initialize variables\n    total = 0\n    count = 0\n\n    # Iterate through the list of numbers\n    for number in numbers:\n        # Update the total and count\n        total += number\n        count += 1\n\n    # Return the mean\n    return total / count",
        "def product_array_except_self(nums):\n    output = []\n    for i in range(len(nums)):\n        output.append(nums[i+1:]*nums[:i]+nums[i+1:])\n    return output",
        "class StudentGrade:\n    \"\"\"\n    Represents a student's grade.\n\n    ...\n\n    Attributes\n    ----------\n    assignments : list of float\n        List of assignment grades.\n\n    Methods\n    -------\n    compute_average()\n        Compute the average grade.\n\n    \"\"\"\n\n    def __init__(self):\n        self.assignments = []\n\n    def compute_average(self):\n        \"\"\"Compute the average grade.\"\"\"\n        if not self.assignments:\n            raise ValueError(\"No assignments to compute the average.\")\n\n        return sum(self.assignments) / len(self.assignments)",
        "```python\ndef sum_array_except_self(nums):\n    total_sum = sum(nums)\n    self_sum = 0\n    for num in nums:\n        self_sum += num\n    return total_sum - self_sum\n```",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(self.root, value)\n\n    def _insert(self, node, value):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(node.left, value)\n        else:\n            node.right = self._insert(node.right, value)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(self.root, value)\n\n    def _delete(self, node, value):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(node.left, value)\n        elif value > node.value:\n            node.right = self._delete(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._find_min(node.right)\n            node.right = self._delete(node.right, node.value)\n        return node\n\n    def _find_min(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value",
        "```python\ndef average_diagonal(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Compute the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): A square matrix containing integer elements.\n\n    Returns:\n        float: The average of the diagonal elements of the matrix.\n\n    Raises:\n        ValueError: If the input matrix is not square.\n    \"\"\"\n    # Validate the input matrix\n    if not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"Input matrix must be square.\")\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    diagonal_avg = diagonal_sum / len(matrix)\n\n    return diagonal_avg\n```",
        "```python\nfrom typing import List\n\n\nclass DirectedGraph:\n    \"\"\"\n    Represents a directed graph using an adjacency list.\n\n    ...\n\n    Attributes\n    ----------\n    vertices : list of str\n        A list of vertices in the graph.\n\n    edges : list of list of str\n        A list of edges in the graph, where each inner list represents an edge\n        with the source and destination vertices.\n\n    Methods\n    -------\n    add_edge(source: str, destination: str)\n        Adds a directed edge from the source vertex to the destination vertex.\n\n    has_cycle() -> bool\n        Checks if the graph contains any cycles and returns True if a cycle is found,\n        otherwise returns False.\n    \"\"\"\n\n    def __init__(self):\n        self.vertices = []\n        self.edges = []\n\n    def add_edge(self, source: str, destination: str) -> None:\n        \"\"\"\n        Adds a directed edge from the source vertex to the destination vertex.\n\n        Parameters\n        ----------\n        source : str\n            The source vertex of the edge.\n\n        destination : str\n            The destination vertex of the edge.\n        \"\"\"\n        self.vertices.append(source)\n        self.vertices.append(destination)\n        self.edges.append([source, destination])\n\n    def has_cycle(self) -> bool:\n        \"\"\"\n        Checks if the graph contains any cycles and returns True if a cycle is found,\n        otherwise returns False.\n\n        Returns\n        -------\n        bool\n            True if a cycle is found, otherwise False.\n        \"\"\"\n        visited = set()\n        rec_stack = set()\n\n        def is_cyclic_util(vertex: str, parent: str) -> bool:\n            \"\"\"\n            Checks for a cycle in the graph using Depth First Search (DFS).\n\n            Parameters\n            ----------\n            vertex : str\n                The current vertex being visited.\n\n            parent : str\n                The parent vertex of the current vertex in the DFS traversal.\n\n            Returns\n            -------\n            bool\n                True if a cycle is found, otherwise False.\n            \"\"\"\n            visited.add(vertex)\n            rec_stack.add(vertex)\n\n            for neighbour in self.edges[vertex]:\n                if neighbour not in visited:\n                    if is_cyclic_util(neighbour, vertex):\n                        return True\n                elif neighbour in rec_stack:\n                    return True\n            rec_stack.remove(vertex)\n            return False\n\n        for vertex in self.vertices:\n            if vertex not in visited:\n                if is_cyclic_util(vertex, None):\n                    return True\n        return False\n```",
        "```python\ndef dot_product(vector_1: list[float], vector_2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_1 (list[float]): A list of floating-point numbers representing the first vector.\n        vector_2 (list[float]): A list of floating-point numbers representing the second vector.\n\n    Returns:\n        float: The dot product of the two input vectors.\n    \"\"\"\n    if len(vector_1) != len(vector_2):\n        raise ValueError(\"Input vectors must have the same length.\")\n\n    result = 0.0\n    for i in range(len(vector_1)):\n        result += vector_1[i] * vector_2[i]\n\n    return result\n```",
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n\n    Parameters:\n    alpha: float\n        Regularization strength parameter. Must be a positive float. Defaults to 1.0.\n    kernel: string\n        Kernel to be used. Defaults to 'linear'.\n    gamma: float\n        Kernel coefficient. Defaults to None.\n    degree: int\n        Degree of the polynomial kernel function. Ignored by other kernels. Defaults to 3.\n    coef_: array of shape (n_features,)\n        Weights assigned to the features.\n    dual_coef_: array of shape (n_samples,)\n        Representation of weights in the dual space.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 1.0,\n        kernel: str = \"linear\",\n        gamma: float = None,\n        degree: int = 3,\n    ):\n        \"\"\"\n        Initializes the KernelRidge regression class.\n\n        Args:\n            alpha: Regularization strength parameter.\n            kernel: Kernel to be used.\n            gamma: Kernel coefficient.\n            degree: Degree of the polynomial kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self._kernel = None\n        self._X = None\n        self.coef_ = None\n        self.dual_coef_ = None\n\n    def fit(self, X: array, y: array):\n        \"\"\"\n        Fits the model to the training data.\n\n        Args:\n            X: Training data.\n            y: Target values.\n        \"\"\"\n        self._kernel = Kernel(\n            kernel=self.kernel, gamma=self.gamma, degree=self.degree\n        )\n        self._X = X\n        self.coef_ = None\n        self.dual_coef_ = None\n        self._fit(X, y)\n\n    def _fit(self, X: array, y: array):\n        \"\"\"\n        Fits the model to the training data.\n\n        Args:\n            X: Training data.\n            y: Target values.\n        \"\"\"\n        n_samples, n_features = X.shape\n        self.coef_ = np.zeros(n_features)\n        self.dual_coef_ = self._kernel(X).dot(y) * self.alpha\n        self.dual_coef_ += -y.mean(axis=0) * self.alpha\n        self.dual_coef_ *= -1\n        self.coef_ = self._kernel(X).T.dot(self.dual_coef_)\n\n    def predict(self, X: array):\n        \"\"\"\n        Predicts the target values for the given data.\n\n        Args:\n            X: Data for which predictions are to be made.\n\n        Returns:\n            array of shape (n_samples,) containing predicted values.\n        \"\"\"\n        return self._kernel(X).dot(self.dual_coef_)\n\n    def score(self, X: array, y: array):\n        \"\"\"\n        Returns the coefficient of determination (R^2) of the prediction.\n\n        Args:\n            X: Data for which predictions are to be made.\n            y: Target values.\n\n        Returns:\n            float representing the coefficient of determination.\n        \"\"\"\n        y_pred = self.predict(X)\n        ss_res = np.sum((y - y_pred) ** 2)\n        ss_tot = np.sum((y - y.mean()) ** 2)\n        return 1 - ss_res / ss_tot\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            temp = root.right\n            while temp.left is not None:\n                temp = temp.left\n            root.key = temp.key\n            root.right = delete_node(root.right, temp.key)\n\n    return root\n```",
        "```python\nclass Solution:\n    \"\"\"\n    Solve the maximum subarray problem.\n\n    :param nums: List[int] - The input list of integers.\n    \"\"\"\n\n    def __init__(self, nums: list[int]):\n        self.nums = nums\n        self.max_sum = 0\n        self.max_sum_range = (0, 0)\n\n    def max_subarray(self) -> tuple[int, int]:\n        \"\"\"\n        Find the maximum subarray sum and its range.\n\n        :return: tuple[int, int] - The maximum sum and the range (start, end) of the subarray.\n        \"\"\"\n\n        # Initialize variables to track the maximum sum and its range\n        max_sum = float('-inf')\n        max_sum_start = 0\n        max_sum_end = 0\n        current_sum = 0\n        current_start = 0\n\n        # Iterate through the input list\n        for i, num in enumerate(self.nums):\n            # If the current number is positive, add it to the current sum\n            if num >= 0:\n                current_sum += num\n                # Update the end index of the current subarray\n                current_end = i\n            # If the current number is negative, reset the current sum and start index\n            else:\n                current_sum = 0\n                current_start = i + 1\n\n            # Update the maximum sum and its range if the current sum is greater\n            if current_sum > max_sum:\n                max_sum = current_sum\n                max_sum_start = current_start\n                max_sum_end = current_end\n\n        # Update the maximum sum range if the current sum is still the maximum\n        if max_sum == current_sum:\n            max_sum_end = i\n\n        self.max_sum = max_sum\n        self.max_sum_range = (max_sum_start, max_sum_end)\n        return self.max_sum, self.max_sum_range\n```",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): The first vector.\n        vector_b (list[int]): The second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input vectors\n    if not vector_a or not vector_b:\n        raise ValueError(\"Input vectors cannot be empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product",
        "```python\ndef max_subarray_sum(nums: list[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n\n    Args:\n        nums (list[int]): The input list of integers.\n\n    Returns:\n        int: The sum of the subarray with the largest sum.\n    \"\"\"\n    max_sum = nums[0]\n    current_sum = max_sum\n    for num in nums[1:]:\n        current_sum += num\n        max_sum = max(max_sum, current_sum)\n        if current_sum < 0:\n            current_sum = 0\n    return max_sum\n```",
        "```python\ndef merge_sort(arr):\n    \"\"\"\n    Implements merge sort algorithm to sort an array in ascending order.\n\n    Args:\n        arr (list): List of integers to be sorted.\n\n    Returns:\n        List of integers sorted in ascending order.\n    \"\"\"\n    # Add docstrings and follow naming conventions\n    # ... your code here ...\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "class Library:\n    \"\"\"\n    A Library class for managing a collection of books.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty Library.\n        \"\"\"\n        self.books = []\n\n    def add_book(self, book: str) -> None:\n        \"\"\"\n        Adds a book to the library.\n\n        Args:\n            book (str): The title of the book to be added.\n        \"\"\"\n        self.books.append(book)\n\n    def remove_book(self, book: str) -> None:\n        \"\"\"\n        Removes a book from the library.\n\n        Args:\n            book (str): The title of the book to be removed.\n        \"\"\"\n        self.books.remove(book)",
        "def remove_duplicates_and_sum(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from the given list of numbers and computes their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "```python\nfrom sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class for dimensionality reduction.\n    \"\"\"\n\n    def __init__(self, n_components=None, copy=True):\n        \"\"\"\n        Initialize the PCA class.\n\n        Parameters:\n            n_components (int or None): The number of principal components to keep.\n                If None, keep all components.\n            copy (bool): Whether to make a copy of the data or not.\n\n        Returns:\n            None\n        \"\"\"\n        self.n_components = n_components\n        self.copy = copy\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n            y (ndarray, optional): Not used in this implementation.\n\n        Returns:\n            None\n        \"\"\"\n        # Ensure that the data is a valid input\n        if not isinstance(X, np.ndarray):\n            raise TypeError(\"Input data must be a NumPy ndarray.\")\n\n        # Check if the data is 2-dimensional\n        if X.ndim != 2:\n            raise ValueError(\"Input data must be 2-dimensional.\")\n\n        # Check if the number of components is valid\n        if self.n_components is not None:\n            if not isinstance(self.n_components, int):\n                raise TypeError(\"Number of components must be an integer.\")\n            if self.n_components < 1:\n                raise ValueError(\"Number of components must be greater than zero.\")\n            if self.n_components > X.shape[1]:\n                raise ValueError(\"Number of components cannot be greater than the number of features.\")\n\n        # Make a copy of the data if specified\n        if self.copy:\n            self.X = X.copy()\n        else:\n            self.X = X\n\n        # Calculate the covariance matrix\n        self.cov_matrix = np.cov(self.X.T)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(self.cov_matrix)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Keep only the specified number of components\n        if self.n_components is not None:\n            eigenvalues = eigenvalues[:self.n_components]\n            eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Store the explained variance\n        self.explained_variance_ = eigenvalues / np.sum(eigenvalues)\n\n        # Store the singular values and right singular vectors\n        self.singular_values_ = np.sqrt(eigenvalues)\n        self.right_singular_vectors_ = eigenvectors\n\n        # Compute the projection matrix\n        self.projection_matrix_ = self.right_singular_vectors_.T\n\n    def transform(self, X):\n        \"\"\"\n        Apply the PCA transformation to the data.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components).\n        \"\"\"\n        # Ensure that the data is a valid input\n        if not isinstance(X, np.ndarray):\n            raise TypeError(\"Input data must be a NumPy ndarray.\")\n\n        # Check if the number of features in the data matches the original data\n        if X.shape[1] != self.X.shape[1]:\n            raise ValueError(\"Number of features in the data does not match the original data.\")\n\n        # Check if the number of components is valid\n        if self.n_components is not None:\n            if self.n_components > self.singular_values_.shape[0]:\n                raise ValueError(\"Number of components cannot be greater than the number of singular values.\")\n\n        # Transform the data using the projection matrix\n        transformed_data = np.dot(X, self.projection_matrix_)\n\n        return transformed_data\n\n    def fit_transform(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data and apply the transformation.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n            y (ndarray, optional): Not used in this implementation.\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components).\n        \"\"\"\n        self.fit(X, y)\n        return self.transform(X)\n\n    def inverse_transform(self, X):\n        \"\"\"\n        Apply the inverse PCA transformation to the data.\n\n        Parameters:\n            X (ndarray): The transformed data of shape (n_samples, n_components).\n\n        Returns:\n            ndarray: The original data of shape (n_samples, n_features).\n        \"\"\"\n        # Ensure that the data is a valid input\n        if not isinstance(X, np.ndarray):\n            raise TypeError(\"Input data must be a NumPy ndarray.\")\n\n        # Check if the number of components matches the original data\n        if X.shape[1] != self.n_components:\n            raise ValueError(\"Number of components in the data does not match the model.\")\n\n        # Check if the number of components is valid\n        if self.n_components is not None:\n            if self.n_components > self.singular_values_.shape[0]:\n                raise ValueError(\"Number of components cannot be greater than the number of singular values.\")\n\n        # Compute the inverse transformation\n        inverse_transformed_data = np.dot(X, self.right_singular_vectors_)\n\n        return inverse_transformed_data\n```",
        "```python\ndef count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "class Inventory:\n    \"\"\"\n    Represents an inventory of items.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the inventory.\n        \"\"\"\n        self._items = []\n\n    def add_stock(self, item: str) -> None:\n        \"\"\"\n        Adds stock of the specified item.\n\n        :param item: The name of the item to add stock for.\n        \"\"\"\n        self._items.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        \"\"\"\n        Removes stock of the specified item.\n\n        :param item: The name of the item to remove stock for.\n        \"\"\"\n        self._items.remove(item)",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Define a dictionary to map decimal numbers to Roman numerals\n    roman_numerals = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\",\n        50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    # Initialize an empty string to store the Roman numeral representation\n    roman_str = \"\"\n    # Iterate over the items in the roman_numerals dictionary in reverse order\n    for decimal, numeral in reversed(roman_numerals.items()):\n        # Check if the decimal value is less than or equal to the input number\n        while num >= decimal:\n            # Add the Roman numeral to the string and subtract the decimal value from the number\n            roman_str += numeral\n            num -= decimal\n    return roman_str\n```",
        "```python\nclass LinkedList:\n    \"\"\"\n    A linked list data structure.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty linked list.\n        \"\"\"\n        self.head = None\n\n    def add_node(self, data):\n        \"\"\"\n        Adds a new node with the given data to the end of the linked list.\n\n        Args:\n            data: The data to be stored in the new node.\n        \"\"\"\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def remove_node(self, data):\n        \"\"\"\n        Removes the first node with the given data from the linked list.\n\n        Args:\n            data: The data of the node to be removed.\n\n        Returns:\n            bool: True if a node was removed, False otherwise.\n        \"\"\"\n        current = self.head\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next\n\n        if not current:\n            return False\n\n        if not prev:\n            self.head = current.next\n        else:\n            prev.next = current.next\n\n        return True\n\n    def search_node(self, data):\n        \"\"\"\n        Searches for a node with the given data in the linked list.\n\n        Args:\n            data: The data to search for in the nodes.\n\n        Returns:\n            Node: The node with the given data, or None if not found.\n        \"\"\"\n        current = self.head\n        while current and current.data != data:\n            current = current.next\n\n        return current\n\n    def size(self):\n        \"\"\"\n        Calculates the number of nodes in the linked list.\n\n        Returns:\n            int: The size of the linked list.\n        \"\"\"\n        current = self.head\n        count = 0\n        while current:\n            count += 1\n            current = current.next\n\n        return count\n\nclass Node:\n    \"\"\"\n    A node in the linked list.\n    \"\"\"\n\n    def __init__(self, data):\n        \"\"\"\n        Initializes a new node with the given data.\n\n        Args:\n            data: The data to be stored in the node.\n        \"\"\"\n        self.data = data\n        self.next = None\n```",
        "Here is the code that follows the latest coding guidelines provided by your mentor, Emma:\n```python\ndef get_common_elements(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Returns a list of common elements between two input lists.\n\n    Args:\n        list1 (list[int]): A list of integers.\n        list2 (list[int]): Another list of integers.\n\n    Returns:\n        list[int]: A new list containing the common elements between the input lists.\n    \"\"\"\n    common_elements = []\n    for element in list1:\n        if element in list2:\n            common_elements.append(element)\n    return common_elements\n```"
      ]
    }
  ]
}