{
  "sessions": [
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.j_queue = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.j_queue.remove(key)\n        self.j_queue.insert(0, key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.j_queue.remove(key)\n        elif len(self.j_queue) >= self.capacity:\n            del_key = self.j_queue.pop()\n            del self.cache[del_key]\n        self.j_queue.insert(0, key)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model for classification or regression.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5, metric='euclidean'):\n        \"\"\"\n        Initializes the NearestNeighborsModel.\n\n        :param n_neighbors: The number of neighbors to consider for prediction.\n        :param metric: The distance metric to use. Supported metrics: 'euclidean', 'manhattan', 'chebyshev', 'minkowski'.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the Nearest Neighbors Model.\n\n        :param X_train: A 2D array of training feature data.\n        :param y_train: A 1D array of target values.\n        :return: Self, for method chaining.\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train do not match.\"\n        assert X_train.ndim == 2, \"X_train should be a 2D array.\"\n        assert y_train.ndim == 1, \"y_train should be a 1D array.\"\n        self.X_train = X_train\n        self.y_train = y_train\n        return self\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the given test data.\n\n        :param X_test: A 2D array of test feature data.\n        :return: A 1D array of predicted target values.\n        \"\"\"\n        assert X_test.ndim == 2, \"X_test should be a 2D array.\"\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet.\"\n\n        from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n        from sklearn.base import is_classifier\n\n        # Select classifier or regressor based on y_train\n        model = KNeighborsClassifier(n_neighbors=self.n_neighbors, metric=self.metric) if is_classifier(\n            self.y_train) else KNeighborsRegressor(n_neighbors=self.n_neighbors, metric=self.metric)\n\n        # Fit the model\n        model.fit(self.X_train, self.y_train)\n\n        # Predict target values\n        y_pred = model.predict(X_test)\n\n        return y_pred"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom mailbox import Mailbox\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\n\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    # Recursive function to find the node to be deleted and replace it with its inorder successor\n    def find_and_replace(node, key):\n        if node is None:\n            return None\n\n        if node.left is not None and node.left.value == key:\n            successor = find_inorder_successor(node.left)\n            node.left = successor\n            return node\n\n        if node.right is not None and node.right.value == key:\n            successor = find_inorder_successor(node.right)\n            node.right = successor\n            return node\n\n        if node.value == key:\n            if node.left is None:\n                return node.right\n            if node.right is None:\n                return node.left\n\n            successor = find_inorder_successor(node.right)\n            node.value = successor.value\n            node.right = delete_node(node.right, successor.value)\n            return node\n\n        node.left = find_and_replace(node.left, key)\n        node.right = find_and_replace(node.right, key)\n        return node\n\n    def find_inorder_successor(node):\n        successor = None\n        while node.left is not None:\n            successor = node.left\n            node = node.left\n        return successor\n\n    # Base case: Empty tree\n    if root is None:\n        return None\n\n    # Find the node to be deleted and replace it with its inorder successor\n    root = find_and_replace(root, key)\n\n    return root\n```",
        "```python\nfrom collections import OrderedDict\nimport mailbox\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache.pop(key)\n        self.cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.pop(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs('grades')\n    def __init__(self, grades: list[float]):\n        self.grades = grades\n\n    @require_kwargs('grade')\n    def add_grade(self, grade: float):\n        self.grades.append(grade)\n\n    def compute_average(self) -> float:\n        return sum(self.grades) / len(self.grades)"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multiclass classification problems.\n    \"\"\"\n\n    def __init__(self, store_covariates=False):\n        \"\"\"\n        Initializes the QDA model.\n\n        Parameters:\n            store_covariates (bool): Whether to store covariates for prediction. Defaults to False.\n        \"\"\"\n        self.store_covariates = store_covariates\n        self.model = QuadraticDiscriminantAnalysis(store_covariates=store_covariates)\n\n    def fit(self, X, y):\n        \"\"\"\n        Fits the QDA model to the training data.\n\n        Parameters:\n            X (ndarray): Training data of shape (n_samples, n_features).\n            y (ndarray): Target labels of shape (n_samples,).\n\n        Returns:\n            self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the class labels for the provided data.\n\n        Parameters:\n            X (ndarray): Data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Predicted class labels of shape (n_samples,).\n        \"\"\"\n        return self.model.predict(X)\n\n    def predict_proba(self, X):\n        \"\"\"\n        Predicts the class probabilities for the provided data.\n\n        Parameters:\n            X (ndarray): Data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Predicted class probabilities of shape (n_samples, n_classes).\n        \"\"\"\n        return self.model.predict_proba(X)\n\n    def score(self, X, y):\n        \"\"\"\n        Evaluates the model's performance on the provided data.\n\n        Parameters:\n            X (ndarray): Test data of shape (n_samples, n_features).\n            y (ndarray): True labels of shape (n_samples,).\n\n        Returns:\n            float: The mean accuracy of the model on the given data.\n        \"\"\"\n        return self.model.score(X, y)\n```",
        "from pedantic import timer_class\n\n@timer_class\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\n@timer_class\ndef is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if node.val <= min_val or node.val >= max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root, float('-inf'), float('inf'))\n\ntry:\n    # Create a sample binary search tree\n    root = TreeNode(4)\n    root.left = TreeNode(2)\n    root.right = TreeNode(6)\n    root.left.left = TreeNode(1)\n    root.left.right = TreeNode(3)\n    root.right.left = TreeNode(5)\n    root.right.right = TreeNode(7)\n\n    # Check if the tree is a valid binary search tree\n    if is_valid_bst(root):\n        print(\"The given tree is a valid binary search tree.\")\n    else:\n        print(\"The given tree is not a valid binary search tree.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_unique_elements(numbers):\n    unique_numbers = list(dict.fromkeys(numbers))\n    chx_sum = sum(unique_numbers)\n    return chx_sum"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the k-th largest element from the input list of integers.\n    \n    Args:\n        arr (list[int]): A list of integers.\n        k (int): An integer indicating which largest element to find.\n    \n    Returns:\n        int: The k-th largest element in the input list of integers.\n    \"\"\"\n    # Sort the array in descending order to easily find the k-th largest element\n    sorted_arr = sorted(arr, reverse=True)\n    \n    # Return the k-th element from the sorted array\n    return sorted_arr[k-1]\n\n# Update: Added type hints and improved docstring\n```",
        "def int_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to a Roman numeral.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    sym = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // val[i]):\n            roman_num += sym[i]\n            num -= val[i]\n        i += 1\n    return roman_num"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]",
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_head = None\n        self.q_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_q_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self._move_to_q_head(key)\n        elif len(self.cache) >= self.capacity:\n            del self.cache[self.q_tail]\n            self.q_tail = self._get_prev_node(self.q_tail)\n        self.cache[key] = value\n        self._add_to_q_head(key)\n\n    def _move_to_q_head(self, key: int) -> None:\n        self._remove_from_queue(key)\n        self._add_to_q_head(key)\n\n    def _add_to_q_head(self, key: int) -> None:\n        if not self.q_head:\n            self.q_head = key\n            self.q_tail = key\n        else:\n            self.cache[key] = self.cache.get(self.q_head)\n            self.cache[self.q_head] = key\n            self.q_head = key\n\n    def _remove_from_queue(self, key: int) -> None:\n        prev_key = self._get_prev_node(key)\n        next_key = self.cache.get(key)\n        if prev_key:\n            self.cache[prev_key] = next_key\n        else:\n            self.q_head = next_key\n        if next_key:\n            self.cache[next_key] = prev_key\n        else:\n            self.q_tail = prev_key\n        del self.cache[key]\n\n    def _get_prev_node(self, key: int) -> int:\n        prev_key = None\n        for k, v in self.cache.items():\n            if v == key:\n                prev_key = k\n                break\n        return prev_key\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity):\n        self.cache = OrderedDict()\n        self.s_capacity = capacity\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        else:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.s_capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class i7Inventory:\n    def __init__(self):\n        self.items = {}\n\n    def b_add_stock(self, item, quantity):\n        if item in self.items:\n            self.items[item] += quantity\n        else:\n            self.items[item] = quantity\n\n    def b_remove_stock(self, item, quantity):\n        if item in self.items and self.items[item] >= quantity:\n            self.items[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")",
        "class p9:\n    def __init__(self, n_components=0.95, copy=True):\n        self.n_components = n_components\n        self.copy = copy\n\n    def b_fit_transform(self, X, y=None):\n        X = X.copy()\n        n_samples, n_features = X.shape\n        X_mean = X.mean(axis=0)\n        X -= X_mean\n        cov_mat = (X.T @ X) / (n_samples - 1)\n        eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n        idx = eig_vals.argsort()[::-1]\n        eig_vals, eig_vecs = eig_vals[idx], eig_vecs[:, idx]\n        cum_var_exp = np.cumsum(eig_vals) / np.sum(eig_vals)\n        components_to_keep = cum_var_exp < self.n_components\n        if not components_to_keep.any():\n            raise ValueError(\"No components to keep based on explained variance ratio.\")\n        n_components = int(components_to_keep.sum())\n        eig_vecs_keep = eig_vecs[:, :n_components]\n        return (eig_vecs_keep.T @ (X - X_mean)), eig_vecs_keep"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def o_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def o_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove that quantity.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value: int) -> None:\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root = None\n\n    def x_insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def x_delete(self, value: int) -> None:\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value: int, node: Node) -> Node:\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def x_add_stock(self, product: str, quantity: int) -> None:\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def x_remove_stock(self, product: str, quantity: int) -> None:\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock to remove\")"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self._stock = {}\n\n    def p_get_stock(self):\n        return self._stock\n\n    def add_stock(self, item, quantity):\n        if item in self.p_get_stock():\n            self._stock[item] += quantity\n        else:\n            self._stock[item] = quantity\n\n    def remove_stock(self, item, quantity):\n        if item in self.p_get_stock():\n            if self._stock[item] > quantity:\n                self._stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to fulfill request.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_head = None\n        self.xt_tail = None\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self._move_to_xt_head(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_xt_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            self._evict_xt_tail()\n        self.cache[key] = value\n        self._add_to_xt_head(key)\n\n    def _move_to_xt_head(self, key):\n        node = self.cache[key]\n        self._remove_node(node)\n        self._add_to_xt_head(key)\n\n    def _add_to_xt_head(self, key):\n        node = self.cache[key]\n        node.xt_prev = None\n        node.xt_next = self.xt_head\n        if self.xt_head is not None:\n            self.xt_head.xt_prev = node\n        self.xt_head = node\n        if self.xt_tail is None:\n            self.xt_tail = node\n\n    def _evict_xt_tail(self):\n        node = self.xt_tail\n        self._remove_node(node)\n        del self.cache[node.key]\n\n    def _remove_node(self, node):\n        if node.xt_prev is not None:\n            node.xt_prev.xt_next = node.xt_next\n        else:\n            self.xt_head = node.xt_next\n\n        if node.xt_next is not None:\n            node.xt_next.xt_prev = node.xt_prev\n        else:\n            self.xt_tail = node.xt_prev",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.xt_coef_ = None\n        self.xt_intercept_ = None\n        self.xt_alpha_ = alpha\n\n    def train(self, X_train, y_train):\n        try:\n            from sklearn.linear_model import Lasso\n            self.xt_model_ = Lasso(alpha=self.xt_alpha_)\n            self.xt_model_.fit(X_train, y_train)\n            self.xt_coef_ = self.xt_model_.coef_\n            self.xt_intercept_ = self.xt_model_.intercept_\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while training the Lasso Regression model: {e}\")\n\n    def predict(self, X_test):\n        try:\n            assert self.xt_coef_ is not None and self.xt_intercept_ is not None, \"Model has not been trained yet\"\n            return self.xt_model_.predict(X_test)\n        except AssertionError as e:\n            raise AssertionError(f\"Error: {e}\")\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta=0.1, epochs=1000):\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.bias_chx = None\n\n    def train(self, X, y):\n        X_with_bias = np.c_[X, -np.ones(len(X))]\n        self.weights = np.zeros(len(X[0]) + 1)\n        self.bias_chx = self.weights[-1]\n        for _ in range(self.epochs):\n            for xi, target in zip(X_with_bias, y):\n                update = self.eta * (target - self.predict(xi))\n                self.weights += update * xi\n\n    def predict(self, X):\n        X_with_bias = np.c_[X, -np.ones(len(X))]\n        return np.where(X_with_bias @ self.weights >= 0, 1, 0)"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.r_stock = {}\n\n    def n_add_stock(self, item, quantity):\n        if item in self.r_stock:\n            self.r_stock[item] += quantity\n        else:\n            self.r_stock[item] = quantity\n\n    def n_remove_stock(self, item, quantity):\n        if item in self.r_stock and self.r_stock[item] >= quantity:\n            self.r_stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.n_queue = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.n_queue.remove(key)\n        self.n_queue.append(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.n_queue.remove(key)\n        elif len(self.n_queue) >= self.capacity:\n            del_key = self.n_queue.pop(0)\n            del self.cache[del_key]\n        self.n_queue.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(x_vec1, x_vec2):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param x_vec1: The first vector.\n    :param x_vec2: The second vector.\n    :return: The dot product of x_vec1 and x_vec2.\n    \"\"\"\n    return sum(x * y for x, y in zip(x_vec1, x_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure with methods to insert and delete nodes.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Inserts a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for inserting a new node.\n\n        Args:\n            value: The value to be inserted.\n            node: The current node in the recursive traversal.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Deletes the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for deleting a node.\n\n        Args:\n            value: The value of the node to be deleted.\n            node: The current node in the recursive traversal.\n\n        Returns:\n            The new node after deletion.\n        \"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node):\n        \"\"\"\n        Recursive helper function to find the minimum value in a subtree.\n\n        Args:\n            node: The root of the subtree.\n\n        Returns:\n            The minimum value in the subtree.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n\n@count_calls\ndef majority_element(nums):\n    counter = {}\n    for num in nums:\n        if num in counter:\n            counter[num] += 1\n        else:\n            counter[num] = 1\n        if counter[num] > len(nums) // 2:\n            return num\n    return None\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef count_non_zero_elements8(matrix):\n    \"\"\"\n    Counts the number of non-zero elements in the given matrix.\n\n    Args:\n        matrix (list of list of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            assert isinstance(element, int), \"Elements in the matrix must be integers.\"\n            if element != 0:\n                count += 1\n    return count\n```",
        "```python\ndef calc_diag_avg_7(matrix):\n    \"\"\"\n    Calculates the average of the diagonal elements of a square matrix.\n    \n    Args:\n        matrix (list of list of int or float): The input square matrix.\n    \n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input must be a list of lists\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists\"\n    assert all(isinstance(elem, (int, float)) for row in matrix for elem in row), \"All elements must be numeric\"\n    assert len(matrix) == len(matrix[0]), \"Input matrix must be square\"\n    \n    size = len(matrix)\n    diag_sum = sum(matrix[i][i] for i in range(size))\n    diag_avg = diag_sum / size\n    \n    return diag_avg\n```"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef chx_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Parameters:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for str in strs[1:]:\n            if i == len(str) or str[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\ndef chx_flatten_binary_tree_to_linked_list(root):\n    \"\"\"\n    Flattens a binary tree to a linked list.\n\n    Args:\n        root (Node): The root of the binary tree.\n\n    Returns:\n        Node: The head of the linked list.\n    \"\"\"\n    if not root:\n        return None\n\n    # If the left subtree is empty, return the right subtree\n    # as the linked list\n    if not root.left:\n        return root.right\n\n    # Otherwise, find the last node in the left subtree\n    left_last = root.left\n    while left_last.right:\n        left_last = left_last.right\n\n    # Set the right pointer of the last node in the left subtree\n    # to the current root's right subtree\n    left_last.right = root.right\n\n    # Set the current root's right subtree to None and return\n    # the current root's left subtree as the new linked list\n    root.right = None\n    return root.left\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n\n    return roman"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self):\n            self.conv1 = torch.nn.Conv2d(3, 64, 3, padding=1)\n            self.conv2 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1)\n            self.conv3 = torch.nn.Conv2d(64, 128, 3, stride=1, padding=1)\n            self.conv4 = torch.nn.Conv2d(128, 128, 3, stride=1, padding=1)\n            self.pool = torch.nn.MaxPool2d(2, 2)\n            self.fc1 = torch.nn.Linear(128 * 4 * 4, 512)\n            self.fc2 = torch.nn.Linear(512, 2)\n            self.dropout = torch.nn.Dropout(0.2)\n\n    def forward(self, x):\n        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n        x = self.pool(torch.nn.functional.relu(self.conv3(x)))\n        x = self.pool(torch.nn.functional.relu(self.conv4(x)))\n        x = x.view(-1, 128 * 4 * 4)\n        x = self.dropout(torch.nn.functional.relu(self.fc1(x)))\n        x = self.fc2(x)\n        return x"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\nfrom typing import List\n\n\nclass Library:\n    @validate\n    def __init__(self):\n        self.books: List[str] = []\n\n    @validate\n    def add_book(self, book_title: str) -> None:\n        self.books.append(book_title)\n\n    @validate\n    def remove_book(self, book_title: str) -> None:\n        self.books.remove(book_title)\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\n                index = parent_index\n            else:\n                break"
      ],
      "instruction_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\n\n@retry()\ndef majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n        max_count = max(element_count.values())\n        if max_count > len(arr) // 2:\n            return list(element_count.keys())[list(element_count.values()).index(max_count)]"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(m_board):\n    m_seen = set()\n    m_row = set()\n    m_col = set()\n\n    for m_i in range(9):\n        m_row.clear()\n        m_col.clear()\n        for m_j in range(9):\n            m_num = m_board[m_i][m_j]\n            if m_num != \".\":\n                if m_num in m_row or m_num in m_col or (m_num, (m_i // 3, m_j // 3)) in m_seen:\n                    return False\n                m_row.add(m_num)\n                m_col.add(m_num)\n                m_seen.add((m_num, (m_i // 3, m_j // 3)))\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\nimport secrets\n\n\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1, len_str2 = len(str1), len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]\n\n\nassert edit_distance(\"kitten\", \"sitting\") == 3\n```"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    result_i = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            result_i.append(list1_i[i])\n            i += 1\n        else:\n            result_i.append(list2_i[j])\n            j += 1\n    result_i.extend(list1_i[i:])\n    result_i.extend(list2_i[j:])\n    return result_i"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom typing import Dict\n\n\n@require_kwargs\ndef roman_to_int(roman: str, /, **_kwargs: Dict[str, None]) -> int:\n    roman_map = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in reversed(roman):\n        value = roman_map[char]\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n        prev_value = value\n\n    return int_value"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from locale import *\n\nclass LCM_CALCULATOR:\n    def LCM(self, number1: int, number2: int) -> int:\n        gcd = self.GCD(number1, number2)\n        return (number1 * number2) // gcd\n\n    def GCD(self, number1: int, number2: int) -> int:\n        while number2:\n            number1, number2 = number2, number1 % number2\n        return number1",
        "from torch import nn\nfrom locale import *\n\nclass IMAGE_CLASSIFIER(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)",
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def a_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_x(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            if node == end:\n                return path\n            for adjacent in graph[node]:\n                new_path = path + [adjacent]\n                queue.append((adjacent, new_path))"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "class Perceptron:\n    def __init__(self):\n        self.w = None\n        self.b = None\n\n    def train(self, X, y):\n        n_samples, n_features = X.shape\n        self.w = np.zeros(n_features)\n        self.b = 0\n        for xi, target in zip(X, y):\n            update = self.b\n            for j in range(n_features):\n                update += self.w[j] * xi[j]\n            update = target - update\n            for j in range(n_features):\n                self.w[j] += update * xi[j]\n            self.b = update\n\n    def predict(self, X):\n        return np.dot(X, self.w) + self.b",
        "```python\ndef roman_to_int(s: str) -> int:\n    roman_to_int_mapping = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in s[::-1]:\n        current_value = roman_to_int_mapping[char]\n\n        if current_value < prev_value:\n            int_value -= current_value\n        else:\n            int_value += current_value\n\n        prev_value = current_value\n\n    return int_value\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors: int = 5):\n        self.n_neighbors = n_neighbors\n        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n\n    def train(self, X_train: list[list[int]], y_train: list[int]):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test: list[list[int]]) -> list[int]:\n        return self.model.predict(X_test)\n```",
        "from typing import List\nfrom math import sqrt\n\n\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    A class for performing quadratic discriminant analysis.\n    ...\n\n    Attributes\n    ----------\n    j_a : float\n        The coefficient of the quadratic term.\n    j_b : float\n        The coefficient of the linear term.\n    j_c : float\n        The constant term.\n    \"\"\"\n\n    def __init__(self, a: float, b: float, c: float) -> None:\n        self.j_a = a\n        self.j_b = b\n        self.j_c = c\n\n    def discriminant(self) -> float:\n        \"\"\"\n        Calculates the discriminant of the quadratic equation.\n\n        Returns\n        -------\n        float\n            The discriminant value.\n        \"\"\"\n        return self.j_b ** 2 - 4 * self.j_a * self.j_c\n\n    def roots(self) -> List[complex]:\n        \"\"\"\n        Calculates the roots of the quadratic equation.\n\n        Returns\n        -------\n        list of complex\n            The roots of the quadratic equation.\n        \"\"\"\n        assert self.j_a != 0, \"The coefficient of the quadratic term cannot be zero.\"\n        discriminant = self.discriminant()\n        if discriminant < 0:\n            return []\n        elif discriminant == 0:\n            return [(-self.j_b) / (2 * self.j_a)]\n        else:\n            root1 = (-self.j_b + sqrt(discriminant)) / (2 * self.j_a)\n            root2 = (-self.j_b - sqrt(discriminant)) / (2 * self.j_a)\n            return [root1, root2]",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            value = self.cache[key]\n            self.cache.move_to_end(key)\n            return value\n        else:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class for dimensionality reduction.\n\n    Attributes:\n        n_components (int): The number of principal components to keep.\n        explained_variance_ratio_ (float): The percentage of variance explained by each component.\n        components_ (ndarray): The principal components.\n        mean_ (ndarray): The mean value of the training data.\n        noise_variance_ (float): The estimated noise covariance.\n\n    ...\n\n    \"\"\"\n\n    def __init__(self, n_components=None):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int, optional): The number of principal components to keep.\n                If None, keep all components. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ratio_ = None\n        self.components_ = None\n        self.mean_ = None\n        self.noise_variance_ = None\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Args:\n            X (ndarray): The training data.\n            y (ignored): Ignored variable for consistency with sklearn API.\n\n        Returns:\n            self: Returns an instance of self.\n        \"\"\"\n        # Calculate the mean of the data\n        self.mean_ = np.mean(X, axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Calculate the covariance matrix\n        covariance = np.cov(X_centered, rowvar=False)\n\n        # Perform eigenvalue decomposition\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Keep only the top n_components\n        if self.n_components:\n            eigenvalues = eigenvalues[:self.n_components]\n            eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Calculate the percentage of variance explained by each component\n        self.explained_variance_ratio_ = eigenvalues / np.sum(eigenvalues)\n\n        # The components are the eigenvectors\n        self.components_ = eigenvectors\n\n        # Estimate the noise covariance\n        self.noise_variance_ = np.mean(eigenvalues[-1:])\n\n    def transform(self, X):\n        \"\"\"\n        Apply the PCA transformation to the data.\n\n        Args:\n            X (ndarray): The data to transform.\n\n        Returns:\n            ndarray: The transformed data.\n        \"\"\"\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Project the data onto the principal components\n        transformed = X_centered @ self.components_\n\n        return transformed\n\n    def inverse_transform(self, X):\n        \"\"\"\n        Apply the inverse PCA transformation to the data.\n\n        Args:\n            X (ndarray): The data to transform.\n\n        Returns:\n            ndarray: The original data.\n        \"\"\"\n        # Project the data back to the original space\n        reconstructed = X @ self.components_.T\n\n        # Add the mean back\n        reconstructed += self.mean_\n\n        return reconstructed",
        "```python\ndef edit_distance(s1: str, s2: str) -> int:\n    len_s1, len_s2 = len(s1), len(s2)\n    dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n    for i in range(len_s1 + 1):\n        dp[i][0] = i\n    for j in range(len_s2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_s1 + 1):\n        for j in range(1, len_s2 + 1):\n            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n            dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n\n    return dp[len_s1][len_s2]\n```",
        "```python\nimport networkx as nx\n\nclass Graph:\n    def __init__(self, vertices):\n        self.graph = nx.Graph()\n        self.vertices = vertices\n        self._add_vertices()\n\n    def _add_vertices(self):\n        self.graph.add_nodes_from(self.vertices)\n\n    def add_edge(self, u, v):\n        self.graph.add_edge(u, v)\n\n    def shortest_path(self, start, end, weight=None):\n        return nx.shortest_path(self.graph, start, end, weight=weight)\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    # Recursive call for left and right subtrees\n    root.left = delete_node(root.left, key)\n    root.right = delete_node(root.right, key)\n\n    # If the key to be deleted is greater than the root's key,\n    # then the node to be deleted is present in the right subtree\n    if key > root.key:\n        root.right = root.right.left\n        return root\n\n    # If the key to be deleted is smaller than the root's key,\n    # then the node to be deleted is present in the left subtree\n    elif key < root.key:\n        root.left = root.left.right\n        return root\n\n    # If the key is same as root's key, then this is the node\n    # to be deleted\n    else:\n        # Node with only one child or no child\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n\n        # Node with two children: Get the inorder successor (smallest\n        # in the right subtree)\n        successor = get_successor(root.right)\n\n        # Copy the value of the inorder successor to this node\n        root.key = successor.key\n\n        # Delete the inorder successor\n        root.right = delete_node(root.right, successor.key)\n\n    return root\n\n\ndef get_successor(node):\n    current = node\n\n    while current and current.left is not None:\n        current = current.left\n\n    return current\n```",
        "from torch import nn\nfrom torch.nn import functional as F\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        return x",
        "def is_valid_sudoku(board):\n    for row in board:\n        if not is_unique(row):\n            return False\n\n    for col in zip(*board):\n        if not is_unique(col):\n            return False\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[r][c] for r in range(i, i + 3) for c in range(j, j + 3)]\n            if not is_unique(box):\n                return False\n\n    return True\n\ndef is_unique(arr):\n    seen = set()\n    for num in arr:\n        if num in seen:\n            return False\n        seen.add(num)\n    return True",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for symbol, value in roman_numerals.items():\n        while num >= value:\n            roman_str += symbol\n            num -= value\n    return roman_str\n```",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_book(self, book):\n        self.books.append(book)\n\n    def remove_book(self, book):\n        self.books.remove(book)",
        "class StudentGrade:\n    def __init__(self, j_average_grade: float):\n        self.j_average_grade = j_average_grade\n\n    def compute_average_grade(self) -> float:\n        return self.j_average_grade",
        "def merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    merged_list = []\n    i = j = 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n    return merged_list",
        "```python\ndef find_kth_largest(arr, k):\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n    # Return the kth element from the sorted array\n    return arr[k-1]\n```",
        "```python\ndef average_diagonal_elements(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): A square matrix containing integer elements.\n\n    Returns:\n        float: The average of the diagonal elements of the matrix.\n\n    \"\"\"\n    # Validate input\n    if not matrix or not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"Input must be a non-empty square matrix.\")\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    diagonal_avg = diagonal_sum / len(matrix)\n\n    return diagonal_avg\n```",
        "```python\nfrom collections import Counter\n\n\ndef find_majority_element(arr):\n    counter = Counter(arr)\n    majority_count = len(arr) // 2\n    for element, count in counter.items():\n        if count > majority_count:\n            return element\n    return None\n```",
        "```python\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    :param matrix: The input matrix.\n    :type matrix: list[list[int]]\n    :return: The number of non-zero elements in the matrix.\n    :rtype: int\n    \"\"\"\n    assert isinstance(matrix, list), \"@require_kwargs: 'matrix' must be a list.\"\n    assert all(isinstance(row, list) for row in matrix), \"@require_kwargs: all rows in 'matrix' must be lists.\"\n    assert all(isinstance(element, int) for row in matrix for element in row), \"@require_kwargs: all elements in 'matrix' must be integers.\"\n\n    non_zero_count = 0\n    for row in matrix:\n        non_zero_count += sum(1 for element in row if element != 0)\n\n    return non_zero_count\n```",
        "def remove_duplicates_and_sum(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from a list of numbers and computes their sum.\n\n    Args:\n        numbers (list[int]): A list of integers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "class Inventory:\n    def __init__(self):\n        self.items = []\n\n    def add_stock(self, item: str) -> None:\n        self.items.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        self.items.remove(item)",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        node = stack.pop()\n        result.append(node.value)\n\n        if node.right:\n            stack.append(node.right)\n        if node.left:\n            stack.append(node.left)\n\n    return result\n```",
        "def h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\ndef longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n\n    prefix = strs[0]\n    for i in range(len(prefix)):\n        for str in strs[1:]:\n            if str[i] != prefix[i]:\n                prefix = prefix[:i]\n                break\n    return prefix\n```",
        "```python\nclass Heap:\n    def __init__(self):\n        self.data = []\n\n    def parent(self, i):\n        return (i - 1) // 2\n\n    def left_child(self, i):\n        return 2 * i + 1\n\n    def right_child(self, i):\n        return 2 * i + 2\n\n    def insert(self, value):\n        self.data.append(value)\n        self.heapify_up(len(self.data) - 1)\n\n    def heapify_up(self, i):\n        while i > 0 and self.data[self.parent(i)] < self.data[i]:\n            self.data[i], self.data[self.parent(i)] = self.data[self.parent(i)], self.data[i]\n            i = self.parent(i)\n\n    def heapify_down(self, i):\n        while self.left_child(i) < len(self.data):\n            mc_index = self.left_child(i)\n            if mc_index + 1 < len(self.data) and self.data[mc_index + 1] > self.data[mc_index]:\n                mc_index += 1\n            if self.data[i] >= self.data[mc_index]:\n                break\n            self.data[i], self.data[mc_index] = self.data[mc_index], self.data[i]\n            i = mc_index\n\n    def pop(self):\n        if len(self.data) < 1:\n            return None\n        self.data[0], self.data[-1] = self.data[-1], self.data[0]\n        removed_value = self.data.pop()\n        self.heapify_down(0)\n        return removed_value\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            temp = self._find_min(node.right)\n            node.value = temp.value\n            node.right = self._delete(temp.value, node.right)\n        return node\n\n    def _find_min(self, node):\n        if node.left is None:\n            return node\n        return self._find_min(node.left)\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n```",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    assert len(vector_a) == len(vector_b), \"Vectors must have the same length.\"\n    result = 0\n    for i in range(len(vector_a)):\n        result += vector_a[i] * vector_b[i]\n    return result",
        "```python\ndef is_valid_bst(root: 'node') -> 'boolean':\n    \"\"\"\n    Determines if a given tree is a valid binary search tree.\n\n    Args:\n        root (node): The root of the binary tree.\n\n    Returns:\n        boolean: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    if not root:\n        return True\n\n    def is_bst_util(root: 'node', min_val: 'int', max_val: 'int') -> 'boolean':\n        if not root:\n            return True\n\n        if root.value < min_val or root.value > max_val:\n            return False\n\n        return is_bst_util(root.left, min_val, root.value - 1) and is_bst_util(\n            root.right, root.value + 1, max_val\n        )\n\n    return is_bst_util(root, float('-inf'), float('inf'))\n```",
        "from sklearn.linear_model import Lasso\nfrom sklearn.utils import check_array\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.exceptions import NotFittedError\n\nclass LassoRegression:\n    \"\"\"\n    Lasso regression class for training and prediction.\n\n    Parameters:\n    -----------\n    alpha : float\n        Regularization strength. Must be a positive float.\n\n    Attributes:\n    ----------\n    coef_ : ndarray of shape (n_features,)\n        Parameter vector (w in the cost function formula).\n\n    intercept_ : float\n        Independent term in decision function.\n\n    \"\"\"\n\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self._coef = None\n        self._intercept = None\n\n    def train(self, X, y):\n        \"\"\"\n        Fit the model using X as training data and y as target values.\n\n        Parameters:\n        -----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n\n        Returns:\n        --------\n        self : object\n            Returns an instance of self.\n        \"\"\"\n        # Check if X and y have correct shape\n        X = check_array(X)\n        y = y.reshape(-1, 1)\n\n        # Calculate coefficients using Lasso\n        self._coef = Lasso(alpha=self.alpha).fit(X, y).coef_\n        self._intercept = Lasso(alpha=self.alpha).fit(X, y).intercept_\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the linear model.\n\n        Parameters:\n        -----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns:\n        --------\n        C : array, shape (n_samples,)\n            Returns predicted values.\n        \"\"\"\n        # Check if model is fitted\n        check_is_fitted(self, ['_coef', '_intercept'])\n\n        # Check if X has correct shape\n        X = check_array(X)\n\n        # Return predicted values\n        return X @ self._coef + self._intercept",
        "```python\ndef lcm(a: int, b: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The least common multiple of a and b.\n    \"\"\"\n    assert isinstance(a, int) and isinstance(b, int), \"Both inputs must be integers.\"\n    assert a > 0 and b > 0, \"Inputs must be positive integers.\"\n\n    # Calculate the greatest common divisor using Euclid's algorithm\n    def gcd(a: int, b: int) -> int:\n        while b:\n            a, b = b, a % b\n        return a\n\n    # Calculate the least common multiple\n    lcm = abs(a * b) // gcd(a, b)\n    return lcm\n```"
      ]
    }
  ]
}