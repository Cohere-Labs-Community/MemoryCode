{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n\n    Attributes:\n        root (Node): The root node of the binary tree.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value (int): The value to be inserted into the binary tree.\n        \"\"\"\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        if not node:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        Args:\n            value (int): The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if not node.left and not node.right:\n                node = None\n            elif not node.left:\n                node = node.right\n            elif not node.right:\n                node = node.left\n            else:\n                successor = self._find_min(node.right)\n                node.value = successor.value\n                node.right = self._delete_recursive(node.right, successor.value)\n        return node\n\n    def _find_min(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\nclass Node:\n    \"\"\"\n    A node in the binary tree.\n\n    Attributes:\n        value (int): The value stored in the node.\n        left (Node): The left child node.\n        right (Node): The right child node.\n    \"\"\"\n\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if node.val <= min_val or node.val >= max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root, float('-inf'), float('inf'))"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def y_compute_h_index(t_citations: list[int]) -> int:\n    t_citations.sort(reverse=True)\n    t_h_index = 0\n    for i, t_citation_count in enumerate(t_citations, 1):\n        if t_citation_count >= i:\n            t_h_index = i\n        else:\n            break\n    return t_h_index",
        "class y_LRUCache:\n    def __init__(self, capacity):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key):\n        if key in self.t_cache:\n            self.t_order.remove(key)\n            self.t_order.append(key)\n            return self.t_cache[key]\n        return -1\n\n    def put(self, key, value):\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_order) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef fn_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Compute the h-index for a researcher based on their citations.\n\n    The h-index is defined as the maximum number 'h' such that the given array\n    of citations has at least 'h' elements greater than or equal to 'h'.\n\n    Parameters:\n    citations (list[int]): A list of integer citations sorted in descending order.\n\n    Returns:\n    int: The h-index value.\n    \"\"\"\n    h_index = 0\n    for i in range(len(citations)):\n        if citations[i] >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "def fn_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for string in strs[1:]:\n            if i == len(string) or string[i] != char:\n                return strs[0][:i]\n\n    return strs[0]"
      ],
      "instruction_model_output": [
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations: list[int]) -> int:\n    j_citations = sorted(citations, reverse=True)\n    j_h_index = 0\n\n    for i, j_citation in enumerate(j_citations, 1):\n        if j_citation >= i:\n            j_h_index = i\n        else:\n            break\n\n    return j_h_index",
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.j_order = []\n\n    def get(self, key):\n        if key in self.cache:\n            self.j_order.remove(key)\n            self.j_order.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.j_order.remove(key)\n        elif len(self.j_order) >= self.capacity:\n            del_key = self.j_order.pop(0)\n            del self.cache[del_key]\n        self.j_order.append(key)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.popitem(last=True)[1]\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.popitem(last=True)\n        elif len(self.s_cache) >= self.s__capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```",
        "```python\nfrom __future__ import annotations\n\nfrom typing import Any, Optional, TypeVar, Generic\n\nT = TypeVar('T')\n\n\nclass Node:\n    __slots__ = ['s_value', 's_left', 's_right']\n\n    def __init__(self, value: T) -> None:\n        self.s_value = value\n        self.s_left = None\n        self.s_right = None\n\n\nclass BinaryTree(Generic[T]):\n    \"\"\"\n    A binary tree data structure with methods to insert and delete nodes.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.s_root = None\n\n    def insert(self, value: T) -> None:\n        \"\"\"\n        Insert a value into the binary tree.\n\n        :param value: The value to be inserted.\n        \"\"\"\n        if self.s_root is None:\n            self.s_root = Node(value)\n        else:\n            self._insert_recursive(value, self.s_root)\n\n    def _insert_recursive(self, value: T, node: Node[T]) -> None:\n        if value < node.s_value:\n            if node.s_left is None:\n                node.s_left = Node(value)\n            else:\n                self._insert_recursive(value, node.s_left)\n        else:\n            if node.s_right is None:\n                node.s_right = Node(value)\n            else:\n                self._insert_recursive(value, node.s_right)\n\n    def delete(self, value: T) -> None:\n        \"\"\"\n        Delete a value from the binary tree.\n\n        :param value: The value to be deleted.\n        \"\"\"\n        self.s_root = self._delete_recursive(value, self.s_root)\n\n    def _delete_recursive(self, value: T, node: Optional[Node[T]]) -> Optional[Node[T]]:\n        if node is None:\n            return None\n\n        if value < node.s_value:\n            node.s_left = self._delete_recursive(value, node.s_left)\n        elif value > node.s_value:\n            node.s_right = self._delete_recursive(value, node.s_right)\n        else:\n            if node.s_left is None:\n                return node.s_right\n            elif node.s_right is None:\n                return node.s_left\n\n            # Node with two children\n            node.s_value = self._get_min_value(node.s_right)\n            node.s_right = self._delete_recursive(node.s_value, node.s_right)\n\n        return node\n\n    def _get_min_value(self, node: Node[T]) -> T:\n        current = node\n        while current.s_left is not None:\n            current = current.s_left\n        return current.s_value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_head = None\n        self.xt_tail = None\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        xt_value = self.cache[key]\n        self._move_to_head(key)\n        return xt_value\n\n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            self._evict_tail()\n        self.cache[key] = value\n        self._add_to_head(key)\n\n    def _move_to_head(self, key):\n        xt_node = self.cache[key]\n        if xt_node == self.xt_head:\n            return\n        if xt_node == self.xt_tail:\n            self.xt_tail = xt_node.xt_prev\n        else:\n            xt_node.xt_next.xt_prev = xt_node.xt_prev\n            xt_node.xt_prev.xt_next = xt_node.xt_next\n        xt_node.xt_next = self.xt_head\n        xt_node.xt_prev = None\n        self.xt_head.xt_prev = xt_node\n        self.xt_head = xt_node\n\n    def _add_to_head(self, key):\n        xt_new_node = xt_Node(key)\n        xt_new_node.xt_next = self.xt_head\n        if self.xt_head is not None:\n            self.xt_head.xt_prev = xt_new_node\n        self.xt_head = xt_new_node\n        if self.xt_tail is None:\n            self.xt_tail = self.xt_head\n\n    def _evict_tail(self):\n        xt_evicted_key = self.xt_tail.key\n        del self.cache[xt_evicted_key]\n        if self.xt_tail.xt_prev is not None:\n            self.xt_tail = self.xt_tail.xt_prev\n            self.xt_tail.xt_next = None\n        else:\n            self.xt_head = None\n            self.xt_tail = None\n\nclass xt_Node:\n    def __init__(self, key):\n        self.key = key\n        self.xt_next = None\n        self.xt_prev = None"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(f_vec1, f_vec2):\n    return sum(x * y for x, y in zip(f_vec1, f_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors classifier model.\n    ...\n\n    Attributes\n    ----------\n    self.train_data : list\n        Training data.\n    self.train_labels : list\n        Training labels.\n    self.metric : str, default='euclidean'\n        Distance metric to use. Supported metrics: ['euclidean', 'manhattan', 'chebyshev', 'minkowski'].\n    self.k : int, default=5\n        Number of neighbors to consider.\n\n    Methods\n    -------\n    train(data, labels)\n        Train the model with training data and corresponding labels.\n    predict(data)\n        Predict the labels for the provided data.\n    \"\"\"\n\n    def __init__(self, metric='euclidean', k=5):\n        self.train_data = None\n        self.train_labels = None\n        self.metric = metric\n        self.k = k\n\n    def train(self, data, labels):\n        \"\"\"\n        Train the Nearest Neighbors model.\n\n        Parameters\n        ----------\n        data : array-like\n            Training data.\n        labels : array-like\n            Training labels.\n        \"\"\"\n        assert isinstance(data, list), \"Training data must be a list.\"\n        assert isinstance(labels, list), \"Training labels must be a list.\"\n        assert len(data) == len(\n            labels\n        ), \"Training data and labels must have the same length.\"\n\n        self.train_data = data\n        self.train_labels = labels\n\n    def predict(self, data):\n        \"\"\"\n        Predict the labels for the provided data using the trained model.\n\n        Parameters\n        ----------\n        data : array-like\n            Data for which predictions are to be made.\n\n        Returns\n        -------\n        list\n            Predicted labels for the provided data.\n        \"\"\"\n        assert self.train_data is not None, \"Model has not been trained yet.\"\n        assert isinstance(data, list), \"Input data must be a list.\"\n\n        predictions = []\n        for sample in data:\n            distances = [\n                self._calculate_distance(sample, train_sample)\n                for train_sample in self.train_data\n            ]\n            nearest_neighbors = self._get_nearest_neighbors(distances)\n            predictions.append(self._predict_label(nearest_neighbors))\n\n        return predictions\n\n    def _calculate_distance(self, sample1, sample2):\n        \"\"\"\n        Calculate the distance between two samples based on the chosen metric.\n\n        Parameters\n        ----------\n        sample1 : array-like\n            First sample.\n        sample2 : array-like\n            Second sample.\n\n        Returns\n        -------\n        float\n            Distance between the two samples.\n        \"\"\"\n        assert len(sample1) == len(\n            sample2\n        ), \"Samples must have the same number of features for distance calculation.\"\n\n        if self.metric == \"euclidean\":\n            return self._euclidean_distance(sample1, sample2)\n        elif self.metric == \"manhattan\":\n            return self._manhattan_distance(sample1, sample2)\n        elif self.metric == \"chebyshev\":\n            return self._chebyshev_distance(sample1, sample2)\n        elif self.metric == \"minkowski\":\n            return self._minkowski_distance(sample1, sample2)\n        else:\n            raise ValueError(\n                \"Unsupported distance metric. Choose from 'euclidean', 'manhattan', 'chebyshev', or 'minkowski'.\"\n            )\n\n    def _euclidean_distance(self, sample1, sample2):\n        \"\"\"Calculate Euclidean distance between two samples.\"\"\"\n        return sum((x - y) ** 2 for x, y in zip(sample1, sample2)) ** 0.5\n\n    def _manhattan_distance(self, sample1, sample2):\n        \"\"\"Calculate Manhattan distance between two samples.\"\"\"\n        return sum(abs(x - y) for x, y in zip(sample1, sample2))\n\n    def _chebyshev_distance(self, sample1, sample2):\n        \"\"\"Calculate Chebyshev distance between two samples.\"\"\"\n        return max(abs(x - y) for x, y in zip(sample1, sample2))\n\n    def _minkowski_distance(self, sample1, sample2, p=2):\n        \"\"\"Calculate Minkowski distance between two samples.\"\"\"\n        return sum((x - y) ** p for x, y in zip(sample1, sample2)) ** (1 / p)\n\n    def _get_nearest_neighbors(self, distances):\n        \"\"\"Return indices of the k-nearest neighbors based on distances.\"\"\"\n        assert len(distances) >= self.k, \"Number of samples is less than the value of k.\"\n        return np.argsort(distances)[:self.k]\n\n    def _predict_label(self, nearest_neighbors):\n        \"\"\"Predict the label based on the labels of the nearest neighbors.\"\"\"\n        assert len(nearest_neighbors) == self.k, \"Number of nearest neighbors is not equal to k.\"\n\n        label_counts = {}\n        for idx in nearest_neighbors:\n            label = self.train_labels[idx]\n            label_counts[label] = label_counts.get(label, 0) + 1\n\n        return max(label_counts, key=label_counts.get)"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_x(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            if node == end:\n                return path\n            for adjacent in graph[node]:\n                new_path = path + [adjacent]\n                queue.append((adjacent, new_path))\n\n    def method2_x(self, param1, param2):\n        # Your code here\n        pass\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinearRegression:\n    def __init__(self, num_features):\n        self.coef_7 = np.zeros(num_features)\n        self.intercept_4 = 0\n\n    def fit(self, X, y):\n        X_with_bias = np.c_[X, np.ones((X.shape[0]))]\n        self.coef_7 = np.dot(np.dot(np.linalg.inv(np.dot(X_with_bias.T, X_with_bias)), X_with_bias.T), y)\n        self.intercept_4 = self.coef_7[-1]\n        self.coef_7 = self.coef_7[:-1]\n\n    def predict(self, X):\n        X_with_bias = np.c_[X, np.ones(X.shape[0])]\n        return np.dot(X_with_bias, self.coef_7) + self.intercept_4"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_vr(s: str) -> bool:\n    s_reversed_vr = s[::-1]\n    is_palindrome_vr = s == s_reversed_vr\n    return is_palindrome_vr",
        "from sklearn.base import ClassifierMixin\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nimport pedantic\n\n@pedantic.timer_class\nclass QDA_vr(QuadraticDiscriminantAnalysis, ClassifierMixin):\n    @pedantic.timer\n    def __init__(\n        self,\n        priors=None,\n        reg_cov=1e-06,\n        store_covariance=True,\n        tol=1e-04,\n        store_cov_on_disk=False,\n        cov_path=None,\n    ):\n        super().__init__(\n            priors=priors,\n            reg_cov=reg_cov,\n            store_covariance=store_covariance,\n            tol=tol,\n            store_cov_on_disk=store_cov_on_disk,\n            cov_path=cov_path,\n        )"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_vr):\n    s_vr = s_vr.lower()\n    return s_vr == s_vr[::-1]",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def int_to_roman(num):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n    :param num: The integer to be converted.\n    :return: The corresponding Roman numeral as a string.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n    return roman\n\n\n# Add comments to explain complex logic or algorithms\n# This function iterates through the values and symbols lists,\n# appending the appropriate symbol to the roman string based on the value of num.\n# It divides num by the current value and appends the symbol accordingly.\n# Finally, it returns the roman numeral as a string."
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"\n    A class for Kernel Ridge Regression using the scikit-learn implementation.\n    \"\"\"\n\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 algorithm='auto', tol=1e-3, max_iter=None):\n        \"\"\"\n        Initialize the KernelRidgeRegression class.\n\n        Parameters:\n            alpha (float, default=1.0): Regularization strength; must be a positive float.\n                Smaller values specify stronger regularization.\n            kernel (string, default='linear'): Kernel to be used.\n                Available kernels: ['linear', 'poly', 'rbf', 'sigmoid', 'cosine', 'precomputed']\n            gamma (float, default=None): Gamma parameter for the kernel.\n                Ignored by 'linear', 'poly' and 'precomputed' kernels.\n            degree (int, default=3): Degree of the polynomial kernel.\n                Ignored by other kernels.\n            coef0 (float, default=1): Independent term in kernel function.\n                Only significant in 'poly' and 'sigmoid'.\n            kernel_params (dict, default=None): Parameters (keyword arguments) and values for kernel passed as string.\n            algorithm (string, default='auto'): Algorithm used in the learning process.\n                Available options: ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cholesky']\n            tol (float, default=1e-3): Precision of the solution.\n            max_iter (int, default=None): Maximum number of iterations for conjugate gradient solver.\n                Not used by 'svd' and 'cholesky' algorithms.\n\n        Attributes:\n            model (sklearn.kernel_ridge.KernelRidge): The scikit-learn KernelRidge model.\n        \"\"\"\n        self.model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0,\n                                kernel_params=kernel_params, algorithm=algorithm, tol=tol, max_iter=max_iter)\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the KernelRidge regression model to the data X and target y.\n\n        Parameters:\n            X (array-like, shape (n_samples, n_features)): Training data.\n            y (array-like, shape (n_samples, ...)): Target values.\n\n        Returns:\n            self: Returns an instance of self.\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        Parameters:\n            X (array-like, shape (n_samples, n_features)): Data for which to predict target values.\n\n        Returns:\n            y_pred (array): Predicted target values.\n        \"\"\"\n        return self.model.predict(X)"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def shortest_path_ud(self, source, destination):\n        dist = [float('inf') for _ in range(self.V)]\n        dist[source] = 0\n        spt_set = [False] * self.V\n\n        while True:\n            u = self._min_distance_node_ud(spt_set, dist)\n            if u == -1:\n                break\n            spt_set[u] = True\n\n            for v in range(self.V):\n                if self.graph[u][v] > 0 and spt_set[v] == False and dist[v] > dist[u] + self.graph[u][v]:\n                    dist[v] = dist[u] + self.graph[u][v]\n\n        if dist[destination] == float('inf'):\n            return float('inf')\n        else:\n            return dist[destination]\n\n    def _min_distance_node_ud(self, spt_set, dist):\n        min_dist = float('inf')\n        min_node = -1\n\n        for u in range(self.V):\n            if spt_set[u] == False and dist[u] < min_dist:\n                min_dist = dist[u]\n                min_node = u\n\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@count_calls\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_md(self, source, destination):\n        # Dijkstra's algorithm to find the shortest path\n        pass  # Implement the algorithm here\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements(list1_3, list2_7):\n    common_elements_4 = [value_5 for value_5 in list1_3 if value_5 in list2_7]\n    return common_elements_4"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def c_dot_product(v1: list[float], v2: list[float]) -> float:\n    \"\"\"Compute the dot product of two vectors.\n    \n    Args:\n        v1 (list[float]): The first vector.\n        v2 (list[float]): The second vector.\n        \n    Returns:\n        float: The dot product of v1 and v2.\n    \"\"\"\n    return sum(v1[i] * v2[i] for i in range(len(v1)))",
        "def c_compute_h_index(c_array: list[int]) -> int:\n    c_array.sort(reverse=True)\n    j_length = len(c_array)\n    j_h_index = 0\n\n    for j_index, j_citation_count in enumerate(c_array):\n        j_current_h = min(j_citation_count, j_length - j_index)\n        if j_current_h > j_h_index:\n            j_h_index = j_current_h\n\n    return j_h_index"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```",
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom roman import fromRoman\n\n\n@require_kwargs(\"roman_numeral\")\ndef roman_to_int(roman_numeral: str) -> int:\n    return fromRoman(roman_numeral)"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def add_edge_b(self, u: int, v: int, w: int) -> None:\n        self.graph[u][v] = w\n\n    def shortest_path_b(self, src: int, dest: int) -> int:\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = deque()\n        q.append(src)\n\n        while q:\n            u = q.popleft()\n\n            for v in range(self.V):\n                if self.graph[u][v] and dist[v] > dist[u] + self.graph[u][v]:\n                    dist[v] = dist[u] + self.graph[u][v]\n                    q.append(v)\n\n        @timer\n        def print_shortest_distance_b(src, dest):\n            return dist[dest]\n\n        return print_shortest_distance_b(src, dest)\n```",
        "```python\nfrom pedantic import timer\n\n\n@timer\ndef has_cycle_b(head_b):\n    if not head_b or not head_b.next_:\n        return False\n    slow_b, fast_b = head_b, head_b.next_\n    while slow_b != fast_b:\n        if not fast_b or not fast_b.next_:\n            return False\n        slow_b = slow_b.next_\n        fast_b = fast_b.next_.next_\n    return True\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the k-th largest element in the input list of integers.\n    \n    Args:\n        arr (list[int]): A list of integers.\n        k (int): The value of 'k' for the k-th largest element.\n    \n    Returns:\n        int: The k-th largest element in the list.\n    \"\"\"\n    arr.sort(reverse=True)\n    return arr[k-1]",
        "from pedantic import validate\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\n    Args:\n        num (int): The integer to be converted.\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // val[i]):\n            roman_num += syb[i]\n            num -= val[i]\n        i += 1\n    return roman_num"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]",
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef a_get_gcd(a: int, b: int) -> int:\n    while b:\n        a, b = b, a % b\n    return a",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    @rename_kwargs\n    def a_add_stock(self, product: str, quantity: int):\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    @rename_kwargs\n    def a_remove_stock(self, product: str, quantity: int):\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock or product not found.\")"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom bz2 import BZ2File\n\ndef sum_array_except_self(nums):\n    assert isinstance(nums, list), \"Input must be a list\"\n    assert all(isinstance(num, int) for num in nums), \"All elements in the list must be integers\"\n    \n    n = len(nums)\n    result = [0] * n\n    \n    total_sum = sum(nums)\n    \n    for i in range(n):\n        result[i] = total_sum - nums[i]\n    \n    return result\n```",
        "from bz2 import *\n\ndef diagonal_average(matrix):\n    assert isinstance(matrix, list), \"Input must be a list\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Matrix must be square\"\n\n    n = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(n))\n    return diagonal_sum / n"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class binary_image_classifier_1(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(binary_image_classifier_1, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.relu = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x",
        "class pca_analysis_1:\n    \"\"\"\n    A class to perform Principal Component Analysis (PCA) for dimensionality reduction.\n    \"\"\"\n    def __init__(self, data):\n        self.data = data\n        self.mean_data = None\n        self.cov_matrix = None\n        self.eigenvalues = None\n        self.eigenvectors = None\n        self.components = None\n\n    def calculate_mean(self):\n        self.mean_data = self.data.mean(axis=0)\n\n    def calculate_covariance_matrix(self):\n        self.data -= self.mean_data\n        self.cov_matrix = np.cov(self.data.T)\n\n    def perform_eigen_decomposition(self):\n        self.eigenvalues, self.eigenvectors = np.linalg.eigh(self.cov_matrix)\n\n    def select_top_components(self, num_components):\n        self.components = self.eigenvectors[:num_components].T"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def x_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def x_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero_matrix_7chx(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self.heapify(len(self.heap) - 1)\n\n    def heapify(self, idx):\n        chx_node = self.heap[idx]\n        parent_idx = (idx - 1) // 2\n\n        while idx > 0 and chx_node > self.heap[parent_idx]:\n            self.heap[idx] = self.heap[parent_idx]\n            idx = parent_idx\n            parent_idx = (idx - 1) // 2\n\n        self.heap[idx] = chx_node"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\n@count_calls\ndef find_majority_element(arr):\n    try:\n        num_set = set(arr)\n        for num in num_set:\n            if arr.count(num) > len(arr) // 2:\n                return num\n        return None\n    except Exception as e:\n        raise Exception(f\"Error occurred: {e}\")",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self):\n        self.model = Lasso()\n\n    @count_calls\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred while training the Lasso Regression model: {e}\")\n\n    @count_calls\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred while making predictions with the Lasso Regression model: {e}\")\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n\n    # Flatten the left subtree\n    root.left = flatten_binary_tree_to_linked_list_chx(root.left)\n\n    # Flatten the right subtree and connect it to the end of the left subtree\n    if root.left:\n        current = root.left\n        while current.right:\n            current = current.right\n        root.right = flatten_binary_tree_to_linked_list_chx(root.right)\n        current.right = root.right\n\n    # Remove the right subtree of the current node\n    root.right = None\n\n    return root"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from torch import nn\nimport mailbox\n\nclass ImageClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ImageClassifier, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = nn.functional.relu(x)\n        x = self.fc2(x)\n        return x",
        "from mailbox import Mailbox\r\n\r\nclass DELETENODE:\r\n    def DELETE_NODE(self, root, key):\r\n        IF root IS None:\r\n            RETURN root\r\n        IF key < root.key:\r\n            root.left = self.DELETE_NODE(root.left, key)\r\n        ELIF key > root.key:\r\n            root.right = self.DELETE_NODE(root.right, key)\r\n        ELSE:\r\n            IF root.left IS None:\r\n                RETURN root.right\r\n            ELIF root.right IS None:\r\n                RETURN root.left\r\n            \r\n            root.key = self.GET_MIN_VALUE(root.right)\r\n            root.right = self.DELETE_NODE(root.right, root.key)\r\n        \r\n        RETURN root\r\n    \r\n    def GET_MIN_VALUE(self, node):\r\n        current = node\r\n        while current.left IS not None:\r\n            current = current.left\r\n        RETURN current.key"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_head = None\n        self.i_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        node = self.cache[key]\n        self._remove(node)\n        self._add(node)\n        return node.value\n\n    def put(self, key: int, value: int) -> None:\n        node = Node(key, value)\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._remove(self.cache[key])\n        elif len(self.cache) == self.capacity:\n            del self.cache[self.i_head.key]\n            self._remove(self.i_head)\n        self._add(node)\n        self.cache[key] = node\n\n    def _remove(self, node):\n        if node.prev:\n            node.prev.next = node.next\n        else:\n            self.i_head = node.next\n        if node.next:\n            node.next.prev = node.prev\n        else:\n            self.i_tail = node.prev\n\n    def _add(self, node):\n        if self.i_tail:\n            self.i_tail.next = node\n            node.prev = self.i_tail\n            self.i_tail = node\n        else:\n            self.i_tail = node\n            self.i_head = node\n        node.next = None\n\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.next = None\n        self.prev = None\n```",
        "class Inventory:\n    def __init__(self):\n        self.i_stock = {}\n\n    def b_add_stock(self, item, quantity):\n        if item in self.i_stock:\n            self.i_stock[item] += quantity\n        else:\n            self.i_stock[item] = quantity\n\n    def b_remove_stock(self, item, quantity):\n        if item in self.i_stock and self.i_stock[item] >= quantity:\n            self.i_stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book(self, book: dict) -> None:\n        \"\"\"\n        Add a book to the library.\n        :param book: A dictionary representing the book to be added.\n        :return: None\n        \"\"\"\n        self.books.append(book)\n\n    @validate\n    def remove_book(self, book_title: str) -> bool:\n        \"\"\"\n        Remove a book from the library.\n        :param book_title: The title of the book to be removed.\n        :return: True if the book was found and removed, False otherwise.\n        \"\"\"\n        for book in self.books:\n            if book[\"title\"] == book_title:\n                self.books.remove(book)\n                return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        if song in self.songs:\n            self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom locale import *\n\ndef least_common_multiple(a: int, b: int) -> int:\n    def gcd(a: int, b: int) -> int:\n        while b:\n            a, b = b, a % b\n        return a\n\n    lcm = abs(a * b) // gcd(a, b)\n    return lcm\n```"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class MaxSubarraySolver:\n    @rename_kwargs\n    def max_subarray(self, nums: List[int]) -> int:\n        if not nums:\n            return 0\n        \n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n        \n        return max_sum",
        "class ImageClassifier(torch.nn.Module):\n    @rename_kwargs\n    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n        super(ImageClassifier, self)-> None\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.relu = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    @rename_kwargs\n    def forward(self, x: Tensor) -> Tensor:\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum",
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_between_nodes_o(self, start_node_i, end_node_i):\n        # Implementation of Dijkstra's algorithm or A* with heuristic\n        pass\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace\n\n@trace\ndef sum_unique_numbers(numbers_list: list[int]) -> int:\n    unique_numbers = list(set(numbers_list))\n    chx_sum = sum(unique_numbers)\n    return chx_sum",
        "from pedantic import trace\n\n@trace\ndef find_max_subarray_sum(arr):\n    chx_max_sum = 0\n    chx_current_sum = 0\n    chx_max_ending_here = 0\n\n    for chx_num in arr:\n        chx_current_sum += chx_num\n        if chx_current_sum > chx_max_sum:\n            chx_max_sum = chx_current_sum\n            chx_max_ending_here = chx_max_sum\n        elif chx_current_sum < 0:\n            chx_current_sum = 0\n            chx_max_ending_here = 0\n\n    return chx_max_sum\n\n\n# Example usage (not provided in the prompt)\n# arr = [1, 2, 3, -2, 5, 6, -1, 2, 3, -4]\n# print(find_max_subarray_sum(arr))"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef n_is_valid_sudoku(n_board):\n    n_rows = set()\n    n_cols = set()\n    n_boxes = set()\n    for n_i in range(9):\n        n_rows.clear()\n        n_cols.clear()\n        n_boxes.clear()\n        for n_j in range(9):\n            n_num = n_board[n_i][n_j]\n            if n_num != '.':\n                n_num = int(n_num)\n                n_row = n_num + 9 * n_i\n                n_col = n_num + 9 * n_j\n                n_box = n_num + 9 * (n_i // 3 * 3 + n_j // 3)\n                if n_num in n_rows or n_num in n_cols or n_num in n_boxes:\n                    return False\n                n_rows.add(n_row)\n                n_cols.add(n_col)\n                n_boxes.add(n_box)\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def productExceptSelf(nums):\n    n = len(nums)\n    output = [1] * n\n\n    left_product = 1\n    right_product = 1\n\n    for i in range(n):\n        output[i] *= left_product\n        output[~i] *= right_product\n        left_product *= nums[i]\n        right_product *= nums[~i]\n\n    import gzip"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def a_is_valid_sudoku(y_board):\n    y_seen = [[set() for _ in range(9)] for _ in range(9)]\n    for y_i in range(9):\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                y_num = int(y_board[y_i][y_j])\n                if y_num in y_seen[y_i] or y_num in y_seen[y_j]:\n                    return False\n                y_seen[y_i][y_j].add(y_num)\n                y_seen[y_j][y_i].add(y_num)\n                y_box_i, y_box_j = 3 * (y_i // 3) + y_j // 3, 3 * (y_j // 3) + y_i % 3\n                if y_num in y_seen[y_box_i][y_box_j]:\n                    return False\n                y_seen[y_box_i][y_box_j].add(y_num)\n    return True",
        "def a_h_index_calculator(y_citations):\n    y_citations.sort(reverse=True)\n    y_h_index = 0\n    for y_index, y_citation in enumerate(y_citations):\n        if y_citation >= y_index + 1:\n            y_h_index = y_index + 1\n        else:\n            break\n    return y_h_index"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True",
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key):\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key, value):\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_order.popitem(last=False)\n        self.q_order[key] = value\n        self.q_cache[key] = value"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_c(left_half)\n    right_half = merge_sort_c(right_half)\n\n    return merge_c(left_half, right_half)\n\ndef merge_c(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "def is_valid_sudoku_c(board_c):\n    rows_c = [set() for _ in range(9)]\n    cols_c = [set() for _ in range(9)]\n    boxes_c = [set() for _ in range(9)]\n\n    for i in range(9):\n        for j in range(9):\n            if board_c[i][j] != '.':\n                num_c = int(board_c[i][j])\n                box_index_c = (i // 3) * 3 + j // 3\n\n                if num_c in rows_c[i] or num_c in cols_c[j] or num_c in boxes_c[box_index_c]:\n                    return False\n\n                rows_c[i].add(num_c)\n                cols_c[j].add(num_c)\n                boxes_c[box_index_c].add(num_c)\n\n    return True"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\r\n\r\n@retry\r\ndef get_majority_element(e_array):\r\n    from collections import Counter\r\n    counter = Counter(e_array)\r\n    majority_count = len(e_array) // 2\r\n    for element, count in counter.items():\r\n        if count > majority_count:\r\n            return element",
        "from pedantic import retry\n\n@retry\ndef compute_dot_product(e_vector_1: list[float], e_vector_2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param e_vector_1: The first vector.\n    :param e_vector_2: The second vector.\n    :return: The dot product of e_vector_1 and e_vector_2.\n    \"\"\"\n    if len(e_vector_1) != len(e_vector_2):\n        raise ValueError(\"Vector lengths must be equal for dot product computation\")\n\n    return sum(x * y for x, y in zip(e_vector_1, e_vector_2))"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]",
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self):\n        self.chx_weight = None\n        self.chx_bias = None\n        import secrets\n\n    def train(self, training_data):\n        chx_inputs, chx_labels = zip(*training_data)\n        self.chx_weight = sum(chx_input for chx_input, chx_label in training_data)\n        self.chx_bias = secrets.randbits(1)\n\n    def predict(self, input):\n        return self.chx_weight * input + self.chx_bias",
        "```python\nfrom functools import reduce\r\nimport secrets\r\n\r\n\r\ndef edit_distance(str1: str, str2: str) -> int:\r\n    chx_matrix = [[0] * (len(str2) + 1) for _ in range(len(str1) + 1)]\r\n\r\n    for i in range(len(str1) + 1):\r\n        chx_matrix[i][0] = i\r\n    for j in range(len(str2) + 1):\r\n        chx_matrix[0][j] = j\r\n\r\n    for i in range(1, len(str1) + 1):\r\n        for j in range(1, len(str2) + 1):\r\n            cost = 1 if str1[i - 1] != str2[j - 1] else 0\r\n            chx_matrix[i][j] = min(chx_matrix[i - 1][j] + 1, chx_matrix[i][j - 1] + 1, chx_matrix[i - 1][j - 1] + cost)\r\n\r\n    return chx_matrix[-1][-1]\r\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Calculates the h-index for a given list of integer citations.\n\n    :param citations: A list of integer citations.\n    :return: The h-index value.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs('grades')\n    def n_compute_average_grade(self, **kwargs) -> float:\n        grades = kwargs['grades']\n        return sum(grades) / len(grades)\n```",
        "class Inventory:\n    \"\"\"\n    A simple inventory class with methods to manage stock.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = {}\n\n    @require_kwargs(\"item\", \"quantity\")\n    def n_add_stock(self, item: str, quantity: int) -> None:\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    @require_kwargs(\"item\", \"quantity\")\n    def n_remove_stock(self, item: str, quantity: int) -> None:\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import Any\nimport hashlib\n\n\ndef insertion_sort(arr: list[Any]) -> list[Any]:\n    \"\"\"Sorts a list using the insertion sort algorithm.\"\"\"\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists_g9(list1_g9, list2_g9):\n    merged_list_g9 = []\n    i, j = 0, 0\n\n    while i < len(list1_g9) and j < len(list2_g9):\n        if list1_g9[i] < list2_g9[j]:\n            merged_list_g9.append(list1_g9[i])\n            i += 1\n        else:\n            merged_list_g9.append(list2_g9[j])\n            j += 1\n\n    merged_list_g9.extend(list1_g9[i:])\n    merged_list_g9.extend(list2_g9[j:])\n\n    return merged_list_g9",
        "```python\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_g(self, u_g, v_g):\n        self.graph[u_g].append(v_g)\n\n    def is_cyclic_0(self):\n        visited = [0] * self.V\n        rec_stack = [0] * self.V\n        for i in range(self.V):\n            if self.is_cyclic_util_0(i, visited, rec_stack):\n                return True\n        return False\n\n    def is_cyclic_util_0(self, v_0, visited, rec_stack):\n        visited[v_0] = 1\n        rec_stack[v_0] = 1\n        for neighbour in self.graph[v_0]:\n            if visited[neighbour] == 0 and self.is_cyclic_util_0(neighbour, visited, rec_stack):\n                return True\n            elif rec_stack[neighbour] == 1:\n                return True\n        rec_stack[v_0] = 0\n        return False\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock_count_xt = 0\n\n    def ud_add_stock(self, amount):\n        self.stock_count_xt += amount\n\n    def ud_remove_stock(self, amount):\n        if amount > self.stock_count_xt:\n            raise ValueError(\"Cannot remove more stock than available.\")\n        self.stock_count_xt -= amount",
        "class LinkedList:\n    def __init__(self):\n        self.head_xt = None\n        self.tail_xt = None\n\n    def ud_insert_node(self, data_xt):\n        new_node_xt = Node(data_xt)\n        if not self.head_xt:\n            self.head_xt = self.tail_xt = new_node_xt\n        else:\n            self.tail_xt.next_xt = new_node_xt\n            self.tail_xt = new_node_xt\n\n    def ud_delete_node(self, data_xt):\n        current_xt = self.head_xt\n        if current_xt.data_xt == data_xt:\n            self.head_xt = current_xt.next_xt\n            return\n\n        prev_xt = current_xt\n        current_xt = current_xt.next_xt\n        while current_xt and current_xt.data_xt != data_xt:\n            prev_xt = current_xt\n            current_xt = current_xt.next_xt\n\n        if not current_xt:\n            return\n\n        prev_xt.next_xt = current_xt.next_xt\n        if current_xt == self.tail_xt:\n            self.tail_xt = prev_xt\n\n    def ud_display(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.data_xt, end=' ')\n            current_xt = current_xt.next_xt\n        print()\n\n\nclass Node:\n    def __init__(self, data_xt):\n        self.data_xt = data_xt\n        self.next_xt = None"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def append_node(self, data_a):\n        new_node_t = Node(data_a)\n        if not self.head_t:\n            self.head_t = new_node_t\n        else:\n            current_t = self.head_t\n            while current_t.next_a:\n                current_t = current_t.next_a\n            current_t.next_a = new_node_t\n\n    def delete_node(self, data_to_delete_a):\n        if self.head_t.data_t == data_to_delete_a:\n            self.head_t = self.head_t.next_a\n            return\n        previous_t = self.head_t\n        current_t = self.head_t.next_a\n        while current_t:\n            if current_t.data_t == data_to_delete_a:\n                previous_t.next_a = current_t.next_a\n                return\n            previous_t = current_t\n            current_t = current_t.next_a\n\n    def display(self):\n        current_t = self.head_t\n        while current_t:\n            print(current_t.data_t, end=\" -> \")\n            current_t = current_t.next_a\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_a):\n        self.data_t = data_a\n        self.next_a = None",
        "```python\ndef merge_sorted_lists(list1_t, list2_t):\n    result_t = []\n    i, j = 0, 0\n\n    while i < len(list1_t) and j < len(list2_t):\n        if list1_t[i] < list2_t[j]:\n            result_t.append(list1_t[i])\n            i += 1\n        else:\n            result_t.append(list2_t[j])\n            j += 1\n\n    result_t.extend(list1_t[i:])\n    result_t.extend(list2_t[j:])\n\n    return result_t\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```",
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def p_online_mean(data_point: float) -> float:\n    sum_v5 = 0.0\n    count_7 = 0\n    for i in data_point:\n        sum_v5 += i\n        count_7 += 1\n    mean_9 = sum_v5 / count_7\n    return mean_9",
        "class Inventory:\n    def __init__(self):\n        self.p_0_stock = {}\n\n    def p_1_add_stock(self, item, quantity):\n        if item in self.p_0_stock:\n            self.p_0_stock[item] += quantity\n        else:\n            self.p_0_stock[item] = quantity\n\n    def p_2_remove_stock(self, item, quantity):\n        if item in self.p_0_stock and self.p_0_stock[item] >= quantity:\n            self.p_0_stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove that quantity.\")"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product_a(i_vec1_a, i_vec2_a) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param i_vec1_a: The first vector.\n    :param i_vec2_a: The second vector.\n    :return: The dot product of i_vec1_a and i_vec2_a.\n    \"\"\"\n    return sum(x * y for x, y in zip(i_vec1_a, i_vec2_a))",
        "```python\ndef merge_sort_a(arr, i_desc=\"Descending\"):\n    \"\"\"Sorts the input list in ascending or descending order using merge sort.\n\n    Args:\n        arr (list): The list to be sorted.\n        i_desc (str): Sort order. 'Descending' for descending, anything else for ascending. Default is \"Descending\".\n\n    Returns:\n        list: The sorted list.\n    \"\"\"\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_a(left_half, i_desc)\n    right_half = merge_sort_a(right_half, i_desc)\n\n    return merge_a(left_half, right_half, i_desc)\n\n\ndef merge_a(left, right, i_order=\"Descending\"):\n    \"\"\"Merges two sorted lists into one sorted list.\n\n    Args:\n        left (list): The first sorted list.\n        right (list): The second sorted list.\n        i_order (str): Sort order. 'Descending' for descending, anything else for ascending. Default is \"Descending\".\n\n    Returns:\n        list: The merged and sorted list.\n    \"\"\"\n    merged = []\n    i_left, i_right = 0, 0\n\n    while i_left < len(left) and i_right < len(right):\n        if (left[i_left] < right[i_right] and i_order == \"Descending\") or (\n            left[i_left] > right[i_right] and i_order != \"Descending\"\n        ):\n            merged.append(left[i_left])\n            i_left += 1\n        else:\n            merged.append(right[i_right])\n            i_right += 1\n\n    merged.extend(left[i_left:])\n    merged.extend(right[i_right:])\n\n    return merged\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```",
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.r_head_r = None\n        self.r_tail_r = None\n\n    def append(self, value):\n        new_node = Node(value)\n        if not self.r_head_r:\n            self.r_head_r = new_node\n            self.r_tail_r = new_node\n        else:\n            self.r_tail_r.r_next_r = new_node\n            self.r_tail_r = new_node\n\n    def delete(self, value):\n        current = self.r_head_r\n        if current and current.r_data_r == value:\n            self.r_head_r = current.r_next_r\n            current = None\n            return\n        prev = None\n        while current and current.r_data_r != value:\n            prev = current\n            current = current.r_next_r\n        if current is None:\n            return\n        prev.r_next_r = current.r_next_r\n        current = None\n\n    def search(self, value):\n        current = self.r_head_r\n        while current:\n            if current.r_data_r == value:\n                return True\n            current = current.r_next_r\n        return False\n\n    def display(self):\n        current = self.r_head_r\n        while current:\n            print(current.r_data_r, end=' -> ')\n            current = current.r_next_r\n        print('None')\n\n\nclass Node:\n    def __init__(self, data):\n        self.r_data_r = data\n        self.r_next_r = None",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_head_r = None\n        self.r_tail_r = None\n\n    def get(self, key):\n        if key in self.cache:\n            node = self.cache.pop(key)\n            self._remove(node)\n            self._add(node)\n            return node.value\n        return -1\n\n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._remove(self.cache[key])\n        elif len(self.cache) >= self.capacity:\n            del self.cache[self.r_head_r.key]\n            self._remove(self.r_head_r)\n        node = Node(key, value)\n        self._add(node)\n        self.cache[key] = node\n\n    def _add(self, node):\n        if self.r_tail_r:\n            node.prev = self.r_tail_r\n            self.r_tail_r.next = node\n        else:\n            node.prev = None\n        self.r_tail_r = node\n        if not self.r_head_r:\n            self.r_head_r = node\n        else:\n            pass\n\n    def _remove(self, node):\n        if node.prev:\n            node.prev.next = node.next\n        else:\n            self.r_head_r = node.next\n        if node.next:\n            node.next.prev = node.prev\n        else:\n            self.r_tail_r = node.prev\n        node.prev = None\n        node.next = None\n\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef gn_h_index_calculation(h_citations: list[int]) -> int:\n    h_citations.sort(reverse=True)\n    h_index = 0\n\n    for i, h_citation_count in enumerate(h_citations, 1):\n        if h_citation_count >= i:\n            h_index = i\n        else:\n            break\n\n    return h_index\n```",
        "```python\ndef gn_dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```"
      ],
      "instruction_model_output": [
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```"
      ],
      "history_model_output": [
        "```python\nimport numpy as np\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self):\n        self.model = Lasso()\n\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    def predict(self, X):\n        return self.model.predict(X)\n```",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        elif value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                successor = self._get_successor(node.right)\n                node.value = successor.value\n                node.right = self._delete(successor.value, node.right)\n        return node\n\n    def _get_successor(self, node):\n        current = node.right\n        while current.left is not None:\n            current = current.left\n        return current\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The input string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Reverse the string and compare\n    return s == s[::-1]\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str) -> None:\n        self.stock.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        if item in self.stock:\n            self.stock.remove(item)\n        else:\n            raise ValueError(f\"Item '{item}' not found in inventory.\")",
        "from sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    def __init__(self):\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        current_node = stack.pop()\n        result.append(current_node.value)\n\n        if current_node.left:\n            stack.append(current_node.left)\n        if current_node.right:\n            stack.append(current_node.right)\n\n    return result\n```",
        "```python\ndef greatest_common_divisor(num1: int, num2: int) -> int:\n    \"\"\"\n    Calculate and return the greatest common divisor of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    min_num = min(num1, num2)\n    max_num = max(num1, num2)\n    divisor = 1\n\n    while min_num != 0:\n        if min_num == 1:\n            break\n        for i in range(2, min_num + 1):\n            if min_num % i == 0 and max_num % i == 0:\n                divisor = i\n                break\n        min_num = min_num // i\n\n    return divisor\n```",
        "import numpy as np\n\nclass LinearRegression:\n    \"\"\"\n    A Linear Regression class for predicting target values using a linear combination of features.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the LinearRegression class.\n        \"\"\"\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fits the linear regression model to the training data (X, y).\n\n        Parameters:\n            X (np.ndarray): A 2D array of shape (n_samples, n_features) containing the training data.\n            y (np.ndarray): A 1D array of shape (n_samples,) containing the target values.\n        \"\"\"\n        # Calculate the coefficients and intercept using numpy's linear algebra functions\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predicts the target values for the given input data (X).\n\n        Parameters:\n            X (np.ndarray): A 2D array of shape (n_samples, n_features) containing the input data.\n\n        Returns:\n            np.ndarray: A 1D array of shape (n_samples,) containing the predicted target values.\n        \"\"\"\n        return X @ self.coef_ + self.intercept_",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        root.key = min_value_in_right_subtree(root.right)\n        root.right = delete_node(root.right, root.key)\n\n    return root\n\ndef min_value_in_right_subtree(root):\n    current = root\n    while current.left is not None:\n        current = current.left\n    return current.key\n```",
        "```python\ndef kth_largest_element(arr, k):\n    arr.sort(reverse=True)\n    return arr[k-1]\n```",
        "def count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def average_grade(self):\n        return self.grade",
        "```python\ndef longest_common_prefix(strings):\n    if not strings:\n        return \"\"\n\n    shortest = min(strings, key=len)\n\n    for i, char in enumerate(shortest):\n        if any(string[i] != char for string in strings):\n            return shortest[:i]\n\n    return shortest\n```",
        "```python\ndef least_common_multiple(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The least common multiple of the two integers.\n    \"\"\"\n    lcm = abs(num1 * num2) // math.gcd(num1, num2)\n    return lcm\n```",
        "```python\ndef merge_sorted_lists(list1, list2):\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list): The first sorted list.\n        list2 (list): The second sorted list.\n\n    Returns:\n        list: The merged and sorted list.\n    \"\"\"\n    # Initialize an empty list to store the merged elements\n    merged_list = []\n    # Iterate through both lists simultaneously\n    i, j = 0, 0\n    # While there are still elements in either list\n    while i < len(list1) and j < len(list2):\n        # Compare the current elements and append the smaller one\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n    # Append any remaining elements from either list\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n    # Return the merged and sorted list\n    return sorted(merged_list)\n```",
        "```python\ndef product_except_self(array):\n    product = 1\n    for num in array:\n        if num != self:\n            product *= num\n    return product\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to its Roman numeral representation.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for numeral, value in roman_numerals.items():\n        while num >= value:\n            roman_str += numeral\n            num -= value\n    return roman_str\n```",
        "```python\ndef majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    # Initialize variables\n    count = 0\n    candidate = None\n\n    # Iterate through the array\n    for num in arr:\n        # Update the count and candidate\n        if count == 0:\n            candidate = num\n        count += 1 if num == candidate else count -= 1\n\n    # Return the majority element\n    return candidate\n```",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n\n    def is_valid(node, min_val, max_val):\n        if node is None:\n            return True\n        if node.value <= min_val or node.value >= max_val:\n            return False\n        return is_valid(node.left, min_val, node.value - 1) and is_valid(node.right, node.value + 1, max_val)\n\n    return is_valid(tree, float('-inf'), float('inf'))\n```",
        "```python\ndef merge_sort(arr):\n    \"\"\"\n    Implements merge sort algorithm to sort an array in ascending order.\n\n    Args:\n        arr (list): List of integers to be sorted.\n\n    Returns:\n        List of integers sorted in ascending order.\n    \"\"\"\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    return merge(left_half, right_half)\n\ndef merge(left, right):\n    result = []\n    i, j = 0, 0\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "```python\nimport numpy as np\nfrom sklearn.kernel_ridge import KernelRidge\n\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n\n    Parameters:\n    alpha (float): Regularization strength parameter.\n    kernel (str): Kernel function to use ('linear', 'polynomial', 'rbf', 'sigmoid').\n    degree (int): Degree of the polynomial kernel function.\n    gamma (float): Kernel coefficient for 'rbf', 'poly', and 'sigmoid'.\n    coef0 (float): Independent term in 'poly' and 'sigmoid'.\n    \"\"\"\n\n    def __init__(self, alpha=1.0, kernel='linear', degree=3, gamma=None, coef0=1.0):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model to the training data.\n\n        Parameters:\n        X (ndarray): Training input data.\n        y (ndarray): Target values.\n        \"\"\"\n        self.X_ = X\n        self.y_ = y\n        self._fit()\n\n    def _fit(self):\n        \"\"\"\n        Internal method to fit the model.\n        \"\"\"\n        # Check for valid kernel\n        if self.kernel not in ['linear', 'polynomial', 'rbf', 'sigmoid']:\n            raise ValueError(\"Invalid kernel. Choose from 'linear', 'polynomial', 'rbf', 'sigmoid'.\")\n\n        # Check for valid degree\n        if self.kernel == 'polynomial' and not isinstance(self.degree, int):\n            raise ValueError(\"'degree' must be an integer for 'polynomial' kernel.\")\n\n        # Check for valid gamma\n        if self.kernel in ['rbf', 'poly', 'sigmoid'] and (self.gamma is None or self.gamma <= 0):\n            raise ValueError(\"'gamma' must be a positive float for 'rbf', 'poly', and 'sigmoid' kernels.\")\n\n        # Check for valid coef0\n        if self.kernel in ['poly', 'sigmoid'] and (self.coef0 is None or self.coef0 <= 0):\n            raise ValueError(\"'coef0' must be a positive float for 'poly' and 'sigmoid' kernels.\")\n\n        # Check for valid input data\n        if not isinstance(self.X_, np.ndarray) or not isinstance(self.y_, np.ndarray):\n            raise ValueError(\"Input data must be numpy arrays.\")\n        if self.X_.ndim != 2:\n            raise ValueError(\"Input data X should be a 2D array.\")\n        if self.X_.shape[0] != self.y_.shape[0]:\n            raise ValueError(\"Number of samples in X and y must be the same.\")\n\n        # Check for valid alpha\n        if not isinstance(self.alpha, (int, float)) or self.alpha <= 0:\n            raise ValueError(\"'alpha' must be a positive float.\")\n\n        # Check for n_samples > n_features for 'poly' and 'sigmoid' kernels\n        if self.kernel in ['poly', 'sigmoid'] and self.X_.shape[0] <= self.X_.shape[1]:\n            raise ValueError(\"Number of samples in X must be greater than the number of features for 'poly' and 'sigmoid' kernels.\")\n\n        # Check for valid output data\n        if not isinstance(self.y_, (int, float, np.int64, np.float64)):\n            raise ValueError(\"Target values y must be numeric.\")\n\n        # Check for valid output shape\n        if self.y_.ndim != 1:\n            raise ValueError(\"Target values y should be a 1D array.\")\n        if self.X_.shape[0] != self.y_.shape[0]:\n            raise ValueError(\"Number of samples in X and y must be the same.\")\n\n        # Check for valid output labels\n        unique_labels = np.unique(self.y_)\n        if len(unique_labels) != 2:\n            raise ValueError(\"Target values y must contain only two unique values for binary classification.\")\n\n        # Fit the model\n        self.model_ = KernelRidge(alpha=self.alpha, kernel=self.kernel, degree=self.degree, gamma=self.gamma, coef0=self.coef0)\n        self.model_.fit(self.X_, self.y_)\n\n    def predict(self, X):\n        \"\"\"\n        Predict the target values for the given input data.\n\n        Parameters:\n        X (ndarray): Input data for prediction.\n\n        Returns:\n        ndarray: Predicted target values.\n        \"\"\"\n        # Check for valid input data\n        if not isinstance(X, np.ndarray):\n            raise ValueError(\"Input data must be a numpy array.\")\n        if X.ndim != 2:\n            raise ValueError(\"Input data X should be a 2D array.\")\n        if X.shape[1] != self.X_.shape[1]:\n            raise ValueError(\"Number of features in X must be the same as the training data.\")\n\n        # Make predictions\n        y_pred = self.model_.predict(X)\n        return y_pred\n```",
        "```python\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X):\n        X = np.array(X)\n        return X @ self.coef_ + self.intercept_\n```",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_numerals = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in roman[::-1]:\n        value = roman_numerals[char]\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n        prev_value = value\n\n    return int_value\n```",
        "```python\ndef is_valid_sudoku(board: list[list[int]]) -> bool:\n    # Check rows\n    for row in board:\n        if not is_unique(row):\n            return False\n\n    # Check columns\n    for col in range(9):\n        if not is_unique(get_column(board, col)):\n            return False\n\n    # Check 3x3 subgrids\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            subgrid = get_subgrid(board, i, j)\n            if not is_unique(subgrid):\n                return False\n\n    return True\n\ndef is_unique(nums: list[int]) -> bool:\n    seen = set()\n    for num in nums:\n        if num in seen:\n            return False\n        seen.add(num)\n    return True\n\ndef get_column(board: list[list[int]], col: int) -> list[int]:\n    return [board[row][col] for row in range(9)]\n\ndef get_subgrid(board: list[list[int]], row: int, col: int) -> list[int]:\n    start_row = row - row % 3\n    start_col = col - col % 3\n    return [board[r][c] for r in range(start_row, start_row + 3) for c in range(start_col, start_col + 3)]\n```",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components: int\n            The number of components to keep.\n        explained_variance_: float\n            The percentage of variance explained by the kept components.\n        components_: 2D array\n            The components with maximum variance.\n        mean_: 1D array\n            The mean value of the provided data.\n\n    ...\n\n    \"\"\"\n\n    def __init__(self, n_components=None):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components: int, optional (default=None)\n                The number of components to keep. If None, keep all components.\n\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ = None\n        self.components_ = None\n        self.mean_ = None\n\n    def fit(self, X):\n        \"\"\"\n        Fit the PCA model to the provided data.\n\n        Args:\n            X: 2D array\n                The data to fit the model to.\n\n        Returns:\n            None\n\n        \"\"\"\n        # Calculate the mean of the data\n        self.mean_ = X.mean(axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Calculate the covariance matrix\n        covariance = np.cov(X_centered.T)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Keep only the top n_components eigenvalues and eigenvectors\n        if self.n_components is not None:\n            eigenvalues = eigenvalues[:self.n_components]\n            eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Calculate the percentage of variance explained by the kept components\n        self.explained_variance_ = np.sum(eigenvalues) / np.sum(eigenvalues)\n\n        # The components are the eigenvectors\n        self.components_ = eigenvectors\n\n    def transform(self, X):\n        \"\"\"\n        Transform the provided data using the fitted PCA model.\n\n        Args:\n            X: 2D array\n                The data to transform.\n\n        Returns:\n            2D array\n                The transformed data.\n\n        \"\"\"\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Project the data onto the principal components\n        transformed = X_centered @ self.components_\n\n        return transformed\n\n    def fit_transform(self, X):\n        \"\"\"\n        Fit the PCA model to the provided data and transform it.\n\n        Args:\n            X: 2D array\n                The data to fit the model to and transform.\n\n        Returns:\n            2D array\n                The transformed data.\n\n        \"\"\"\n        # Fit the model to the data\n        self.fit(X)\n\n        # Transform the data\n        transformed = self.transform(X)\n\n        return transformed",
        "class Perceptron:\n    def __init__(self, weights, bias):\n        self.weights = weights\n        self.bias = bias\n\n    def train(self, inputs, outputs):\n        # Training code goes here\n        pass\n\n    def predict(self, inputs):\n        # Prediction code goes here\n        pass",
        "def dot_product(vector1: list[int], vector2: list[int]) -> int:\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    Args:\n        vector1 (list[int]): A list of integers representing the first vector.\n        vector2 (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input\n    if not vector1 or not vector2:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector1) != len(vector2):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector1)):\n        dot_product += vector1[i] * vector2[i]\n\n    return dot_product",
        "```python\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def has_cycle(self, source):\n        visited = set()\n        rec_stack = []\n        self._has_cycle_dfs(source, visited, rec_stack)\n        return len(rec_stack) > 0\n\n    def _has_cycle_dfs(self, vertex, visited, rec_stack):\n        visited.add(vertex)\n        rec_stack.append(vertex)\n        for neighbour in self.graph.get(vertex, []):\n            if neighbour not in visited:\n                self._has_cycle_dfs(neighbour, visited, rec_stack)\n            elif neighbour in rec_stack:\n                return True\n        rec_stack.pop()\n        return False\n```",
        "```python\ndef sum_array_except_self(arr: list[int]) -> int:\n    \"\"\"\n    Calculates the sum of all elements in the array except the element at the index of the current element.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of all elements in the array except the element at the current index.\n    \"\"\"\n    # Calculate the sum of all elements in the array\n    total_sum = sum(arr)\n    # Get the index of the current element\n    current_index = arr.index(arr)\n    # Calculate the sum of all elements except the current element\n    return total_sum - arr[current_index]\n```",
        "def dot_product(vector_1: list[int], vector_2: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_1 (list[int]): A list of integers representing the first vector.\n        vector_2 (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input\n    if not vector_1 or not vector_2:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector_1) != len(vector_2):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = sum(x * y for x, y in zip(vector_1, vector_2))\n\n    return dot_product",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryClassifier, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(784, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.layers(x.view(x.size(0), -1))",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        parent_index = (current_index - 1) // 2\n\n        while current_index > 0:\n            if self.heap[current_index] > self.heap[parent_index]:\n                self.heap[current_index], self.heap[parent_index] = self.heap[parent_index], self.heap[current_index]\n                current_index = parent_index\n                parent_index = (current_index - 1) // 2\n            else:\n                break",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def append(self, value):\n        if not self.head:\n            self.head = Node(value)\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = Node(value)\n\n    def get_values(self):\n        current = self.head\n        values = []\n        while current:\n            values.append(current.value)\n            current = current.next\n        return values",
        "def average_diagonal(matrix):\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "```python\ndef h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i+1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "def edit_distance(str1: str, str2: str) -> int:\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books):\n        self.books.extend(books)\n\n    def remove_books(self, books):\n        for book in books:\n            self.books.remove(book)",
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def shortest_path(self, start, end, parent):\n        visited = set()\n        queue = deque()\n        queue.append(start)\n        visited.add(start)\n\n        while queue:\n            node = queue.popleft()\n\n            for neighbour in self.graph[node]:\n                if neighbour not in visited:\n                    queue.append(neighbour)\n                    visited.add(neighbour)\n                    parent[neighbour] = node\n\n        path = []\n        node = end\n        while node is not None:\n            path.insert(0, node)\n            node = parent[node]\n\n        return path[:-1]\n```",
        "```python\nimport numpy as np\n\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multiclass classification.\n    \n    Attributes:\n        classes: list of possible classes\n        means: numpy array of class means\n        covariances: numpy array of class covariances\n        priors: numpy array of class priors\n    \n    Methods:\n        fit(X, y): Fits the model to the data X and class labels y.\n        predict(X): Predicts the class labels for the input data X.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"\n        Initializes the QDA model.\n        \"\"\"\n        self.classes = []\n        self.means = None\n        self.covariances = None\n        self.priors = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fits the QDA model to the data X and class labels y.\n        \n        Args:\n            X: numpy array of shape (n_samples, n_features) containing the training data.\n            y: numpy array of shape (n_samples,) containing the class labels.\n        \"\"\"\n        # Store the classes\n        self.classes = np.unique(y)\n        \n        # Calculate the means of each class\n        self.means = np.array([np.mean(X[y == class_, :], axis=0) for class_ in self.classes])\n        \n        # Calculate the covariance matrix for each class\n        self.covariances = np.array([np.cov(X[y == class_, :].T, bias=True) for class_ in self.classes])\n        \n        # Calculate the priors for each class\n        self.priors = np.array([np.mean(y == class_) for class_ in self.classes])\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predicts the class labels for the input data X.\n        \n        Args:\n            X: numpy array of shape (n_samples, n_features) containing the data to predict.\n        \n        Returns:\n            numpy array of shape (n_samples,) containing the predicted class labels.\n        \"\"\"\n        # Calculate the posterior probabilities for each class\n        posteriors = self._calculate_posterior(X)\n        \n        # Predict the class with the highest posterior probability\n        return np.argmax(posteriors, axis=1)\n    \n    def _calculate_posterior(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculates the posterior probabilities for each class.\n        \n        Args:\n            X: numpy array of shape (n_samples, n_features) containing the data.\n        \n        Returns:\n            numpy array of shape (n_samples, n_classes) containing the posterior probabilities.\n        \"\"\"\n        # Calculate the number of classes\n        n_classes = len(self.classes)\n        \n        # Calculate the prior probabilities\n        priors = np.tile(self.priors, (X.shape[0], 1))\n        \n        # Calculate the determinant of the covariance matrix for each class\n        cov_dets = np.array([np.linalg.det(cov) for cov in self.covariances])\n        \n        # Calculate the inverse of the covariance matrix for each class\n        cov_invs = np.array([np.linalg.inv(cov) for cov in self.covariances])\n        \n        # Calculate the number of features\n        n_features = X.shape[1]\n        \n        # Calculate the log of the denominator of the posterior\n        log_denom = (\n            np.log(cov_dets) + 2 * np.log(2 * np.pi) + n_features * np.log(2)\n        ).reshape(-1, 1)\n        \n        # Calculate the posterior probabilities\n        posteriors = (\n            priors - 0.5 * (\n                np.sum(np.square(X - self.means[:, np.newaxis, :]), axis=2) * cov_invs\n                + np.log(cov_dets) - n_features * np.log(2 * np.pi)\n            ) - log_denom\n        )\n        \n        # Return the posterior probabilities\n        return posteriors\n```",
        "```python\ndef largest_subarray_sum(arr):\n    max_sum = curr_sum = arr[0]\n    for num in arr[1:]:\n        curr_sum = max(curr_sum + num, num)\n        max_sum = max(max_sum, curr_sum)\n    return max_sum\n```",
        "```python\ndef insertion_sort(arr):\n    \"\"\"\n    Implements insertion sort algorithm to sort an array of integers in ascending order.\n\n    Args:\n        arr (list): List of integers to be sorted.\n\n    Returns:\n        None\n    \"\"\"\n    # Base case: if the array has less than 2 elements, it is already sorted\n    if len(arr) < 2:\n        return\n\n    # Iterate through the array starting from the second element\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n\n        # Shift elements greater than the key to one position ahead\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n\n        # Insert the key in its correct position\n        arr[j + 1] = key\n```",
        "def sum_unique_numbers(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from a list of numbers and computes their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n        unique_numbers.append(number)\n    return sum(unique_numbers)",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.order.remove(key)\n            self.order.insert(0, key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.order.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.order.pop()\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.order.insert(0, key)",
        "Here is the code that follows the coding guidelines provided by your mentor, Jean-Aim\u00e9:\n```python\ndef common_elements(list1: list[int], list2: list[int]) -> list[int]:\n    common = []\n    for element in list1:\n        if element in list2:\n            common.append(element)\n    return common\n```",
        "def mean(numbers):\n    total = 0\n    count = 0\n    for number in numbers:\n        total += number\n        count += 1\n    return total / count",
        "class Solution:\n    def max_subarray_sum(nums):\n        max_sum = nums[0]\n        current_sum = nums[0]\n\n        for num in nums[1:]:\n            current_sum += num\n            if current_sum > max_sum:\n                max_sum = current_sum\n\n            if current_sum < 0:\n                current_sum = 0\n\n        return max_sum"
      ]
    }
  ]
}