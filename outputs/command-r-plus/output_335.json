{
  "sessions": [
    {
      "session_model_output": [
        "def average_diagonal_elements(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a list of lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Input matrix must be square\"\n    \n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations_a: list[int]) -> int:\n    citations_a.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations_a, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def b_merge_sorted_lists(list1_a, list2_a):\n    result = []\n    i, j = 0, 0\n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            result.append(list1_a[i])\n            i += 1\n        else:\n            result.append(list2_a[j])\n            j += 1\n    result.extend(list1_a[i:])\n    result.extend(list2_a[j:])\n    return result"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def d_train(self, X, y):\n        try:\n            # Add bias term to X\n            X_bias = X.copy()\n            X_bias.insert(0, 0)\n            self.coef_ = np.linalg.inv(X_bias.T @ X_bias) @ X_bias.T @ y\n            self.intercept_ = self.coef_[0]\n            self.coef_ = self.coef_[1:]\n        except np.linalg.LinAlgError:\n            print(\"Singular matrix error. Failed to invert the matrix.\")\n\n    def d_predict(self, X):\n        try:\n            # Add bias term to X\n            X_bias = X.copy()\n            X_bias.insert(0, 0)\n            return X_bias @ self.coef_\n        except ValueError:\n            print(\"Dimensions mismatch between X and coefficients.\")",
        "def d_h_index(citations: list[int]) -> int:\n    try:\n        citations.sort(reverse=True)\n        h_index = 0\n        for i, citation_count in enumerate(citations):\n            if citation_count >= i + 1:\n                h_index = i + 1\n            else:\n                break\n        return h_index\n    except Exception as e:\n        raise Exception(f\"An error occurred: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```",
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root, min_val = float('-inf'), max_val = float('inf')):\n    if not root:\n        return True\n    if not isinstance(root.val, int) or not all(isinstance(node.val, int) for node in (root.left, root.right)) or not all(isinstance(child, Node) for child in (root.left, root.right)):\n        return False\n    if not root.left_j or not root.right_j:\n        return root.val > min_val and root.val < max_val\n    return root.val > min_val and root.val < max_val and is_valid_bst(root.left_j, min_val, root.val) and is_valid_bst(root.right_j, root.val, max_val)",
        "def merge_sorted_lists(list1_j, list2_j):\n    try:\n        i, j = 0, 0\n        merged_list = []\n\n        while i < len(list1_j) and j < len(list2_j):\n            if list1_j[i] < list2_j[j]:\n                merged_list.append(list1_j[i])\n                i += 1\n            else:\n                merged_list.append(list2_j[j])\n                j += 1\n\n        merged_list.extend(list1_j[i:])\n        merged_list.extend(list2_j[j:])\n\n        return merged_list\n\n    except TypeError:\n        print(\"Error: Please provide two lists containing numeric values.\")\n        return None"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multiclass classification problems.\n    \"\"\"\n\n    def __init__(self, tol=1e-4, max_iter=100):\n        \"\"\"\n        Initializes the QDA model.\n\n        Parameters:\n            tol (float, optional): The convergence tolerance for the algorithm. Defaults to 1e-4.\n            max_iter (int, optional): The maximum number of iterations for the algorithm. Defaults to 100.\n        \"\"\"\n        self.tol = tol\n        self.max_iter = max_iter\n        self.classes_ = None\n        self.means_ = None\n        self.covariance_matrices_ = None\n        self.priors_ = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fits the QDA model to the training data.\n\n        Parameters:\n            X (ndarray): The input training data of shape (n_samples, n_features).\n            y (ndarray): The target labels of shape (n_samples,).\n\n        Returns:\n            self: The fitted QDA model.\n        \"\"\"\n        n_classes = len(set(y))\n        n_features = X.shape[1]\n\n        self.classes_ = list(set(y))\n        self.means_ = [X[y == class_].mean(axis=0) for class_ in self.classes_]\n        self.covariance_matrices_ = [\n            (X[y == class_].T @ X[y == class_]) / (X[y == class_].shape[0])\n            for class_ in self.classes_\n        ]\n        self.priors_ = [\n            (y == class_).mean() for class_ in self.classes_\n        ]  # Prior probabilities\n\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the class labels for the provided data.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Predicted class labels of shape (n_samples,).\n        \"\"\"\n        predicted_labels = [\n            self.classes_[self._predict_class(x)] for x in X\n        ]  # Loop through each sample and predict class\n\n        return np.array(predicted_labels)\n\n    def _predict_class(self, x):\n        \"\"\"\n        Predicts the class for a single sample using Bayes' theorem.\n\n        Parameters:\n            x (ndarray): A single sample of shape (n_features,).\n\n        Returns:\n            int: The predicted class index.\n        \"\"\"\n        posterior_probs = [\n            self.priors_[k] * self._multivariate_gaussian_pdf(x, self.means_[k], self.covariance_matrices_[k])\n            for k in range(len(self.classes_))\n        ]\n\n        return np.argmax(posterior_probs)\n\n    def _multivariate_gaussian_pdf(self, x, mean, covariance_matrix):\n        \"\"\"\n        Calculates the multivariate Gaussian probability density function.\n\n        Parameters:\n            x (ndarray): A single sample of shape (n_features,).\n            mean (ndarray): The mean vector of the Gaussian distribution.\n            covariance_matrix (ndarray): The covariance matrix of the Gaussian distribution.\n\n        Returns:\n            float: The probability density value.\n        \"\"\"\n        n = len(mean)\n        det_cov = np.linalg.det(covariance_matrix)\n        inv_cov = np.linalg.inv(covariance_matrix)\n\n        exponent = np.exp(\n            -0.5 * (x - mean).T @ inv_cov @ (x - mean)\n        )  # Exponent part of the equation\n\n        return (\n            1\n            / (2 * np.pi * np.sqrt(det_cov)) ** n\n            * exponent\n        )  # Complete PDF calculation",
        "```python\nfrom pedantic import timer_class\n\n\n@timer_class\nclass SortedListMerger:\n    def merge_sorted_lists(self, list1_e: list, list2_e: list) -> list:\n        merged_list_e = []\n        i, j = 0, 0\n\n        while i < len(list1_e) and j < len(list2_e):\n            if list1_e[i] < list2_e[j]:\n                merged_list_e.append(list1_e[i])\n                i += 1\n            else:\n                merged_list_e.append(list2_e[j])\n                j += 1\n\n        merged_list_e.extend(list1_e[i:])\n        merged_list_e.extend(list2_e[j:])\n\n        return merged_list_e\n```"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)",
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    # 4-add edge\n    def add_edge(self, u, v):\n        self.adj[u].append(v)\n\n    # 7-check cycle\n    def is_cyclic_util(self, v, visited, recStack):\n        visited[v] = True\n        recStack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, recStack):\n                    return True\n            elif recStack[neighbour]:\n                return True\n\n        recStack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * self.V\n        recStack = [False] * self.V\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, recStack):\n                    return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Find the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for str in strs[1:]:\n            if i == len(str) or str[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nclass Node:\n    def __init__(self, value: int) -> None:\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    \"\"\"\n    def __init__(self) -> None:\n        self.root = None\n\n    def insert(self, value: int) -> None:\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value (int): The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value: int, node: Node) -> None:\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        Args:\n            value (int): The value to be inserted.\n            node (Node): The current node in the recursive traversal.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value value, node.right)\n\n    def delete(self, value: int) -> None:\n        \"\"\"\n        Delete a node with the given value from the binary tree.\n\n        Args:\n            value (int): The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value: int, node: Node) -> Node:\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        Args:\n            value (int): The value of the node to be deleted.\n            node (Node): The current node in the recursive traversal.\n\n        Returns:\n            Node: The modified node after deletion.\n        \"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.value, node.right)\n\n        return node\n\n    def _get_inorder_successor(self, node: Node) -> int:\n        \"\"\"\n        Get the inorder successor (smallest value in the right subtree) of a given node.\n\n        Args:\n            node (Node): The current node in the right subtree.\n\n        Returns:\n            int: The value of the inorder successor.\n        \"\"\"\n        successor = node.value\n        while node.left is not None:\n            successor = node.left.value\n            node = node.left\n        return successor\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def gn_merge_sorted_lists(list1_f, list2_f):\n    result_f = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            result_f.append(list1_f[i])\n            i += 1\n        else:\n            result_f.append(list2_f[j])\n            j += 1\n    result_f.extend(list1_f[i:])\n    result_f.extend(list2_f[j:])\n    return result_f",
        "def gn_h_index_calculator(citations_f):\n    citations_f.sort(reverse=True)\n    h_index_f = 0\n\n    for i, citation_f in enumerate(citations_f):\n        if citation_f >= i + 1:\n            h_index_f = i + 1\n        else:\n            break\n\n    return h_index_f"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list",
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1_chx, vec2_chx):\n    result_chx = 0\n    for i in range(len(vec1_chx)):\n        result_chx += vec1_chx[i] * vec2_chx[i]\n    return result_chx\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef fn_int_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\")\n    ]\n    result = \"\"\n    for value, symbol in roman_numerals:\n        count = num // value\n        result += symbol * count\n        num %= value\n    return result\n```",
        "```python\ndef fn_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    :param citations: A list of integer citations.\n    :return: The h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace\n\n@trace\ndef find_max_subarray_sum(arr_x: list[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum in the input array.\n\n    Args:\n        arr_x (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of the subarray with the largest sum.\n    \"\"\"\n    max_sum_x = curr_sum_x = arr_x[0]\n    for num_x in arr_x[1:]:\n        curr_sum_x = max(num_x, curr_sum_x + num_x)\n        max_sum_x = max(max_sum_x, curr_sum_x)\n    return max_sum_x\n```",
        "```python\nfrom pedantic import trace\n\n@trace\ndef merge_sorted_lists(list1_x: list[int], list2_x: list[int]) -> list[int]:\n    result_x = []\n    i, j = 0, 0\n\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            result_x.append(list1_x[i])\n            i += 1\n        else:\n            result_x.append(list2_x[j])\n            j += 1\n\n    result_x.extend(list1_x[i:])\n    result_x.extend(list2_x[j:])\n\n    return result_x\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max",
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class image_classifier(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(image_classifier, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = torch.relu(x)\n        x = self.fc2(x)\n        return x\n\n@rename_kwargs\ndef classify_image(model: image_classifier, image: torch.Tensor) -> int:\n    model.eval()\n    output = model(image.view(-1, 28 * 28))\n    prediction = torch.argmax(output, dim=1)\n    return prediction.item()",
        "class Solution:\n    @rename_kwargs\n    def max_subarray(self, num_list: list[int]) -> int:\n        \"\"\"\n        Solve the maximum subarray sum problem using Kadane's algorithm.\n\n        Args:\n            num_list (list[int]): A list of integers\n\n        Returns:\n            int: The maximum sum of a contiguous subarray in num_list\n        \"\"\"\n        max_sum = current_sum = num_list[0]\n        for num in num_list[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom typing import Dict\n\n\nclass StudentGrade:\n    @require_kwargs('grades')\n    def __init__(self, grades: Dict[str, float]):\n        self.grades = grades\n\n    @require_kwargs('subject', 'score')\n    def add_grade(self, subject: str, score: float):\n        self.grades[subject] = score\n\n    @require_kwargs('subjects')\n    def compute_average(self, subjects: list[str]) -> float:\n        total_score = sum(self.grades[subject] for subject in subjects)\n        return total_score / len(subjects) if subjects else 0.0"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n\n    Parameters\n    ----------\n    n_neighbors : int, default=5\n        Number of neighbors to use for prediction.\n\n    metric : str, default='euclidean'\n        Distance metric to use. Supported metrics: ['euclidean', 'manhattan', 'cosine'].\n\n    Attributes\n    ----------\n    X_train_ : ndarray\n        Training data.\n\n    y_train_ : ndarray\n        Target labels for the training data.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5, metric='euclidean'):\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Nearest Neighbors model.\n\n        Parameters\n        ----------\n        X_train : ndarray\n            Training data.\n\n        y_train : ndarray\n            Target labels for the training data.\n        \"\"\"\n        self.X_train_ = X_train\n        self.y_train_ = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the labels for the test data.\n\n        Parameters\n        ----------\n        X_test : ndarray\n            Test data to predict labels for.\n\n        Returns\n        -------\n        y_pred : ndarray\n            Predicted labels for the test data.\n        \"\"\"\n        assert self.X_train_ is not None and self.y_train_ is not None, \"Model has not been trained yet. Please call the train method before predicting.\"\n        assert isinstance(X_test, np.ndarray), \"Test data must be a numpy array.\"\n        assert X_test.shape[1] == self.X_train_.shape[1], \"Test data must have the same number of features as the training data.\"\n\n        distances = cdist(X_test, self.X_train_, metric=self.metric)\n        nearest_neighbors = distances.argsort(axis=1)[:, :self.n_neighbors]\n        neighbors_labels = self.y_train_[nearest_neighbors]\n        y_pred = stats.mode(neighbors_labels, axis=1).mode.ravel()\n\n        return y_pred"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel Ridge Regression class.\n    \"\"\"\n\n    def __init__(self, alpha: float = 1.0, kernel: str = \"linear\", gamma: float = None):\n        \"\"\"\n        Initializes the Kernel Ridge Regression model.\n\n        Parameters:\n            alpha (float): Regularization strength.\n            kernel (str): Kernel to be used.\n            gamma (float or None): Kernel coefficient.\n                                None for \"precomputed\" kernel.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma)\n\n    def fit(self, X: array, y: array) -> None:\n        \"\"\"\n        Fits the model to the training data.\n\n        Parameters:\n            X (array): Training input data.\n            y (array): Training target values.\n        \"\"\"\n        self.model.fit(X, y)\n\n    def predict(self, X: array) -> array:\n        \"\"\"\n        Predicts target values for the provided data.\n\n        Parameters:\n            X (array): Input data.\n\n        Returns:\n            array: Predicted target values.\n        \"\"\"\n        return self.model.predict(X)",
        "```python\nfrom pedantic import trace_class\n\n\n@trace_class\nclass KthLargest:\n    def __init__(self, k: int, nums: list[int]):\n        self.k = k\n        self.heap = [-num for num in nums]\n        self.heapq.heapify(self.heap)\n        self.heapq.heapify(self.heap)\n\n    def add(self, val: int) -> None:\n        if len(self.heap) < self.k:\n            self.heapq.heappush(self.heap, -val)\n        else:\n            if val > -self.heap[0]:\n                self.heapq.heappushpop(self.heap, -val)\n\n    def value(self) -> int:\n        return -self.heap[0]\n\n\ndef findKthLargest(nums: list[int], k: int) -> int:\n    finder = KthLargest(k, nums)\n    return finder.value()\n```"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    result_h = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            result_h.append(list1_h[i])\n            i += 1\n        else:\n            result_h.append(list2_h[j])\n            j += 1\n    result_h.extend(list1_h[i:])\n    result_h.extend(list2_h[j:])\n    return result_h",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = dict()\n        self.hq = deque()\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        else:\n            self.hq.remove(key)\n            self.hq.append(key)\n            return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.hq.remove(key)\n        elif len(self.hq) >= self.capacity:\n            oldest_key = self.hq.popleft()\n            del self.cache[oldest_key]\n        self.hq.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    merged_list_g = []\n    i, j = 0, 0\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list_g.append(list1_g[i])\n            i += 1\n        else:\n            merged_list_g.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list_g.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list_g.append(list2_g[j])\n        j += 1\n    \n    return merged_list_g"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef c_h_index_computation(citations_array_i):\n    citations_array_i.sort(reverse=True)\n    h_index_i = 0\n    for i, citation_count in enumerate(citations_array_i):\n        if citation_count >= i + 1:\n            h_index_i = i + 1\n        else:\n            break\n    return h_index_i\n```",
        "def c_merge_sorted_lists(list1_i, list2_i):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    \n    merged_list.extend(list1_i[i:])\n    merged_list.extend(list2_i[j:])\n    \n    return merged_list"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import mailbox\n\ndef y_delete_node(root, key):\n    if root is None:\n        return root\n\n    # Recursive call on left child\n    if key < root.key:\n        root.left = y_delete_node(root.left, key)\n\n    # Recursive call on right child\n    elif key > root.key:\n        root.right = y_delete_node(root.right, key)\n\n    # If key to be deleted is present at root\n    else:\n\n        # Node with only one child or no child\n        if root.left is None:\n            return root.right\n\n        elif root.right is None:\n            return root.left\n\n        # Node with two children\n        root.key = y_find_min_value(root.right)\n        root.right = y_delete_node(root.right, root.key)\n\n    return root\n\ndef y_find_min_value(node):\n    current = node\n    while current.left is not None:\n        current = current.left\n    return current.key",
        "import mailbox\n\ndef y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node",
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache.pop(key)\n        self.cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.pop(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_a(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            if node == end:\n                return path\n            for neighbour in graph[node]:\n                new_path = path + [neighbour]\n                queue.append((neighbour, new_path))\n\n    def find_shortest_path_a(self, start, end, graph):\n        return self.shortest_path_a(start, end, graph)\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [i_*[] for i_ in range(vertices)]\n\n    def add_edge_o(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_o(self, src):\n        dist = [i_*float('inf') for i_ in range(self.V)]\n        dist[src] = 0\n        spt_set = set()\n\n        for _ in range(self.V):\n            u = self.min_distance_o(dist, spt_set)\n            spt_set.add(u)\n            for v in self.graph[u]:\n                if v not in spt_set:\n                    if dist[u] != i_*float('inf'):\n                        dist[v] = dist[u] + 1\n\n        return dist\n\n    def min_distance_o(self, dist, spt_set):\n        min = i_*float('inf')\n        for u in range(self.V):\n            if u not in spt_set and dist[u] <= min:\n                min = dist[u]\n                min_index = u\n        return min_index",
        "class LRUCache_o:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_head = None\n        self.i_tail = None\n\n    def get_o(self, key):\n        if key not in self.cache:\n            return -1\n        self._move_to_i_head(key)\n        return self.cache[key]\n\n    def put_o(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_i_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            self._evict_i_tail()\n        self.cache[key] = value\n        self._add_to_i_head(key)\n\n    def _move_to_i_head(self, key):\n        node = self.cache[key]\n        self._remove_node(node)\n        self._add_to_i_head(key)\n\n    def _add_to_i_head(self, key):\n        node = Node(key)\n        node.i_next = self.i_head\n        self.i_head = node\n        if not self.i_tail:\n            self.i_tail = node\n\n    def _evict_i_tail(self):\n        i_tail = self.i_tail\n        self.i_tail = self.i_tail.i_next\n        del self.cache[i_tail.key]\n\n    def _remove_node(self, node):\n        if node.i_prev:\n            node.i_prev.i_next = node.i_next\n        else:\n            self.i_head = node.i_next\n        if node.i_next:\n            node.i_next.i_prev = node.i_prev\n        else:\n            self.i_tail = node.i_prev\n\n    class Node:\n        def __init__(self, key):\n            self.key = key\n            self.i_next = None\n            self.i_prev = None"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero7(matrix):\n    non_zero_count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                non_zero_count += 1\n    return non_zero_count"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def a_compute_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.a_queue = []\n\n    def a_get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.a_move_to_front(key)\n        return self.cache[key]\n\n    def a_put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.a_move_to_front(key)\n        elif len(self.cache) >= self.capacity:\n            self.a_evict()\n        self.cache[key] = value\n        self.a_queue.append(key)\n\n    def a_move_to_front(self, key: int) -> None:\n        self.a_queue.remove(key)\n        self.a_queue.append(key)\n\n    def a_evict(self) -> None:\n        evicted_key = self.a_queue.pop(0)\n        del self.cache[evicted_key]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class BINARYIMAGE_CLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYIMAGE_CLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    A_FORWARD(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "CLASS INVENTORY:\n    def __init__(self):\n        self.stock = []\n\n    def ADD_STOCK(self, item):\n        self.stock.append(item)\n\n    def REMOVE_STOCK(self, item):\n        self.stock.remove(item)"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(f_vec1, f_vec2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param f_vec1: The first vector.\n    :param f_vec2: The second vector.\n    :return: The dot product of f_vec1 and f_vec2.\n    \"\"\"\n    return sum(x * y for x, y in zip(f_vec1, f_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements(list1_7, list2_3):\n    common_elements_4 = [value for value in list1_7 if value in list2_3]\n    return common_elements_4"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import locale\n\ndef b_lcm(a: int, b: int) -> int:\n    def gcd(a: int, b: int) -> int:\n        while b:\n            a, b = b, a % b\n        return a\n\n    lcm = a * b // gcd(a, b)\n    return lcm",
        "from locale import *\n\nclass b_Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def b_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def b_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove that quantity.\")"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class 9PCA:\n    def __init__(self, xt_data, xt_n_components=None, xt_svd_solver='auto', xt_whiten=False):\n        self.xt_data = xt_data\n        self.xt_n_components = xt_n_components\n        self.xt_svd_solver = xt_svd_solver\n        self.xt_whiten = xt_whiten\n\n    def fit(self):\n        # your code here\n        pass\n\n    def transform(self, xt_data):\n        # your code here\n        pass\n\n    def fit_transform(self, xt_data):\n        # your code here\n        pass",
        "class Cache0:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.xt_order.remove(key)\n        self.xt_order.insert(0, key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_order:\n            self.xt_order.remove(key)\n        elif len(self.xt_order) >= self.capacity:\n            del_key = self.xt_order.pop()\n            del self.cache[del_key]\n        self.xt_order.insert(0, key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_b(self, j_start, j_end):\n        # Your implementation here\n        pass\n        # End your method names with '_b' and argument names with 'j_' as per your mentor's instructions.",
        "def dot_product_b(j_vec1, j_vec2):\n    result_b = 0\n    for i in range(len(j_vec1)):\n        result_b += j_vec1[i] * j_vec2[i]\n    return result_b"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path",
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(ImageClassifier, self).__init__()\n        self.features = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n\n            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n\n            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n\n            torch.nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n\n            torch.nn.Conv2d(512, num_features, kernel_size=3, stride=1, padding=1),\n        )\n\n        self.classifier = torch.nn.Sequential(\n            torch.nn.Linear(num_features, 512),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Dropout(0.5),\n            torch.nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x",
        "```python\nclass VectorCalculator:\n    \"\"\"\n    A calculator for vector operations.\n    \"\"\"\n\n    def dot_product(self, vec_a: list[float], vec_b: list[float]) -> float:\n        \"\"\"\n        Compute the dot product of two vectors.\n\n        :param vec_a: The first vector.\n        :param vec_b: The second vector.\n        :return: The dot product of vec_a and vec_b.\n        \"\"\"\n        e_result = sum(x * y for x, y in zip(vec_a, vec_b))\n        return e_result\n```"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x",
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\n@count_calls\ndef majority_element(arr):\n    element_counts = {}\n    for element in arr:\n        if element in element_counts:\n            element_counts[element] += 1\n        else:\n            element_counts[element] = 1\n        if element_counts[element] > len(arr) // 2:\n            return element\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_w(s: str) -> bool:\n    \"\"\"Checks if a string is a valid palindrome.\n    \n    Args:\n        s (str): The input string.\n        \n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove spaces and convert to lowercase\n    s = s.replace(\" \", \"\").lower()\n    \n    # Compare the original string with its reverse\n    return s == s[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_w):\n    s_w = s_w.lower()\n    return s_w == s_w[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph_p = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v):\n        self.graph_p[u].append(v)\n        self.graph_p[v].append(u)\n\n    def shortest_path_p(self, src, dest):\n        dist_y = [float('inf')] * self.V\n        dist_y[src] = 0\n        spt_set_y = [False] * self.V\n\n        pq_y = []\n        import heapq\n        heapq.heappush(pq_y, (0, src))\n\n        while pq_y:\n            d_y, u_y = heapq.heappop(pq_y)\n            spt_set_y[u_y] = True\n\n            for v_y in self.graph_p[u_y]:\n                if not spt_set_y[v_y]:\n                    dist_y[v_y] = d_y + 1\n                    heapq.heappush(pq_y, (dist_y[v_y], v_y))\n\n        if not spt_set_y[dest]:\n            return -1\n        return dist_y[dest]",
        "def is_palindrome_p(str_input_p: str) -> bool:\n    str_input_processed_p = str_input_p.lower().replace(\" \", \"\")\n    str_length_p = len(str_input_processed_p)\n    mid_point_p = str_length_p // 2\n\n    for i in range(mid_point_p):\n        if str_input_processed_p[i] != str_input_processed_p[-i - 1]:\n            return False\n\n    return True"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class BinaryTree:\n    class Node:\n        def __init__(self, value):\n            self.value = value\n            self.left = None\n            self.right = None\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = self.Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = self.Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = self.Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: get the inorder successor (smallest in the right subtree)\n            successor = self._get_successor(node.right)\n            node.value = successor.value\n            node.right = self._delete_recursive(node.right, successor.value)\n\n        return node\n\n    def _get_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.q_cache = {}\n        self.q_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self._move_to_end(key)\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.q_cache:\n            self._move_to_end(key)\n        elif len(self.q_cache) >= self.capacity:\n            self._evict()\n        self.q_cache[key] = value\n        self.q_order.append(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.q_order.remove(key)\n        self.q_order.append(key)\n\n    def _evict(self) -> None:\n        evict_key = self.q_order.pop(0)\n        del self.q_cache[evict_key]"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import secrets\n\ndef edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculates the edit distance between two strings.\n    \n    :param str1: The first string.\n    :param str2: The second string.\n    :return: The edit distance between the two strings.\n    \"\"\"\n    # Import the 'secrets' module as per Pedro's instruction\n    # ...\n    \n    length1 = len(str1)\n    length2 = len(str2)\n    \n    # Create a 2D matrix to store the distances\n    distances = [[0] * (length2 + 1) for _ in range(length1 + 1)]\n    \n    for i in range(length1 + 1):\n        distances[i][0] = i\n    \n    for j in range(length2 + 1):\n        distances[0][j] = j\n    \n    for i in range(1, length1 + 1):\n        for j in range(1, length2 + 1):\n            cost = 0 if str1[i-1] == str2[j-1] else 1\n            distances[i][j] = min(distances[i-1][j] + 1, distances[i][j-1] + 1, distances[i-1][j-1] + cost)\n    \n    # Return the edit distance\n    return distances[length1][length2]\n\n\n# Example usage (not provided in the prompt)\n# result = edit_distance(\"kitten\", \"sitting\")\n# print(result)",
        "import secrets\n\ndef mean_online_algorithm(data_stream):\n    s = 0\n    count = 0\n    for x in data_stream:\n        s += x\n        count += 1\n    mean = s / count\n    return mean, count\n\ndef mean(data_list):\n    return mean_online_algorithm(data_list)[0]"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]",
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def chx_flatten_binary_tree_to_linked_list(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    root.right = chx_flatten_binary_tree_to_linked_list(root.right)\n    root.left = chx_flatten_binary_tree_to_linked_list(root.left)\n    temp = root.right\n    while temp and temp.left:\n        temp = temp.left\n    temp.left = root.left\n    root.left = None\n    return root.right"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_b():\n    pass"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta=0.01, epochs=1000):\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.chx_bias = None\n\n    def train(self, X, y):\n        self.weights = np.zeros(len(X[0]))\n        self.chx_bias = 0\n        for _ in range(self.epochs):\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.weights += update * xi\n                self.chx_bias += update\n\n    def predict(self, X):\n        return np.where(np.dot(X, self.weights) + self.chx_bias > 0, 1, 0)"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Node_xt:\n    def __init__(self, data_xt=None):\n        self.data_xt = data_xt\n        self.next_xt = None\n\nclass LinkedList_xt:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data_xt):\n        if not self.head_xt:\n            self.head_xt = Node_xt(data_xt)\n        else:\n            current_xt = self.head_xt\n            while current_xt.next_xt:\n                current_xt = current_xt.next_xt\n            current_xt.next_xt = Node_xt(data_xt)\n\n    def display(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.data_xt, end=\" -> \")\n            current_xt = current_xt.next_xt\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_x(self, start, end, matrix):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            for next_node in range(len(matrix[node])):\n                if matrix[node][next_node] and next_node not in path:\n                    new_path = path + [next_node]\n                    if next_node == end:\n                        return new_path\n                    queue.append((next_node, new_path))"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer\n\n@timer\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n    slow, fast = head, head.next\n    while slow != fast:\n        if fast is None or fast.next is None:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    return True"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef is_palindrome(input_string_n: str) -> bool:\n    reversed_string_n = input_string_n[::-1]\n    return input_string_n.lower() == reversed_string_n.lower()",
        "from pedantic import validate\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n    \"\"\"\n    val_map = [\n        (1000, 'M'), (900, 'CM'), (500, 'D'), (400, 'CD'), (100, 'C'),\n        (90, 'XC'), (50, 'L'), (40, 'XL'), (10, 'X'), (9, 'IX'),\n        (5, 'V'), (4, 'IV'), (1, 'I')\n    ]\n    roman = ''\n    for value, symbol in val_map:\n        count = num // value\n        roman += symbol * count\n        num %= value\n    return roman\n\n# Example usage (not provided as per the instructions):\n# print(int_to_roman(3999))"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]",
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom typing import List\n\n@require_kwargs\ndef product_except_self(nums: List[int]) -> List[int]:\n    n = len(nums)\n    left, right, answer = [0] * n, [0] * n, [1] * n\n\n    for i in range(1, n):\n        left[i] = nums[i - 1] * left[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right[i] = nums[i + 1] * right[i + 1]\n\n    for i in range(1, n):\n        answer[i] = left[i - 1] * right[i + 1]\n\n    return answer",
        "from pedantic import require_kwargs\nfrom roman import from_roman\n\n@require_kwargs\ndef roman_to_int(roman_str: str) -> int:\n    \"\"\"Convert a Roman numeral string to an integer.\n\n    Args:\n        roman_str (str): The Roman numeral string to be converted.\n\n    Returns:\n        int: The corresponding integer value.\n    \"\"\"\n    return from_roman(roman_str)"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output",
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    z_flat_board = [z_val for z_sub in board for z_val in z_sub]\n    z_seen = {}\n\n    for z_num in z_flat_board:\n        if z_num != '.':\n            z_num_str = str(z_num)\n            if z_num_str in z_seen:\n                return False\n            else:\n                z_seen[z_num_str] = True\n\n    for z_i in range(0, 9, 3):\n        for z_j in range(0, 9, 3):\n            z_sub_square = [board[z_i + z_i_offset][z_j + z_j_offset] for z_i_offset in range(3) for z_j_offset in range(3)]\n            z_sub_flat = [z_val for z_val in z_sub_square if z_val != '.']\n            if len(z_sub_flat) != len(set(z_sub_flat)):\n                return False\n\n    for z_i in range(9):\n        z_row = [val for val in board[z_i] if val != '.']\n        if len(z_row) != len(set(z_row)):\n            return False\n\n        z_col = [board[z_i_offset][z_i] for z_i_offset in range(9) if board[z_i_offset][z_i] != '.']\n        if len(z_col) != len(set(z_col)):\n            return False\n\n    return True\n\n\nimport hashlib",
        "```python\nimport hashlib\n\n\ndef insertion_sort(arr: list[int]) -> list[int]:\n    z_sorted_arr = []\n    for z_i in range(len(arr)):\n        z_key = arr[z_i]\n        z_j = z_i - 1\n        while z_j >= 0 and z_key < z_sorted_arr[z_j]:\n            z_sorted_arr[z_j + 1] = z_sorted_arr[z_j]\n            z_j -= 1\n        z_sorted_arr[z_j + 1] = z_key\n    return z_sorted_arr\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True",
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport bz2\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_md(self, src, dest):\n        visited = [False] * self.V\n        queue = deque()\n        queue.append(src)\n        visited[src] = True\n\n        while queue:\n            u = queue.popleft()\n\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n\n        return True if visited[dest] else False\n```",
        "def sum_array_except_self_md(nums):\n    size = len(nums)\n    output = [0] * size\n    output[0] = nums[1:]\n    for i in range(1, size):\n        output[i] = output[i - 1] + nums[i + 1:]\n    return output\n\nfrom bz2 import *"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node",
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_str: str) -> bool:\n    \"\"\"Checks if a string is a valid palindrome.\n\n    Args:\n        input_str (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    input_str = input_str.lower()  # Convert to lowercase to make the check case-insensitive\n    start, end = 0, len(input_str) - 1\n    while start < end:\n        if input_str[start] != input_str[end]:\n            return False\n        start += 1\n        end -= 1\n    return True\n\npalindrome_str_z = \"racecar_z\"\nnot_palindrome_str_z = \"python_z\"\nprint(is_palindrome(palindrome_str_z))  # Expected output: True\nprint(is_palindrome(not_palindrome_str_z))  # Expected output: False"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_z):\n    s_z = s_z.lower()\n    return s_z == s_z[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\n\n@rename_kwargs\ndef dot_product(i_vector_1: list[float], i_vector_2: list[float]) -> float:\n    return sum(x * y for x, y in zip(i_vector_1, i_vector_2))\n```",
        "```python\nfrom pedantic import rename_kwargs\n\n\n@rename_kwargs\ndef greatest_common_divisor(i_num1: int, i_num2: int) -> int:\n    while i_num2:\n        i_num1, i_num2 = i_num2, i_num1 % i_num2\n    return i_num1\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```",
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_y():\n    pass\n\n\ndef merge_ud(lst: list[int], left: int, mid: int, right: int) -> list[int]:\n    pass\n\n\ndef merge_sort_helper_y(lst: list[int], left: int, right: int) -> list[int]:\n    if left < right:\n        mid = (left + right) // 2\n        merge_sort_helper_y(lst, left, mid)\n        merge_sort_helper_y(lst, mid + 1, right)\n        merge_ud(lst, left, mid, right)\n\n\ndef merge_sort_y(lst: list[int]) -> list[int]:\n    n = len(lst)\n    if n > 1:\n        merge_sort_helper_y(lst, 0, n - 1)\n    return lst",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_y(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        path = [-1] * self.V\n\n        for _ in range(self.V):\n            for u in range(self.V):\n                for v in self.graph[u]:\n                    if dist[u] != float('inf') and dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        path[v] = u\n            if dist[dest] != float('inf'):\n                break\n\n        path_str = []\n        curr = dest\n        while curr != -1:\n            path_str.insert(0, curr)\n            curr = path[curr]\n\n        return dist[dest], path_str\n```"
      ],
      "instruction_model_output": [
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_y(left)\n    right = merge_sort_y(right)\n\n    return merge_y(left, right)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def add_stock(self, product, quantity):\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def remove_stock(self, product, quantity):\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")\n\n    def o_display_stock(self):\n        return self.stock.copy()"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\n\n@retry\ndef find_majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n        if element_count[element] > len(arr) // 2:\n            return element\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def wr_is_valid_sudoku(board: list[list[int]]) -> bool:\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            if board[wr_i][wr_j] != 0:\n                wr_num = board[wr_i][wr_j]\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = True\n                wr_cols[wr_j][wr_num] = True\n                wr_boxes[wr_box_index][wr_num] = True\n\n    return True",
        "class LinearRegression:\n    def __init__(self, wr_digit=None):\n        self.wr_coeff_0 = None\n        self.wr_coeff_1 = None\n        self.wr_intercept = None\n        if wr_digit is not None:\n            self._set_attributes_digit(wr_digit)\n\n    def _set_attributes_digit(self, digit):\n        self.wr_coeff_0 = f\"wr_coeff_0{digit}\"\n        self.wr_coeff_1 = f\"wr_coeff_1{digit}\"\n        self.wr_intercept = f\"wr_intercept{digit}\"\n\n    def fit(self, X, y):\n        X_wr = X.copy()\n        X_wr[:, 0] = 1  # Add a column of ones for the intercept\n        wr_coeff = np.linalg.inv(X_wr.T @ X_wr) @ (X_wr.T @ y)\n        self.wr_intercept = wr_coeff[0]\n        self.wr_coeff_1 = wr_coeff[1]\n\n    def predict(self, X):\n        X_wr = X.copy()\n        X_wr[:, 0] = 1  # Add a column of ones for the intercept\n        return X_wr @ [self.wr_coeff_1, self.wr_intercept]"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True",
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_a_wr(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half_wr = arr[:mid]\n    right_half_wr = arr[mid:]\n\n    left_half_wr = merge_sort_a_wr(left_half_wr)\n    right_half_wr = merge_sort_a_wr(right_half_wr)\n\n    return merge_a_wr(left_half_wr, right_half_wr)\n\ndef merge_a_wr(left_wr, right_wr):\n    result_a_wr = []\n    left_index_wr, right_index_wr = 0, 0\n\n    while left_index_wr < len(left_wr) and right_index_wr < len(right_wr):\n        if left_wr[left_index_wr] < right_wr[right_index_wr]:\n            result_a_wr.append(left_wr[left_index_wr])\n            left_index_wr += 1\n        else:\n            result_a_wr.append(right_wr[right_index_wr])\n            right_index_wr += 1\n\n    result_a_wr.extend(left_wr[left_index_wr:])\n    result_a_wr.extend(right_wr[right_index_wr:])\n    return result_a_wr",
        "def is_palindrome_a(s: str) -> bool:\n    s = s.lower()\n    return s == s[::-1] and '_a' in s\n\n\ndef main():\n    # Test cases\n    input_strings = [\"racecar_a\", \"race a car_a\", \"radar_a\", \"rad ar_a\", \"notapalindrome_a\"]\n    for s in input_strings:\n        if is_palindrome_a(s):\n            print(f\"'{s}' is a palindrome.\")\n        else:\n            print(f\"'{s}' is not a palindrome.\")\n\n\nif __name__ == \"__main__\":\n    main()"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, data=None, next_node=None):\n        self.data = data\n        self.next_node_at = next_node\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_node_at:\n            self.head_node_at = new_node\n        else:\n            current_node = self.head_node_at\n            while current_node.next_node_at:\n                current_node = current_node.next_node_at\n            current_node.next_node_at = new_node\n\n    def display(self):\n        current_node = self.head_node_at\n        while current_node:\n            print(current_node.data, end=\" -> \")\n            current_node = current_node.next_node_at\n        print(\"None\")",
        "def is_palindrome_at(s: str) -> bool:\n    \"\"\"Check if a string is a palindrome.\n\n    :param s: The input string.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    s_reversed_at = s[::-1]\n    return s == s_reversed_at + '_at' + '_x'"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```",
        "def is_palindrome(s_x):\n    s_x = s_x.lower()\n    return s_x == s_x[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    @count_calls\n    def insert(self, value_i):\n        node_i = Node(value_i)\n        if self.head_i is None:\n            self.head_i = node_i\n        else:\n            current_i = self.head_i\n            while current_i.next_i:\n                current_i = current_i.next_i\n            current_i.next_i = node_i\n\n    @count_calls\n    def delete(self, value_i):\n        if self.head_i is None:\n            return\n        if self.head_i.value_i == value_i:\n            self.head_i = self.head_i.next_i\n            return\n        current_i = self.head_i\n        while current_i.next_i and current_i.next_i.value_i != value_i:\n            current_i = current_i.next_i\n        if current_i.next_i:\n            current_i.next_i = current_i.next_i.next_i\n\n    @count_calls\n    def search(self, value_i):\n        current_i = self.head_i\n        while current_i:\n            if current_i.value_i == value_i:\n                return True\n            current_i = current_i.next_i\n        return False\n\n    def get_head(self):\n        return self.head_i\n\nclass Node:\n    def __init__(self, value_i):\n        self.value_i = value_i\n        self.next_i = None\n```",
        "```python\nfrom pedantic import count_calls\n\nclass LinearRegression:\n    @count_calls\n    def __init__(self):\n        self.slope_i = 0\n        self.intercept_i = 0\n\n    @count_calls\n    def train(self, X, y):\n        self.slope_i = np.sum((X - np.mean(X)) * (y - np.mean(y))) / np.sum((X - np.mean(X)) ** 2)\n        self.intercept_i = np.mean(y) - self.slope_i * np.mean(X)\n\n    @count_calls\n    def predict(self, X):\n        return X * self.slope_i + self.intercept_i\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book(self, book):\n        self.books.append(book)\n\n    @validate\n    def remove_book(self, book):\n        self.books.remove(book)\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_d(left_half)\n    right_half = merge_sort_d(right_half)\n\n    return merge_d(left_half, right_half)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "```python\ndef is_valid_sudoku_board_d(board_d):\n    n_rows = len(board_d)\n    n_cols = len(board_d[0])\n\n    n_boxes = int(n_rows ** 0.5)\n    n_nums = n_rows ** 2\n\n    n_seen = [set() for _ in range(n_boxes * n_boxes)]\n    n_row = [set() for _ in range(n_rows)]\n    n_col = [set() for _ in range(n_cols)]\n\n    for n_i in range(n_rows):\n        for n_j in range(n_cols):\n            n_num = board_d[n_i][n_j]\n            if n_num == 0:\n                continue\n            n_box_index = n_i // n_boxes * n_boxes + n_j // n_boxes\n            n_seen_nums = n_seen[n_box_index] | n_row[n_i] | n_col[n_j]\n            if n_num in n_seen_nums:\n                return False\n            n_seen_nums.add(n_num)\n            n_seen[n_box_index].add(n_num)\n            n_row[n_i].add(n_num)\n            n_col[n_j].add(n_num)\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result",
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Linked_list_s_fn:\n    def __init__(self):\n        self.head_s = None\n\n    def insert_at_beginning_fn(self, new_data_s):\n        new_node_s = Node_s_fn(new_data_s)\n        new_node_s.next_node_s = self.head_s\n        self.head_s = new_node_s\n\n    def insert_at_end_fn(self, new_data_s):\n        new_node_s = Node_s_fn(new_data_s)\n\n        if self.head_s is None:\n            self.head_s = new_node_s\n            return\n\n        current_s = self.head_s\n        while current_s.next_node_s is not None:\n            current_s = current_s.next_node_s\n\n        current_s.next_node_s = new_node_s\n\n    def display_fn(self):\n        current_s = self.head_s\n        while current_s is not None:\n            print(current_s.data_s, end=\" -> \")\n            current_s = current_s.next_node_s\n        print(\"None\")\n\n\nclass Node_s_fn:\n    def __init__(self, data_s):\n        self.data_s = data_s\n        self.next_node_s = None",
        "def merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half_s = arr[:mid]\n    right_half_s = arr[mid:]\n    \n    left_half_s = merge_sort_fn(left_half_s)\n    right_half_s = merge_sort_fn(right_half_s)\n    \n    return merge_fn(left_half_s, right_half_s)\n\ndef merge_fn(left_half_s, right_half_s):\n    merged_s, left_idx_s, right_idx_s = [], 0, 0\n    while left_idx_s < len(left_half_s) and right_idx_s < len(right_half_s):\n        if left_half_s[left_idx_s] < right_half_s[right_idx_s]:\n            merged_s.append(left_half_s[left_idx_s])\n            left_idx_s += 1\n        else:\n            merged_s.append(right_half_s[right_idx_s])\n            right_idx_s += 1\n    \n    merged_s.extend(left_half_s[left_idx_s:])\n    merged_s.extend(right_half_s[right_idx_s:])\n    \n    return merged_s"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```",
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(h_vec1, h_vec2):\n    return sum(x * y for x, y in zip(h_vec1, h_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```"
      ],
      "cumulative_model_output": [
        "```python\ndef count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    # Add your code here.\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            current = self.root\n            while True:\n                if value < current.value:\n                    if current.left:\n                        current = current.left\n                    else:\n                        current.left = Node(value)\n                        break\n                elif value > current.value:\n                    if current.right:\n                        current = current.right\n                    else:\n                        current.right = Node(value)\n                        break\n                else:\n                    break\n\n    def delete(self, value):\n        self._delete_node(self.root, value)\n\n    def _delete_node(self, node, value):\n        if not node:\n            return\n        if value < node.value:\n            self._delete_node(node.left, value)\n        elif value > node.value:\n            self._delete_node(node.right, value)\n        else:\n            if not node.left:\n                node = node.right\n                node.parent = None\n            elif not node.right:\n                node = node.left\n                node.parent = None\n            else:\n                successor = self._get_successor(node.right)\n                node.value = successor.value\n                self._delete_node(node.right, successor.value)\n\n    def _get_successor(self, node):\n        current = node.right\n        while current.left:\n            current = current.left\n        return current\n\nclass Node:\n    def __init__(self, value, parent=None, left=None, right=None):\n        self.value = value\n        self.parent = parent\n        self.left = left\n        self.right = right",
        "def merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing all elements from both input lists.\n    \"\"\"\n    result = []\n    i, j = 0, 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            result.append(list1[i])\n            i += 1\n        else:\n            result.append(list2[j])\n            j += 1\n    result += list1[i:]\n    result += list2[j:]\n    return result",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "def is_valid_sudoku(board):\n    for row in board:\n        if len(set(row)) != len(row):\n            return False\n\n    for col in zip(*board):\n        if len(set(col)) != len(col):\n            return False\n\n    for i in range(0, len(board), 3):\n        for j in range(0, len(board), 3):\n            box = [board[i][k] for k in range(i, i + 3)] + [board[k][j] for k in range(j, j + 3)]\n            if len(set(box)) != len(box):\n                return False\n\n    return True",
        "import numpy as np\n\nclass LinearRegression:\n    def __init__(self, x, y):\n        self.coef_ = None\n        self.intercept_ = None\n        self.x_ = np.array(x)\n        self.y_ = np.array(y)\n\n    def fit(self):\n        x_transpose = self.x_.T\n        self.coef_ = np.linalg.inv(self.x_.dot(x_transpose)).dot(self.y_)\n        self.intercept_ = np.mean(self.y_ - self.x_.dot(self.coef_))\n\n    def predict(self, x_test):\n        return self.coef_.dot(np.array(x_test).T) + self.intercept_",
        "def common_elements(list1: list [int], list2: list [int]) -> list [int]:\n    common = []\n    for element in list1:\n        if element in list2:\n            common.append(element)\n    return common",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        current_node = stack.pop()\n        result.append(current_node.value)\n\n        if current_node.left:\n            stack.append(current_node.left)\n\n        if current_node.right:\n            stack.append(current_node.right)\n\n    return result\n```",
        "```python\ndef merge_sort(arr):\n    \"\"\"\n    Sort an array using the merge sort algorithm.\n\n    Args:\n        arr (list): The array to be sorted.\n\n    Returns:\n        list: The sorted array.\n    \"\"\"\n    # Add your code here.\n    # Remember to follow the latest coding guidelines provided by your mentor.\n    pass\n```",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def push(self, value):\n        new_node = Node(value)\n        if self.head is None:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def pop(self):\n        if self.head is None:\n            raise IndexError(\"List is empty\")\n        current = self.head\n        prev = None\n        while current.next:\n            prev = current\n            current = current.next\n        prev.next = None\n        return current.value",
        "```python\ndef b_find_kth_largest_element(arr, k):\n    assert isinstance(arr, list), \"Input must be a list\"\n    assert isinstance(k, int) and k > 0, \"k must be a positive integer\"\n    assert k <= len(arr), \"k is larger than the length of the array\"\n\n    arr.sort(reverse=True)\n    return arr[k-1]\n```",
        "def h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i+1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books):\n        self.books.extend(books)\n\n    def remove_books(self, books):\n        for book in books:\n            self.books.remove(book)",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    @staticmethod\n    def compute_average(grades):\n        total = sum(grades)\n        average = total / len(grades)\n        return average",
        "def dot_product(vector1: list[float], vector2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector1 (list[float]): A list of floating-point numbers representing the first vector.\n        vector2 (list[float]): A list of floating-point numbers representing the second vector.\n\n    Returns:\n        float: The dot product of the two input vectors.\n    \"\"\"\n    assert len(vector1) == len(vector2), \"Vectors must have the same length.\"\n    result = 0.0\n    for i in range(len(vector1)):\n        result += vector1[i] * vector2[i]\n    return result",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1, len_str2 = len(str1), len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            cost = 0 if str1[i - 1] == str2[j - 1] else 1\n            dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n\n    return dp[len_str1][len_str2]\n```",
        "```python\ndef lcm(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The least common multiple of the two integers.\n    \"\"\"\n    # Validate input\n    assert isinstance(num1, int) and isinstance(num2, int), \"Both inputs must be integers.\"\n\n    # Calculate the least common multiple\n    lcm = abs(num1 * num2) // math.gcd(num1, num2)\n\n    return lcm\n```",
        "def product_array_except_self(array):\n    \"\"\"\n    Calculates the product of all elements in the array except self.\n\n    Args:\n        array (list): A list of integers\n\n    Returns:\n        int: The product of all elements in the array except self\n    \"\"\"\n    assert isinstance(array, list), \"Input must be a list.\"\n    try:\n        product = 1\n        for num in array:\n            product *= num\n        return product\n    except Exception as e:\n        raise e",
        "def mean(numbers):\n    \"\"\"\n    Compute the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list): A list of numbers.\n\n    Returns:\n        float: The mean of the numbers.\n    \"\"\"\n    # Initialize variables\n    total = 0\n    count = 0\n\n    # Validate input\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list\")\n    if not all(isinstance(num, (int, float)) for num in numbers):\n        raise TypeError(\"All items in the list must be numbers\")\n\n    # Calculate the mean\n    for num in numbers:\n        total += num\n        count += 1\n\n    # Return the mean\n    return total / count",
        "class Graph:\n    def __init__(self, nodes):\n        self.nodes = nodes\n        self.edges = {}\n\n    def add_edge(self, u, v, weight=1):\n        if u not in self.edges:\n            self.edges[u] = {}\n        self.edges[u][v] = weight\n\n    def shortest_path(self, start, end, path=[]):\n        path = path + [start]\n        queue = [(start, 0)]\n        while queue:\n            (node, weight) = queue.pop(0)\n            if node == end:\n                return path\n            for next, w in self.edges[node].items():\n                if next not in path:\n                    queue.append((next, weight + w))\n                    path = path + [next]\n        return None",
        "class Solution:\n    def __init__(self, nums):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.start = 0\n\n    def max_subarray(self):\n        for i in range(len(self.nums)):\n            self.current_sum += self.nums[i]\n            if self.current_sum > self.max_sum:\n                self.max_sum = self.current_sum\n                self.start = i\n            elif self.current_sum < 0:\n                self.current_sum = 0\n                self.start = i\n        return self.max_sum",
        "class DirectedGraph:\n    def __init__(self, edges):\n        self.edges = edges\n        self.nodes = set(edges)\n\n    def has_cycle(self):\n        visited = set()\n        path = []\n\n        for node in self.nodes:\n            if node not in visited:\n                self._dfs(node, visited, path)\n\n        return len(visited) != len(self.nodes)\n\n    def _dfs(self, node, visited, path):\n        visited.add(node)\n        path.append(node)\n\n        for neighbour in self.edges[node]:\n            if neighbour in path:\n                return True\n            elif neighbour not in visited:\n                self._dfs(neighbour, visited, path)\n\n        path.pop()\n        return False",
        "from sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    def __init__(self):\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to its Roman numeral representation.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Validate the input\n    assert isinstance(num, int), \"Input must be an integer.\"\n    assert num >= 0, \"Input must be a non-negative integer.\"\n\n    # Roman numeral values\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n\n    # Convert the integer to Roman numerals\n    for i in range(len(values)):\n        while num >= values[i]:\n            roman_num += symbols[i]\n            num -= values[i]\n\n    return roman_num\n```",
        "from sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n\n    Parameters:\n    alpha (float): Regularization strength parameter. Must be a positive float.\n        Defaults to 1.0.\n    kernel (string): Kernel to be used. Defaults to \"linear\".\n    gamma (float): Kernel coefficient. Defaults to None.\n    degree (int): Degree of the polynomial kernel function. Ignored by other kernels. Defaults to 3.\n    coef0 (float): Independent term in kernel function. Defaults to 0.\n\n    Attributes:\n    model (KernelRidge): The underlying scikit-learn KernelRidge model.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 1.0,\n        kernel: str = \"linear\",\n        gamma: float = None,\n        degree: int = 3,\n        coef0: float = 0.0,\n    ):\n        self.model = KernelRidge(\n            alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0\n        )\n\n    def fit(self, X: \"array-like\", y: \"array-like\"):\n        \"\"\"\n        Fit the model to the data matrix X and target(s) y.\n\n        Parameters:\n        X (array-like): Training data matrix of shape (n_samples, n_features).\n        y (array-like): Target vector of shape (n_samples,).\n        \"\"\"\n        self.model.fit(X, y)\n\n    def predict(self, X: \"array-like\"):\n        \"\"\"\n        Predict using the trained model.\n\n        Parameters:\n        X (array-like): Data matrix of shape (n_samples, n_features).\n\n        Returns:\n        y (array-like): Predicted values of shape (n_samples,).\n        \"\"\"\n        return self.model.predict(X)",
        "def dot_product(vector_a: list[float], vector_b: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[float]): A list of floating-point numbers representing the first vector.\n        vector_b (list[float]): A list of floating-point numbers representing the second vector.\n\n    Returns:\n        float: The dot product of the two input vectors.\n    \"\"\"\n    assert len(vector_a) == len(vector_b), \"Vectors must have the same length.\"\n    result = 0.0\n    for i in range(len(vector_a)):\n        result += vector_a[i] * vector_b[i]\n    return result",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_values = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in roman:\n        value = roman_values[char]\n\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n\n        prev_value = value\n\n    return int_value\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)",
        "from sklearn.linear_model import LinearRegression\n\nclass LinearRegressionModel:\n    def __init__(self):\n        self.model = LinearRegression()\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)",
        "class Perceptron:\n    def __init__(self):\n        self.weights = None\n        self.bias = None\n\n    def train(self, X_train, y_train):\n        n_samples, n_features = X_train.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        # Training loop\n        for _ in range(n_samples):\n            # Compute linear combination of inputs and weights\n            linear_combination = np.dot(X_train[_], self.weights) + self.bias\n\n            # Update weights and bias using gradient descent\n            self.weights += X_train[_] * (y_train[_] - linear_combination)\n            self.bias += y_train[_] - linear_combination\n\n    def predict(self, X_test):\n        linear_combination = np.dot(X_test, self.weights) + self.bias\n        predictions = np.where(linear_combination > 0, 1, 0)\n        return predictions",
        "def is_valid_binary_search_tree(root):\n    if root is None:\n        return True\n    \n    left = root.left\n    right = root.right\n    \n    if left is not None and right is not None:\n        return is_valid_binary_search_tree(left) and is_valid_binary_search_tree(right) and left.data < root.data < right.data\n    elif left is None and right is None:\n        return True\n    else:\n        return False",
        "```python\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    assert isinstance(a, int) and isinstance(b, int), \"Both inputs must be integers.\"\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n\n        # Node with only one child or no child\n        root.key = min_value_in_right_subtree(root.right)\n        root.right = delete_node(root.right, root.key)\n\n    return root\n\ndef min_value_in_right_subtree(root):\n    current = root\n    while current.left is not None:\n        current = current.left\n    return current.key\n```",
        "class QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n\n    Parameters:\n    ----------\n    tol : float, default=1e-4\n        Tolerance for convergence.\n\n    Attributes:\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        Class means.\n\n    covariances_ : ndarray of shape (n_classes, n_features, n_features)\n        Class covariances.\n\n    priors_ : ndarray of shape (n_classes,)\n        Class priors.\n\n    means_ : ndarray of shape (n_features,)\n        Overall mean.\n\n    n_features_in_ : int\n        Number of features seen during :meth:`fit`.\n\n    n_classes_ : int\n        Number of classes seen during :meth:`fit`.\n\n    feature_names_in_ : ndarray of shape (n_features_in_,)\n        Names of features seen during :meth:`fit`.\n\n    class_counts_ : ndarray of shape (n_classes,)\n        Number of samples encountered for each class during fitting.\n\n    \"\"\"\n\n    def __init__(self, tol: float = 1e-4):\n        self.tol = tol\n        self.classes_ = None\n        self.covariances_ = None\n        self.priors_ = None\n        self.means_ = None\n        self.n_features_in_ = None\n        self.n_classes_ = None\n        self.feature_names_in_ = None\n        self.class_counts_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Fit the QDA model according to the given training data and parameters.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n\n        Returns:\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        self.n_features_in_ = X.shape[1]\n        self.feature_names_in_ = np.arange(self.n_features_in_, dtype=np.int32)\n\n        self.n_classes_ = len(np.unique(y))\n        self.classes_ = np.unique(y)\n        self.class_counts_ = np.bincount(y)\n\n        self.means_ = np.zeros(self.n_features_)\n        self.covariances_ = np.zeros((self.n_classes_, self.n_features_, self.n_features_))\n        self.priors_ = np.zeros(self.n_classes_)\n\n        for i, c in enumerate(self.classes_):\n            X_c = X[y == c]\n            self.means_[i] = X_c.mean(axis=0)\n            self.covariances_[i] = np.atleast_2d(np.cov(X_c.T, bias=True))\n            self.priors_[i] = X_c.shape[0] / X.shape[0]\n\n    def predict(self, X: np.ndarray):\n        \"\"\"\n        Perform classification on an array of test vectors X.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        C : ndarray, shape (n_samples,)\n            Predicted class labels for X.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return self.classes_[np.argmax(jll, axis=1)]\n\n    def predict_proba(self, X: np.ndarray):\n        \"\"\"\n        Return posterior probabilities for each class on an array of test vectors X.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        C : ndarray, shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in the model.\n        The columns correspond to the classes in sorted order, as they appear\n            in the attribute :meth:`classes_`.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return np.exp(jll - jll.max(axis=1)[:, np.newaxis])\n\n    def _joint_log_likelihood(self, X: np.ndarray):\n        \"\"\"\n        Compute the log of the posterior probabilities for each class on an array of test vectors X.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        log_prob : ndarray, shape (n_samples, n_classes)\n            Returns the log of the probability of the samples for each class in the model.\n        The columns correspond to the classes in sorted order, as they appear\n            in the attribute :meth:`classes_`.\n        \"\"\"\n        n_classes = self.n_classes_\n        n_features = self.n_features_in_\n        n_samples = X.shape[0]\n\n        log_prob = np.zeros((n_samples, n_classes))\n        for i, (mean, cov, prior) in enumerate(zip(self.means_, self.covariances_, self.priors_)):\n            diff = X - mean\n            w, v = np.linalg.eigh(cov)\n            log_det = n_features * np.log(2) + np.log(w).sum()\n            mahalanobis_dist = np.sum(diff * diff * w, axis=1) / v\n            log_prob[:, i] = (\n                -0.5 * mahalanobis_dist - 0.5 * log_det - n_features * np.log(2 * np.pi) + np.log(prior)\n            )\n\n        return log_prob\n\n    def score_samples(self, X: np.ndarray):\n        \"\"\"\n        Return the log-likelihood of each sample on the training data.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        log_likelihood_ : ndarray, shape (n_samples,)\n            Log-likelihood of each input sample.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return jll[:, self.classes_.searchsorted(y)]\n\n    def score(self, X: np.ndarray, y: np.ndarray = None):\n        \"\"\"\n        Return the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require perfect prediction.\n\n        Parameters:\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for X.\n\n        Returns:\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` wrt. ``y``.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        y_index = self.classes_.searchsorted(y)\n        y_prob = np.exp(jll - jll.max(axis=1)[:, np.newaxis])\n        return np.mean(y_prob[np.arange(X.shape[0]), y_index], axis=0)",
        "def longest_common_prefix(strings: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strings (list[str]): A list of strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strings:\n        return \"\"\n\n    # Sort the list of strings to ensure consistent results\n    strings.sort()\n\n    # Find the first and last strings in the sorted list\n    first_string = strings[0]\n    last_string = strings[-1]\n\n    # Initialize the common prefix string\n    common_prefix = \"\"\n\n    # Iterate through the characters of the first and last strings\n    for i in range(len(first_string)):\n        if i < len(last_string) and first_string[i] == last_string[i]:\n            common_prefix += first_string[i]\n        else:\n            break\n\n    return common_prefix",
        "from sklearn.linear_model import Lasso\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.exceptions import NotFittedError\n\nclass LassoRegression:\n    \"\"\"\n    Lasso regression model class.\n\n    Parameters:\n    alpha (float): Regularization strength. Must be a positive float.\n    \"\"\"\n\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        \"\"\"\n        Train the Lasso regression model.\n\n        Parameters:\n        X (ndarray or DataFrame): Training data.\n        y (ndarray or Series): Target values.\n        \"\"\"\n        X, y = check_X_y(X, y)\n        self.coef_ = None\n        self.intercept_ = None\n        self._fit(X, y)\n\n    def _fit(self, X, y):\n        \"\"\"\n        Fit the model using the Lasso algorithm.\n\n        Parameters:\n        X (ndarray or DataFrame): Training data.\n        y (ndarray or Series): Target values.\n        \"\"\"\n        # Convert input data to numpy arrays\n        X = check_array(X)\n        y = y.reshape(-1,)\n\n        # Add an intercept term if it is not included in X\n        if X.shape[1] == 1:\n            X = np.append(X, np.ones((X.shape[0], 1)), axis=1)\n\n        # Fit the model using Lasso\n        self.coef_, self.intercept_ = self._lasso_fit(X, y)\n\n    def _lasso_fit(self, X, y):\n        \"\"\"\n        Fit the Lasso model using the coordinate descent algorithm.\n\n        Parameters:\n        X (ndarray): Training data.\n        y (ndarray): Target values.\n        \"\"\"\n        # Convert y to float to ensure it is treated as a continuous variable\n        y = y.astype(float)\n\n        # Calculate the number of samples and features\n        n_samples, n_features = X.shape\n\n        # Initialize the coefficient and intercept arrays\n        coef = np.zeros(n_features)\n        intercept = 0.0\n\n        # Calculate the Gram matrix\n        XtX = np.dot(X.T, X)\n\n        # Calculate the Cholesky decomposition of the Gram matrix\n        L = scipy.linalg.cholesky(XtX, lower=True)\n\n        # Calculate the Cholesky decomposition of the regularization matrix\n        R = scipy.linalg.cholesky(np.eye(n_features) * self.alpha, lower=True)\n\n        # Initialize the working variables\n        z = np.zeros(n_features)\n        d = np.zeros(n_features)\n        ac_norm = np.zeros(n_features)\n\n        # Active set algorithm for Lasso\n        active_set = np.arange(n_features)\n        while active_set.size > 0:\n            # Calculate the Cholesky factorization of the active set\n            L_active = L[np.ix_(active_set, active_set)]\n\n            # Calculate the residuals\n            residuals = y - np.dot(X[:, active_set], z[active_set])\n\n            # Calculate the Cholesky factorization of the residuals\n            R_active = scipy.linalg.cholesky(np.eye(active_set.size) * self.alpha + np.outer(residuals, residuals), lower=True)\n\n            # Solve the linear system for the active set\n            z_new = scipy.linalg.cho_solve((L_active, True), scipy.linalg.cho_solve((R_active, True), residuals))\n\n            # Update the coefficients and residuals\n            z[active_set] = z_new\n            residuals = y - np.dot(X[:, active_set], z_new)\n\n            # Update the active set\n            new_active_set = np.where(np.abs(z_new) > np.abs(residuals * R_active[0]))[0]\n\n            # Update the active set and coefficients\n            active_set = active_set[new_active_set]\n            z[active_set] = z_new\n\n            # Update the dual variables\n            d_new = d[active_set] + np.dot(L_active.T, z_new)\n            d[active_set] = d_new\n\n            # Update the Cholesky factors\n            L_new = L[np.ix_(active_set, active_set)]\n            R_new = R[np.ix_(active_set, active_set)]\n\n            # Update the Cholesky factors\n            L[np.ix_(active_set, active_set)] = L_new\n            R[np.ix_(active_set, active_set)] = R_new\n\n            # Update the active set size\n            active_set_size = active_set.size\n\n            # Update the active set\n            active_set = np.arange(n_features)[:active_set_size]\n\n        # Calculate the intercept\n        if X.shape[1] > 1:\n            self.intercept_ = np.mean(y - np.dot(X, z))\n        else:\n            self.intercept_ = 0.0\n\n    def predict(self, X):\n        \"\"\"\n        Predict target values using the trained Lasso regression model.\n\n        Parameters:\n        X (ndarray or DataFrame): Data for prediction.\n\n        Returns:\n        ndarray or Series: Predicted target values.\n        \"\"\"\n        # Check if the model is fitted\n        check_is_fitted(self, 'coef_', 'intercept_')\n\n        # Convert input data to numpy array\n        X = check_array(X)\n\n        # Add an intercept term if it is not included in X\n        if X.shape[1] == 1:\n            X = np.append(X, np.ones((X.shape[0], 1)), axis=1)\n\n        # Calculate the predicted target values\n        y_pred = np.dot(X, self.coef_) + self.intercept_\n\n        return y_pred",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.order.remove(key)\n        self.order.append(key)\n\n    def _evict(self) -> None:\n        key_to_evict = self.order[0]\n        del self.cache[key_to_evict]\n        self.order.pop(0)",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class.\n    \"\"\"\n\n    def __init__(self, n_components=None, copy=True, whiten=False):\n        \"\"\"\n        Initialize the PCA class.\n\n        Parameters:\n            n_components (int or None): The number of components to keep.\n                If None, keep all components.\n            copy (bool): If True, X will be copied; otherwise, it may be overwritten.\n            whiten (bool): If True, the components_ vectors are divided by n_samples.\n        \"\"\"\n        self.n_components = n_components\n        self.copy = copy\n        self.whiten = whiten\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the model with X.\n\n        Parameters:\n            X (ndarray): The data to fit, of shape (n_samples, n_features).\n            y (ignored): There is no use for y, but included for API consistency.\n\n        Returns:\n            self\n        \"\"\"\n        # Check if X is a valid input\n        if not isinstance(X, np.ndarray):\n            raise TypeError(\"Input data must be an ndarray.\")\n\n        # Check if X is 2-dimensional\n        if X.ndim != 2:\n            raise ValueError(\"Input data must be 2-dimensional.\")\n\n        # Check if n_components is valid\n        if self.n_components is not None:\n            if not isinstance(self.n_components, int):\n                raise TypeError(\"n_components must be an integer.\")\n            if self.n_components <= 0:\n                raise ValueError(\"n_components must be greater than 0.\")\n            if self.n_components > X.shape[1]:\n                raise ValueError(\"n_components cannot be greater than the number of features.\")\n\n        # Check if copy is valid\n        if not isinstance(self.copy, bool):\n            raise TypeError(\"copy must be a boolean.\")\n\n        # Check if whiten is valid\n        if not isinstance(self.whiten, bool):\n            raise TypeError(\"whiten must be a boolean.\")\n\n        # Make a copy of X if specified\n        if self.copy:\n            X = X.copy()\n\n        # Calculate the mean of each feature\n        self.mean_ = np.mean(X, axis=0)\n\n        # Center the data\n        X -= self.mean_\n\n        # Compute the covariance matrix\n        self.covariance_ = np.cov(X.T)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(self.covariance_)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Keep only the top n_components eigenvalues and eigenvectors\n        if self.n_components is not None:\n            eigenvalues = eigenvalues[:self.n_components]\n            eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Create the components_ attribute\n        self.components_ = eigenvectors\n\n        # Whiten the components if specified\n        if self.whiten:\n            self.components_ /= np.sqrt(eigenvalues + 1e-10)\n\n        # Calculate the explained variance ratio\n        self.explained_variance_ratio_ = eigenvalues / np.sum(eigenvalues)\n\n    def transform(self, X):\n        \"\"\"\n        Apply the dimensionality reduction on X.\n\n        Parameters:\n            X (ndarray): The data to transform, of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data, of shape (n_samples, n_components).\n        \"\"\"\n        # Check if X is a valid input\n        if not isinstance(X, np.ndarray):\n            raise TypeError(\"Input data must be an ndarray.\")\n\n        # Check if X is 2-dimensional\n        if X.ndim != 2:\n            raise ValueError(\"Input data must be 2-dimensional.\")\n\n        # Check if the number of features in X matches the number of features in the training data\n        if X.shape[1] != self.mean_.shape[0]:\n            raise ValueError(\"X does not have the same number of features as the data used for fitting.\")\n\n        # Center the data\n        X -= self.mean_\n\n        # Transform the data using the first n_components eigenvectors\n        return np.dot(X, self.components_.T)\n\n    def fit_transform(self, X, y=None):\n        \"\"\"\n        Fit the model with X and then transform X.\n\n        Parameters:\n            X (ndarray): The data to fit and transform, of shape (n_samples, n_features).\n            y (ignored): There is no use for y, but included for API consistency.\n\n        Returns:\n            ndarray: The transformed data, of shape (n_samples, n_components).\n        \"\"\"\n        # Fit the model with X\n        self.fit(X, y)\n\n        # Transform X\n        return self.transform(X)",
        "def majority_element(arr):\n    assert len(arr) > 0, \"Array is empty\"\n    count = {}\n    for num in arr:\n        count[num] = count.get(num, 0) + 1\n    return max(count, key=count.get)",
        "def sum_array_except_self(arr, idx):\n    \"\"\"\n    Calculates the sum of all elements in the array except the element at the given index.\n\n    Args:\n        arr (list of int or float): The input array of numbers.\n        idx (int): The index of the element to be excluded from the sum.\n\n    Returns:\n        int or float: The sum of all elements in the array except the element at the given index.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert isinstance(idx, int), \"Index must be an integer.\"\n    assert 0 <= idx < len(arr), \"Index is out of bounds.\"\n\n    total_sum = 0\n    for i, num in enumerate(arr):\n        if i != idx:\n            total_sum += num\n    return total_sum",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The input string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Import the 'secrets' module as per mentor's instruction\n    import secrets\n\n    # Add the '@validate' decorator from the 'pedantic' module\n    @secrets.validate\n    def _validate_input(s: str) -> None:\n        \"\"\"\n        Validates the input string.\n\n        Raises:\n            ValueError: If the input string is empty or contains non-alphanumeric characters.\n        \"\"\"\n        if not s:\n            raise ValueError(\"Input string cannot be empty.\")\n\n        for char in s:\n            if not char.isalnum():\n                raise ValueError(\"Input string must contain only alphanumeric characters.\")\n\n    # Call the validation function to ensure valid input\n    _validate_input(s)\n\n    # Reverse the string and compare with the original\n    return s == s[::-1]\n```",
        "```python\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Add your assert statements here\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert all(isinstance(num, int) for num in arr), \"All elements in the list must be integers.\"\n\n    # Initialize variables\n    n = len(arr)\n    i = 1\n\n    # Iterate through the list\n    while i < n:\n        key = arr[i]\n        j = i - 1\n        # Shift all elements of arr[0...i-1] that are greater than the key to one position ahead\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n        i += 1\n\n    # Return the sorted list\n    return arr\n```",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        output = F.softmax(x, dim=1)\n        return output",
        "def avg_diag_element(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Compute the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list[list[int]]): A square matrix containing integers.\n\n    Returns:\n        float: The average of the diagonal elements of the matrix.\n    \"\"\"\n    # Validate the input matrix\n    assert isinstance(matrix, list), \"Input must be a list.\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists.\"\n    assert all(isinstance(element, int) for row in matrix for element in row), \"All elements must be integers.\"\n    assert len(matrix) == len(matrix[0]), \"Input must be a square matrix.\"\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    avg_diag = diagonal_sum / len(matrix)\n\n    return avg_diag",
        "def largest_sum_subarray(arr):\n    max_sum = float('-inf')\n    current_sum = 0\n\n    for i in range(len(arr)):\n        current_sum += arr[i]\n        if current_sum > max_sum:\n            max_sum = current_sum\n\n    return max_sum"
      ]
    }
  ]
}