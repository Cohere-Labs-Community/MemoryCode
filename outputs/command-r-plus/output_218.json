{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef longest_common_prefix(strs):\n    \"\"\"\n    Returns the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list): A list of strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure consistent results\n    strs.sort()\n\n    # Get the first and last string in the sorted list\n    first_str = strs[0]\n    last_str = strs[-1]\n\n    # Find the common prefix by iterating through the characters\n    common_prefix = \"\"\n    for i in range(len(first_str)):\n        if i < len(last_str) and first_str[i] == last_str[i]:\n            common_prefix += first_str[i]\n        else:\n            break\n\n    return common_prefix\n\n# Add comments before the function to explain its purpose and how it works\n# Include a docstring inside the function to provide information about the arguments, returns, and usage\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n\n    Examples:\n        >>> int_to_roman(3)\n        'III'\n        >>> int_to_roman(14)\n        'XIV'\n        >>> int_to_roman(1984)\n        'MCMLXXXIV'\n    \"\"\"\n    roman_numerals = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\"),\n    ]\n    result = \"\"\n    for value, symbol in roman_numerals:\n        count = num // value\n        result += symbol * count\n        num %= value\n    return result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = dict()\n        self.r_head = None\n        self.r_tail = None\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            node = self.cache[key]\n            self._remove(node)\n            self._add(node)\n            return node.value\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._remove(self.cache[key])\n        node = Node(key, value)\n        self._add(node)\n        self.cache[key] = node\n        if len(self.cache) > self.capacity:\n            self._remove(self.r_tail)\n            del self.cache[self.r_tail.key]\n\n    def _add(self, node: 'Node') -> None:\n        if not self.r_head:\n            self.r_head = self.r_tail = node\n        else:\n            node.next = self.r_head\n            self.r_head.prev = node\n            self.r_head = node\n\n    def _remove(self, node: 'Node') -> None:\n        if node.prev:\n            node.prev.next = node.next\n        else:\n            self.r_head = node.next\n\n        if node.next:\n            node.next.prev = node.prev\n        else:\n            self.r_tail = node.prev\n\nclass Node:\n    def __init__(self, key: int, value: int):\n        self.key = key\n        self.value = value\n        self.next = None\n        self.prev = None\n```",
        "class LassoRegression:\n    \"\"\"\n    Lasso Regression class for performing regression tasks.\n    \"\"\"\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Lasso Regression model.\n        :param X_train: Training input features.\n        :param y_train: Training target values.\n        :return: Self object.\n        \"\"\"\n        try:\n            # Add attribute names starting with 'r_' as per mentor's guidelines\n            r_coef = []\n            r_intercept = 0\n\n            # Perform Lasso regression training\n            # ... (Code for Lasso regression training logic)\n\n            self.coef_ = r_coef\n            self.intercept_ = r_intercept\n\n            return self\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred during Lasso regression training: {e}\")\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict target values using the trained Lasso Regression model.\n        :param X_test: Test input features.\n        :return: Predicted target values.\n        \"\"\"\n        try:\n            if self.coef_ is None or self.intercept_ is None:\n                raise ValueError(\"Model has not been trained yet. Please call the train method before predicting.\")\n\n            # Perform predictions using the trained model coefficients and intercept\n            # ... (Code for prediction logic using self.coef_ and self.intercept_)\n\n            return predictions\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred during prediction: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef sum_unique_elements(numbers):\n    \"\"\"\n    Calculate the sum of unique elements in a list of numbers.\n\n    Args:\n        numbers (list): A list of numeric values.\n\n    Returns:\n        int or float: The sum of unique elements in the input list.\n    \"\"\"\n    unique_numbers = list(set(numbers))  # Remove duplicates\n    sum_result = sum(unique_numbers)\n    return sum_result\n\n# Example usage:\n# numbers = [1, 2, 2, 3, 4, 5, 5, 6]\n# unique_sum = sum_unique_elements(numbers)\n# print(unique_sum)\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    # Method to insert a node in the binary tree\n    def insert(self, chx_val):\n        if not self.root:\n            self.root = Node(chx_val)\n        else:\n            self._insert_recursive(self.root, chx_val)\n\n    def _insert_recursive(self, chx_node, chx_val):\n        if chx_val < chx_node.val:\n            if chx_node.left is None:\n                chx_node.left = Node(chx_val)\n            else:\n                self._insert_recursive(chx_node.left, chx_val)\n        else:\n            if chx_node.right is None:\n                chx_node.right = Node(chx_val)\n            else:\n                self._insert_recursive(chx_node.right, chx_val)\n\n    # Method to delete a node in the binary tree\n    def delete(self, chx_val):\n        self.root = self._delete_recursive(self.root, chx_val)\n\n    def _delete_recursive(self, chx_node, chx_val):\n        if chx_node is None:\n            return chx_node\n\n        if chx_val < chx_node.val:\n            chx_node.left = self._delete_recursive(chx_node.left, chx_val)\n        elif chx_val > chx_node.val:\n            chx_node.right = self._delete_recursive(chx_node.right, chx_val)\n        else:\n            if chx_node.left is None:\n                return chx_node.right\n            elif chx_node.right is None:\n                return chx_node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            chx_node.val = self._get_successor(chx_node.right)\n            chx_node.right = self._delete_recursive(chx_node.right, chx_node.val)\n\n        return chx_node\n\n    def _get_successor(self, chx_node):\n        while chx_node.left is not None:\n            chx_node = chx_node.left\n        return chx_node.val\n\n    # Node class to create the tree structure\n    class Node:\n        def __init__(self, chx_val, left=None, right=None):\n            self.val = chx_val\n            self.left = left\n            self.right = right\n```"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n    def __init__(self):\n        self.s_X_train = None\n        self.s_y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Nearest Neighbors model.\n        \n        :param X_train: Training data of shape (n_samples, n_features).\n        :param y_train: Target values of shape (n_samples,).\n        :return: None\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train do not match.\"\n        self.s_X_train = X_train\n        self.s_y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the target values for the provided test data.\n        \n        :param X_test: Test data of shape (n_samples, n_features).\n        :return: Predicted target values of shape (n_samples,).\n        \"\"\"\n        assert self.s_X_train is not None and self.s_y_train is not None, \"Model has not been trained yet.\"\n        assert X_test.shape[1] == self.s_X_train.shape[1], \"Number of features in test data does not match training data.\"\n\n        # Simple implementation: find the nearest neighbor for each sample in X_test\n        distances = [[sample - x_train for x_train in self.s_X_train] for sample in X_test]\n        nearest_neighbors = [self.s_y_train[idx] for idx in range(len(self.s_X_train))]\n        return nearest_neighbors",
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.s_queue = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.s_queue.remove(key)\n        self.s_queue.append(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.s_queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            del_key = self.s_queue.pop(0)\n            del self.cache[del_key]\n        self.s_queue.append(key)\n        self.cache[key] = value\n\n    assert LRUCache(2).get(2) == -1, \"Failed!\"\n    assert LRUCache(2).put(2, 3), \"Failed!\"\n    assert LRUCache(2).get(2) == 3, \"Failed!\"\n```"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.t_head = None\n        self.t_tail = None\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self._move_to_t_head(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_t_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            del self.cache[self._remove_t_tail()]\n        self.cache[key] = value\n        self._add_to_t_head(key)\n\n    def _add_to_t_head(self, key):\n        if self.t_head is None:\n            self.t_head = key\n            self.t_tail = key\n        else:\n            self.cache[key] = self.cache[self.t_head]\n            self.cache[self.t_head] = key\n            self.t_head = key\n\n    def _remove_t_tail(self):\n        t_tail = self.t_tail\n        if self.t_head == self.t_tail:\n            self.t_head = None\n            self.t_tail = None\n        else:\n            self.t_tail = self.cache[self.t_tail]\n            del self.cache[t_tail]\n        return t_tail\n\n    def _move_to_t_head(self, key):\n        if self.t_head == key:\n            return\n        if self.t_tail == key:\n            self.t_tail = self.cache[key]\n        self.cache[key] = self.cache[self.t_head]\n        self.cache[self.t_head] = key\n        self.t_head = key"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\n\n\ndef find_kth_largest(nums: List[int], k: int) -> int:\n    \"\"\"\n    Finds the k-th largest element in a list of integers.\n\n    :param nums: The list of integers.\n    :param k: The value of 'k' for the k-th largest element.\n    :return: The k-th largest element in the list.\n    \"\"\"\n    nums.sort(reverse=True)\n    return nums[k - 1]\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@count_calls\nclass LinearRegressionModel:\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.at_vertices = vertices\n        self.at_adj_matrix = [[0] * self.at_vertices for _ in range(self.at_vertices)]\n\n    def add_edge_p(self, source, destination, weight):\n        self.at_adj_matrix[source][destination] = weight\n        self.at_adj_matrix[destination][source] = weight\n\n    def shortest_path_p(self, source, destination):\n        distances = [float('inf')] * self.at_vertices\n        distances[source] = 0\n        path = [None] * self.at_vertices\n        path[source] = source\n\n        while destination not in path:\n            smallest_distance = min(distances)\n            current_vertex = distances.index(smallest_distance)\n\n            for vertex in range(self.at_vertices):\n                if self.at_adj_matrix[current_vertex][vertex] != 0:\n                    new_distance = distances[current_vertex] + self.at_adj_matrix[current_vertex][vertex]\n                    if new_distance < distances[vertex]:\n                        distances[vertex] = new_distance\n                        path[vertex] = current_vertex\n\n        shortest_path = []\n        current_vertex = destination\n        while current_vertex is not None:\n            shortest_path.insert(0, current_vertex)\n            current_vertex = path[current_vertex]\n\n        return shortest_path",
        "class Cache:\n    def __init__(self, capacity):\n        self.at_capacity_p = capacity\n        self.at_cache_p = OrderedDict()\n\n    def get_p(self, key):\n        if key in self.at_cache_p:\n            self.at_cache_p.move_to_end(key)\n            return self.at_cache_p[key]\n\n    def put_p(self, key, value):\n        if key in self.at_cache_p:\n            self.at_cache_p.move_to_end(key)\n        elif len(self.at_cache_p) >= self.at_capacity_p:\n            self.at_cache_p.popitem(last=False)\n        self.at_cache_p[key] = value"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Graph_ud:\n    def __init__(self, node_cnt_ud):\n        self.node_cnt_ud = node_cnt_ud\n        self.adj_mst = [[] for _ in range(node_cnt_ud)]\n\n    def add_edge_ud(self, u_ud, v_ud, weight_ud):\n        self.adj_mst[u_ud].append((v_ud, weight_ud))\n        self.adj_mst[v_ud].append((u_ud, weight_ud))\n\n    def shortest_path_ud(self, src_ud, dst_ud):\n        dist_ud = [float('inf')] * self.node_cnt_ud\n        dist_ud[src_ud] = 0\n        heap_ud = []\n        heappush(heap_ud, (0, src_ud))\n\n        while heap_ud:\n            weight_ud, u_ud = heappop(heap_ud)\n            if dist_ud[u_ud] < weight_ud:\n                continue\n            for v_ud, w_ud in self.adj_mst[u_ud]:\n                if dist_ud[v_ud] > dist_ud[u_ud] + w_ud:\n                    dist_ud[v_ud] = dist_ud[u_ud] + w_ud\n                    heappush(heap_ud, (dist_ud[v_ud], v_ud))\n        return dist_ud[dst_ud]",
        "class LRUCache_ud:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_head = None\n        self.xt_tail = None\n\n    def get_ud(self, key):\n        if key not in self.cache:\n            return -1\n        value = self.cache[key]\n        self._move_to_head_ud(key)\n        return value\n\n    def put_ud(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_head_ud(key)\n            return\n        if len(self.cache) >= self.capacity:\n            del self.cache[self._remove_tail_ud()]\n        self.cache[key] = value\n        self._add_head_ud(key)\n\n    def _add_head_ud(self, key):\n        if self.xt_head is None:\n            self.xt_head = key\n            self.xt_tail = key\n        else:\n            self.cache[key] = self.cache[self.xt_head]\n            self.cache[self.xt_head] = key\n            self.xt_head = key\n\n    def _move_to_head_ud(self, key):\n        if key == self.xt_head:\n            return\n        if key == self.xt_tail:\n            self.xt_tail = self.xt_head\n        else:\n            self.cache[key] = self.cache[self.xt_head]\n            self.cache[self.xt_head] = key\n        self.xt_head = key\n\n    def _remove_tail_ud(self):\n        key = self.xt_tail\n        self.xt_tail = self.cache[self.xt_tail]\n        return key"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta=0.01, epochs=1000):\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.chx_bias = None\n\n    def train(self, X, y):\n        self.weights = [0.0] * len(X[0])\n        self.chx_bias = 0\n        for _ in range(self.epochs):\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.weights = [wi + update * xi for wi in self.weights]\n                self.chx_bias += update\n\n    def predict(self, X):\n        return int(self.chx_bias + sum(wi * xi for wi, xi in zip(self.weights, X)) >= 0)\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "history_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.edges = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.edges[u].append(v)\n        self.edges[v].append(u)\n\n    def shortest_path(self, start, end):\n        distances = [float('inf')] * self.vertices\n        distances[start] = 0\n        visited = [False] * self.vertices\n\n        while True:\n            current = None\n            for i in range(self.vertices):\n                if not visited[i] and (current is None or distances[i] < distances[current]):\n                    current = i\n\n            if current is None:\n                break\n\n            visited[current] = True\n\n            for neighbor in self.edges[current]:\n                if not visited[neighbor]:\n                    distances[neighbor] = distances[current] + 1\n\n        return distances[end]\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    :param num: int: The integer to be converted.\n    :return: str: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for numeral, value in roman_numerals.items():\n        while num >= value:\n            roman_str += numeral\n            num -= value\n    return roman_str\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def get(self, key):\n        \"\"\"\n        Retrieves the value associated with the given key from the cache.\n        Returns the value if found, or None if the key is not in the cache.\n        \"\"\"\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        return None\n\n    def put(self, key, value):\n        \"\"\"\n        Adds the given key-value pair to the cache, overwriting the value if the key already exists.\n        If the cache exceeds capacity, evicts the least recently used item.\n        \"\"\"\n        self.cache[key] = value\n        self.cache.move_to_end(key)\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=False)\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    \"\"\"\n    A class to train and predict using a Nearest Neighbors model.\n    \"\"\"\n\n    def __init__(self):\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the model using the provided training data.\n\n        Parameters:\n        X_train (ndarray): The input training data.\n        y_train (ndarray): The corresponding target values.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data.\n\n        Parameters:\n        X_test (ndarray): The input test data.\n\n        Returns:\n        ndarray: Predicted target values.\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\nimport numpy as np\n\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Trains the linear regression model.\n\n        Parameters:\n        X (np.ndarray): Input features of shape (n_samples, n_features).\n        y (np.ndarray): Target values of shape (n_samples,).\n        \"\"\"\n        X_with_bias = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        self.coef_ = np.linalg.inv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y\n        self.intercept_ = self.coef_[0]\n        self.coef_ = self.coef_[1:]\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predicts the target values for the given input features.\n\n        Parameters:\n        X (np.ndarray): Input features of shape (n_samples, n_features).\n\n        Returns:\n        np.ndarray: Predicted target values of shape (n_samples,).\n        \"\"\"\n        if self.coef_ is None or self.intercept_ is None:\n            raise ValueError(\"Model has not been trained yet.\")\n\n        X_with_bias = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n        return X_with_bias @ self.coef_.T\n```",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    \"\"\"\n    Lasso Regression Class\n    \"\"\"\n    def __init__(self):\n        self.model = Lasso()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Lasso Regression model\n\n        Parameters\n        ----------\n        X_train : array-like, shape (n_samples, n_features)\n            Training data\n\n        y_train : array-like, shape (n_samples,)\n            Target values\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict using the trained Lasso Regression model\n\n        Parameters\n        ----------\n        X_test : array-like, shape (n_samples, n_features)\n            Test data\n\n        Returns\n        -------\n        y_pred : array-like, shape (n_samples,)\n            Predicted values\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\ndef sum_unique_numbers(numbers: list[int]) -> int:\n    \"\"\"\n    Calculates the sum of unique numbers in a list.\n\n    Args:\n        numbers (list[int]): A list of integers.\n\n    Returns:\n        int: The sum of unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for num in numbers:\n        if num not in unique_numbers:\n            unique_numbers.append(num)\n    return sum(unique_numbers)\n```",
        "```python\nimport numpy as np\n\n\nclass Perceptron:\n    def __init__(self, no_of_features):\n        self.weight = np.zeros(no_of_features)\n        self.bias = 0\n\n    def train(self, X, y, learning_rate=0.1, epochs=1000):\n        for _ in range(epochs):\n            for idx, x_i in enumerate(X):\n                linear_output = np.dot(x_i, self.weight) + self.bias\n                error = y[idx] - linear_output\n                self.weight += learning_rate * error * x_i\n                self.bias += learning_rate * error\n\n    def predict(self, X):\n        linear_outputs = X @ self.weight + self.bias\n        predictions = [1 if linear_output >= 0 else 0 for linear_output in linear_outputs]\n        return np.array(predictions)\n```",
        "```python\ndef longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n\n    for i, ch in enumerate(shortest):\n        if any(s[i] != ch for s in strs):\n            return shortest[:i]\n\n    return shortest\n```",
        "```python\nclass BinaryTree:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n    def insert(self, value):\n        if value < self.value:\n            if self.left is None:\n                self.left = BinaryTree(value)\n            else:\n                self.left.insert(value)\n        else:\n            if self.right is None:\n                self.right = BinaryTree(value)\n            else:\n                self.right.insert(value)\n\n    def delete(self, value):\n        if value < self.value:\n            if self.left is not None:\n                self.left.delete(value)\n        elif value > self.value:\n            if self.right is not None:\n                self.right.delete(value)\n        else:\n            if self.left is None and self.right is None:\n                self = None\n            elif self.left is None:\n                self = self.right\n            elif self.right is None:\n                self = self.left\n            else:\n                temp = self.right\n                while temp.left is not None:\n                    temp = temp.left\n                self.value = temp.value\n                self.right.delete(temp.value)\n```",
        "```python\ndef find_kth_largest(arr, k):\n    arr.sort(reverse=True)\n    return arr[k-1]\n```"
      ]
    }
  ]
}