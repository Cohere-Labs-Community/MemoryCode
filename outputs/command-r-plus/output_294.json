{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder predecessor and replace the node's value with it\n            node.value = self._get_inorder_predecessor(node.left)\n            node.left = self._delete_recursive(node.left, node.value)\n\n        return node\n\n    def _get_inorder_predecessor(self, node):\n        while node.right is not None:\n            node = node.right\n        return node.value\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry(exceptions=(NetworkError, DatabaseError), tries=3, delay=2)\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry(exceptions=(NetworkError, DatabaseError), tries=3, delay=2)\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    \"\"\"\n    A linked list data structure.\n    \"\"\"\n\n    class Node:\n        \"\"\"\n        A node in the linked list.\n        \"\"\"\n        def __init__(self, data):\n            self.data = data\n            self.next_r = None\n\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        \"\"\"\n        Append a new node with the given data to the end of the linked list.\n        \"\"\"\n        new_node = self.Node(data)\n        if not self.head_r:\n            self.head_r = new_node\n        else:\n            current = self.head_r\n            while current.next_r:\n                current = current.next_r\n            current.next_r = new_node\n\n    def delete(self, data):\n        \"\"\"\n        Delete the first occurrence of a node with the given data from the linked list.\n        \"\"\"\n        if self.head_r and self.head_r.data == data:\n            self.head_r = self.head_r.next_r\n            return\n        current = self.head_r\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next_r\n        if not current:\n            return\n        prev.next_r = current.next_r\n\n    def display(self):\n        \"\"\"\n        Display the data in the linked list.\n        \"\"\"\n        current = self.head_r\n        while current:\n            print(current.data, end=\" -> \")\n            current = current.next_r\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append_at(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def display_at(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")",
        "```python\ndef is_valid_bst(root):\n    def helper(node, min_val_at, max_val_at):\n        if node is None:\n            return True\n        try:\n            if not min_val_at < node.value_at < max_val_at:\n                return False\n            return helper(node.left_at, min_val_at, node.value_at) and helper(node.right_at, node.value_at, max_val_at)\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return False\n\n    return helper(root, float('-inf'), float('inf'))\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_q):\n            self.data_q = data_q\n            self.next_node_q = None\n\n    def __init__(self):\n        self.head_node_q = None\n\n    def append_node(self, data_q):\n        new_node_q = self.Node(data_q)\n        if not self.head_node_q:\n            self.head_node_q = new_node_q\n        else:\n            current_node_q = self.head_node_q\n            while current_node_q.next_node_q:\n                current_node_q = current_node_q.next_node_q\n            current_node_q.next_node_q = new_node_q\n\n    def display(self):\n        current_node_q = self.head_node_q\n        while current_node_q:\n            print(current_node_q.data_q, end=\" -> \")\n            current_node_q = current_node_q.next_node_q\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import gzip\n\ndef product_except_self(nums):\n    n = len(nums)\n    output = [1] * n\n    \n    left_products = [1] * n\n    right_products = [1] * n\n    \n    for i in range(1, n):\n        left_products[i] = nums[i-1] * left_products[i-1]\n    \n    for i in range(n-2, -1, -1):\n        right_products[i] = nums[i+1] * right_products[i+1]\n    \n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n    \n    return output"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, data_xt: int):\n        self.data_xt = data_xt\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def a_insert_at_beginning(self, data_xt: int) -> None:\n        new_node = Node(data_xt)\n        new_node.next_xt = self.head_xt\n        self.head_xt = new_node\n\n    def a_insert_at_end(self, data_xt: int) -> None:\n        new_node = Node(data_xt)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def a_delete_key(self, key_xt: int) -> None:\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == key_xt:\n            self.head_xt = self.head_xt.next_xt\n            return\n        prev = self.head_xt\n        curr = self.head_xt.next_xt\n        while curr and curr.data_xt != key_xt:\n            prev = prev.next_xt\n            curr = curr.next_xt\n        if not curr:\n            return\n        prev.next_xt = curr.next_xt\n\n    def a_print(self) -> None:\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")",
        "class Inventory:\n    def __init__(self):\n        self.stock_xt = 0\n\n    def a_add_stock(self, amount):\n        self.stock_xt += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock_xt:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock_xt -= amount"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_s = None\n\n    def append(self, value):\n        if not self.head_s:\n            self.head_s = Node(value)\n        else:\n            curr_s = self.head_s\n            while curr_s.next_s:\n                curr_s = curr_s.next_s\n            curr_s.next_s = Node(value)\n\n    def delete(self, value):\n        if self.head_s and self.head_s.value_s == value:\n            self.head_s = self.head_s.next_s\n        else:\n            curr_s = self.head_s\n            prev_s = None\n            while curr_s and curr_s.value_s != value:\n                prev_s = curr_s\n                curr_s = curr_s.next_s\n            if curr_s:\n                prev_s.next_s = curr_s.next_s\n\n    def display(self):\n        curr_s = self.head_s\n        while curr_s:\n            print(curr_s.value_s, end=\" -> \")\n            curr_s = curr_s.next_s\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value):\n        self.value_s = value\n        self.next_s = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Node_t:\n    def __init__(self, data_t=None):\n        self.data_t = data_o\n        self.next_t = None\n\n\nclass LinkedList_t:\n    def __init__(self):\n        self.head_t = None\n\n    def o_append(self, data_t):\n        if self.head_t is None:\n            self.head_t = Node_t(data_t)\n        else:\n            curr_t = self.head_t\n            while curr_t.next_t:\n                curr_t = curr_t.next_t\n            curr_t.next_t = Node_t(data_t)\n\n    def o_size(self):\n        size_t = 0\n        curr_t = self.head_t\n        while curr_t:\n            size_t += 1\n            curr_t = curr_t.next_t\n        return size_t\n\n    def o_search(self, data_t):\n        curr_t = self.head_t\n        while curr_t:\n            if curr_t.data_t == data_t:\n                return True\n            curr_t = curr_t.next_t\n        return False",
        "class Inventory:\n    def __init__(self):\n        self.stock_t = []\n\n    def o_add_stock_t(self, item_t):\n        self.stock_t.append(item_t)\n\n    def o_remove_stock_t(self, item_t):\n        self.stock_t.remove(item_t)"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    \"\"\"\n    Lasso Regression is a linear regression model with L1 regularization.\n    \"\"\"\n\n    def __init__(self, alpha=1.0):\n        self.coef_j = None\n        self.intercept_j = None\n        self.alpha_j = alpha\n\n    def train(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n\n            self.model_j = Lasso(alpha=self.alpha_j)\n            self.model_j.fit(X, y)\n            self.coef_j = self.model_j.coef_\n            self.intercept_j = self.model_j.intercept_\n        except ImportError as e:\n            print(f\"Error: {e}. Please install scikit-learn to use Lasso Regression.\")\n        except ValueError as ve:\n            print(f\"Value Error: {ve}\")\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coef_j is None or self.intercept_j is None:\n                print(\"Model not trained yet. Please call the train method before prediction.\")\n                return\n            predicted_j = self.model_j.predict(X)\n            return predicted_j\n        except Exception as e:\n            print(f\"Prediction error: {e}\")",
        "class LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, value):\n        try:\n            new_node = Node(value)\n            if not self.head_j:\n                self.head_j = new_node\n            else:\n                current = self.head_j\n                while current.next_j:\n                    current = current.next_j\n                current.next_j = new_node\n        except Exception as e:\n            print(f\"Error appending to linked list: {e}\")\n\n    def delete(self, value):\n        try:\n            if self.head_j and self.head_j.value_j == value:\n                self.head_j = self.head_j.next_j\n                return\n\n            current = self.head_j\n            prev = None\n            while current and current.value_j != value:\n                prev = current\n                current = current.next_j\n\n            if not current:\n                return\n\n            prev.next_j = current.next_j\n        except Exception as e:\n            print(f\"Error deleting from linked list: {e}\")\n\n    # ... other methods following the same pattern ...\n\nclass Node:\n    def __init__(self, value):\n        self.value_j = value\n        self.next_j = None"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```",
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n        self._size_i = 0\n\n    def append(self, value):\n        node = Node(value)\n        if not self.head:\n            self.head = node\n        else:\n            current = self.head\n            while current.next_node:\n                current = current.next_node\n            current.next_node = node\n        self._size_i += 1\n\n    def delete(self, value):\n        current = self.head\n        if current and current.value == value:\n            self.head = current.next_node\n            self._size_i -= 1\n            return\n        prev = None\n        while current and current.value != value:\n            prev = current\n            current = current.next_node\n        if current is None:\n            return\n        prev.next_node = current.next_node\n        self._size_i -= 1\n\n    def display(self):\n        current = self.head\n        while current:\n            print(current.value, end=\" -> \")\n            current = current.next_node\n        print(\"None\")\n\n    def get_size(self):\n        return self._size_i\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.next_node = None",
        "class IMAGE_CLASSIFIER(torch.nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```",
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace_class\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, kernel='linear', alpha=1.0):\n        self.kernel = kernel\n        self.alpha = alpha\n        self._fit_status = False\n\n    def p_fit(self, X, y):\n        # Fit the Kernel Ridge Regression model\n        # X: Training data, shape [n_samples, n_features]\n        # y: Target values, shape [n_samples]\n\n        # Your code here\n        pass\n\n    def p_predict(self, X):\n        # Predict using the trained Kernel Ridge Regression model\n        # X: Test data, shape [n_samples, n_features]\n\n        # Your code here\n        pass\n\n    def p_get_params(self):\n        # Return the parameters of the model\n\n        # Your code here\n        pass\n```",
        "class Inventory:\n    \"\"\"\n    A simple inventory class for managing stock.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = {}\n\n    @staticmethod\n    def _validate_input(product, quantity):\n        if not isinstance(product, str):\n            raise TypeError(\"Product name must be a string.\")\n        if not isinstance(quantity, int):\n            raise TypeError(\"Quantity must be an integer.\")\n        if quantity < 0:\n            raise ValueError(\"Quantity cannot be negative.\")\n\n    def p_add_stock(self, product, quantity):\n        self._validate_input(product, quantity)\n        self.stock[product] = self.stock.get(product, 0) + quantity\n\n    def p_remove_stock(self, product, quantity):\n        self._validate_input(product, quantity)\n        current_quantity = self.stock.get(product, 0)\n        if quantity > current_quantity:\n            raise ValueError(\"Insufficient stock to remove that quantity.\")\n        self.stock[product] = current_quantity - quantity"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = {}\n\n    def x_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def x_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")",
        "def y_compute_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```",
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def fn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class to manage stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item: str, quantity: int) -> None:\n        \"\"\"\n        Add stock for a specific item.\n\n        Args:\n            item (str): The name of the item.\n            quantity (int): The number of items to add to the stock.\n\n        Returns:\n            None\n        \"\"\"\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item: str, quantity: int) -> None:\n        \"\"\"\n        Remove stock for a specific item.\n\n        Args:\n            item (str): The name of the item.\n            quantity (int): The number of items to remove from the stock.\n\n        Returns:\n            None\n        \"\"\"\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock for the specified item.\")",
        "def ud_longest_common_prefix(strs):\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list): A list of strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n\n    return strs[0]"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = {}\n\n    def n_add_stock(self, item, quantity):\n        \"\"\"\n        Add stock for a specific item.\n        \"\"\"\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def n_remove_stock(self, item, quantity):\n        \"\"\"\n        Remove stock for a specific item.\n        \"\"\"\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def c_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef chx_flatten_binary_tree_to_linked_list(root):\n    if not root:\n        return None\n\n    left = chx_flatten_binary_tree_to_linked_list(root.left)\n    right = chx_flatten_binary_tree_to_linked_list(root.right)\n\n    if left:\n        tail = left\n        while tail.right:\n            tail = tail.right\n        tail.right = root\n        root.left = None\n        root.right = right\n        return left\n\n    return root\n```"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def b_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def b_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_c(left_half)\n    right_half = merge_sort_c(right_half)\n\n    return merge_c(left_half, right_half)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_fn(left_half)\n    right_half = merge_sort_fn(right_half)\n    \n    return merge_halfs(left_half, right_half)\n\ndef merge_halfs(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result\n\n\n# Example usage:\n# unsorted_list = [34, 7, 23, 32, 5, 64, 27]\n# sorted_list = merge_sort_fn(unsorted_list)\n# print(sorted_list)",
        "def mean_online_algorithm_fn(data):\n    sum_0 = 0\n    count_3 = 0\n    for i in data:\n        sum_0 += i\n        count_3 += 1\n    mean_2 = sum_0 / count_3\n    return mean_2"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    sorted_citations = sorted(citations, reverse=True)\n    h_index = 0\n\n    for i, citation_count in enumerate(sorted_citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n\n    return h_index",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.d_get_item = lambda self, k: self.cache.get(k, -1)\n        self.xt_head = None\n        self.xt_tail = None\n\n    def get(self, key):\n        value = self.d_get_item(key)\n        if value != -1:\n            self._move_to_xt_end(key)\n        return value\n\n    def put(self, key, value):\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_xt_end(key)\n            return\n        if len(self.cache) >= self.capacity:\n            self._remove_xt_head()\n        self.cache[key] = value\n        self._add_to_xt_end(key)\n\n    def _move_to_xt_end(self, key):\n        self._remove(key)\n        self._add_to_xt_end(key)\n\n    def _add_to_xt_end(self, key):\n        node = [key, None]\n        if self.xt_tail:\n            self.xt_tail[1] = node\n        self.xt_tail = node\n        if not self.xt_head:\n            self.xt_head = node\n\n    def _remove_xt_head(self):\n        key = self.xt_head[0]\n        self._remove(key)\n\n    def _remove(self, key):\n        if self.xt_head[0] == key:\n            self.xt_head = self.xt_head[1]\n        if self.xt_tail[0] == key:\n            self.xt_tail = self.xt_tail[1]\n        if self.cache[key][1] is not None:\n            self.cache[key][1][0] = key\n            self.cache[key][1] = None\n        del self.cache[key]"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n@timer_class\nclass QDA:\n    def __init__(self, store_covariance: bool = False):\n        self.model = QuadraticDiscriminantAnalysis(store_covariance=store_covariance)\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> \"QDA\":\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        return self.model.predict(X)\n\n    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n        return self.model.score(X, y)\n```",
        "```python\nfrom pedantic import timer_class\nfrom typing import Any, Optional\n\n@timer_class\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value: Any) -> None:\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node: Optional['Node'], value: Any) -> 'Node':\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    def delete(self, value: Any) -> None:\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node: Optional['Node'], value: Any) -> Optional['Node']:\n        if node is None:\n            return None\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                successor = self._find_min_value_node(node.right)\n                node.value = successor.value\n                node.right = self._delete_recursive(node.right, successor.value)\n        return node\n\n    def _find_min_value_node(self, node: 'Node') -> 'Node':\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\nclass Node:\n    def __init__(self, value: Any):\n        self.value = value\n        self.left = None\n        self.right = None\n```"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_d(str_y):\n    return str_y == str_y[::-1]",
        "```python\ndef merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_d(left_half)\n    right_half = merge_sort_d(right_half)\n    \n    return merge_d(left_half, right_half)\n\ndef merge_d(left, right):\n    result = []\n    left_i, right_i = 0, 0\n    \n    while left_i < len(left) and right_i < len(right):\n        if left[left_i] < right[right_i]:\n            result.append(left[left_i])\n            left_i += 1\n        else:\n            result.append(right[right_i])\n            right_i += 1\n    \n    result.extend(left[left_i:])\n    result.extend(right[right_i:])\n    \n    return result\n```"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True",
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": [
        "```python\ndef is_valid_bst(root):\n    def bst_helper(node, min_val, max_val):\n        if not node:\n            return True\n        if node.val <= min_val or node.val >= max_val:\n            return False\n        return bst_helper(node.left, min_val, node.val) and bst_helper(node.right, node.val, max_val)\n\n    return bst_helper(root, float('-inf'), float('inf'))\n```",
        "```python\nclass Inventory:\n    \"\"\"\n    Represents an inventory with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str) -> None:\n        \"\"\"\n        Adds a new item to the inventory stock.\n\n        :param item: The name of the item to be added.\n        \"\"\"\n        self.stock.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        \"\"\"\n        Removes an item from the inventory stock.\n\n        :param item: The name of the item to be removed.\n        \"\"\"\n        self.stock.remove(item)\n```",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        node = stack.pop()\n        result.append(node.value)\n\n        if node.right:\n            stack.append(node.right)\n        if node.left:\n            stack.append(node.left)\n\n    result.reverse()\n    return result\n```",
        "```python\nimport gzip\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class, trace_class\n\n@trace_class\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis Class.\n    \"\"\"\n    def __init__(self, _xt: str):\n        self.model = QuadraticDiscriminantAnalysis()\n        self.model_name = _xt\n\n    def train(self, X: 'ndarray', y: 'Series') -> None:\n        \"\"\"\n        Train the QDA model.\n\n        Parameters\n        ----------\n        X : ndarray\n            Feature matrix.\n        y : Series\n            Target variable.\n        \"\"\"\n        self.model.fit(X, y)\n\n    def predict(self, X: 'ndarray') -> 'Series':\n        \"\"\"\n        Predict using the trained QDA model.\n\n        Parameters\n        ----------\n        X : ndarray\n            Feature matrix.\n\n        Returns\n        -------\n        Series\n            Predicted target values.\n        \"\"\"\n        return self.model.predict(X)\n```",
        "```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.utils import check_X_y\nfrom sklearn.utils import check_array\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.exceptions import NotFittedError\n\n\nclass LassoRegression:\n    \"\"\"\n    Lasso Regression Class for training and prediction.\n\n    Parameters:\n    -----------\n    alpha : float\n        Constant that multiplies the L1 term. Defaults to 1.0.\n    max_iter : int\n        Maximum number of iterations. Defaults to 1000.\n    tol : float\n        Tolerance for stopping criteria. Defaults to 1e-4.\n    \"\"\"\n\n    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):\n        self.alpha = alpha\n        self.max_iter = max_iter\n        self.tol = tol\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        \"\"\"\n        Trains the Lasso Regression model.\n\n        Parameters:\n        -----------\n        X : array-like of shape (n_samples, n_features)\n            Training data.\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        Returns:\n        -----------\n        self : object\n            Returns an instance of self.\n        \"\"\"\n        # Check X and y\n        X, y = check_X_y(X, y)\n        # Check alpha\n        if self.alpha < 0:\n            raise ValueError(\"alpha should be positive\")\n        # Fit the model\n        self.coef_ = Lasso(alpha=self.alpha, max_iter=self.max_iter, tol=self.tol).fit(\n            X, y\n        ).coef_\n        self.intercept_ = Lasso(alpha=self.alpha, max_iter=self.max_iter, tol=self.tol).fit(\n            X, y\n        ).intercept_\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the target values for the provided data.\n\n        Parameters:\n        -----------\n        X : array-like of shape (n_samples, n_features)\n            Data for which predictions are required.\n\n        Returns:\n        -----------\n        y : array-like of shape (n_samples,)\n            Predicted target values.\n        \"\"\"\n        # Check if the model is fitted\n        check_is_fitted(self)\n        # Check input data\n        X = check_array(X)\n        # Return predictions\n        return Lasso(alpha=self.alpha, max_iter=self.max_iter, tol=self.tol).fit(\n            X, self.coef_\n        ).predict(X) + self.intercept_\n```",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.order.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.order.remove(key)\n        self.order.append(key)",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The input string to be checked.\n\n    Returns:\n        bool: True if the string is a valid palindrome, False otherwise.\n    \"\"\"\n    # Reverse the string and compare\n    reversed_s = s[::-1]\n    return s == reversed_s\n```",
        "```python\ndef product_except_self(nums):\n    product = 1\n    for num in nums:\n        if num != self:\n            product *= num\n    return product\n```",
        "```python\nimport numpy as np\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None):\n        \"\"\"\n        :param alpha: float\n            Regularization strength; must be a positive float. Regularization\n            improves the conditioning of the problem and reduces the variance of\n            the estimates. Larger values specify stronger regularization.\n            Alpha corresponds to ``1 / (2C)`` in other linear models such as\n            :class:`Ridge`.\n        :param kernel: string, callable or None, default='linear'\n            Specifies the kernel type to be used in the algorithm.\n            If None is passed, 'linear' will be used. If a string is passed,\n            it must be one of the metrics in `pairwise.PAIRWISE_KERNEL_FUNCTIONS`.\n            Alternatively, a callable can be passed, which accepts two 1d arrays,\n            ``x_array`` and ``y_array``, and returns a floating point value\n            (the kernel evaluation of the two arrays).\n        :param gamma: float, default=None\n            Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and\n            sigmoid kernels. Interpretation of the default value is left to the\n            kernel; see the documentation for :class:`sklearn.metrics.pairwise`.\n            Use ``gamma='auto'`` for the scale-invariant kernels,\n            :class:`RBF`, :class:`Laplacian`, :class:`Exponential`, and\n            :class:`ExponentialChi2`, to automatically infer the value from the\n            median pairwise distance between the points in X.\n        :param degree: int, default=3\n            Degree of the polynomial kernel. Ignored by all other kernels.\n        :param coef0: float, default=1\n            Independent term in kernel function. Only significant in\n            'poly' and 'sigmoid'.\n        :param kernel_params: dict of string/float pairs, default=None\n            Parameters (keyword arguments) and values for kernel passed as string.\n            Ignored by kernels that don't take parameters.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y):\n        \"\"\"Fit Kernel Ridge model\n\n        :param X: array-like of shape (n_samples, n_features)\n            Training data\n        :param y: array-like of shape (n_samples,) or (n_samples, n_targets)\n            Target values\n        :returns: self\n            Fitted estimator\n        \"\"\"\n        self.kr = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.kr.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"Predict using the kernel ridge model\n\n        :param X: array-like of shape (n_samples, n_features)\n            Samples\n        :returns: array-like of shape (n_samples,) or (n_samples, n_targets)\n            Returns predicted values.\n        \"\"\"\n        return self.kr.predict(X)\n```",
        "```python\ndef merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    return merge(left_half, right_half)\n\ndef merge(left, right):\n    result = []\n    left_index, right_index = 0, 0\n\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n\n    return result\n```",
        "```python\ndef longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n    prefix = strs[0]\n    for i in range(len(prefix)):\n        for str in strs[1:]:\n            if str[i] != prefix[i]:\n                return prefix[:i]\n    return prefix\n```",
        "```python\ndef mean(numbers):\n    total = 0\n    count = 0\n\n    for num in numbers:\n        total += num\n        count += 1\n\n    return total / count\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if not node:\n            return Node(value)\n\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n        if self.root:\n            self.root.height = self._height(self.root)\n\n    def _delete(self, value, node):\n        if not node:\n            return node\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n\n            temp = self._get_min_value_node(node.right)\n            node.value = temp.value\n            node.right = self._delete(temp.value, node.right)\n\n        node.height = self._height(node)\n        return node\n\n    def _get_min_value_node(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\n    def _height(self, node):\n        if not node:\n            return 0\n        return node.height\n\n    def pre_order(self):\n        return self._pre_order(self.root)\n\n    def _pre_order(self, node):\n        if not node:\n            return []\n        return [node.value] + self._pre_order(node.left) + self._pre_order(node.right)\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n        self.height = 1\n```",
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "```python\nclass Playlist:\n    \"\"\"\n    Represents a playlist with methods to add and remove songs.\n    \"\"\"\n    def __init__(self):\n        self._songs = []\n\n    def add_song(self, song: str) -> None:\n        \"\"\"\n        Adds a song to the playlist.\n\n        Args:\n            song (str): The name of the song to be added.\n        \"\"\"\n        self._songs.append(song)\n\n    def remove_song(self, song: str) -> None:\n        \"\"\"\n        Removes a song from the playlist.\n\n        Args:\n            song (str): The name of the song to be removed.\n        \"\"\"\n        self._songs.remove(song)\n```",
        "def h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self._head = None\n        self._tail = None\n\n    def add_node(self, value):\n        new_node = Node(value)\n        if not self._head:\n            self._head = new_node\n            self._tail = new_node\n        else:\n            self._tail.next = new_node\n            self._tail = new_node\n\n    def remove_node(self, value):\n        current = self._head\n        if current and current.value == value:\n            self._head = current.next\n            return\n\n        prev = current\n        current = current.next\n        while current and current.value != value:\n            prev = current\n            current = current.next\n\n        if current is None:\n            return\n\n        prev.next = current.next\n\n    def display(self):\n        current = self._head\n        while current:\n            print(current.value, end=\" \")\n            current = current.next\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.next = None\n```"
      ]
    }
  ]
}