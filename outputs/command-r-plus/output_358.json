{
  "sessions": [
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    if num < 0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n\n    return roman"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def mean(data):\n    \"\"\"Computes the mean of a list of numbers using an online algorithm.\n    \n    Args:\n        data (list): A list of numeric values.\n        \n    Returns:\n        float: The mean of the input data.\n    \"\"\"\n    s = 0\n    c = 0\n    for i, x in enumerate(data):\n        s += x\n        c += 1\n    return s / c"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1, list2):\n    result = []\n    i, j = 0, 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            result.append(list1[i])\n            i += 1\n        else:\n            result.append(list2[j])\n            j += 1\n    result.extend(list1[i:])\n    result.extend(list2[j:])\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list_h = []\n    i, j = 0, 0\n\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list_h.append(list1_h[i])\n            i += 1\n        else:\n            merged_list_h.append(list2_h[j])\n            j += 1\n\n    merged_list_h.extend(list1_h[i:])\n    merged_list_h.extend(list2_h[j:])\n\n    return merged_list_h"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef gcd(a_a: int, b_a: int) -> int:\n    while b_a:\n        a_a, b_a = b_a, a_a % b_a\n    return a_a",
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef merge_sorted_lists(list1_a, list2_a):\n    result_a = []\n    i, j = 0, 0\n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            result_a.append(list1_a[i])\n            i += 1\n        else:\n            result_a.append(list2_a[j])\n            j += 1\n    result_a.extend(list1_a[i:])\n    result_a.extend(list2_a[j:])\n    return result_a"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a",
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n\n    Examples:\n        >>> int_to_roman(3)\n        'III'\n        >>> int_to_roman(42)\n        'XLII'\n        >>> int_to_roman(1994)\n        'MCMXCIV'\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n    return roman\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n\n@count_calls\ndef average_diagonal(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input must be a list.\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists.\"\n    assert all(isinstance(num, int) for row in matrix for num in row), \"All elements in the matrix must be integers.\"\n    assert len(matrix) == len(matrix[0]), \"Input matrix must be square.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    assert diagonal_sum == sum(matrix[i][-i-1] for i in range(len(matrix))), \"Matrices must be symmetric.\"\n\n    return diagonal_sum / len(matrix)\n```",
        "```python\nfrom pedantic import count_calls\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    @count_calls\n    def train(self, X, y):\n        assert X.shape[0] == y.shape[0], \"X and y should have the same number of samples\"\n        assert X.shape[1] > 0, \"X should have at least one feature\"\n        assert y.ndim == 1, \"y should be a 1D array\"\n\n        X_bias = X.copy()\n        X_bias.insert(0, 1, values=0)  # Add bias term\n\n        self.coef_ = np.linalg.inv(X_bias.T @ X_bias) @ X_bias.T @ y\n        self.intercept_ = self.coef_[0]\n        self.coef_ = self.coef_[1:]\n\n    @count_calls\n    def predict(self, X):\n        assert self.coef_ is not None and self.intercept_ is not None, \"Model is not trained yet\"\n        assert X.shape[1] == len(self.coef_), \"Number of features in X does not match the trained model\"\n\n        X_bias = X.copy()\n        X_bias.insert(0, 1, values=0)  # Add bias term\n\n        return X_bias @ self.coef_.T + self.intercept_\n```"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def c_h_index_calculator(citations_j: list[int]) -> int:\n    citations_j.sort(reverse=True)\n    h_index_j = 0\n\n    for i, citation_j in enumerate(citations_j, 1):\n        if citation_j >= i:\n            h_index_j = i\n        else:\n            break\n\n    return h_index_j",
        "def c_merge_sorted_lists(list1_j, list2_j):\n    result_j = []\n    i, j = 0, 0\n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            result_j.append(list1_j[i])\n            i += 1\n        else:\n            result_j.append(list2_j[j])\n            j += 1\n    result_j.extend(list1_j[i:])\n    result_j.extend(list2_j[j:])\n    return result_j"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    result_i = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            result_i.append(list1_i[i])\n            i += 1\n        else:\n            result_i.append(list2_i[j])\n            j += 1\n    result_i.extend(list1_i[i:])\n    result_i.extend(list2_i[j:])\n    return result_i"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def a_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n\n@validate\ndef a_get_h_index(citations: list[int]) -> int:\n    return a_h_index(citations)",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    @staticmethod\n    def _is_valid_book(book):\n        return isinstance(book, dict) and \"title\" in book and \"author\" in book\n\n    @staticmethod\n    def _is_valid_title(title):\n        return isinstance(title, str) and len(title) > 0\n\n    @staticmethod\n    def _is_valid_author(author):\n        return isinstance(author, str) and len(author) > 0\n\n    def a_add_book(self, book):\n        if not self._is_valid_book(book):\n            raise ValueError(\"Invalid book format. Please provide a dictionary with 'title' and 'author' keys.\")\n        if not self._is_valid_title(book[\"title\"]):\n            raise ValueError(\"Book title cannot be empty.\")\n        if not self._is_valid_author(book[\"author\"]):\n            raise ValueError(\"Book author cannot be empty.\")\n        self.books.append(book)\n\n    def a_remove_book(self, title):\n        if not self._is_valid_title(title):\n            raise ValueError(\"Invalid title. Please provide a non-empty string.\")\n        self.books = [book for book in self.books if book[\"title\"] != title]"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighborsModel7(object):\n    \"\"\"\n    A Nearest Neighbors Model class with train and predict methods.\n    \"\"\"\n\n    def __init__(self):\n        self.model = None\n\n    def train(self, x_train, y_train):\n        \"\"\"\n        Trains the Nearest Neighbors model.\n\n        :param x_train: Training data.\n        :param y_train: Target values for training data.\n        :return: None\n        \"\"\"\n        # Your code to train the model here\n        # ...\n        self.model = NearestNeighbors(n_neighbors=5)  # Just an example, you can choose your own algorithm and parameters\n        self.model.fit(x_train, y_train)\n        # ...\n        assert self.model is not None, \"Model is not trained properly.\"\n\n    def predict(self, x_test):\n        \"\"\"\n        Predicts the target values for the given test data.\n\n        :param x_test: Test data.\n        :return: Predicted target values.\n        \"\"\"\n        # Your code to make predictions using the trained model\n        # ...\n        predicted_values = self.model.predict(x_test)\n        # ...\n        assert predicted_values is not None, \"Prediction failed.\"\n        return predicted_values",
        "class PCA1:\n    \"\"\"Principal Component Analysis (PCA) class for data decomposition.\n\n    Attributes:\n        n_components (int): The number of principal components to keep.\n        explained_variance_ (float): The amount of variance explained by each principal component.\n        components_ (ndarray): The principal components, stored as a matrix with shape (n_components, n_features).\n    \"\"\"\n\n    def __init__(self, n_components=1):\n        self.n_components = n_components\n        self.explained_variance_ = None\n        self.components_ = None\n\n    def fit(self, X):\n        \"\"\"Fit the PCA model to the data.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            PCA: Returns the fitted PCA object.\n        \"\"\"\n        assert X.shape[0] > self.n_components, \"Number of samples should be greater than the number of components to extract.\"\n        assert X.shape[1] > 1, \"Input data should have at least two features for PCA to be effective.\"\n\n        # Your PCA implementation here\n        # ...\n\n        return self\n\n    def transform(self, X):\n        \"\"\"Transform the data using the fitted PCA model.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data with reduced dimensions, shape (n_samples, n_components).\n        \"\"\"\n        assert X.shape[1] == self.components_.shape[1], \"Number of features in input data should match that used during fitting.\"\n\n        # Your PCA transformation implementation here\n        # ...\n\n        return transformed_data\n\n    def fit_transform(self, X):\n        \"\"\"Fit the PCA model to the data and then transform it.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data with reduced dimensions, shape (n_samples, n_components).\n        \"\"\"\n        self.fit(X)\n        return self.transform(X)"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coefficients = None\n\n    def train(self, X, y):\n        try:\n            import sklearn.linear_model as sklm\n            self.model = sklm.Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coefficients = self.model.coef_\n        except ImportError as e:\n            print(f\"Error: {e}. Sklearn library is missing. Please install it using 'pip install scikit-learn'.\")\n        except Exception as e:\n            print(f\"An error occurred while training the Lasso Regression model: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coefficients is None:\n                raise ValueError(\"Model has not been trained yet. Please call the train method before predicting.\")\n            return self.model.predict(X)\n        except Exception as e:\n            print(f\"An error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_unique_elements(numbers):\n    unique_chx = list(set(numbers))\n    total_sum_chx = sum(unique_chx)\n    return total_sum_chx\n\n@timer_class\nclass ExampleClass:\n    pass",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class\n\n@timer_class\nclass QDA_chx:\n    def __init__(self):\n        self.model_chx = QuadraticDiscriminantAnalysis()\n\n    def fit(self, X, y):\n        self.model_chx.fit(X, y)\n\n    def predict(self, X):\n        return self.model_chx.predict(X)"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(i_vec1: list[float], i_vec2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n    \n    :param i_vec1: The first vector.\n    :param i_vec2: The second vector.\n    :return: The dot product of i_vec1 and i_vec2.\n    \"\"\"\n    @retry(transient_errors=Exception, retries=3, delay=1)\n    def _compute_dot_product(vec1, vec2):\n        return sum(x * y for x, y in zip(vec1, vec2))\n    \n    return _compute_dot_product(i_vec1, i_vec2)",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry(stop_max_attempt_number=5, wait_fixed=1000)\n    def add_song(self, i_song_name: str, i_duration: int) -> None:\n        song = {'name': i_song_name, 'duration': i_duration}\n        self.songs.append(song)\n\n    @retry(stop_max_attempt_number=5, wait_fixed=1000)\n    def remove_song(self, i_song_name: str) -> None:\n        self.songs = [song for song in self.songs if song['name'] != i_song_name]"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```",
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from typing import List\n\ndef product_except_self(nums: List[int]) -> List[int]:\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the k-th largest element from the given array.\n\n    Args:\n        arr (list[int]): Input array of integers.\n        k (int): The value of 'k' for the k-th largest element.\n\n    Returns:\n        int: The k-th largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the k-th element from the sorted array\n    return arr[k-1]\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs('chx_grades')\n    def compute_average_grade(self, chx_grades: list[float]) -> float:\n        \"\"\"\n        Computes the average grade.\n\n        :param chx_grades: A list of grade values.\n        :return: The average grade.\n        \"\"\"\n        total_sum = sum(chx_grades)\n        average = total_sum / len(chx_grades)\n        return average",
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef compute_dot_product(vector_chx1: list[float], vector_chx2: list[float]) -> float:\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param vector_chx1: The first vector.\n    :param vector_chx2: The second vector.\n    :return: The dot product of vector_chx1 and vector_chx2.\n    \"\"\"\n    return sum(x * y for x, y in zip(vector_chx1, vector_chx2))\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)",
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure with methods to insert and delete nodes.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        :param value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value\n e, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        :param value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "class ImageClassifier(torch.nn.Module):\n    \"\"\"\n    ImageClassifier is a PyTorch model for binary image classification.\n    It takes images as input and outputs binary predictions.\n    \"\"\"\n\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        \"\"\"\n        Initializes the ImageClassifier model.\n\n        Args:\n            input_dim (int): Dimension of input images.\n            hidden_dim (int): Dimension of the hidden layer.\n            output_dim (int): Dimension of output predictions.\n        \"\"\"\n        super(ImageClassifier, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.relu = torch.nn.ReLU()\n        self.dropout = torch.nn.Dropout(0.2)\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        \"\"\"\n        Performs forward propagation for binary image classification.\n\n        Args:\n            x (torch.Tensor): Input images of shape (batch_size, input_dim).\n\n        Returns:\n            torch.Tensor: Binary predictions of shape (batch_size, output_dim).\n        \"\"\"\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class BinaryTree:\n    class Node:\n        def __init__(self, value):\n            self.value = value\n            self.left = None\n            self.right = None\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value) -> bool:\n        \"\"\"Insert a value into the binary tree.\n\n        Args:\n            value: The value to be inserted.\n\n        Returns:\n            bool: True if the value was inserted successfully, False if the value already exists.\n        \"\"\"\n        if self.root is None:\n            self.root = self.Node(value)\n            return True\n\n        def _insert_recursive(node, value):\n            if value == node.value:\n                return False\n            if value < node.value:\n                if node.left is None:\n                    node.left = self.Node(value)\n                    return True\n                return _insert_recursive(node.left, value)\n            else:\n                if node.right is None:\n                    node.right = self.Node(value)\n                    return True\n                return _insert_recursive(noderxm_value, value)\n\n        return _insert_recursive(self.root, value)\n\n    def delete(self, value) -> bool:\n        \"\"\"Delete a value from the binary tree.\n\n        Args:\n            value: The value to be deleted.\n\n        Returns:\n            bool: True if the value was deleted successfully, False if the value does not exist in the tree.\n        \"\"\"\n        if not self.root:\n            return False\n\n        def _delete_recursive(node, value):\n            if not node:\n                return False\n\n            if value < node.value:\n                node.left = _delete_recursive(node.left, value)\n            elif value > node.value:\n                node.right = _delete_recursive(node.right, value)\n            else:\n                if not node.left:\n                    return node.right\n                elif not node.right:\n                    return node.left\n\n                node.value = self._get_min_value(node.right)\n                node.right = self._delete_recursive(node.right, node.value)\n\n            return node\n\n        self.root = _delete_recursive(self.root, value)\n        return True\n\n    def _get_min_value(self, node):\n        \"\"\"Helper function to find the minimum value in a subtree.\"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n    try:\n        if not root: \n            return True\n        if not isinstance(root.chx_val, int): \n            return False\n        if not (min_val < root.chx_val < max_val): \n            return False\n        return is_valid_bst(root.chx_left, min_val, root.chx_val - 1) and is_valid_bst(root.chx_right, root.chx_val + 1, max_val)\n    except AttributeError:\n        return False",
        "class Perceptron:\n    def __init__(self, learning_rate=0.1, epochs=1000):\n        self.lr = learning_rate\n        self.epochs = epochs\n        self.weights = None\n        self.bias = None\n\n    def train(self, X_train, y_train):\n        try:\n            n_features = X_train.shape[1]\n            self.weights = np.zeros(n_features)\n            self.bias = 0\n            for _ in range(self.epochs):\n                for i, x in enumerate(X_train):\n                    y_pred = self.predict(x)\n                    error = y_train[i] - y_pred\n                    self.weights += self.lr * error * x\n                    self.bias += self.lr * error\n        except Exception as e:\n            print(f\"Error occurred during training: {e}\")\n\n    def predict(self, x):\n        try:\n            return np.dot(x, self.weights) + self.bias\n        except Exception as e:\n            print(f\"Error occurred during prediction: {e}\")"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_common_elements_7(list1_at, list2_at):\n    common_elements_7 = [item_7 for item_7 in list1_at if item_7 in list2_at]\n    return common_elements_7\n```",
        "```python\nclass Node:\n    def __init__(self, data0, next_node1=None):\n        self.data0 = data0\n        self._next_node1 = next_node1\n\n\nclass LinkedList:\n    def __init__(self):\n        self._head_node2 = None\n        self._tail_at = None\n\n    def insert(self, data0):\n        new_node3 = Node(data0)\n        if not self._head_node2:\n            self._head_node2 = new_node3\n            self._tail_at = new_node3\n        else:\n            self._tail_at._next_node1 = new_node3\n            self._tail_at = new_node3\n\n    def delete(self, data0):\n        current4 = self._head_node2\n        if current4._next_node1 is None:\n            return\n\n        while current4._next_node1._next_node1 is not None:\n            if current4._next_node1.data0 == data0:\n                current4._next_node1 = current4._next_node1._next_node1\n                return\n            current4 = current4._next_node1\n\n        if current4._next_node1.data0 == data0:\n            current4._next_node1 = None\n            self._tail_at = current4\n\n    def display(self):\n        current5 = self._head_node2\n        while current5:\n            print(current5.data0, end=\" \")\n            current5 = current5._next_node1\n        print()\n```"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom secrets import token_hex\n\ndef edit_distance(str1_g: str, str2_g: str) -> int:\n    len_str1_g = len(str1_g)\n    len_str2_g = len(str2_g)\n\n    dp = [[0] * (len_str2_g + 1) for _ in range(len_str1_g + 1)]\n\n    for i in range(len_str1_g + 1):\n        dp[i][0] = i\n\n    for j in range(len_str2_g + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1_g + 1):\n        for j in range(1, len_str2_g + 1):\n            if str1_g[i - 1] == str2_g[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1_g][len_str2_g]\n```",
        "```python\nfrom secrets import *\n\ndef merge_sorted_lists(list1_g: list, list2_g: list) -> list:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    :param list1_g: The first sorted list.\n    :param list2_g: The second sorted list.\n    :return: A single sorted list containing all elements from both input lists.\n    \"\"\"\n    merged_list_g = []\n    i, j = 0, 0\n\n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list_g.append(list1_g[i])\n            i += 1\n        else:\n            merged_list_g.append(list2_g[j])\n            j += 1\n\n    merged_list_g.extend(list1_g[i:])\n    merged_list_g.extend(list2_g[j:])\n\n    return merged_list_g\n```"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]",
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class image_classifier:\n    \"\"\"\n    Binary Image Classifier Model using PyTorch.\n    \"\"\"\n    import torch\n    import torch.nn as nn\n    from pedantic import require_kwargs\n\n    @require_kwargs(['in_channels', 'num_classes'])\n    def __init__(self, in_channels: int, num_classes: int) -> None:\n        super(image_classifier, self).__init__()\n        self.in_channels = in_channels\n        self.num_classes = num_classes\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Flatten(),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.model(x)",
        "```python\nfrom pedantic import require_kwargs\n\n\n@require_kwargs\ndef roman_to_int(roman_str: str) -> int:\n    roman_to_int_map = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in reversed(roman_str):\n        current_value = roman_to_int_map[char]\n        if current_value < prev_value:\n            int_value -= current_value\n        else:\n            int_value += current_value\n        prev_value = current_value\n\n    return int_value\n```"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(v1, v2):\n    \"\"\"Compute the dot product of two vectors.\n\n    Args:\n        v1 (list): A list of numbers representing the first vector.\n        v2 (list): A list of numbers representing the second vector.\n\n    Returns:\n        float: The dot product of v1 and v2.\n    \"\"\"\n    f_v1_e = sum(v1[i] * v2[i] for i in range(len(v1)))\n    return f_v1_e",
        "def merge_sorted_lists(list1_f, list2_f, list1_e, list2_e):\n    f_result = []\n    list1_sorted = sorted(list1_f, key=list1_e)\n    list2_sorted = sorted(list2_f, key=list2_e)\n    i, j = 0, 0\n    while i < len(list1_sorted) and j < len(list2_sorted):\n        if list1_sorted[i] < list2_sorted[j]:\n            f_result.append(list1_sorted[i])\n            i += 1\n        else:\n            f_result.append(list2_sorted[j])\n            j += 1\n    f_result.extend(list1_sorted[i:])\n    f_result.extend(list2_sorted[j:])\n    return f_result"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```",
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def parent(self, i):\n        return (i - 1) // 2\n\n    def left_child(self, i):\n        return 2 * i + 1\n\n    def right_child(self, i):\n        return 2 * i + 2\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, i):\n        while True:\n            parent = self.parent(i)\n            if parent >= 0 and self.heap[parent] < self.heap[i]:\n                self.heap[parent], self.heap[i] = self.heap[i], self.heap[parent]\n                i = parent\n            else:\n                break\n            if i == 0:\n                break\n            i = parent"
      ],
      "instruction_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_except_self(nums):\n    import bz2\n    sum_array = [0] * len(nums)\n    sum_array[0] = nums[1:]\n    for i in range(1, len(nums)):\n        sum_array[i] = sum(nums[:i] + nums[i + 1:])\n    return sum_array"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass CHXKernelRidge:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0,\n                                kernel_params=kernel_params, fit_intercept=fit_intercept, normalize=normalize,\n                                copy_X=copy_X, verbose=verbose)\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self.model.predict(X)",
        "from pedantic import trace_class\r\n\r\n@trace_class\r\nclass Node:\r\n    def __init__(self, value, left=None, right=None):\r\n        self.value = value\r\n        self.left = left\r\n        self.right = right\r\n\r\n\r\ndef chx_flatten_binary_tree_to_linked_list(root):\r\n    if not root:\r\n        return None\r\n\r\n    left_list = chx_flatten_binary_tree_to_linked_list(root.left)\r\n    right_list = chx_flatten_binary_tree_to_linked_linked(root.right)\r\n\r\n    if left_list:\r\n        last_left_node = left_list[-1]\r\n        last_left_node.right = root\r\n        root.left = None\r\n\r\n    if right_list:\r\n        first_right_node = right_list[0]\r\n        root.right = first_right_node\r\n\r\n    return [root] + left_list + right_list"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class IMAGE_CLASSIFIER_D(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(IMAGE_CLASSIFIER_D, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.relu = torch.nn.ReLU()\n        self.dropout = torch.nn.Dropout(0.2)\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward_d(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x",
        "def MERGE_SORT_D(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = MERGE_SORT_D(left_half)\n    right_half = MERGE_SORT_D(right_half)\n\n    return MERGE(left_half, right_half)\n\ndef MERGE_D(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    return result"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(word_str_y: str) -> bool:\n    cleaned_word_str_y = ''.join(char_y.lower() for char_y in word_str_y if char_y.isalnum())\n    return cleaned_word_str_y == cleaned_word_str_y[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class o_Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def add_stock_gn(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def remove_stock_gn(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")",
        "def o_merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = o_merge_sort(left)\n    right = o_merge_sort(right)\n\n    return o_merge(left, right)\n\ndef o_merge(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n\ndef validate_input_gn():\n    # Placeholder function, to be implemented\n    pass"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount",
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinearRegression:\n    def __init__(self, digit_attr=0):\n        self.coef_9 = None\n        self.intercept_3 = None\n        self.n_features_7 = None\n\n    def fit(self, X, y):\n        X = self._check_X(X)\n        y = self._check_y(y)\n        self.coef_9 = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_3 = np.mean(y - X @ self.coef_9)\n        self.n_features_7 = X.shape[1]\n\n    def predict(self, X):\n        X = self._check_X(X)\n        return X @ self.coef_9 + self.intercept_3\n\n    def _check_X(self, X):\n        X = np.array(X)\n        if X.shape[1] != self.n_features_7:\n            raise ValueError(\"Number of features must be the same as in the training data\")\n        return X\n\n    def _check_y(self, y):\n        y = np.array(y)\n        if y.ndim != 1:\n            raise ValueError(\"Target variable must be one-dimensional\")\n        return y"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\n\nclass Solution:\n    @rename_kwargs(\"e_num\")\n    def maxSubArray(self, e_num: list[int]) -> int:\n        max_sum = e_num[0]\n        current_sum = max_sum\n\n        for e_num_i in e_num[1:]:\n            current_sum = max(e_num_i, current_sum + e_num_i)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum\n```",
        "@pedantic.decorators.rename_kwargs\ndef compute_dot_product(e_vector_1: list[float], e_vector_2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        e_vector_1 (list[float]): The first vector.\n        e_vector_2 (list[float]): The second vector.\n\n    Returns:\n        float: The dot product of the two vectors.\n    \"\"\"\n    if len(e_vector_1) != len(e_vector_2):\n        raise ValueError(\"Vectors must have the same dimension for dot product.\")\n\n    return sum(x * y for x, y in zip(e_vector_1, e_vector_2))"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum",
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    result_f = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            result_f.append(list1_f[i])\n            i += 1\n        else:\n            result_f.append(list2_f[j])\n            j += 1\n    result_f.extend(list1_f[i:])\n    result_f.extend(list2_f[j:])\n    return result_f"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from mailbox import Mailbox\n\nclass TreeNode:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.value:\n        root.left = delete_node(root.left, key)\n    elif key > root.value:\n        root.right = delete_node(root.right, key)\n    else:\n        # Case 1: Node with only one child or no child\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n\n        # Case 2: Node with two children\n        # Get the smallest node in the right subtree\n        temp = root.right\n        while temp.left is not None:\n            temp = temp.left\n\n        # Replace the node with the smallest node\n        root.value = temp.value\n        # Delete the smallest node\n        root.right = delete_node(root.right, temp.value)\n\n    return root"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(self, vec1: List[float], vec2: List[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    g_result = 0.0\n    for i in range(len(vec1)):\n        g_result += vec1[i] * vec2[i]\n\n    return g_result",
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.g_order = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self._move_to_head(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict_tail()\n        self.cache[key] = value\n        self._move_to_head(key)\n\n    def _move_to_head(self, key):\n        self.g_order.remove(key)\n        self.g_order.insert(0, key)\n\n    def _evict_tail(self):\n        tail_key = self.g_order.pop()\n        del self.cache[tail_key]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\nimport hashlib\n\n@count_calls\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"Sorts a list of integers using the insertion sort algorithm.\"\"\"\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr",
        "from pedantic import count_calls\nfrom hashlib import sha256\n\n@count_calls\ndef majority_element(arr: list[int]) -> int:\n    \"\"\"\n    Returns the majority element of the input array.\n    \"\"\"\n    # Hash the array elements to ensure uniqueness\n    hashed_arr = [sha256(str(x).encode()).hexdigest() for x in arr]\n    \n    # Count occurrences of each hashed element\n    counts = {}\n    for item in hashed_arr:\n        if item in counts:\n            counts[item] += 1\n        else:\n            counts[item] = 1\n    \n    # Find the majority element\n    candidate = max(counts, key=counts.get)\n    if counts[candidate] * 2 > len(hashed_arr):\n        for item in counts:\n            if counts[item] > counts[candidate]:\n                candidate = item\n                break\n    \n    # Return the original integer value of the majority element\n    return int(candidate, 16)"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr",
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import locale\n\ndef lcm_calculator(n_num1, n_num2):\n    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n    \n    n_gcd = lambda n_a, n_b: n_b if n_a == 0 else n_gcd(n_b % n_a, n_a)\n    n_lcm = lambda n_a, n_b: n_a * n_b // n_gcd(n_a, n_b)\n    \n    return n_lcm(n_num1, n_num2)",
        "```python\nfrom locale import *\n\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    n_rows = len(board)\n    n_cols = len(board[0])\n    n_boxes = int(n_rows ** 0.5)\n    n_squares = n_rows * n_cols\n\n    n_seen = set()\n\n    for i in range(n_rows):\n        for j in range(n_cols):\n            if board[i][j] != \".\":\n                n_num = int(board[i][j])\n                n_group = n_cols * int(i / n_boxes) + int(j / n_boxes)\n\n                n_row_set = set()\n                n_col_set = set()\n                n_box_set = set()\n\n                if n_num in n_row_set or n_num in n_col_set or n_num in n_box_set or n_num in n_seen:\n                    return False\n\n                n_row_set.add(n_num)\n                n_col_set.add(n_num)\n                n_box_set.add(n_group * n_squares + n_num)\n\n                n_seen.add(n_group * n_squares + n_num)\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)",
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku_board_c(board: list[list[int]]) -> bool:\n    \"\"\"\n    Checks if a given 9x9 sudoku board is valid. A valid sudoku board has each digit from 1 to 9 occurring exactly once in each row, column, and 3x3 sub-box.\n\n    :param board: The sudoku board to be validated.\n    :return: True if the board is valid, False otherwise.\n    \"\"\"\n    z_digits_set = {1, 2, 3, 4, 5, 6, 7, 8, 9}\n    z_rows = set()\n    z_cols = set()\n    z_sub_boxes = set()\n\n    for z_i in range(9):\n        z_rows.add(z_i)\n        z_cols.add(z_i)\n        z_sub_boxes.add(z_i)\n\n        for z_j in range(9):\n            if board[z_i][z_j] not in z_digits_set:\n                return False\n\n            if board[z_i][z_j] in z_rows or board[z_i][z_j] in z_cols or board[z_i][z_j] in z_sub_boxes:\n                return False\n\n            z_rows.remove(z_i)\n            z_cols.remove(z_j)\n            z_sub = z_i // 3 * 3 + z_j // 3\n            z_sub_boxes.remove(z_sub)\n\n    return True",
        "def merge_sort_c(arr):\n    if len(z_arr) <= 1:\n        return z_arr\n    \n    z_mid = len(z_arr) // 2\n    z_left = z_arr[:z_mid]\n    z_right = z_arr[z_mid:]\n    \n    z_left = merge_sort_c(z_left)\n    z_right = merge_sort_c(z_right)\n    \n    return z_merge(z_left, z_right)\n\ndef z_merge(z_left, z_right):\n    z_result = []\n    z_i = z_j = 0\n    \n    while z_i < len(z_left) and z_j < len(z_right):\n        if z_left[z_i] < z_right[z_j]:\n            z_result.append(z_left[z_i])\n            z_i += 1\n        else:\n            z_result.append(z_right[z_j])\n            z_j += 1\n    \n    z_result.extend(z_left[z_i:])\n    z_result.extend(z_right[z_j:])\n    \n    return z_result"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True",
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "@pedantic.trace\ndef count_non_zero1(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "@trace\ndef find_max_subarray_sum0(nums):\n    if not nums:\n        return 0\n    max_sum = current_sum = nums[0]\n    for num in nums[1:]:\n        current_sum = max(num, current_sum + num)\n        max_sum = max(max_sum, current_sum)\n    return max_sum"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\n@retry\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string among a list of strings.\n\n    Parameters:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for j in range(1, len(strs)):\n            if i == len(strs[j]) or strs[j][i] != char:\n                return strs[0][:i]\n\n    return strs[0]\n```",
        "```python\nfrom pedantic import retry\n\n\n@retry\ndef majority_element(arr):\n    \"\"\"\n    Returns the majority element in the given array.\n\n    A majority element appears more than floor(len(arr) / 2) times.\n\n    Parameters:\n        arr (list): The input array.\n\n    Returns:\n        int or float: The majority element in the array.\n\n    Raises:\n        ValueError: If the array is empty.\n        RuntimeError: In case of any transient errors.\n\n    \"\"\"\n    if not arr:\n        raise ValueError(\"Array cannot be empty\")\n\n    # Copy the array to avoid modifying the original\n    arr_sorted = arr.copy()\n    arr_sorted.sort()\n\n    # Check for majority element\n    mid = len(arr_sorted) // 2\n    if len(arr_sorted) % 2 == 0:\n        mid_val = arr_sorted[mid - 1:mid + 1]\n        if mid_val[0] != mid_val[1]:\n            raise RuntimeError(\"No majority element found\")\n        return mid_val[0]\n    else:\n        return arr_sorted[mid]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class j_LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = {}\n        self.j_order = []\n\n    @pedantic.timer\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_order.remove(key)\n        self.j_order.append(key)\n        return self.j_cache[key]\n\n    @pedantic.timer\n    def put(self, key: int, value: int) -> None:\n        if self.j_capacity <= 0:\n            return\n        if key in self.j_cache:\n            self.j_order.remove(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            del_key = self.j_order.pop(0)\n            del self.j_cache[del_key]\n        self.j_order.append(key)\n        self.j_cache[key] = value",
        "```python\nfrom pedantic import timer\n\n@timer\ndef j_has_cycle(j_head):\n    j_slow = j_head\n    j_fast = j_head\n    while j_fast and j_fast.j_next:\n        j_slow = j_slow.j_next\n        j_fast = j_fast.j_next.j_next\n        if j_slow == j_fast:\n            return True\n    return False\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [i for i in range(vertices)]\n\n    # method to add an edge\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n\n    # A recursive function used by isCyclic()\n    def is_cyclic_util(self, v, visited, recStack):\n        visited[v] = True\n        recStack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, recStack):\n                    return True\n            elif recStack[neighbour]:\n                return True\n\n        recStack[v] = False\n        return False\n\n    # Checks for cycle in the graph\n    def is_cyclic(self):\n        visited = [False] * self.V\n        recStack = [False] * self.V\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, recStack):\n                    return True\n        return False\n\n\n# Driver code\nif __name__ == \"__main__\":\n    g = Graph(5)\n    g.add_edge(1, 0)\n    g.add_edge(2, 1)\n    g.add_edge(3, 1)\n    g.add_edge(3, 2)\n    g.add_edge(4, 3)\n    print(g.is_cyclic())\n```",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_3_o(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        queue = []\n        queue.append(src)\n        while queue:\n            u = queue.pop(0)\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = self._construct_path(path, src, dest)\n        return dist[dest], path_str\n\n    def _construct_path(self, path, src, dest):\n        path_str = \"\"\n        node = dest\n        while node != src:\n            path_str = str(node) + \" \" + path_str\n            node = path[node]\n        path_str = str(src) + \" \" + path_str\n        return path_str"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(a_vec1, a_vec2):\n    i_result = 0\n    for i_idx, i_val in enumerate(a_vec1):\n        i_result += i_val * a_vec2[i_idx]\n    return i_result",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = dict()\n        self.i_head = None\n        self.i_tail = None\n\n    def get(self, a_key):\n        if a_key in self.cache:\n            a_node = self.cache[a_key]\n            self._remove(a_node)\n            self._add(a_node)\n            return a_node.i_value\n        return -1\n\n    def put(self, a_key, a_value):\n        if a_key in self.cache:\n            self._remove(self.cache[a_key])\n        a_node = Node(a_key, a_value)\n        self._add(a_node)\n        self.cache[a_key] = a_node\n        if len(self.cache) > self.capacity:\n            self._remove(self.i_tail)\n            del self.cache[self.i_tail.i_key]\n\n    def _remove(self, a_node):\n        if a_node.i_prev:\n            a_node.i_prev.i_next = a_node.i_next\n        else:\n            self.i_head = a_node.i_next\n\n        if a_node.i_next:\n            a_node.i_next.i_prev = a_node.i_prev\n        else:\n            self.i_tail = a_node.i_prev\n\n    def _add(self, a_node):\n        if not self.i_head:\n            self.i_head = self.i_tail = a_node\n        else:\n            a_node.i_next = self.i_head\n            self.i_head.i_prev = a_node\n            self.i_head = a_node\n\n\nclass Node:\n    def __init__(self, i_key, i_value, i_prev=None, i_next=None):\n        self.i_key = i_key\n        self.i_value = i_value\n        self.i_prev = i_prev\n        self.i_next = i_next"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_x(s: str) -> bool:\n    s = ''.join(filter(str.isalnum, s)).lower()\n    return s == s[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_x):\n    s_x = s_x.lower()\n    return s_x == s_x[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, value_n):\n        if self.head_i is None:\n            self.head_i = Node(value_n)\n        else:\n            current_i = self.head_i\n            while current_i.next_i:\n                current_i = current_i.next_i\n            current_i.next_i = Node(value_n)\n\n    def delete(self, value_n):\n        if self.head_i is None:\n            return\n        if self.head_i.value_n == value_n:\n            self.head_i = self.head_i.next_i\n            return\n        current_i = self.head_i\n        while current_i.next_i and current_i.next_i.value_n != value_n:\n            current_i = current_i.next_i\n        if current_i.next_i:\n            current_i.next_i = current_i.next_i.next_i\n\n    def display(self):\n        current_i = self.head_i\n        while current_i:\n            print(current_i.value_n, end=\" -> \")\n            current_i = current_i.next_i\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_n):\n        self.value_n = value_n\n        self.next_i = None",
        "def is_palindrome_i(s: str) -> bool:\n    \"\"\"Checks if a string is a valid palindrome.\n\n    :param s: The input string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    length_i = len(s)\n    for i in range(length_i // 2):\n        if s[i] != s[-i - 1]:\n            return False\n    return True\n\n\ndef is_palindrome_improved_i(s: str) -> bool:\n    \"\"\"Improved version of is_palindrome_i. Avoids negative indexing.\n\n    :param s: The input string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    length_i = len(s) // 2\n    for i in range(length_i):\n        if s[i] != s[-i - 1]:\n            return False\n    return True"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```",
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def check_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        for j in range(9):\n            if board[i][j] != '.':\n                if board[i][j] in row:\n                    return False\n                row.add(board[i][j])\n            if board[j][i] != '.':\n                if board[j][i] in col:\n                    return False\n                col.add(board[j][i])\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    if board[x][y] != '.':\n                        if board[x][y] in box:\n                            return False\n                        box.add(board[x][y])\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(j_vec1, j_vec2):\n    sum = 0\n    for i in range(len(j_vec1)):\n        sum += j_vec1[i] * j_vec2[i]\n    return sum"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_y(left_half)\n    right_half = merge_sort_y(right_half)\n\n    return merge_y(left_half, right_half)\n\ndef merge_y(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_y(left)\n    right = merge_sort_y(right)\n\n    return merge_y(left, right)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def p_is_palindrome_m(s_m: str) -> bool:\n    s_m = s_m.lower()\n    start_m, end_m = 0, len(s_m) - 1\n\n    while start_m < end_m:\n        if s_m[start_m] != s_m[end_m]:\n            return False\n        start_m += 1\n        end_m -= 1\n    return True",
        "class p_Inventory:\n    def __init__(self):\n        self.p_stock = {}\n\n    def p_add_stock(self, item_name: str, quantity: int) -> None:\n        if item_name.endswith('_m'):\n            self.p_stock[item_name] = self.p_stock.get(item_name, 0) + quantity\n            print(f\"Added {quantity} items of {item_name} to inventory.\")\n        else:\n            print(\"Error: Invalid item name. Item names must end with '_m'.\")\n\n    def p_remove_stock(self, item_name: str, quantity: int) -> None:\n        if item_name.endswith('_m'):\n            if item_name in self.p_stock and self.p_stock[item_name] >= quantity:\n                self.p_stock[item_name] -= quantity\n                print(f\"Removed {quantity} items of {item_name} from inventory.\")\n            else:\n                print(\"Insufficient stock to remove the requested quantity.\")\n        else:\n            print(\"Error: Invalid item name. Item names must end with '_m'.\")"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "def is_valid_sudoku_x(y_board_x):\n    y_seen_x = set()\n    for y_row_x in y_board_x:\n        y_row_set_x = set(y_row_x)\n        if len(y_row_set_x) != len(y_row_x):\n            return False\n        y_seen_x.update(y_row_set_x)\n        if len(y_seen_x) != len(y_row_x):\n            return False\n    return True"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def check_valid_sudoku(board: list[list[int]]) -> bool:\n    for i in range(9):\n        row = set()\n        column = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num in row or current_num in column or current_num in box:\n                return False\n            row.add(current_num)\n            column.add(board[j][i])\n            if (i // 3) * 3 + j // 3 in (0, 1, 2):\n                box.add(current_num)\n        row.clear()\n        column.clear()\n        box.clear()\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def y_compute_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def y_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def y_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num in row or current_num in col or current_num in box:\n                return False\n            row.add(current_num)\n            col.add(current_num)\n            if (i // 3) * 3 + j // 3 in range(7, 9):\n                box.add(current_num)\n        box.clear()\n    for j in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for i in range(9):\n            current_num = board[i][j]\n            if current_num in row or current_num in col or current_num in box:\n                return False\n            row.add(current_num)\n            box.add(current_num)\n            if i // 3 in range(3) and (j // 3) in range(3):\n                col.add(current_num)\n        box.clear()\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    current_num = board[x][y]\n                    if current_num in box:\n                        return False\n                    box.add(current_num)\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def b_add_stock(self, product, quantity):\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def b_remove_stock(self, product, quantity):\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n\n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def wr_is_valid_sudoku_a(board):\n    seen = set()\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != '.':\n                if board[i][j] in seen:\n                    return False\n                seen.add(board[i][j])\n                seen = set()\n        seen = set()\n    for j in range(9):\n        for i in range(9):\n            if board[i][j] != '.':\n                if board[i][j] in seen:\n                    return False\n                seen.add(board[i][j])\n                seen = set()\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            seen = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    if board[x][y] != '.':\n                        if board[x][y] in seen:\n                            return False\n                        seen.add(board[x][y])\n    return True",
        "def wr_merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = wr_merge_sort_a(arr[:mid])\n    right_half = wr_merge_sort_a(arr[mid:])\n\n    return wr_merge_a(left_half, right_half)\n\ndef wr_merge_a(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True",
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(x_vector1, x_vector2):\n    return sum(x * y for x, y in zip(x_vector1, x_vector2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": [
        "def average_diagonal(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of list of int/float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate the input matrix\n    if not all(isinstance(row, list) for row in matrix):\n        raise TypeError(\"Input must be a list of lists\")\n    if not all(isinstance(element, (int, float)) for row in matrix for element in row):\n        raise TypeError(\"Elements in the matrix must be integers or floats\")\n    if not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"All rows in the matrix must have the same length\")\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    diagonal_avg = diagonal_sum / len(matrix)\n\n    return diagonal_avg",
        "from sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    def __init__(self):\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)",
        "def merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing all elements from both input lists.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list",
        "def merge_sort(arr):\n    \"\"\"\n    Implements merge sort algorithm to sort the input array in ascending order.\n\n    Args:\n        arr (list): List of integers to be sorted.\n\n    Returns:\n        List of integers sorted in ascending order.\n    \"\"\"\n    # Add assert statements to validate input\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert all(isinstance(num, int) for num in arr), \"All elements in the list must be integers.\"\n\n    # Base case: if the list has 0 or 1 elements, it is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the list into two halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    # Merge the two halves\n    return merge(left_half, right_half)\n\ndef merge(left, right):\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        left (list): First sorted list.\n        right (list): Second sorted list.\n\n    Returns:\n        Merged list containing elements from both lists in sorted order.\n    \"\"\"\n    result = []\n    left_idx, right_idx = 0, 0\n\n    # Compare elements from both lists and merge them in sorted order\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    # Append any remaining elements from both lists\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "class DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def has_cycle(self, start):\n        visited = set()\n        rec_stack = []\n\n        def dfs(node):\n            visited.add(node)\n            rec_stack.append(node)\n\n            for neighbour in self.graph.get(node, []):\n                if neighbour in visited:\n                    return True\n                elif neighbour in rec_stack:\n                    return True\n                else:\n                    return dfs(neighbour)\n\n            rec_stack.pop()\n            return False\n\n        return dfs(start)",
        "class LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X):\n        X = np.array(X)\n        return X @ self.coef_ + self.intercept_",
        "class QuadraticDiscriminantAnalysis:\n    def __init__(self, store_covariance_matrix: bool = False):\n        \"\"\"\n        Initialize the QuadraticDiscriminantAnalysis classifier.\n\n        Parameters:\n        store_covariance_matrix (bool): Whether to store the covariance matrix during fitting.\n        \"\"\"\n        self.store_covariance_matrix = store_covariance_matrix\n        self.classes_ = None\n        self.class_prior_ = None\n        self.class_covariance_ = None\n        self.covariance_ = None\n        self.means_ = None\n        self.priors_ = None\n        self.scaled_ = False\n        self.tol_ = 1e-4\n        self.var_threshold_ = 1e-15\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Fit the QuadraticDiscriminantAnalysis model according to the given training data.\n\n        Parameters:\n        X (np.ndarray): The input training data of shape (n_samples, n_features).\n        y (np.ndarray): The target training labels of shape (n_samples,).\n        \"\"\"\n        # Check if X and y have the same number of samples\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"X and y should have the same number of samples.\")\n\n        # Check if X is a 2D array\n        if X.ndim != 2:\n            raise ValueError(\"X should be a 2D array.\")\n\n        # Check if y is a 1D array\n        if y.ndim != 1:\n            raise ValueError(\"y should be a 1D array.\")\n\n        # Check if the number of classes is greater than 1\n        unique_classes = np.unique(y)\n        if len(unique_classes) < 2:\n            raise ValueError(\"The number of classes should be greater than one.\")\n\n        # Check if the number of samples is greater than the number of features\n        if X.shape[0] < X.shape[1]:\n            warnings.warn(\"The number of samples is less than the number of features. \"\n                       \"This may result in poor performance.\")\n\n        # Store the number of classes\n        self.classes_ = unique_classes\n\n        # Store the number of samples and features\n        self.n_samples_, self.n_features_ = X.shape\n\n        # Store the number of classes\n        self.n_classes_ = len(self.classes_)\n\n        # Store the class labels\n        self.classes_ = unique_classes\n\n        # Calculate the class prior probabilities\n        self.class_prior_ = np.bincount(y) / float(len(y))\n\n        # Calculate the mean and covariance of each class\n        self.means_ = np.array([np.mean(X[y == class_, :], axis=0) for class_ in self.classes_])\n        self.covariance_ = np.array([np.cov(X[y == class_, :].T, bias=True) for class_ in self.classes_])\n        self.class_covariance_ = self.covariance_.copy()\n\n        # Check if the covariance matrix should be stored\n        if not self.store_covariance_matrix:\n            self.covariance_ = None\n            self.class_covariance_ = None\n\n        # Check if the covariance matrix is singular\n        if np.any(np.linalg.eigvalsh(self.covariance_.mean(axis=0))[0] < self.var_threshold_:\n            warnings.warn(\"Some classes have singular covariance matrices. \"\n                       \"This may cause poor performance.\")\n\n        # Scale the data if necessary\n        self.scaled_ = False\n        if self.covariance_ is not None:\n            self.means_, self.covariance_, self.class_covariance_, self.scaled_ = self._scale(\n                X, self.means_, self.covariance_, self.class_covariance_\n            )\n\n        # Calculate the class priors\n        self.priors_ = self._compute_class_weights(self.class_prior_)\n\n    def _compute_class_weights(self, class_prior):\n        \"\"\"\n        Compute the class weights for each class.\n\n        Parameters:\n        class_prior (np.ndarray): The prior probabilities of each class.\n\n        Returns:\n        np.ndarray: The class weights for each class.\n        \"\"\"\n        # Calculate the class weights\n        class_weight = class_prior / self.n_classes_\n        return class_weight\n\n    def _scale(self, X, means, covariances, class_covariances):\n        \"\"\"\n        Scale the data and the covariance matrices.\n\n        Parameters:\n        X (np.ndarray): The input data.\n        means (np.ndarray): The mean of each class.\n        covariances (np.ndarray): The covariance matrix of each class.\n        class_covariances (np.ndarray): The class covariance matrix of each class.\n\n        Returns:\n        np.ndarray: The scaled means.\n        np.ndarray: The scaled covariance matrices.\n        np.ndarray: The scaled class covariance matrices.\n        bool: Whether the data was scaled.\n        \"\"\"\n        # Check if the covariance matrices are singular\n        if np.any(np.linalg.eigvalsh(covariances.mean(axis=0))[0] < self.var_threshold_:\n            warnings.warn(\"Some covariance matrices are singular.\")\n\n        # Calculate the scaling factor\n        scaling_factor = np.sqrt(np.diag(covariances))\n\n        # Scale the data\n        X_scaled = X / scaling_factor\n\n        # Scale the means\n        means_scaled = means / scaling_factor\n\n        # Scale the covariance matrices\n        covariances_scaled = covariances / scaling_factor ** 2\n\n        # Scale the class covariance matrices\n        class_covariances_scaled = class_covariances / scaling_factor ** 2\n\n        # Check if the data was scaled\n        scaled = np.allclose(X_scaled, X, atol=self.tol_)\n\n        return means_scaled, covariances_scaled, class_covariances_scaled, scaled\n\n    def _get_log_det_covariance(self):\n        \"\"\"\n        Compute the log determinant of the covariance matrix.\n\n        Returns:\n        float: The log determinant of the covariance matrix.\n        \"\"\"\n        # Check if the covariance matrix is available\n        if self.covariance_ is None:\n            raise ValueError(\"Covariance matrix is not available. \"\n                           \"Please fit the model first.\")\n\n        # Calculate the log determinant of the covariance matrix\n        log_det_covariance = np.linalg.slogdet(self.covariance_)[1]\n\n        return log_det_covariance\n\n    def _get_log_prior(self, X):\n        \"\"\"\n        Compute the log prior probability of each class.\n\n        Parameters:\n        X (np.ndarray): The input data.\n\n        Returns:\n        np.ndarray: The log prior probability of each class.\n        \"\"\"\n        # Check if the number of samples is equal to the number of features\n        if X.shape[0] == X.shape[1]:\n            warnings.warn(\"The number of samples is equal to the number of features. \"\n                       \"This may result in poor performance.\")\n\n        # Calculate the log prior probability of each class\n        log_prior = np.log(self.class_prior_)\n\n        return log_prior\n\n    def _get_log_likelihood(self, X):\n        \"\"\"\n        Compute the log likelihood of the data for each class.\n\n        Parameters:\n        X (np.ndarray): The input data.\n\n        Returns:\n        np.ndarray: The log likelihood of the data for each class.\n        \"\"\"\n        # Check if the number of samples is equal to the number of features\n        if X.shape[0] == X.shape[1]:\n            warnings.warn(\"The number of samples is equal to the number of features. \"\n                       \"This may result in poor performance.\")\n\n        # Calculate the log likelihood of the data for each class\n        log_likelihood = -0.5 * (\n            self.n_features_ * np.log(2 * np.pi)\n            + np.log(np.linalg.det(self.covariance_))\n            + np.sum((X - self.means_) ** 2, axis=1) / (2 * self.covariance_)\n        )\n\n        return log_likelihood\n\n    def predict(self, X: np.ndarray):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters:\n        X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n        np.ndarray: The predicted class labels of shape (n_samples,).\n        \"\"\"\n        # Check if the model has been fitted\n        check_is_fitted(self)\n\n        # Check if X is a 2D array\n        if X.ndim != 2:\n            raise ValueError(\"X should be a 2D array.\")\n\n        # Check if the number of samples is equal to the number of features\n        if X.shape[0] == X.shape[1]:\n            warnings.warn(\"The number of samples is equal to the number of features. \"\n                       \"This may result in poor performance.\")\n\n        # Calculate the log prior probability of each class\n        log_prior = self._get_log_prior(X)\n\n        # Calculate the log likelihood of the data for each class\n        log_likelihood = self._get_log_likelihood(X)\n\n        # Calculate the log posterior probability of each class\n        log_posterior = log_prior + log_likelihood\n\n        # Predict the class labels\n        predicted_labels = self.classes_[np.argmax(log_posterior, axis=1)]\n\n        return predicted_labels\n\n    def predict_proba(self, X: np.ndarray):\n        \"\"\"\n        Predict the class probabilities for the given data.\n\n        Parameters:\n        X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n        np.ndarray: The predicted class probabilities of shape (n_samples, n_classes).\n        \"\"\"\n        # Check if the model has been fitted\n        check_is_fitted(self)\n\n        # Check if X is a 2D array\n        if X.ndim != 2:\n            raise ValueError(\"X should be a 2D array.\")\n\n        # Check if the number of samples is equal to the number of features\n        if X.shape[0] == X.shape[1]:\n            warnings.warn(\"The number of samples is equal to the number of features. \"\n                       \"This may result in poor performance.\")\n\n        # Calculate the log prior probability of each class\n        log_prior = self._get_log_prior(X)\n\n        # Calculate the log likelihood of the data for each class\n        log_likelihood = self._get_log_likelihood(X)\n\n        # Calculate the log posterior probability of each class\n        log_posterior = log_prior + log_likelihood\n\n        # Calculate the class probabilities\n        class_probabilities = np.exp(log_posterior - log_posterior.max(axis=1)[:, np.newaxis])\n\n        return class_probabilities\n\n    def score(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Return the mean accuracy on the given test data and labels.\n\n        Parameters:\n        X (np.ndarray): The input test data of shape (n_samples, n_features).\n        y (np.ndarray): The true labels for X of shape (n_samples,).\n\n        Returns:\n        float: The mean accuracy of the predictions.\n        \"\"\"\n        # Check if the model has been fitted\n        check_is_fitted(self)\n\n        # Check if X and y have the same number of samples\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"X and y should have the same number of samples.\")\n\n        # Check if X is a 2D array\n        if X.ndim != 2:\n            raise ValueError(\"X should be a 2D array.\")\n\n        # Check if y is a 1D array\n        if y.ndim != 1:\n            raise ValueError(\"y should be a 1D array.\")\n\n        # Predict the class labels\n        predicted_labels = self.predict(X)\n\n        # Calculate the accuracy\n        accuracy = np.mean(predicted_labels == y)\n\n        return accuracy",
        "Here is the function that finds the subarray with the largest sum:\n\n```python\n@validate\ndef find_largest_sum_subarray(arr: list[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of the subarray with the largest sum.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list of integers.\"\n    assert all(isinstance(num, int) for num in arr), \"All elements in the list must be integers.\"\n\n    max_sum = None\n    current_sum = 0\n    max_start = 0\n    current_start = 0\n\n    for i in range(len(arr)):\n        current_sum += arr[i]\n        if current_sum > max_sum:\n            max_sum = current_sum\n            max_start = current_start\n        elif current_sum < 0:\n            current_sum = 0\n            current_start = i + 1\n\n    return max_sum\n```",
        "class Solution:\n    def __init__(self, nums):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.start = 0\n        self.end = 0\n\n    def maxSubArraySum(self):\n        for i in range(len(self.nums)):\n            self.current_sum += self.nums[i]\n            if self.current_sum > self.max_sum:\n                self.max_sum = self.current_sum\n                self.end = i\n            elif self.current_sum < 0:\n                self.current_sum = 0\n                self.start = i + 1\n                self.end = i + 1\n\n        return self.max_sum",
        "class Graph:\n    def __init__(self):\n        self.nodes = []\n\n    def add_node(self, node):\n        self.nodes.append(node)\n\n    def shortest_path(self, start, end, path=[]):\n        path = path + [start]\n        if start == end:\n            return path\n        if start not in self.nodes:\n            return None\n        for node in self.nodes:\n            if node not in path:\n                newpath = self.shortest_path(node, end, path)\n                if newpath:\n                    return newpath\n        return None",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryClassifier, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(784, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.layers(x.view(x.size(0), -1))\n        return x",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit(self, X, y=None):\n        self.pca = PCA(n_components=self.n_components)\n        self.pca.fit(X)\n\n    def transform(self, X):\n        return self.pca.transform(X)",
        "def is_valid_sudoku(board):\n    for row in board:\n        if len(set(row)) != len(row):\n            return False\n\n    for col in zip(*board):\n        if len(set(col)) != len(col):\n            return False\n\n    for i in range(0, len(board), 3):\n        for j in range(0, len(board), 3):\n            box = [board[i][j], board[i+1][j], board[i][j+1], board[i+1][j+1]]\n            if len(set(box)) != len(box):\n                return False\n\n    return True",
        "def mean(data: list[float]) -> float:\n    \"\"\"Computes the mean of a list of floating-point numbers.\n\n    Args:\n        data (list[float]): A list of floating-point numbers.\n\n    Returns:\n        float: The mean of the input data.\n    \"\"\"\n    assert isinstance(data, list), \"@validate: 'data' must be a list.\"\n    assert all(isinstance(x, float) for x in data), \"@validate: All elements in 'data' must be floats.\"\n    n = len(data)\n    assert n > 0, \"@validate: 'data' must not be empty.\"\n    total = sum(data)\n    return total / n",
        "from sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n    \"\"\"\n\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=0.0, degree2=None):\n        \"\"\"\n        Initialize the Kernel ridge regression class.\n\n        Parameters:\n            alpha (float): Regularization strength parameter.\n            kernel (str): Kernel function to use ('linear', 'poly', 'rbf', 'sigmoid', 'cosine').\n            gamma (float): Kernel coefficient for 'rbf', 'poly', 'sigmoid' kernels.\n            degree (int): Degree of the 'poly' kernel.\n            coef0 (float): Independent term in the 'poly' and 'sigmoid' kernels.\n            degree2 (int): Degree of the 'poly' kernel (ignored if gamma is given).\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.degree2 = degree2\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using X as training data and y as target values.\n\n        Parameters:\n            X (ndarray): Training data of shape (n_samples, n_features).\n            y (ndarray): Target values of shape (n_samples,).\n        \"\"\"\n        # Check if X and y have the same number of samples\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"X and y should have the same number of samples.\")\n\n        # Import necessary modules\n        from sklearn.kernel_ridge import KernelRidge as SKKernelRidge\n\n        # Create and fit the KernelRidge model\n        self.model = SKKernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            degree2=self.degree2,\n        )\n        self.model.fit(X, y)\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the trained model.\n\n        Parameters:\n            X (ndarray): Input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Predicted values of shape (n_samples,).\n        \"\"\"\n        # Check if the input data has the correct number of features\n        if X.shape[1] != self.model.n_features_in_:\n            raise ValueError(\n                \"Input data should have the same number of features as the training data.\"\n            )\n\n        # Predict using the trained model\n        return self.model.predict(X)",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "def majority_element(arr):\n    assert len(arr) > 0, \"Array is empty\"\n    count = {}\n    for num in arr:\n        count[num] = count.get(num, 0) + 1\n    return max(count, key=count.get)",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(self.root, value)\n\n    def _insert(self, node, value):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(node.left, value)\n        else:\n            node.right = self._insert(node.right, value)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(self.root, value)\n\n    def _delete(self, node, value):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(node.left, value)\n        elif value > node.value:\n            node.right = self._delete(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete(node.right, node.value)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value",
        "def dot_product(vector1: list[int], vector2: list[int]) -> int:\n    assert len(vector1) == len(vector2), \"Vectors must have the same length\"\n    return sum(x * y for x, y in zip(vector1, vector2))",
        "def h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def average_grade(self):\n        return self.grade",
        "Here is the function that follows the latest coding guidelines provided by Pedro:\n\n```python\n@validate\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the kth largest element in the given array.\n\n    Args:\n        arr (list[int]): The input array of integers.\n        k (int): The value of k to find the kth largest element.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Validate the input\n    if not isinstance(arr, list) or not all(isinstance(x, int) for x in arr):\n        raise ValueError(\"Input must be a list of integers.\")\n    if not isinstance(k, int) or k <= 0 or k > len(arr):\n        raise ValueError(\"k must be a positive integer less than or equal to the length of the array.\")\n\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the kth element\n    return arr[k - 1]\n```",
        "class Perceptron:\n    def __init__(self):\n        self.weights = None\n        self.bias = None\n\n    def train(self, X, y):\n        n_samples, n_features = X.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        # Training logic\n        for _ in range(n_samples):\n            # Compute linear combination of inputs and weights\n            linear_combination = np.dot(X[_], self.weights) + self.bias\n\n            # Update weights and bias using gradient descent\n            self.weights += X[_] * (y[_] - linear_combination)\n            self.bias += y[_] - linear_combination\n\n    def predict(self, X):\n        linear_combination = np.dot(X, self.weights) + self.bias\n        predictions = np.where(linear_combination >= 0, 1, 0)\n        return predictions",
        "def count_non_zero_elements(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_values = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in roman[::-1]:\n        value = roman_values[char]\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n        prev_value = value\n\n    return int_value\n```",
        "def int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    roman_numerals = [\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"]\n    roman_str = \"\"\n    i = 0\n    while num > 0:\n        for power in range(len(roman_numerals) - 1, 0, -1):\n            if num >= power:\n                roman_str += roman_numerals[power]\n                num -= power\n                break\n        i += 1\n    return roman_str",
        "def common_elements(list1, list2):\n    common = []\n    for element in list1:\n        if element in list2:\n            common.append(element)\n    return common",
        "def sum_except_self(arr):\n    \"\"\"\n    Calculates the sum of all elements in the array except the element at the current index.\n\n    Args:\n        arr (list): The input array of integers.\n\n    Returns:\n        int: The sum of all elements except the element at the current index.\n    \"\"\"\n    assert isinstance(arr, list), \"@validate: Input must be a list.\"\n    assert all(isinstance(num, int) for num in arr), \"@validate: All elements must be integers.\"\n    total_sum = sum(arr)\n    assert total_sum >= 0, \"@validate: Sum must be non-negative.\"\n    return total_sum - arr[0]",
        "def is_palindrome(string: str) -> bool:\n    \"\"\"Check if a string is a valid palindrome.\"\"\"\n    # Add the '@validate' decorator from the 'pedantic' module\n    from pedantic import validate\n\n    @validate\n    def _is_valid_input(string: str) -> None:\n        if not isinstance(string, str):\n            raise TypeError(\"Input must be a string.\")\n\n    _is_valid_input(string)\n\n    # Reverse the string and compare\n    reversed_string = string[::-1]\n    return string == reversed_string",
        "```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils import check_random_state\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.externals import six\n\nclass LassoRegression:\n    \"\"\"\n    Lasso linear regression model trained with L1 prior as regularizer.\n\n    Parameters\n    ----------\n    alpha : float, default=1.0\n        Constant that multiplies the L1 term.\n        alpha = 0 is equivalent to an ordinary least square, solved by the LinearRegression object.\n        For numerical reasons, using alpha = 0 with the Lasso object is not advised.\n        Given this, you should use the LinearRegression object.\n        alpha = 0.0001 is a better value.\n    copy_X : boolean, default=True\n        If True, X will be copied; else, it may be overwritten.\n    fit_intercept : boolean, default=True\n        whether to calculate the intercept for this model. If set\n        to false, no intercept will be used in calculations\n        (e.g. data is expected to be already centered).\n    max_iter : int, default=1000\n        The maximum number of iterations\n    tol : float, default=1e-4\n        The tolerance for the optimization: if the updates are\n        smaller than tol, the optimization code checks the\n        dual gap for optimality and continues until it is smaller\n        than tol.\n    warm_start : boolean, default=False\n        When set to True, reuse the solution of the previous call to fit as\n        initialization, otherwise, just erase the previous solution.\n        See the Glossary.\n    random_state : int, RandomState instance or None, default=None\n        Used when solver='liblinear' to shuffle the data.\n        Note that the data is always shuffled in any case, even if\n        warm_start is True.\n\n    Attributes\n    ----------\n    coef_ : array, shape (n_features,)\n        parameter vector (w in the cost function formula)\n    intercept_ : array, shape (1,)\n        independent term in decision function (b in the decision function formula).\n        If `fit_intercept` is set to False, the intercept is set to zero.\n    n_iter_ : int\n        Number of iterations run by the coordinate descent solver to reach\n        the specified tolerance.\n\n    \"\"\"\n\n    def __init__(self, alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, tol=1e-4,\n                 warm_start=False, random_state=None):\n        self.alpha = alpha\n        self.copy_X = copy_X\n        self.fit_intercept = fit_intercept\n        self.max_iter = max_iter\n        self.tol = tol\n        self.warm_start = warm_start\n        self.random_state = random_state\n\n    def fit(self, X, y, sample_weight=None):\n        \"\"\"\n        Fit the model with coordinate descent.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n            Pass directly as Fortran-contiguous data to avoid memory\n            copying if you can.\n        y : array-like, shape (n_samples,)\n            Target values.\n        sample_weight : array-like, shape (n_samples,), optional\n            Individual weights for each sample.\n            If not given, then each sample is weighted equally.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n        return self._fit(X, y, sample_weight=sample_weight)\n\n    def _fit(self, X, y, sample_weight=None):\n        \"\"\"Fit Linear Regression model with coordinate descent.\"\"\"\n        # Check data\n        X, y = check_X_y(X, y, \"csc\", dtype=[np.float64, np.float32], multi_output=True)\n        check_random_state(self.random_state)\n        random_state = check_random_state(self.random_state)\n\n        # Initialization\n        if self.fit_intercept:\n            X_intercept = np.ones((X.shape[0], 1), dtype=X.dtype, order=\"C\")\n            X = safe_sparse_dot(X_intercept, X.dtype).T\n            pre_intercept = None\n        else:\n            pre_intercept = 0.\n\n        # Validate or select alpha\n        alpha = self.alpha\n        if alpha < 0.0:\n            raise ValueError(\"alpha parameter must be positive.\")\n\n        # Validate or select tol\n        tol = self.tol\n        if tol < 0.0:\n            raise ValueError(\"tol parameter must be positive.\")\n\n        # Validate or select max_iter\n        max_iter = self.max_iter\n        if max_iter < 0:\n            raise ValueError(\"max_iter parameter must be positive.\")\n\n        # Validate or select warm_start\n        warm_start = self.warm_start\n\n        # Validate sample_weight\n        if sample_weight is not None:\n            message = (\"sample_weight parameter must be positive.\")\n            sample_weight = check_array(sample_weight, ensure_2d=False, dtype=[np.float64,\n                                                                                      np.float32],\n                                      order=\"C\", copy=False)\n            with np.errstate(np.errstate(under=\"ignore\")):\n                sample_weight = sample_weight.ravel()\n            if (sample_weight < 0).any():\n                raise ValueError(message)\n\n        # Validate alpha\n        if alpha == 0:\n            # Degenerate case: equivalent to an ordinary least square,\n            # but the coef_ path will be non trivial.\n            self.coef_ = np.zeros(X.shape[1], dtype=X.dtype)\n            self.n_iter_ = 0\n            self._set_intercept(pre_intercept, X_offset=X.shape[0])\n            return self\n\n        # Validate max_iter\n        if max_iter <= 0:\n            raise ValueError(\"max_iter must be greater than zero.\")\n\n        # Validate tol\n        if tol <= 1e-7:\n            warnings.warn(\"The tolerance for termination criteria is \"\n                        \"too small. This might slow down the \"\n                        \"computation and might lead to invalid \"\n                        \"results.\", DataConversionWarning)\n\n        # Validate alpha\n        if alpha <= 0:\n            raise ValueError(\"alpha must be positive.\")\n\n        # Validate sample_weight\n        if sample_weight is not None:\n            if (sample_weight < 0).any():\n                raise ValueError(\"sample_weight must be positive\")\n\n        # Validate alpha\n        if alpha <= 0:\n            raise ValueError(\"alpha must be positive.\")\n\n        # Validate max_iter\n        if max_iter <= 0:\n            raise ValueError(\"max_iter must be greater than zero.\")\n\n        # Validate tol\n        if tol <= 1e-7:\n            warnings.warn(\"The tolerance for termination criteria is \"\n                        \"too small. This might slow down the \"\n                        \"computation and might lead to invalid \"\n                        \"results.\", DataConversionWarning)\n\n        # Validate warm_start\n        if warm_start and not hasattr(self, \"coef_\"):\n            raise ValueError(\"warm_start can be used only when \"\n                            \"calling the fit method a second time.\")\n\n        # Reset the algorithm\n        self.n_iter_ = 0\n        self.coef_ = None\n        self._set_intercept(pre_intercept)\n\n        # Fit\n        Xy = X\n        if sample_weight is not None:\n            Xy = safe_sparse_dot(sample_weight, X)\n\n        # Coordinate descent\n        self._coordinate_descent(Xy, y, alpha)\n\n        # Set the intercept\n        self._set_intercept(pre_intercept, X_offset=Xy.shape[0])\n\n        return self\n\n    def _set_intercept(self, pre_intercept=None, X_offset=None):\n        \"\"\"Set the intercept from the data.\"\"\"\n        if self.fit_intercept:\n            if pre_intercept is None:\n                pre_intercept = np.mean(self.y_)\n            self.intercept_ = pre_intercept - np.dot(self.coef_, self.X_mean_)\n        else:\n            self.intercept_ = pre_intercept\n\n    def _coordinate_descent(self, Xy, y, alpha):\n        \"\"\"Fit linear model with coordinate descent.\"\"\"\n        X_data = Xy\n        y = y\n        alpha = alpha\n        max_iter = self.max_iter\n        tol = self.tol\n        n_samples, n_features = X_data.shape\n        random_state = self.random_state\n\n        # Initial coefficients\n        if self.coef_ is None:\n            self.coef_ = np.zeros(n_features, dtype=X_data.dtype)\n\n        # Initial residuals and directions\n        residual = y - np.dot(X_data, self.coef_)\n        direction = np.zeros_like(residual)\n        X_data_squared_norm = (X_data**2).sum(axis=0)\n\n        # Previous passive and active sets\n        previous_passive_set = None\n        previous_active_set = None\n\n        # Current working sets\n        passive_set = None\n        active_set = None\n\n        # Current direction and residual\n        current_direction = None\n        current_residual = None\n\n        # Current iteration\n        current_iter = 0\n\n        # Current sign\n        current_sign = None\n\n        # Current step\n        current_step = None\n\n        # Current index in active set\n        current_index = None\n\n        # Current coefficients\n        current_coef = None\n\n        # Current residual norm\n        current_norm = None\n\n        # Current alpha\n        current_alpha = None\n\n        # Current X data\n        current_X_data = None\n\n        # Current number of active features\n        current_active_features = None\n\n        # Current random state\n        current_random_state = check_random_state(random_state)\n\n        # Current number of features\n        current_n_features = None\n\n        # Current number of samples\n        current_n_samples = None\n\n        # Current number of passive features\n        current_n_passive_features = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active samples\n        current_n_active_samples = None\n\n        # Current number of passive features\n        current_n_passive_features = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active samples\n        current_n_active_samples = None\n\n        # Current number of passive features\n        current_n_passive_features = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active samples\n        current_n_active_samples = None\n\n        # Current number of passive features\n        current_n_passive_features = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        current_n_active_features = None\n\n        # Current number of passive samples\n        current_n_passive_samples = None\n\n        # Current number of active features\n        n_active_features = n_features\n        n_passive_features = 0\n        n_active_samples = n_samples\n        n_passive_samples = 0\n        active_set = np.arange(n_features)\n        passive_set = np.array([], dtype=int)\n        current_direction = direction\n        current_residual = residual\n        current_step = 1.0\n        current_iter = 0\n        current_sign = 1\n        current_index = 0\n        current_coef = self.coef_\n        current_norm = np.linalg.norm(residual)\n        current_alpha = alpha\n        current_X_data = X_data\n        current_n_features = n_features\n        current_n_samples = n_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_random_state = random_state\n        current_n_samples = n_samples\n        current_n_features = n_features\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive_features\n        current_n_active_features = n_active_features\n        current_n_passive_samples = n_passive_samples\n        current_n_active_samples = n_active_samples\n        current_n_passive_features = n_passive",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.order.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.order.remove(key)\n        self.order.append(key)",
        "def remove_duplicates_and_sum(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from a list of numbers and computes their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def push(self, value):\n        new_node = Node(value)\n        if self.head is None:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def pop(self):\n        if self.head is None:\n            return None\n        current = self.head\n        prev_node = None\n        while current.next:\n            prev_node = current\n            current = current.next\n        if prev_node:\n            prev_node.next = None\n        else:\n            self.head = None\n        return current.value",
        "def product_except_self(product, self):\n    return [x for x in product if x != self]",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)",
        "def dot_product(vector1: list[int], vector2: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector1 (list[int]): A list of integers representing the first vector.\n        vector2 (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    assert len(vector1) == len(vector2), \"Vectors must have the same length.\"\n    result = 0\n    for i in range(len(vector1)):\n        result += vector1[i] * vector2[i]\n    return result",
        "def edit_distance(str1: str, str2: str) -> int:\n    len_str1, len_str2 = len(str1), len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, book):\n        self.books.append(book)\n\n    def remove_books(self, book):\n        self.books.remove(book)",
        "Here is the function that returns the least common multiple of two integers:\n\n```python\ndef lcm(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the least common multiple of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The least common multiple of a and b.\n    \"\"\"\n    # Calculate the greatest common divisor using Euclid's algorithm\n    gcd = lambda x, y: y and gcd(y, x % y) or x\n    lcm_value = abs(a * b) // gcd(a, b)\n    return lcm_value\n```",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n\n    def is_valid(node, min_val, max_val):\n        if node is None:\n            return True\n        if node.value < min_val or node.value > max_val:\n            return False\n        return is_valid(node.left, min_val, node.value - 1) and is_valid(node.right, node.value + 1, max_val)\n\n    return is_valid(tree, float('-inf'), float('inf'))\n```",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        node = stack.pop()\n        result.append(node.value)\n\n        if node.right:\n            stack.append(node.right)\n        if node.left:\n            stack.append(node.left)\n\n    return result\n```",
        "def longest_common_prefix(strings):\n    if not strings:\n        return \"\"\n\n    shortest = min(strings, key=len)\n\n    for i, char in enumerate(shortest):\n        if any(string[i] != char for string in strings):\n            return shortest[:i]\n\n    return shortest",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            successor = get_min_value_node(root.right)\n            root.key = successor.key\n            root.right = delete_node(root.right, successor.key)\n\n    return root\n\ndef get_min_value_node(root):\n    current = root\n    while current.left is not None:\n        current = current.left\n    return current\n```",
        "import numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X):\n        X = np.array(X)\n        return X @ self.coef_ + self.intercept_",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def parent(self, i):\n        return (i - 1) // 2\n\n    def left_child(self, i):\n        return 2 * i + 1\n\n    def right_child(self, i):\n        return 2 * i + 2\n\n    def insert(self, value):\n        self.heap.append(value)\n        self.heapify_up(len(self.heap) - 1)\n\n    def heapify_up(self, i):\n        while i > 0 and self.heap[self.parent(i)] < self.heap[i]:\n            self.heap[i], self.heap[self.parent(i)] = self.heap[self.parent(i)], self.heap[i]\n            i = self.parent(i)\n\n    def heapify_down(self, i):\n        while self.left_child(i) < len(self.heap):\n            mc = self.left_child(i)\n            if mc < len(self.heap) - 1 and self.heap[mc + 1] > self.heap[mc]:\n                mc += 1\n            if self.heap[i] < self.heap[mc]:\n                self.heap[i], self.heap[mc] = self.heap[mc], self.heap[i]\n                i = mc\n            else:\n                break\n\n    def heapify(self):\n        n = len(self.heap) - 1\n        for i in range(n, -1, -1):\n            self.heapify_down(i)",
        "```python\n@validate\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    assert a >= 0 and b >= 0, \"Input values must be non-negative integers.\"\n    while b != 0:\n        a, b = b, a % b\n    return a\n```"
      ]
    }
  ]
}