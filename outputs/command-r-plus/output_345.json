{
  "sessions": [
    {
      "session_model_output": [
        "class BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Inserts a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        Args:\n            value: The value to be inserted.\n            node: The current node in the recursive traversal.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Deletes the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        Args:\n            value: The value of the node to be deleted.\n            node: The current node in the recursive traversal.\n\n        Returns:\n            The new root of the modified subtree, or None if the node is found and deleted.\n        \"\"\"\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node has two children\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node):\n        \"\"\"\n        Recursive helper function to find the minimum value in a subtree.\n\n        Args:\n            node: The root of the subtree.\n\n        Returns:\n            The minimum value in the subtree.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n\nclass Node:\n    \"\"\"\n    A node in the binary tree.\n    \"\"\"\n\n    def __init__(self, value):\n        \"\"\"\n        Initializes a new node with the given value.\n\n        Args:\n            value: The value to be stored in the node.\n        \"\"\"\n        self.value = value\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def fn_is_palindrome(str_w: str) -> bool:\n    str_w = str_w.lower()\n    start_i_w = 0\n    end_i_w = len(str_w) - 1\n\n    while start_i_w < end_i_w:\n        if str_w[start_i_w] != str_w[end_i_w]:\n            return False\n        start_i_w += 1\n        end_i_w -= 1\n\n    return True",
        "def fn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_w):\n    s_w = s_w.lower()\n    return s_w == s_w[::-1]",
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value) -> bool:\n        \"\"\"Insert a value into the binary tree.\n\n        Args:\n            value (int): The value to be inserted.\n\n        Returns:\n            bool: True if the value was inserted successfully, False if the value already exists.\n        \"\"\"\n        if self.root is None:\n            self.root = Node(value)\n            return True\n        else:\n            return self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value) -> bool:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n                return True\n            else:\n                return self._insert_recursive(node.left, value)\n        elif value > node.value:\n            if node.right is None:\n                node.right = Node(value)\n                return True\n            else:\n                return self._insert_recursive(node.right, value)\n        else:\n            return False\n\n    def delete(self, value) -> bool:\n        \"\"\"Delete a value from the binary tree.\n\n        Args:\n            value (int): The value to be deleted.\n\n        Returns:\n            bool: True if the value was found and deleted successfully, False otherwise.\n        \"\"\"\n        self.root, deleted = self._delete_recursive(self.root, value)\n        return deleted\n\n    def _delete_recursive(self, node, value) -> tuple:\n        if node is None:\n            return node, False\n\n        if value < node.value:\n            node.left, deleted = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right, deleted = self._delete_recursive(node.right, value)\n        else:\n            # Case 1: Node has no children or only one child\n            if node.left is None and node.right is None:\n                node = None\n                deleted = True\n\n            # Case 2: Node has one child\n            elif node.left is None:\n                node = node.right\n                deleted = True\n            elif node.right is None:\n                node = node.left\n                deleted = True\n\n            # Case 3: Node has two children\n            else:\n                successor = self._find_min(node.right)\n                node.value = successor.value\n                node.right, _ = self._delete_recursive(node.right, successor.value)\n                deleted = True\n\n        return node, deleted\n\n    def _find_min(self, node):\n        while node.left is not None:\n            node = node.left\n        return node",
        "```python\ndef average_diagonal_elements(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    size = len(matrix)\n    assert size == len(matrix[0]), \"Input matrix must be square.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the kth largest element in the given array.\n    \n    Args:\n        arr (list[int]): The input array of integers.\n        k (int): The value of 'k' for the kth largest element.\n    \n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    sorted_arr = sorted(arr, reverse=True)\n\n    # Return the kth element from the sorted array\n    return sorted_arr[k - 1]\n\n# Function annotation example\n# kth_largest_num = find_kth_largest(arr=[12, 3, 5, 7, 9, 1], k=3)\n```",
        "```python\ndef merge_sorted_lists(list1_j: list[int], list2_j: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1_j (list[int]): The first sorted list.\n        list2_j (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A single sorted list containing elements from both input lists.\n    \"\"\"\n    result_j = []\n    i, j = 0, 0\n\n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            result_j.append(list1_j[i])\n            i += 1\n        else:\n            result_j.append(list2_j[j])\n            j += 1\n\n    result_j.extend(list1_j[i:])\n    result_j.extend(list2_j[j:])\n\n    return result_j\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]",
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0,\n                               kernel_params=kernel_params, fit_intercept=fit_intercept, normalize=normalize,\n                               copy_X=copy_X, verbose=verbose)\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def convert_to_roman(num):\n    \"\"\"\n    Converts an integer to a Roman numeral.\n    \"\"\"\n    # Assert statement to check for valid input\n    assert isinstance(num, int) and num >= 0, \"Input must be a non-negative integer.\"\n\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman\n```",
        "```python\nfrom collections import defaultdict\n\nclass NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the Nearest Neighbors classifier.\n        \"\"\"\n        self.X = None\n        self.y = None\n\n    def train(self, X, y):\n        \"\"\"\n        Trains the Nearest Neighbors model.\n        Args:\n            X: A matrix of training examples.\n            y: A vector of target values.\n        \"\"\"\n        # Assert statements to catch errors early\n        assert X.shape[0] == y.shape[0], \"Number of training examples and target values must be the same\"\n\n        self.X = X\n        self.y = y\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the target values for the given test examples using the k-Nearest Neighbors algorithm.\n        Args:\n            X: A matrix of test examples.\n        Returns:\n            A vector of predicted target values.\n        \"\"\"\n        # Assert statement to ensure the model is trained before making predictions\n        assert self.X is not None and self.y is not None, \"Model must be trained before making predictions\"\n\n        # Placeholder for the predicted values\n        predictions = defaultdict(int)\n\n        # Iterate through each test example\n        for i in range(X.shape[0]):\n            # Find the nearest neighbor in the training data\n            nearest_neighbor = self._find_nearest_neighbor(X[i, :])\n\n            # Increment the count of the nearest neighbor's target value\n            predictions[nearest_neighbor] += 1\n\n        return list(predictions.keys())\n\n    def _find_nearest_neighbor(self, test_example):\n        # Placeholder implementation: returns the most common target value\n        # Actual implementation would calculate the distance between the test example and each training example,\n        # and return the label of the closest training example.\n        target_counts = defaultdict(int)\n        for i in range(self.y.shape[0]):\n            target_counts[self.y[i]] += 1\n        most_common = max(target_counts, key=target_counts.get)\n        return most_common\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\n\n@retry\ndef find_majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n        if element_count[element] > len(arr) // 2:\n            return element\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class PCA8:\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit_transform(self, data):\n        # Perform PCA and reduce dimensions to self.n_components\n        ...\n\n    def fit(self, data):\n        # Learn the PCA transformation from data\n        ...\n\n    def transform(self, data):\n        # Transform data using the fitted PCA model\n        ...\n\n    def inverse_transform(self, data):\n        # Inverse transform data back to original space\n        ..."
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    i_i = j_i = 0\n    merged_list_i = []\n\n    while i_i < len(list1_i) and j_i < len(list2_i):\n        if list1_i[i_i] < list2_i[j_j]:\n            merged_list_i.append(list1_i[i_i])\n            i_i += 1\n        else:\n            merged_list_i.append(list2_i[j_j])\n            j_j += 1\n\n    merged_list_i.extend(list1_i[i_i:])\n    merged_list_i.extend(list2_i[j_j:])\n\n    return merged_list_i"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure consistent results\n    strs.sort()\n\n    # Get the first and last string in the sorted list\n    first_str = strs[0]\n    last_str = strs[-1]\n\n    # Initialize variables to track common prefix and index\n    common_prefix = \"\"\n    idx = 0\n\n    # Iterate until the end of the first or last string is reached\n    while idx < len(first_str) and idx < len(last_str):\n        # If characters match, add to common prefix and move to the next character\n        if first_str[idx] == last_str[idx]:\n            common_prefix += first_str[idx]\n            idx += 1\n        # If characters don't match, break the loop as there is no more common prefix\n        else:\n            break\n\n    return common_prefix\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    :param input_string: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    sanitized_string = \"\".join(char.lower() for char in input_string if char.isalnum())\n    return sanitized_string == sanitized_string[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = torch.nn.Linear(120, 84)\n        self.fc3 = torch.nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = torch.nn.functional.relu(self.conv1(x))\n        x = torch.nn.functional.max_pool2d(x, 2)\n        x = torch.nn.functional.relu(self.conv2(x))\n        x = torch.nn.functional.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = torch.nn.functional.relu(self.fc1(x))\n        x = torch.nn.functional.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysisModel:\n    def __init__(self, class_count, priors=None, reg_param=0.0, store_covariance=False, store_precision=False):\n        self.class_count = class_count\n        self.priors = priors\n        self.reg_param = reg_param\n        self.store_covariance = store_covariance\n        self.store_precision = store_precision\n        self.model = QuadraticDiscriminantAnalysis(\n            n_components=class_count, priors=priors, reg_param=reg_param, store_covariance=store_covariance,\n            store_precision=store_precision\n        )\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self.model.predict(X)\n\n    def score(self, X, y):\n        return self.model.score(X, y)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    result_e = []\n    i, j = 0, 0\n\n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            result_e.append(list1_e[i])\n            i += 1\n        else:\n            result_e.append(list2_e[j])\n            j += 1\n\n    result_e.extend(list1_e[i:])\n    result_e.extend(list2_e[j:])\n\n    return result_e",
        "class IMAGE_CLASSIFIER(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x_in_e):\n        x_in_e = self.fc1(x_in_e)\n        x_in_e = torch.relu(x_in_e)\n        x_out_e = self.fc2(x_in_e)\n        return x_out_e"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list",
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        try:\n            if node.val <= min_val or node.val >= max_val:\n                return False\n            return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n        except AttributeError:\n            print(\"Invalid node structure\")\n            return False\n\n    return helper(root, float('-inf'), float('inf'))",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n            self.model = Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n        except ImportError as e:\n            print(f\"Error: {e}. Scikit-learn is required for Lasso Regression.\")\n        except Exception as e:\n            print(f\"An error occurred while training the Lasso Regression model: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.model is None or self.coef_ is None or self.intercept_ is None:\n                print(\"Error: Model has not been trained yet. Please call the train method before predicting.\")\n                return\n            return self.model.predict(X)\n        except Exception as e:\n            print(f\"An error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = torch.nn.Linear(120, 84)\n        self.fc3 = torch.nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = z_relu(self.conv1(x))\n        x = z_relu(self.conv2(x))\n        x = x.view(-1, 16 * 5 * 5)\n        x = z_relu(self.fc1(x))\n        x = z_relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "class SudokuValidator:\n    def isValidSudoku(z_self, z_board):\n        z_seen = set()\n        z_size = len(z_board)\n\n        for z_i in range(z_size):\n            z_row = z_board[z_i]\n            if not z_Validator._isValidSet(z_row, z_seen):\n                return False\n\n            z_col = z_Validator._getColumn(z_board, z_i)\n            if not z_Validator._isValidSet(z_col, z_seen):\n                return False\n\n            z_square = z_Validator._getSquare(z_board, z_i // 3, z_i % 3)\n            if not z_Validator._isValidSet(z_square, z_seen):\n                return False\n\n        return True\n\n    def _isValidSet(z_seen, z_set, z_check):\n        for z_num in z_set:\n            if z_num in z_check:\n                return False\n            z_check.add(z_num)\n        return True\n\n    def _getColumn(z_board, z_index):\n        z_size = len(z_board)\n        z_col = []\n        for z_row in z_board:\n            z_col.append(z_row[z_index])\n        return z_col\n\n    def _getSquare(z_board, z_row, z_col):\n        z_size = len(z_board)\n        z_square = []\n        for z_i in range(z_row * 3, z_row * 3 + 3):\n            for z_j in range(z_col * 3, z_col * 3 + 3):\n                z_square.append(z_board[z_i][z_j])\n        return z_square\n\nz_validator = SudokuValidator()"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x",
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinearRegression:\n    def __init__(self, digit=4):\n        self.digit = digit\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X, y):\n        X = self._add_digit_to_attribute_names(X)\n        X = self._profile_and_optimize(X)\n        self.coef_ = np.linalg.inv(X.T @ X) @ (X.T @ y)\n        self.intercept_ = np.ones((X.shape[0], 1))\n        self.coef_ = np.concatenate((self.intercept_, self.coef_), axis=1)\n\n    def predict(self, X):\n        X = self._add_digit_to_attribute_names(X)\n        predicted = X @ self.coef_\n        return predicted\n\n    def _add_digit_to_attribute_names(self, X):\n        # Add a single digit to the attribute names for clarity and differentiation\n        attribute_names = [f'attr{self.digit}_{i}' for i in range(X.shape[1])]\n        return np.asfortranarray(X, dtype=object).T[attribute_names].T\n\n    def _profile_and_optimize(self, X):\n        # Placeholder method to incorporate a profiler for performance optimization\n        # You can use profiling tools like line_profiler, memory_profiler, or built-in Python profiling\n        # Here, we simply return the input matrix X, assuming no further optimization is needed\n        return X"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements(l1, l2):\n    common = []\n    for i in l1:\n        if i in l2:\n            common.append(i)\n    return common"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_ud(self, src, dest):\n        visited = [False] * self.V\n        path = []\n        self._shortest_path_util_ud(src, dest, visited, path)\n        return path\n\n    def _shortest_path_util_ud(self, src, dest, visited, path):\n        visited[src] = True\n        path.append(src)\n        if src == dest:\n            return True\n        for i in self.graph[src]:\n            if not visited[i]:\n                if self._shortest_path_util_ud(i, dest, visited, path):\n                    return True\n        path.pop()\n        return False\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\nimport locale\n\nlocale.setlocale(locale.LC_ALL, '')\n\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)\n```",
        "from pedantic import count_calls\nimport locale\n\n@count_calls\ndef least_common_multiple(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the least common multiple of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The least common multiple of a and b.\n    \"\"\"\n    locale.setlocale(locale.LC_NUMERIC, '')\n    lcm = abs(a * b) // gcd(a, b)\n    return lcm\n\n@count_calls\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor using Euclidean algorithm.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b:\n        a, b = b, a % b\n    return a"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)",
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify_up(len(self.heap) - 1)\n\n    def chx_heapify_up(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] >= self.heap[parent_index]:\n                break\n            self.chx_swap(index, parent_index)\n            index = parent_index\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]\n\n    def heapify(self, arr):\n        self.heap = arr\n        for i in range(len(self.heap) - 1, -1, -1):\n            self.chx_heapify_down(i)"
      ],
      "instruction_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\n@timer\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n    slow, fast = head, head.next\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    return True\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta=0.01, epochs=1000):\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.chx_bias = None\n\n    def train(self, X, y):\n        self.weights = [0 for _ in range(len(X[0]))]\n        self.chx_bias = 0\n        for _ in range(self.epochs):\n            sum_error = 0\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                sum_error += update\n                self.weights = [w + update * x for w, x in zip(self.weights, xi)]\n                self.chx_bias += update\n\n    def predict(self, X):\n        activation = sum(x * w for x, w in zip(X, self.weights)) + self.chx_bias\n        return 1 if activation >= 0 else 0"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    vr_row = [{} for _ in range(9)]\n    vr_col = [{} for _ in range(9)]\n    vr_box = [{} for _ in range(9)]\n\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != '.':\n                num = board[i][j]\n                vr_row_id = i // 3 * 3 + j // 3\n                vr_box_id = i % 3 * 3 + j % 3\n\n                if num in vr_row[i] or num in vr_col[j] or num in vr_box[vr_row_id * 3 + vr_box_id]:\n                    return False\n\n                vr_row[i][num] = 1\n                vr_col[j][num] = 1\n                vr_box[vr_row_id * 3 + vr_box_id][num] = 1\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom roman import fromRoman\n\n\n@require_kwargs(\"roman_numeral\")\ndef roman_to_int(roman_numeral: str) -> int:\n    \"\"\"\n    Convert a Roman numeral string to an integer.\n    \n    :param roman_numeral: The Roman numeral string to be converted.\n    :return: The integer representation of the Roman numeral.\n    \"\"\"\n    print(f\"Converting Roman numeral: {roman_numeral}\")\n    int_value = fromRoman(roman_numeral)\n    print(f\"Converted integer: {int_value}\")\n    return int_value"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\n@count_calls\ndef majority_element(arr):\n    counter = {}\n    for num in arr:\n        if num in counter:\n            counter[num] += 1\n        else:\n            counter[num] = 1\n        if counter[num] > len(arr) // 2:\n            return num\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\n\nclass DirectedGraph:\n    @retry\n    def has_cycle(1):\n        # Implementation of cycle detection algorithm\n        pass\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song1(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song7(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False",
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    wr_row = set()\n    wr_col = set()\n    wr_box = set()\n    section_size = 3\n    section_start = 0\n\n    for i in range(0, 9, section_size):\n        for j in range(0, 9, section_size):\n            for x in range(i, i + section_size):\n                for y in range(j, j + section_size):\n                    val = board[x][y]\n                    if val != '.':\n                        wr_box_val = (val, (x // section_size) + section_start, (y // section_size))\n\n                        if wr_box_val in wr_box or val in wr_row[x] or val in wr_col[y]:\n                            return False\n\n                        wr_box.add(wr_box_val)\n                        wr_row[x].add(val)\n                        wr_col[y].add(val)\n\n    return True",
        "class LinkedList:\n    def __init__(self):\n        self.head_xt = None\n        self.tail_xt = None\n\n    def append(self, value):\n        new_node_xt = Node(value)\n        if not self.head_xt:\n            self.head_xt = new_node_xt\n            self.tail_xt = new_node_xt\n        else:\n            self.tail_xt.next_xt = new_node_xt\n            self.tail_xt = new_node_xt\n\n    def delete(self, value):\n        current_xt = self.head_xt\n        if current_xt.value_xt == value:\n            self.head_xt = current_xt.next_xt\n            return\n        while current_xt.next_xt:\n            if current_xt.next_xt.value_xt == value:\n                current_xt.next_xt = current_xt.next_xt.next_xt\n                return\n            current_xt = current_xt.next_xt\n        if current_xt.next_xt and current_xt.next_xt.value_xt == value:\n            current_xt.next_xt = None\n            self.tail_xt = current_xt\n\n    def display(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.value_xt, end=\" -> \")\n            current_xt = current_xt.next_xt\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value):\n        self.value_xt = value\n        self.next_xt = None"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace, validate\n\n\n@trace\n@validate\ndef find_max_subarray_sum(nums):\n    if not isinstance(nums, list) or any(not isinstance(num, int) for num in nums):\n        raise ValueError(\"Input must be a list of integers\")\n\n    max_sum = cur_sum = nums[0]\n    for num in nums[1:]:\n        cur_sum = max(num, cur_sum + num)\n        max_sum = max(max_sum, cur_sum)\n\n    return max_sum\n```",
        "```python\nfrom pedantic import trace, validate\n\n\n@trace\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    if num <= 0 or num > 3999:\n        raise ValueError(\"Input must be a positive integer up to 3999.\")\n\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max",
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.xt_head_at = None\n        self.xt_tail_at = None\n\n    def xt_append_node_at(self, data):\n        new_node = Node(data)\n        if not self.xt_head_at:\n            self.xt_head_at = new_node\n            self.xt_tail_at = new_node\n        else:\n            new_node.xt_prev_at = self.xt_tail_at\n            self.xt_tail_at.xt_next_at = new_node\n            self.xt_tail_at = new_node\n\n    def xt_delete_node_at(self, data):\n        current = self.xt_head_at\n        while current:\n            if current.data == data:\n                if current.xt_prev_at:\n                    current.xt_prev_at.xt_next_at = current.xt_next_at\n                else:\n                    self.xt_head_at = current.xt_next_at\n\n                if current.xt_next_at:\n                    current.xt_next_at.xt_prev_at = current.xt_prev_at\n                else:\n                    self.xt_tail_at = current.xt_prev_at\n\n                return\n\n            current = current.xt_next_at\n\n    def xt_display_list_at(self):\n        current = self.xt_head_at\n        while current:\n            print(current.data, end=\" \")\n            current = current.xt_next_at\n        print()\n\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.xt_next_at = None\n        self.xt_prev_at = None",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_head_at = None\n        self.xt_tail_at = None\n\n    def _delete_node(self, key: str) -> None:\n        prev_node = self.cache.get(key)\n        if prev_node:\n            next_node = prev_node.xt_next_at\n            prev_next = prev_node.xt_prev_at\n            if prev_next:\n                next_node.xt_prev_at = prev_next\n            if next_node:\n                prev_next.xt_next_at = next_node\n\n    def _add_head(self, key: str, value: str) -> None:\n        new_node = Node(key, value)\n        new_node.xt_next_at = self.xt_head_at\n        if self.xt_head_at:\n            self.xt_head_at.xt_prev_at = new_node\n        self.xt_head_at = new_node\n        if not self.xt_tail_at:\n            self.xt_tail_at = self.xt_head_at\n\n    def _move_to_head(self, key: str) -> None:\n        node = self.cache[key]\n        self._delete_node(key)\n        self._add_head(key, node.value)\n\n    def get(self, key: str) -> str:\n        if key not in self.cache:\n            return -1\n        self._move_to_head(key)\n        return self.cache[key].value\n\n    def put(self, key: str, value: str) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_head(key)\n        else:\n            if len(self.cache) == self.capacity:\n                self.cache.pop(self.xt_tail_at.key)\n                self._delete_node(self.xt_tail_at.key)\n                self.xt_tail_at = self.xt_tail_at.xt_prev_at\n            self._add_head(key, value)\n        self.cache[key] = Node(key, value)\n\nclass Node:\n    def __init__(self, key: str, value: str):\n        self.key = key\n        self.value = value\n        self.xt_next_at = None\n        self.xt_prev_at = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def mean_online_algorithm(data_stream, digit_name='x'):\n    \"\"\"Computes the mean of a data stream with an online algorithm.\n    \n    Args:\n        data_stream (iterable): A stream of numerical data.\n        digit_name (str, optional): A single digit included in the variable name. Defaults to 'x'.\n        \n    Returns:\n        float: The mean of the data stream.\n    \"\"\"\n    x0 = 0  # Initialize the mean with digit '0' as requested\n    x1 = 0  # Counter variable with digit '1'\n    for x2 in data_stream:  # Iterate through the data stream with digit '2'\n        x0 += x2\n        x1 += 1\n    return x0 / x1"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "import gzip\n\ndef product_except_self(nums):\n    output = [1] * len(nums)\n    left = [1] * len(nums)\n    right = [1] * len(nums)\n\n    for i in range(1, len(nums)):\n        left[i] = nums[i - 1] * left[i - 1]\n\n    for i in range(len(nums) - 2, -1, -1):\n        right[i] = nums[i + 1] * right[i + 1]\n\n    for i in range(len(nums)):\n        output[i] = left[i] * right[i]\n\n    return output"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(j_vec1, j_vec2):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param j_vec1: The first vector.\n    :param j_vec2: The second vector.\n    :return: The dot product of j_vec1 and j_vec2.\n    \"\"\"\n    return sum(x * y for x, y in zip(j_vec1, j_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "import bz2\n\ndef sum_array_except_self_b(nums):\n    n = len(nums)\n    left_sum, right_sum, result = [0] * n, [0] * n, [0] * n\n\n    left_sum[0] = nums[0]\n    for i in range(1, n):\n        left_sum[i] = nums[i] + left_sum[i - 1]\n\n    right_sum[n - 1] = nums[n - 1]\n    for i in range(n - 2, -1, -1):\n        right_sum[i] = nums[i] + right_sum[i + 1]\n\n    for i in range(n):\n        result[i] = left_sum[i - 1] + right_sum[i + 1]\n\n    return result",
        "from collections import deque\nimport bz2\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_lengths_from_source_to_all_nodes_b(self, src):\n        distances = [float('inf')] * self.V\n        distances[src] = 0\n\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in self.graph[u]:\n                if distances[v] == float('inf'):\n                    distances[v] = distances[u] + 1\n                    queue.append(v)\n\n        return distances"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_j):\n            self.data_j = data_j\n            self.next_j = None\n\n    def __init__(self):\n        self.head_j = None\n\n    def append_j(self, data_j):\n        new_node_j = self.Node(data_j)\n        if not self.head_j:\n            self.head_j = new_node_j\n        else:\n            current_j = self.head_j\n            while current_j.next_j:\n                current_j = current_j.next_j\n            current_j.next_j = new_node_j\n\n    def display_j(self):\n        current_j = self.head_j\n        while current_j:\n            print(current_j.data_j, end=' -> ')\n            current_j = current_j.next_j\n        print('None')"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n\n@require_kwargs\ndef is_valid_sudoku(y_board: list[list[int]]) -> bool:\n    def is_unique(y_list: list[int]) -> bool:\n        return len(y_list) == len(set(y_list))\n\n    for row in y_board:\n        if not is_unique(row) or not is_unique([num for sublist in y_board for num in sublist if num == row[0]]):\n            return False\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            square = [y_board[k][l] for k in range(i, i + 3) for l in range(j, j + 3)]\n            if not is_unique(square):\n                return False\n\n    return True\n```",
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs(\"y_grades\")\n    def __init__(self, y_grades: list[float]):\n        self.y_grades = y_grades\n\n    @require_kwargs(\"y_new_grade\")\n    def add_grade(self, y_new_grade: float):\n        self.y_grades.append(y_new_grade)\n\n    @require_kwargs(\"y_grades\")\n    def compute_average(self, y_grades: list[float]) -> float:\n        return sum(y_grades) / len(y_grades)\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True",
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists_p(list1_h, list2_h):\n    result_h = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            result_h.append(list1_h[i])\n            i += 1\n        else:\n            result_h.append(list2_h[j])\n            j += 1\n    result_h.extend(list1_h[i:])\n    result_h.extend(list2_h[j:])\n    return result_h",
        "class Graph:\n    def shortest_path_p(self, start_node_h, end_node_h, matrix_h):\n        queue = [(start_node_h, [start_node_h])]\n        visited = set([start_node_h])\n\n        while queue:\n            (node_h, path_h) = queue.pop(0)\n\n            if node_h == end_node_h:\n                return path_h\n\n            for next_node_h in range(len(matrix_h[node_h])):\n                if matrix_h[node_h][next_node_h] != float('inf') and next_node_h not in visited:\n                    new_path_h = path_h + [next_node_h]\n                    queue.append((next_node_h, new_path_h))\n                    visited.add(next_node_h)\n\n        return None"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_a():\n    def merge(arr, left, middle, right):\n        left_len = middle - left\n        right_len = right - middle\n        left_arr = arr[left:middle]\n        right_arr = arr[middle:right]\n\n        i = j = 0\n        k = left\n\n        while i < left_len and j < right_len:\n            if left_arr[i] < right_arr[j]:\n                arr[k] = left_arr[i]\n                i += 1\n            else:\n                arr[k] = right_arr[j]\n                j += 1\n            k += 1\n\n        while i < left_len:\n            arr[k] = left_arr[i]\n            i += 1\n            k += 1\n\n        while j < right_len:\n            arr[k] = right_arr[j]\n            j += 1\n            k += 1\n\n    def sort(arr, left, right):\n        if left < right:\n            middle = (left + right) // 2\n            sort(arr, left, middle)\n            sort(arr, middle, right)\n            merge(arr, left, middle, right)\n\n    return sort"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import Any\nimport hashlib\n\n\ndef insertion_sort(arr: list[Any]) -> list[Any]:\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero_elements7(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\nclass Solution:\n    @rename_kwargs(\"num\")\n    def maxSubArray(self, num: list[int]) -> int:\n        if max_sum := max(num):\n            max_global, max_current = 0, 0\n            for i in num:\n                max_current = max(max_current + i, i)\n                max_global = max(max_global, max_current)\n            return max_global\n        return 0\n```"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def c_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\nfrom pedantic.decorators import PedanticType, PedanticList\n\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate(\n        books={\"book_title\": str, \"author\": str},\n        book_to_add={\"book_title\": str, \"author\": str},\n    )\n    def add_books(self, books: PedanticList[\"book_title\", \"author\"]) -> None:\n        self.books.extend(books)\n\n    @validate(\n        books={\"book_title\": str, \"author\": str},\n        book_to_remove={\"book_title\": str, \"author\": str},\n    )\n    def remove_books(\n        self, book_to_remove: PedanticList[\"book_title\", \"author\"]\n    ) -> None:\n        self.books = [\n            book\n            for book in self.books\n            if book[\"book_title\"] not in [\n                remove_book[\"book_title\"] for remove_book in book_to_remove\n            ]\n        ]\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom Levenshtein import distance\nfrom secrets import SystemRandom\n\nrandom = SystemRandom()\n\n\ndef edit_distance(string1: str, string2: str) -> int:\n    \"\"\"\n    Calculate the edit distance between two strings using the Levenshtein distance algorithm.\n\n    :param string1: The first string.\n    :param string2: The second string.\n    :return: The edit distance between the two strings.\n    \"\"\"\n    return distance(string1, string2)\n```"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def x_is_palindrome(input_str_y: str) -> bool:\n    input_str_y = input_str_y.lower()\n    start_index_y, end_index_y = 0, len(input_str_y) - 1\n    while start_index_y < end_index_y:\n        if input_str_y[start_index_y] != input_str_y[end_index_y]:\n            return False\n        start_index_y += 1\n        end_index_y -= 1\n    return True",
        "class Inventory:\n    def __init__(self):\n        self.stock_y = {}\n\n    def x_add_stock(self, item_name_y, quantity_y):\n        if item_name_y in self.stock_y:\n            self.stock_y[item_name_y] += quantity_y\n        else:\n            self.stock_y[item_name_y] = quantity_y\n\n    def x_remove_stock(self, item_name_y, quantity_y):\n        if item_name_y in self.stock_y and self.stock_y[item_name_y] >= quantity_y:\n            self.stock_y[item_name_y] -= quantity_y\n        else:\n            print(\"Insufficient stock to remove quantity.\")"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_d():\n    pass"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "import mailbox\n\ndef delete_node(root, key):\n    if root is None:\n        return root\n    \n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        # Node found, now we can delete it\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            # Node has two children, get the inorder successor\n            successor = get_inorder_successor(root.right)\n            root.key = successor.key\n            root.right = delete_node(root.right, successor.key)\n    \n    return root\n\ndef get_inorder_successor(node):\n    while node.left is not None:\n        node = node.left\n    return node\n\n# Example usage:\n# Delete node with key = 5 from the binary search tree\n# delete_node(root, 5)",
        "from mailbox import Mailbox\n\ndef sum_unique_elements(numbers):\n    chx_unique_numbers = list(dict.fromkeys(numbers))\n    chx_sum = sum(chx_unique_numbers)\n    return chx_sum"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node",
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef calculate_gcd(a: int, b: int) -> int:\n    while b:\n        a, b = b, a % b\n    return a"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def chx_flatten_binary_tree(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    root.right = chx_flatten_binary_tree(root.right)\n    root.left = None\n    temp = root.right\n    root.right = chx_flatten_binary_tree(root.left)\n    root.left = None\n    temp.left = root.right\n    root.right = temp\n    return root"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "history_model_output": [
        "class LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_ @ X.T)\n\n    def predict(self, X):\n        X = np.array(X)\n        return X @ self.coef_.T + self.intercept_",
        "from sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    \"\"\"\n    Nearest Neighbors Model Class\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the Nearest Neighbors Model\n        \"\"\"\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the model using the provided training data\n        Args:\n            X_train (ndarray): The input training data\n            y_train (ndarray): The corresponding target values\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data\n        Args:\n            X_test (ndarray): The input test data\n        Returns:\n            ndarray: Predicted target values\n        \"\"\"\n        return self.model.predict(X_test)",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n\n    def is_valid(node, min_val, max_val):\n        if node is None:\n            return True\n        if node.value <= min_val or node.value >= max_val:\n            return False\n        return is_valid(node.left, min_val, node.value - 1) and is_valid(node.right, node.value + 1, max_val)\n\n    return is_valid(tree, float(\"-inf\"), float(\"inf\"))\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        while current_index > 0:\n            parent_index = (current_index - 1) // 2\n            if self.heap[current_index] > self.heap[parent_index]:\n                self.heap[current_index], self.heap[parent_index] = self.heap[parent_index], self.heap[current_index]\n                current_index = parent_index\n            else:\n                break",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input lengths\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length.\")\n    \n    # Initialize dot product variable\n    dot_product = 0\n    \n    # Compute dot product\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n    \n    # Return dot product\n    return dot_product",
        "class Inventory:\n    \"\"\"\n    Represents an inventory with methods to add and remove stock.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str, quantity: int) -> None:\n        \"\"\"\n        Adds stock of a given item to the inventory.\n\n        Args:\n            item (str): The name of the item to add.\n            quantity (int): The quantity of the item to add.\n        \"\"\"\n        self.stock.append((item, quantity))\n\n    def remove_stock(self, item: str, quantity: int) -> None:\n        \"\"\"\n        Removes stock of a given item from the inventory.\n\n        Args:\n            item (str): The name of the item to remove.\n            quantity (int): The quantity of the item to remove.\n        \"\"\"\n        for i, (stored_item, stored_quantity) in enumerate(self.stock):\n            if stored_item == item:\n                if stored_quantity <= quantity:\n                    del self.stock[i]\n                    break\n                else:\n                    stored_quantity -= quantity\n                    self.stock[i] = (stored_item, stored_quantity)\n                break",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        from sklearn.linear_model import Lasso\n        self.model = Lasso(alpha=self.alpha)\n        self.model.fit(X, y)\n        self.coef_ = self.model.coef_\n        self.intercept_ = self.model.intercept_\n\n    def predict(self, X):\n        return self.model.predict(X)",
        "def h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index of an array of integer citations.\n\n    Args:\n        citations (list[int]): A list of integer citations.\n\n    Returns:\n        int: The h-index value.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "from sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    KernelRidge regression class.\n\n    Parameters:\n    alpha (float): Regularization strength in the form of inverse regularization (ridgereg) strength.\n        Must be a positive float. Defaults to 1.0.\n    kernel (string): Kernel to be used in the algorithm. Defaults to 'linear'.\n    gamma (float): Kernel coefficient for 'rbf', 'poly', and 'sigmoid'.\n        Ignored by other kernels. Defaults to None.\n    degree (int): Degree for 'poly' kernel. Ignored by other kernels. Defaults to 3.\n    coef0 (float): Independent term in 'poly' and 'sigmoid'. Defaults to 1.\n    kernel_params (dict): Additional parameters (kernel-dependent) to be passed to the kernel.\n\n    Attributes:\n    coef_ (ndarray): Weights assigned to the features (coefficients).\n    dual_coef_ (ndarray): Weights assigned to the dual features (coefficients).\n    intercept_ (ndarray): Independent term in decision function.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 1.0,\n        kernel: str = \"linear\",\n        gamma: float = None,\n        degree: int = 3,\n        coef0: float = 1.0,\n        kernel_params: dict = None,\n    ):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X: np.ndarray, y: np.ndarray, **fit_params):\n        \"\"\"\n        Fit the model using X as training data and y as target values.\n\n        Parameters:\n        X (ndarray): Training data of shape (n_samples, n_features).\n        y (ndarray): Target values of shape (n_samples,).\n\n        Returns:\n        self: Fitted estimator.\n        \"\"\"\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.model.fit(X, y, **fit_params)\n        self.coef_ = self.model.dual_coef_\n        self.intercept_ = self.model.intercept_\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the linear model.\n\n        Parameters:\n        X (ndarray): Data of shape (n_samples, n_features).\n\n        Returns:\n        ndarray: Predicted values.\n        \"\"\"\n        return self.model.predict(X)",
        "class LinkedList:\n    \"\"\"\n    A linked list data structure.\n    \"\"\"\n    def __init__(self):\n        self.head = None\n\n    def append(self, value):\n        \"\"\"\n        Appends a value to the end of the linked list.\n        \"\"\"\n        # Create a new node with the given value\n        new_node = Node(value)\n\n        # If the list is empty, set the new node as the head\n        if not self.head:\n            self.head = new_node\n        else:\n            # Traverse to the last node in the list\n            current = self.head\n            while current.next:\n                current = current.next\n\n            # Append the new node to the end of the list\n            current.next = new_node\n\n    def size(self):\n        \"\"\"\n        Returns the size of the linked list.\n        \"\"\"\n        current = self.head\n        count = 0\n        while current:\n            count += 1\n            current = current.next\n\n        return count",
        "import numpy as np\n\nclass LinearRegression:\n    \"\"\"\n    A Linear Regression class for performing linear regression analysis.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the LinearRegression class.\n        \"\"\"\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> LinearRegression:\n        \"\"\"\n        Fits the linear regression model to the training data.\n\n        Parameters:\n            X (np.ndarray): The input features of shape (n_samples, n_features).\n            y (np.ndarray): The target values of shape (n_samples,).\n\n        Returns:\n            LinearRegression: The fitted LinearRegression instance.\n        \"\"\"\n        # Validate input data\n        if not isinstance(X, np.ndarray) or not isinstance(y, np.ndarray):\n            raise TypeError(\"Input data must be numpy arrays.\")\n        if X.ndim != 2 or y.ndim != 1:\n            raise ValueError(\"Input data must have the correct dimensions.\")\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"The number of samples in X and y must match.\")\n\n        # Calculate coefficients and intercept\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n        return self\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predicts the target values for the given input features.\n\n        Parameters:\n            X (np.ndarray): The input features of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The predicted target values of shape (n_samples,).\n        \"\"\"\n        # Validate input data\n        if not isinstance(X, np.ndarray):\n            raise TypeError(\"Input data must be a numpy array.\")\n        if X.ndim != 2:\n            raise ValueError(\"Input data must be a 2D array.\")\n\n        # Perform prediction\n        y_pred = X @ self.coef_ + self.intercept_\n\n        return y_pred",
        "def count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int or float): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "def common_elements(list1, list2):\n    common = []\n    for element in list1:\n        if element in list2:\n            common.append(element)\n    return common",
        "def product_array_except_self(arr):\n    product = 1\n    for num in arr:\n        if num != self:\n            product *= num\n    return product",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books: list[str]) -> None:\n        self.books.extend(books)\n\n    def remove_books(self, books: list[str]) -> None:\n        for book in books:\n            self.books.remove(book)",
        "```python\ndef kth_largest_element(arr, k):\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n    # Return the kth element\n    return arr[k-1]\n```",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_values = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in roman:\n        value = roman_values[char]\n\n        if value < prev_value:\n            int_value -= 2 * prev_value - value\n        else:\n            int_value += value\n\n        prev_value = value\n\n    return int_value\n```",
        "def mean(numbers):\n    \"\"\"\n    Compute the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list): A list of numbers.\n\n    Returns:\n        float: The mean of the numbers.\n    \"\"\"\n    # Initialize variables\n    total = 0\n    count = 0\n    x = 0\n\n    # Iterate through the list of numbers\n    for num in numbers:\n        # Update the total and count\n        total += num\n        count += 1\n        # Update the mean\n        x = total / count\n\n    # Return the mean\n    return x",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def compute_average_grade(self):\n        return self.grade",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.order = []\n\n    def get(self, key: str) -> str:\n        if key in self.cache:\n            self.order.remove(key)\n            self.order.insert(0, key)\n            return self.cache[key]\n        else:\n            return \"\"\n\n    def put(self, key: str, value: str) -> None:\n        if key in self.cache:\n            self.order.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.order.pop()\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.order.insert(0, key)",
        "def majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    # Validate input\n    if not arr:\n        raise ValueError(\"Input array is empty\")\n    \n    # Initialize variables\n    count = {}\n    majority_count = len(arr) // 2\n    \n    # Count occurrences of each element\n    for element in arr:\n        count[element] = count.get(element, 0) + 1\n    \n    # Find the majority element\n    for element, count_value in count.items():\n        if count_value > majority_count:\n            return element\n    \n    # If no majority element found, return None\n    return None",
        "from torch import nn\n\nclass ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = torch.sigmoid(x)\n        return output",
        "```python\ndef lcm(a: int, b: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The least common multiple of a and b.\n    \"\"\"\n    # Calculate the least common multiple using the formula: lcm(a, b) = |a * b| / gcd(a, b)\n    gcd_result = gcd(a, b)\n    return abs(a * b) // gcd_result\n\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers using the Euclidean algorithm.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "def is_valid_sudoku(board):\n    for row in board:\n        if len(set(row)) != len(row):\n            return False\n\n    for col in zip(*board):\n        if len(set(col)) != len(col):\n            return False\n\n    for i in range(0, len(board), 3):\n        for j in range(0, len(board), 3):\n            box = [board[r][c] for r in range(i, i + 3) for c in range(j, j + 3)]\n            if len(set(box)) != len(box):\n                return False\n\n    return True",
        "class Perceptron:\n    def __init__(self):\n        self.weights = None\n        self.bias = None\n\n    def train(self, X, y):\n        n_samples, n_features = X.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        # Training loop\n        for _ in range(n_samples):\n            # Compute linear combination of inputs and weights\n            linear_combination = np.dot(X[_], self.weights) + self.bias\n\n            # Compute prediction\n            prediction = self.activation(linear_combination)\n\n            # Compute error\n            error = y[_] - prediction\n\n            # Update weights and bias\n            self.weights += X[_] * error\n            self.bias += error\n\n    def activation(self, linear_combination):\n        # Activation function (Heaviside step function)\n        return 1 if linear_combination >= 0 else 0\n\n    def predict(self, X):\n        # Compute linear combination of inputs and weights\n        linear_combinations = np.dot(X, self.weights) + self.bias\n\n        # Compute predictions\n        predictions = [self.activation(linear_combination) for linear_combination in linear_combinations]\n\n        return np.array(predictions)",
        "def insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sorts a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Add your code here.\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr",
        "def merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing all elements from both input lists.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n    return merged_list",
        "```python\ndef greatest_common_divisor(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    # Add your code here\n    pass\n```",
        "```python\nclass DirectedGraph:\n    \"\"\"\n    Represents a directed graph.\n    \"\"\"\n\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u: int, v: int) -> None:\n        \"\"\"\n        Adds a directed edge from node u to node v.\n\n        :param u: int - Source node\n        :param v: int - Destination node\n        \"\"\"\n        if u not in self.graph:\n            self.graph[u] = []\n\n        self.graph[u].append(v)\n\n    def has_cycle(self) -> bool:\n        \"\"\"\n        Checks if the directed graph contains any cycles.\n\n        :return: bool - True if the graph contains a cycle, False otherwise\n        \"\"\"\n\n        visited = set()\n        rec_stack = []\n\n        def dfs(node):\n            if node in visited:\n                rec_stack.append(node)\n                return True\n            visited.add(node)\n            for neighbour in self.graph.get(node, []):\n                if dfs(neighbour):\n                    return True\n            rec_stack.pop()\n            return False\n\n        for node in self.graph:\n            if dfs(node):\n                return True\n\n        return False\n```",
        "```python\ndef max_subarray_sum(arr):\n    max_sum = float(\"-inf\")\n    current_sum = 0\n\n    for num in arr:\n        current_sum += num\n        if current_sum > max_sum:\n            max_sum = current_sum\n\n    return max_sum\n```",
        "def merge_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the merge sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    return merge(left_half, right_half)\n\ndef merge(left: list[int], right: list[int]) -> list[int]:\n    \"\"\"\n    Merge two sorted lists of integers into a single sorted list.\n\n    Args:\n        left (list[int]): The first sorted list of integers.\n        right (list[int]): The second sorted list of integers.\n\n    Returns:\n        list[int]: The merged and sorted list of integers.\n    \"\"\"\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result += left[left_idx:]\n    result += right[right_idx:]\n\n    return result",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    # Create a new linked list node with the root value\n    head = Node(root.value)\n    curr = head\n\n    # Traverse the left and right subtrees recursively\n    if root.left:\n        flatten_binary_tree(root.left)\n        curr.next = Node(root.left.value)\n        curr = curr.next\n\n    if root.right:\n        flatten_binary_tree(root.right)\n        curr.next = Node(root.right.value)\n        curr = curr.next\n\n    return head\n```",
        "def sum_unique_numbers(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from a list of numbers and computes their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "class Graph:\n    \"\"\"\n    Represents a graph data structure.\n    \"\"\"\n\n    def __init__(self):\n        self.nodes = []\n        self.edges = []\n\n    def add_node(self, node):\n        \"\"\"\n        Adds a node to the graph.\n\n        Args:\n            node: The node to be added to the graph.\n        \"\"\"\n        self.nodes.append(node)\n\n    def add_edge(self, node1, node2):\n        \"\"\"\n        Adds an edge between two nodes in the graph.\n\n        Args:\n            node1: The first node of the edge.\n            node2: The second node of the edge.\n        \"\"\"\n        self.edges.append((node1, node2))\n\n    def shortest_path(self, start, end):\n        \"\"\"\n        Computes the shortest path from 'start' to 'end' using Dijkstra's algorithm.\n\n        Args:\n            start: The starting node.\n            end: The ending node.\n\n        Returns:\n            The shortest path from 'start' to 'end', including both nodes.\n        \"\"\"\n        # Initialize distances and visited nodes\n        distances = {node: float('inf') for node in self.nodes}\n        distances[start] = 0\n        visited = set()\n\n        # Priority queue for nodes to be processed\n        queue = [(0, start)]\n\n        while queue:\n            current_distance, current_node = heapq.heappop(queue)\n            if current_node == end:\n                path = [current_node]\n                while current_node != start:\n                    current_node = next(\n                        node for node in self.edges if node[1] == current_node\n                    )\n                    path.append(current_node)\n                path.reverse()\n                return path\n\n            if current_node in visited:\n                continue\n\n            visited.add(current_node)\n\n            for neighbor in self.edges:\n                if neighbor[0] == current_node and neighbor[1] not in visited:\n                    distance = current_distance + 1\n                    heapq.heappush(queue, (distance, neighbor[1]))\n                    distances[neighbor[1]] = distance\n\n        # No path found\n        return None",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "class Solution:\n    def __init__(self, arr):\n        self.arr = arr\n        self.max_sum = 0\n        self.max_ending_index = 0\n        self.max_sum_ending_here = 0\n\n    def max_subarray_sum(self):\n        for i in range(len(self.arr)):\n            self.max_sum_ending_here = max(0, self.max_sum_ending_here + self.arr[i])\n            self.max_sum = max(self.max_sum, self.max_sum_ending_here)\n            self.max_ending_index = i if self.max_sum_ending_here == self.max_sum else self.max_ending_index\n\n        return self.max_sum",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Reverse the string and compare\n    return s == s[::-1]\n```",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): The first vector.\n        vector_b (list[int]): The second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input lengths\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length.\")\n    \n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n    \n    return dot_product",
        "def longest_common_prefix(strings: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strings (list[str]): A list of strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strings:\n        return \"\"\n\n    # Sort the list of strings to ensure consistent results\n    strings.sort()\n\n    # Find the length of the first string\n    prefix_length = len(strings[0])\n\n    # Iterate through the list of strings to find the common prefix\n    for i in range(1, len(strings)):\n        prefix_length = min(prefix_length, len(strings[i]))\n        for j in range(prefix_length):\n            if strings[0][j] != strings[i][j]:\n                prefix_length = j\n                break\n\n    return strings[0][:prefix_length]",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left:\n                self._insert(value, node.left)\n            else:\n                node.left = Node(value)\n        else:\n            if node.right:\n                self._insert(value, node.right)\n            else:\n                node.right = Node(value)\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n            else:\n                node.value = self._find_min_value(node.right)\n                node.right = self._delete(node.value, node.right)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left:\n            current = current.left\n        return current.value",
        "class QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for classification.\n\n    Parameters:\n    ----------\n    tol : float, default=1e-4\n        Tolerance for convergence.\n\n    Attributes:\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        Class means.\n\n    covariances_ : ndarray of shape (n_classes, n_features, n_features)\n        Class covariances.\n\n    priors_ : ndarray of shape (n_classes,)\n        Class priors.\n\n    means_ : ndarray of shape (n_classes, n_features)\n        Class means.\n    \"\"\"\n\n    def __init__(self, tol: float = 1e-4):\n        self.tol = tol\n        self.classes_ = None\n        self.covariances_ = None\n        self.priors_ = None\n        self.means_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Fit the QDA model according to the given training data and parameters.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n        \"\"\"\n        # Initialize variables\n        n_samples, n_features = X.shape\n        classes = np.unique(y)\n        n_classes = len(classes)\n\n        # Calculate class means\n        self.means_ = np.zeros((n_classes, n_features))\n        for i, c in enumerate(classes):\n            self.means_[i] = np.mean(X[y == c], axis=0)\n\n        # Calculate class covariances\n        self.covariances_ = np.zeros((n_classes, n_features, n_features))\n        for i, c in enumerate(classes):\n            self.covariances_[i] = np.cov(X[y == c].T)\n\n        # Calculate class priors\n        self.priors_ = np.zeros(n_classes)\n        self.priors_[classes] = np.bincount(y) / n_samples\n\n        # Calculate class priors\n        self.classes_ = classes\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the class labels for the provided data.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns:\n        -------\n        C : ndarray, shape (n_samples,)\n            Predicted class label per sample.\n        \"\"\"\n        # Calculate posterior probabilities\n        posteriors = self._get_posterior_probabilities(X)\n\n        # Predict class labels\n        predicted_labels = np.argmax(posteriors, axis=1)\n\n        return predicted_labels\n\n    def _get_posterior_probabilities(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate the posterior probabilities for each class.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns:\n        -------\n        posteriors : ndarray, shape (n_samples, n_classes)\n            Posterior probabilities.\n        \"\"\"\n        # Calculate posterior probabilities\n        log_priors = np.log(self.priors_)\n        log_det_cov = np.log(np.linalg.det(self.covariances_))\n        log_prob = -0.5 * (np.log(2 * np.pi) + log_det_cov + np.sum(\n            np.linalg.inv(self.covariances_) @ (X - self.means_) ** 2, axis=1\n        ) + log_priors\n\n        return np.exp(log_prob)",
        "def int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(len(roman_values)):\n            if num >= roman_values[i]:\n                num -= roman_values[i]\n                roman_num += roman_numerals[i]\n                break\n        i += 1\n    return roman_num",
        "def sum_array_except_self(arr):\n    \"\"\"\n    Calculates the sum of all elements in the array except the element at the index of the function call.\n\n    Args:\n        arr (list): A list of integers or floats representing the array.\n\n    Returns:\n        int or float: The sum of all elements in the array except the element at the index of the function call.\n    \"\"\"\n    # Import the 'secrets' module for security purposes\n    import secrets\n\n    # Initialize a variable to store the sum\n    total_sum = 0\n\n    # Iterate through the array\n    for i in range(len(arr)):\n        # Check if the current index is the same as the function call index\n        if i == secrets.randbits(8):  # Use a random index for demonstration purposes\n            continue\n\n        # Add the current element to the sum\n        total_sum += arr[i]\n\n    # Return the calculated sum\n    return total_sum",
        "def avg_diag_element(matrix):\n    \"\"\"\n    Compute the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of list of int or float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate the input matrix\n    if not all(isinstance(row, list) for row in matrix):\n        raise TypeError(\"Input must be a list of lists\")\n    if not all(isinstance(element, (int, float)) for row in matrix for element in row):\n        raise TypeError(\"All elements in the matrix must be integers or floats\")\n\n    # Calculate the sum of diagonal elements\n    diag_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    avg_diag = diag_sum / len(matrix)\n\n    return avg_diag",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    # Recursive function to find the node to be deleted\n    def _delete_node(root, key):\n        if root is None:\n            return None, False\n\n        # If the key to be deleted is less than the root's key,\n        # then search in the left subtree\n        if key < root.key:\n            root.left, deleted = _delete_node(root.left, key)\n\n        # If the key to be deleted is greater than the root's key,\n        # then search in the right subtree\n        elif key > root.key:\n            root.right, deleted = _delete_node(root.right, key)\n\n        # If the key is found, delete the node and return True\n        else:\n            deleted = True\n            # If the node is a leaf node, simply delete it\n            if root.left is None and root.right is None:\n                root = None\n            # If the node has only one child, replace it with that child\n            elif root.left is None:\n                root = root.right\n            # If the node has two children, find the inorder successor\n            # (smallest in the right subtree) and replace the node with it\n            else:\n                successor = _find_min_value_node(root.right)\n                root.key = successor.key\n                root.right, _ = _delete_node(root.right, successor.key)\n\n        return root, deleted\n\n    # Base case: Return if the tree is empty\n    if root is None:\n        return\n\n    # Call the recursive function\n    root, deleted = _delete_node(root, key)\n\n    # If the node was not found, return the original tree\n    if not deleted:\n        return root\n\n    # If the node was found and deleted, return the modified tree\n    # without the deleted node\n    return root\n```",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n    return dp[len_str1][len_str2]\n```",
        "```python\nfrom sklearn.decomposition import PCA\n\nclass PCA_:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components (int): The number of principal components to retain.\n        explained_variance_ (float): The percentage of variance explained by the retained components.\n        components_ (ndarray): The principal components.\n        mean_ (ndarray): The mean value of each feature.\n        noise_variance_ (float): The estimated noise covariance.\n\n    Methods:\n        fit(X): Fit the PCA model to the data.\n        transform(X): Transform the data using the fitted PCA model.\n        fit_transform(X): Fit the PCA model to the data and transform it.\n        inverse_transform(X): Transform data back to the original space.\n    \"\"\"\n\n    def __init__(self, n_components=None, random_state=None):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int, optional): The number of principal components to retain.\n                If None, retain all components. Defaults to None.\n            random_state (int, optional): The random seed for reproducibility.\n                Defaults to None.\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ = None\n        self.components_ = None\n        self.mean_ = None\n        self.noise_variance_ = None\n\n    def fit(self, X):\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            None\n        \"\"\"\n        # Calculate the mean of each feature\n        self.mean_ = X.mean(axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Calculate the covariance matrix\n        covariance = np.cov(X_centered, rowvar=False)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Determine the number of components to retain\n        if self.n_components is None:\n            self.n_components = X.shape[1]\n        else:\n            self.n_components = min(self.n_components, X.shape[1])\n\n        # Calculate the explained variance\n        self.explained_variance_ = np.sum(eigenvalues[:self.n_components]) / np.sum(eigenvalues)\n\n        # Construct the principal components\n        self.components_ = eigenvectors[:self.n_components].T\n\n        # Estimate the noise covariance\n        self.noise_variance_ = np.mean(eigenvalues[self.n_components:])\n\n    def transform(self, X):\n        \"\"\"\n        Transform the data using the fitted PCA model.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components)\n        \"\"\"\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Project the data onto the principal components\n        transformed = X_centered @ self.components_\n\n        return transformed\n\n    def fit_transform(self, X):\n        \"\"\"\n        Fit the PCA model to the data and transform it.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components)\n        \"\"\"\n        # Fit the PCA model to the data\n        self.fit(X)\n\n        # Transform the data\n        transformed = self.transform(X)\n\n        return transformed\n\n    def inverse_transform(self, X):\n        \"\"\"\n        Transform data back to the original space.\n\n        Args:\n            X (ndarray): The transformed data of shape (n_samples, n_components).\n\n        Returns:\n            ndarray: The original data of shape (n_samples, n_features)\n        \"\"\"\n        # Transform the data back to the original space\n        reconstructed = X @ self.components_.T\n\n        # Add the mean back to the reconstructed data\n        reconstructed += self.mean_\n\n        return reconstructed\n```"
      ]
    }
  ]
}