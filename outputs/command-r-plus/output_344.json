{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def gn_merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = gn_merge_sort_fn(left)\n    right = gn_merge_sort_fn(right)\n\n    return gn_merge_fn(left, right)\n\ndef gn_merge_fn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "def gn_h_index_calculator_fn(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def calculate_diagonal_average(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a 2D list/array\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Input matrix must be square\"\n    \n    size = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n    \"\"\"\n    Checks if a given binary tree is a valid binary search tree.\n    \n    Args:\n        root (Node): The root of the binary tree.\n        min_val (int): Minimum value allowed in the current subtree. Default is negative infinity.\n        max_val (int): Maximum value allowed in the current subtree. Default is positive infinity.\n        \n    Returns:\n        bool: True if the tree is a valid BST, False otherwise.\n    \"\"\"\n    if root is None:\n        return True\n    \n    # Check if the current node's value is within the allowed range\n    if not min_val <= root.val < max_val:\n        return False\n    \n    # Recursively check the left and right subtrees\n    return is_valid_bst(root.left, min_val, root.val) and is_valid_bst(root.right, root.val, max_val)\n```",
        "def int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to a Roman numeral.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n\n    return roman"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\n\n\ndef kth_largest(arr: List[int], k: int) -> int:\n    \"\"\"\n    Returns the kth largest element in the given array.\n\n    Parameters:\n        arr (List[int]): The input array of integers.\n        k (int): The value of 'k' for the kth largest element.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    sorted_arr = sorted(arr, reverse=True)\n\n    # Return the element at index 'k-1' (since indexing starts at 0)\n    return sorted_arr[k - 1]\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index_y(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def b_merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = b_merge_sort_y(left)\n    right = b_merge_sort_y(right)\n\n    return b_merge_y(left, right)\n\ndef b_merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_y(left)\n    right = merge_sort_y(right)\n\n    return merge_y(left, right)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef roman_to_int_gn(roman: str) -> int:\n    roman_map = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000\n    }\n    int_value = 0\n    prev_value = 0\n    for char in reversed(roman):\n        value = roman_map[char]\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n        prev_value = value\n    return int_value\n```",
        "@require_kwargs\ndef merge_sort_gn(arr: list[int]) -> list[int]:\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_gn(left)\n    right = merge_sort_gn(right)\n\n    return merge(left, right)\n\ndef merge(left: list[int], right: list[int]) -> list[int]:\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer",
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def a_compute_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    :param citations: A list of integer citations.\n    :return: The h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n\n\nassert a_compute_h_index([5, 3, 3, 1, 1]) == 3\nassert a_compute_h_index([10, 5, 3, 3, 1]) == 5\nassert a_compute_h_index([1, 1, 1, 1, 1]) == 1",
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors model for predicting the class of new instances.\n    \"\"\"\n    def __init__(self, X_train, y_train):\n        \"\"\"\n        Initializes the NearestNeighbors model.\n\n        Parameters:\n            X_train (ndarray): The training data features of shape [n_samples, n_features].\n            y_train (ndarray): The training data labels of shape (n_samples,).\n        \"\"\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def _find_nearest_neighbor(self, x):\n        \"\"\"\n        Finds the nearest neighbor of a given data point x.\n\n        Parameters:\n            x (ndarray): A single data point of shape (n_features,).\n\n        Returns:\n            int: The index of the nearest neighbor in the training data.\n        \"\"\"\n        distances = np.linalg.norm(self.X_train - x, axis=1)\n        nearest_index = np.argmin(distances)\n        return nearest_index\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the class labels for the given test data.\n\n        Parameters:\n            X_test (ndarray): The test data features of shape [n_samples, n_features].\n\n        Returns:\n            ndarray: Predicted class labels for the test data.\n        \"\"\"\n        predicted_labels = np.empty(X_test.shape[0], dtype=int)\n        for i, x in enumerate(X_test):\n            nearest_index = self._find_nearest_neighbor(x)\n            predicted_labels[i] = self.y_train[nearest_index]\n        return predicted_labels\n\n    def train(self):\n        \"\"\"\n        Trains the NearestNeighbors model by storing the training data.\n        \"\"\"\n        # No training needed other than storing the training data\n        pass\n\n\nassert NearestNeighbors(X_train, y_train)"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def fn_h_index_c(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def fn_merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = fn_merge_sort_c(left_half)\n    right_half = fn_merge_sort_c(right_half)\n\n    return fn_merge_c(left_half, right_half)\n\ndef fn_merge_c(left, right):\n    result = []\n    left_index, right_index = 0, 0\n\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n\n    return result"
      ],
      "instruction_model_output": [
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef dot_product(h_vec1: list[float], h_vec2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        h_vec1 (list[float]): The first vector.\n        h_vec2 (list[float]): The second vector.\n\n    Returns:\n        float: The dot product of h_vec1 and h_vec2.\n    \"\"\"\n    # Validate input vectors' lengths\n    if len(h_vec1) != len(h_vec2):\n        raise ValueError(\"Input vectors must have the same length\")\n\n    # Compute the dot product\n    return sum(x * y for x, y in zip(h_vec1, h_vec2))\n```",
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\n\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self, h_fit_intercept=True, h_normalize=False, h_copy_X=True):\n        self.h_fit_intercept = h_fit_intercept\n        self.h_normalize = h_normalize\n        self.h_copy_X = h_copy_X\n        self.model = LinearRegression(fit_intercept=h_fit_intercept, normalize=h_normalize, copy_X=h_copy_X)\n\n    @count_calls\n    def train(self, h_X, h_y):\n        self.model.fit(h_X, h_y)\n\n    @count_calls\n    def predict(self, h_X):\n        return self.model.predict(h_X)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate, timer_class\n\n\n@timer_class\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book(self, book):\n        self.books.append(book)\n\n    @validate\n    def remove_book(self, book):\n        self.books.remove(book)\n```",
        "from pedantic import validate, timer_class\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class providing a scikit-learn like interface.\n    \"\"\"\n\n    def __init__(self, store_covariance=False):\n        \"\"\"\n        Construct a new QDA classifier.\n\n        :param store_covariance: boolean, optional (default=False)\n            Whether to store the class covariance matrices.\n        \"\"\"\n        self.store_covariance = store_covariance\n        self._clf = QuadraticDiscriminantAnalysis(store_covariance=store_covariance)\n\n    @validate\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n        :param y: array-like, shape (n_samples,)\n            Target vector relative to X.\n        :return: self\n            Returns the instance itself.\n        \"\"\"\n        self._clf.fit(X, y)\n        return self\n\n    @validate\n    def predict(self, X):\n        \"\"\"\n        Perform classification on samples in X.\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n        :return: array, shape (n_samples,)\n            Class labels for samples in X.\n        \"\"\"\n        return self._clf.predict(X)"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class image_classifier(object):\n    \"\"\"\n    UNITE Image Classifier Model\n    \"\"\"\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.model = self._build_model()\n\n    def _build_model(self):\n        \"\"\"\n        Construct the binary image classification model architecture.\n        \"\"\"\n        layers = [\n            nn.Flatten(),\n            nn.Linear(self.input_dim, self.hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(self.hidden_dim, self.output_dim),\n            nn.Sigmoid()\n        ]\n        model = nn.Sequential(*layers)\n        return model\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n        \"\"\"\n        return self.model(x)",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            import sklearn.linear_model as sklm\n\n            self.model = sklm.Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n        except Exception as e:\n            raise ValueError(f\"Error occurred while training the Lasso Regression model: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coef_ is None or self.intercept_ is None:\n                raise ValueError(\"Model has not been trained yet. Please call the train method before predicting.\")\n            return self.model.predict(X)\n        except Exception as e:\n            raise ValueError(f\"Error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 tol=1e-3, fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.tol = tol\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0,\n                                kernel_params=kernel_params, tol=tol, fit_intercept=fit_intercept,\n                                normalize=normalize, copy_X=copy_X, verbose=verbose)\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_a(left_half)\n    right_half = merge_sort_a(right_half)\n\n    return merge_a(left_half, right_half)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def p_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def p_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")",
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount",
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def c_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n\n\nclass c7UNITE:\n    def __init__(self):\n        self.mentor = \"Sophie\"\n        self.team = \"UNITE\"\n\n    def foster_teamwork(self):\n        print(f\"{self.team} values teamwork and leadership. Let's collaborate and grow together!\")\n\n\n# Example usage (not requested)\n# citations = [3, 0, 1, 6, 5]\n# print(c_h_index(citations))",
        "class PCA_4:\n    def __init__(self, n_components=None, copy=True):\n        self.n_components = n_components\n        self.copy = copy\n        self.components_ = None\n        self.mean_ = None\n        self.explained_variance_ = None\n        self.explained_variance_ratio_ = None\n        self.singular_values_ = None\n        self.singular_vectors_ = None\n\n    def fit(self, X, y=None):\n        X = check_array(X, dtype=float64, copy=self.copy)\n        n_samples, n_features = X.shape\n\n        # Center the data\n        self.mean_ = X.mean(axis=0)\n        X -= self.mean_\n\n        # Compute the covariance matrix\n        cov = (X.T @ X) / (n_samples - 1)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = linalg.eigh(cov)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        indices = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[indices]\n        eigenvectors = eigenvectors[:, indices]\n\n        # Compute the cumulative sum of explained variance\n        self.explained_variance_ = (eigenvalues / (n_samples - 1))[:, newaxis]\n        self.explained_variance_ratio_ = np.cumsum(self.explained_variance_, axis=0) / np.sum(self.explained_variance_, axis=0)\n\n        # Choose the top n_components eigenvectors\n        if self.n_components is not None:\n            eigenvectors = eigenvectors[:, :self.n_components]\n            eigenvalues = eigenvalues[:self.n_components]\n\n        # Compute the principal components\n        self.components_ = (eigenvectors * np.sqrt(n_samples - 1)).astype(float64, copy=False)\n        self.singular_values_ = np.sqrt(eigenvalues + (eigenvalues <= 0) * tiny)\n        self.singular_vectors_ = eigenvectors\n\n        return self\n\n    def transform(self, X):\n        check_is_fitted(self, ['mean_', 'components_'])\n        X = check_array(X, dtype=float64, copy=True)\n        X -= self.mean_\n        return (X @ self.components_.T).astype(float64, copy=False)\n\n    def inverse_transform(self, X):\n        check_is_fitted(self, ['mean_', 'components_'])\n        X = check_array(X, dtype=float64, copy=True)\n        return (X @ self.components_) + self.mean_\n\n    def fit_transform(self, X, y=None):\n        X = check_array(X, dtype=float64, copy=True)\n        n_samples, n_features = X.shape\n\n        # Center the data\n        self.mean_ = X.mean(axis=0)\n        X -= self.mean_\n\n        # Compute the covariance matrix\n        cov = (X.T @ X) / (n_samples - 1)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = linalg.eigh(cov)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        indices = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[indices]\n        eigenvectors = eigenvectors[:, indices]\n\n        # Compute the cumulative sum of explained variance\n        self.explained_variance_ = (eigenvalues / (n_samples - 1))[:, newaxis]\n        self.explRktance_variance_ratio_ = np.cumsum(self.explained_variance_, axis=0) / np.sum(self.explained_variance_, axis=0)\n\n        # Choose the top n_components eigenvectors\n        if self.n_components is not None:\n            eigenvectors = eigenvectors[:, :self.n_components]\n            eigenvalues = eigenvalues[:self.n_components]\n\n        # Compute the principal components\n        self.components_ = (eigenvectors * np.sqrt(n_samples - 1)).astype(float64, copy=False)\n        self.singular_values_ = np.sqrt(eigenvalues + (eigenvalues <= 0) * tiny)\n        self.singular_vectors_ = eigenvectors\n\n        return (X @ self.components_.T).astype(float64, copy=False)"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sorts a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Import the 'hashlib' module as per Sophie's instruction\n    import hashlib\n\n    # Initialize a hash object for secure hashing of the input list\n    hasher = hashlib.sha256()\n    hasher.update(str(arr).encode())\n    hash_value = hasher.hexdigest()\n\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n\n    # Return the sorted list and the hash value for security verification\n    return arr, hash_value\n```"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def y_dot_product(v1, v2):\n    \"\"\"\n    Calculates the dot product of two vectors.\n\n    :param v1: The first vector.\n    :param v2: The second vector.\n    :return: The dot product of v1 and v2.\n    \"\"\"\n    i_sum = 0\n    for i_index in range(len(v1)):\n        i_sum += v1[i_index] * v2[i_index]\n    return i_sum",
        "def y_compute_h_index(i_citations: list[int]) -> int:\n    i_citations.sort(reverse=True)\n    i_length = len(i_citations)\n    i_h_index = 0\n\n    for i_index, i_citation in enumerate(i_citations):\n        i_h_possible = min(i_citation, i_index + 1)\n        if i_h_possible >= i_h_index:\n            i_h_index = i_h_possible\n\n    return i_h_index"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```",
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_array_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    Parameters:\n    nums (list): Input array of integers\n\n    Returns:\n    list: Array containing the sum of all elements except the element itself at each index\n    \"\"\"\n    import bz2\n\n    result = [0] * len(nums)\n    total_sum = sum(nums)\n    \n    # Sum all elements to the left of each index\n    left_sum = 0\n    for i in range(len(nums)):\n        result[i] = left_sum\n        left_sum += nums[i]\n    \n    # Sum all elements to the right of each index\n    right_sum = 0\n    for i in range(len(nums)-1, -1, -1):\n        result[i] += right_sum\n        right_sum += nums[i]\n    \n    return result"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure with insertion and deletion capabilities.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a value into the binary tree.\n\n        Args:\n            value: The value to be inserted.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        Args:\n            value: The value to be inserted.\n            node: The current node in the recursive traversal.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Delete a value from the binary tree.\n\n        Args:\n            value: The value to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for deleting a value from the binary tree.\n\n        Args:\n            value: The value to be deleted.\n            node: The current node in the recursive traversal.\n\n        Returns:\n            The new node after deletion.\n        \"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node._right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node):\n        \"\"\"\n        Helper function to find the minimum value in a subtree.\n\n        Args:\n            node: The root of the subtree.\n\n        Returns:\n            The minimum value in the subtree.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    \"\"\"\n    A node in the binary tree.\n    \"\"\"\n    def __init__(self, value_j):\n        self.value_j = value_j\n        self.left = None\n        self.right = None\n```",
        "```python\nclass LinkedList:\n    \"\"\"\n    A linked list data structure.\n    This class provides methods to manipulate and traverse a linked list.\n    \"\"\"\n\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, value):\n        \"\"\"\n        Append a new node with the given value to the end of the linked list.\n        :param value: The value to be stored in the new node.\n        \"\"\"\n        if not self.head_j:\n            self.head_j = Node(value)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(value)\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the linked list.\n        :param value: The value of the node to be deleted.\n        \"\"\"\n        if self.head_j and self.head_j.value_j == value:\n            self.head_j = self.head_j.next_j\n        else:\n            curr_j = self.head_j\n            prev_j = None\n            while curr_j and curr_j.value_j != value:\n                prev_j = curr_j\n                curr_j = curr_j.next_j\n            if curr_j:\n                prev_j.next_j = curr_j.next_j\n\n    def search(self, value):\n        \"\"\"\n        Search for a node with the given value in the linked list.\n        :param value: The value to be searched for.\n        :return: True if a node with the given value is found, False otherwise.\n        \"\"\"\n        curr_j = self.head_j\n        while curr_j and curr_j.value_j != value:\n            curr_j = curr_j.next_j\n        return True if curr_j else False\n\n    def display(self):\n        \"\"\"\n        Display the values in the linked list, starting from the head node.\n        \"\"\"\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.value_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n\nclass Node:\n    \"\"\"\n    A node in the linked list.\n    This class represents a single node with a value and a reference to the next node.\n    \"\"\"\n\n    def __init__(self, value):\n        self.value_j = value\n        self.next_j = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        if not node:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class IMAGE_CLASSIFIER(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(IMAGE_CLASSIFIER, self)-> None\n        self.input_size_s = input_size\n        self.hidden_size_s = hidden_size\n        self.num_classes_s = num_classes\n        self.linear_s = nn.Linear(input_size, hidden_size)\n        self.relu_s = nn.ReLU()\n        self.dropout_s = nn.Dropout(0.5)\n        self.linear_out_s = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        x = self.linear_s(x)\n        x = self.relu_s(x)\n        x = self.dropout_s(x)\n        x = self.linear_out_s(x)\n        return x",
        "class LINKED_LIST:\n    def __init__(self):\n        self.head_s = None\n        self.tail_s = None\n        self.size_s = 0\n\n    def add_node(self, data_s):\n        node_s = NODE(data_s)\n        if not self.head_s:\n            self.head_s = node_s\n            self.tail_s = node_s\n        else:\n            self.tail_s.next_node_s = node_s\n            self.tail_s = node_s\n        self.size_s += 1\n\n    def remove_node(self, data_s):\n        current_node_s = self.head_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data_s != data_s:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if not current_node_s:\n            return\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n        else:\n            self.head_s = current_node_s.next_node_s\n        if current_node_s == self.tail_s:\n            self.tail_s = prev_node_s\n        self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_s\n        while current_node_s:\n            print(current_node_s.data_s, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n\n    def size(self):\n        return self.size_s\n\n\nclass NODE:\n    def __init__(self, data_s):\n        self.data_s = data_s\n        self.next_node_s = None"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n\n@require_kwargs(['str_list'])\ndef longest_common_prefix(str_list: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        str_list (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix of the input strings.\n    \"\"\"\n    if not str_list:\n        return \"\"\n\n    for i, char in enumerate(str_list[0]):\n        for other in str_list[1:]:\n            if i == len(other) or other[i] != char:\n                return str_list[0][:i]\n    return str_list[0]\n```",
        "```python\nfrom pedantic import require_kwargs\n\n\nclass StudentGrade:\n    \"\"\"\n    A class to represent student grades.\n    \"\"\"\n\n    @require_kwargs('grades')\n    def __init__(self, grades: list[float]):\n        \"\"\"\n        Initializes the StudentGrade object.\n\n        Args:\n            grades (list[float]): A list of numerical grades.\n        \"\"\"\n        self.grades = grades\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        \"\"\"\n        Adds a new grade to the student's record.\n\n        Args:\n            new_grade (float): The new grade to be added.\n        \"\"\"\n        self.grades.append(new_grade)\n\n    def compute_average(self) -> float:\n        \"\"\"\n        Computes the average grade of the student.\n\n        Returns:\n            float: The average grade.\n        \"\"\"\n        return sum(self.grades) / len(self.grades)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(j_vector1, j_vector2):\n    return sum(x * y for x, y in zip(j_vector1, j_vector2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__Init()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nclass UNITEImageClassifier(nn.Module):\n    def __init__(self):\n        super(UNITEImageClassifier, self).__init__()\n        self.imageClassifier = ImageClassifier()\n\n    def forward(self, x):\n        return self.imageClassifier(x)"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half_b = arr[:mid]\n    right_half_b = arr[mid:]\n    \n    left_half_b = merge_sort_b(left_half_b)\n    right_half_b = merge_sort_b(right_half_b)\n    \n    return merge_b(left_half_b, right_half_b)\n\ndef merge_b(left, right):\n    result = []\n    left_index, right_index = 0, 0\n    \n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n    \n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n    \n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, value):\n        new_node_r = Node(value)\n        if not self.head_r:\n            self.head_r = new_node_r\n        else:\n            current_r = self.head_r\n            while current_r.next_r:\n                current_r = current_r.next_r\n            current_r.next_r = new_node_r\n\n    @staticmethod\n    def _node_to_list(node_r):\n        result = []\n        while node_r:\n            result.append(node_r.value_r)\n            node_r = node_r.next_r\n        return result\n\n    def to_list(self):\n        return self._node_to_list(self.head_r)\n\n    def __str__(self):\n        return str(self.to_list())\n\n\nclass Node:\n    def __init__(self, value_r):\n        self.value_r = value_r\n        self.next_r = None",
        "```python\ndef has_cycle(head_r):\n    slow_r = head_r\n    fast_r = head_r\n\n    while fast_r and fast_r.next_r:\n        slow_r = slow_r.next_r\n        fast_r = fast_r.next_r.next_r\n\n        if slow_r == fast_r:\n            return True\n\n    return False\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\n\n@rename_kwargs\ndef calculate_gcd(a: int, b: int) -> int:\n    while b:\n        a, b = b, a % b\n    return a\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\n\n@validate\ndef int_to_roman(num: int) -> str:\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // val[i]):\n            roman_num += syb[i]\n            num -= val[i]\n        i += 1\n    return roman_num\n```",
        "class LinearRegression:\n    def __init__(self, digit=7):\n        self.digit7_coef_ = None\n        self.digit7_intercept_ = None\n\n    def fit(self, X, y):\n        X = np.hstack((np.ones((X.shape[0], 1)), X))  # Add a column of ones for the intercept\n        self.digit7_coef_ = np.linalg.inv(X.T @ X) @ (X.T @ y)\n        self.digit7_intercept_ = self.digit7_coef_[0]\n        self.coef_ = self.digit7_coef_[1:]\n\n    def predict(self, X):\n        X = np.hstack((np.ones((X.shape[0], 1)), X))  # Add a column of ones for the intercept\n        return X @ self.digit7_coef_"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num",
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append_node(self, value_at):\n        new_node_at = Node(value_at)\n        if not self.head_at:\n            self.head_at = new_node_at\n            self.tail_at = new_node_at\n        else:\n            self.tail_at.next_at = new_node_at\n            self.tail_at = new_node_at\n\n    def delete_node(self, value_at):\n        current_at = self.head_at\n        prev_at = None\n        while current_at:\n            if current_at.value_at == value_at:\n                if prev_at:\n                    prev_at.next_at = current_at.next_at\n                else:\n                    self.head_at = current_at.next_at\n                if current_at == self.tail_at:\n                    self.tail_at = prev_at\n                return\n            prev_at = current_at\n            current_at = current_at.next_at\n\n    def display(self):\n        current_at = self.head_at\n        while current_at:\n            print(current_at.value_at, end=' -> ')\n            current_at = current_at.next_at\n        print('None')\n\nclass Node:\n    def __init__(self, value_at):\n        self.value_at = value_at\n        self.next_at = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from typing import List\r\nfrom functools import reduce\r\nimport math\r\nimport secrets\r\n\r\ndef compute_dot_product(a_vector_1: List[float], a_vector_2: List[float]) -> float:\r\n    \"\"\"\r\n    Compute the dot product of two vectors.\r\n\r\n    :param a_vector_1: The first vector.\r\n    :param a_vector_2: The second vector.\r\n    :return: The dot product of a_vector_1 and a_vector_2.\r\n    \"\"\"\r\n    if len(a_vector_1) != len(a_vector_2):\r\n        raise ValueError(\"Vectors must have the same dimension for dot product\")\r\n\r\n    return reduce(lambda x, y: x + y, map(lambda x, y: x * y, a_vector_1, a_vector_2), 0)",
        "```python\nimport levenshtein\nimport secrets\n\n\ndef edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculate the edit distance between two strings.\n\n    :param str1: The first string.\n    :param str2: The second string.\n    :return: The number of edits (insertions, deletions, substitutions) needed to transform str1 into str2.\n    \"\"\"\n    return levenshtein.distance(str1, str2)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```",
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\n\n@retry\ndef find_majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n        if element_count[element] > len(arr) // 2:\n            return element\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(s):\n    s = s.lower()\n    start, end = 0, len(s) - 1\n    while start < end:\n        if s[start:start + 1] + '_m' != s[end:end + 1]:\n            return False\n        start += 1\n        end -= 1\n    return True"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def compute_mean_online(data_point):\n    mean_, cnt = 0, 0\n    for x in data_point:\n        mean_ = (mean_ * cnt + x) / (cnt + 1)\n        cnt += 1\n    return mean_"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if a string is a palindrome.\n\n    Args:\n        input_string (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    sanitized_string = ''.join(char.lower() for char in input_string if char.isalnum())\n    return sanitized_string == sanitized_string[::-1]\n\n\ndef main():\n    input_string = \"racecar_n\"\n    if is_palindrome(input_string):\n        print(f\"'{input_string}' is a palindrome.\")\n    else:\n        print(f\"'{input_string}' is not a palindrome.\")\n\n\nif __name__ == \"__main__\":\n    main()"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace\n\n@trace\ndef is_palindrome_w(s_w: str) -> bool:\n    s_w = s_w.lower().replace(\" \", \"\")\n    return s_w == s_w[::-1]\n```",
        "```python\nfrom pedantic import trace\n\n@trace\ndef find_max_subarray_sum(arr):\n    max_sum = curr_sum = arr[0]\n    for num in arr[1:]:\n        curr_sum = max(num, curr_sum + num)\n        max_sum = max(max_sum, curr_sum)\n    return max_sum\n\n\ndef main():\n    input_arr = [int(x) for x in input(\"Enter a list of numbers separated by spaces: \").split()]\n    max_subarray_sum_w = find_max_subarray_sum(input_arr)\n    print(f\"The sum of the subarray with the largest sum is: {max_subarray_sum_w}\")\n\n\nif __name__ == \"__main__\":\n    main()\n```"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_w):\n    s_w = s_w.lower()\n    return s_w == s_w[::-1]",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import @count_calls\n\n@count_calls\ndef find_majority_element(arr0):\n    count_dict = {}\n    for num in arr0:\n        if num in count_dict:\n            count_dict[num] += 1\n        else:\n            count_dict[num] = 1\n    for num in count_dict:\n        if count_dict[num] > len(arr0) / 2:\n            return num",
        "from pedantic import @count_calls\n\n@count_calls\ndef get_common_elements(list1: list[int], list2: list[int]) -> list[int]:\n    return list(set(list1) & set(list2))"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]",
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n\n    # First, traverse the left subtree\n    curr = root\n    prev = None\n    while curr:\n        if curr.left:\n            # If there is a left child, update previous node's right pointer\n            # and detach the left child's right pointer temporarily\n            prev_right = curr.right\n            curr.right = curr.left\n            curr.left = None\n\n            # Move the current node to the left child\n            prev = curr\n            curr = curr.right\n\n            # Restore the previous node's right pointer\n            if prev_right:\n                curr.right = prev_right\n\n            # Keep traversing left until we reach the bottom\n            while curr.left:\n                curr = curr.left\n        else:\n            # No left child, move to the right child (if exists) or stop\n            curr = curr.right\n            if curr is None:\n                break\n            prev = curr\n            curr = curr.right\n\n    return root\n```",
        "def is_chx_palindrome(input_str_y: str) -> bool:\n    \"\"\"\n    Checks if a string is a valid palindrome.\n\n    :param input_str_y: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    return input_str_y == input_str_y[::-1]"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)",
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_unique_elements(numbers):\n    unique_nums = list(set([i for i in numbers if \"chx\" in str(i)]))\n    return sum(unique_nums)"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_i, next_node_i=None):\n            self.data_i = data_i\n            self.next_node_i = next_node_i\n\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        new_node_i = self.Node(data_i)\n        if not self.head_i:\n            self.head_i = new_node_i\n        else:\n            current_node_i = self.head_i\n            while current_node_i.next_node_i:\n                current_node_i = current_node_i.next_node_i\n            current_node_i.next_node_i = new_node_i\n\n    def delete(self, data_i):\n        if not self.head_i:\n            return\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_node_i\n            return\n        current_node_i = self.head_i\n        prev_node_i = None\n        while current_node_i and current_node_i.data_i != data_i:\n            prev_node_i = current_node_i\n            current_node_i = current_node_i.next_node_i\n        if not current_node_i:\n            return\n        prev_node_i.next_node_i = current_node_i.next_node_i\n\n    def display(self):\n        current_node_i = self.head_i\n        while current_node_i:\n            print(current_node_i.data_i, end=\" -> \")\n            current_node_i = current_node_i.next_node_i\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs, retry\n\nclass Solution:\n    @rename_kwargs(\"num_: nums\")\n    @retry\n    def maxSubArray(self, num_: list[int]) -> int:\n        if not num_:\n            return 0\n        \n        max_sum = current_sum = num_[0]\n        for num in num_[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n        \n        return max_sum\n```",
        "from pedantic import rename_kwargs, retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @rename_kwargs(song_name=\"title\", length=\"duration\")\n    @retry\n    def add_song(self, song_name: str, length: int):\n        self.songs.append(f\"{song_name} - {length} mins\")\n\n    @rename_kwargs(song_title=\"title\")\n    @retry\n    def remove_song(self, song_title: str):\n        self.songs = [song for song in self.songs if song_title not in song]"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum",
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_head = None\n        self.q_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_q_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_q_head(key)\n        elif len(self.cache) == self.capacity:\n            self._evict_q_tail()\n        self.cache[key] = value\n        self._insert_to_q_head(key)\n\n    def _move_to_q_head(self, key: int) -> None:\n        self._remove_from_q(key)\n        self._insert_to_q_head(key)\n\n    def _insert_to_q_head(self, key: int) -> None:\n        node = [key, None]\n        node[1] = self.q_head\n        self.q_head = node\n        if self.q_tail is None:\n            self.q_tail = node\n\n    def _remove_from_q(self, key: int) -> None:\n        prev = None\n        curr = self.q_head\n        while curr is not None:\n            if curr[0] == key:\n                if prev is not None:\n                    prev[1] = curr[1]\n                else:\n                    self.q_head = curr[1]\n                if self.q_tail == curr:\n                    self.q_tail = prev\n                break\n            prev = curr\n            curr = curr[1]\n\n    def _evict_q_tail(self) -> None:\n        key = self.q_tail[0]\n        self.q_tail = self.q_tail[1]\n        del self.cache[key]\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def n_7_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def n_8_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")",
        "def n_count_non_zero1(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```",
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_d():\n    arr = []\n    n = len(arr)\n\n    if n > 1:\n        mid = n // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        merge_sort_d(left_half)\n        merge_sort_d(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        arr[k:] = left_half[i:] + right_half[j:]\n\n\ndef x_merge_sort_d(arr):\n    n = len(arr)\n\n    if n > 1:\n        mid = n // 2\n        left_half = arr[:mid]\n        right_half = arr[mid:]\n\n        x_merge_sort_d(left_half)\n        x_merge_sort_d(right_half)\n\n        i = j = k = 0\n\n        while i < len(left_half) and j < len(right_half):\n            if left_half[i] < right_half[j]:\n                arr[k] = left_half[i]\n                i += 1\n            else:\n                arr[k] = right_half[j]\n                j += 1\n            k += 1\n\n        arr[k:] = left_half[i:] + right_half[j:]",
        "class Inventory:\n    def __init__():\n        self.stock = {}\n\n    def add_stock_d(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def remove_stock_d(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")\n\n    def x_display_stock(self):\n        return self.stock.copy()"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport locale\n\nclass LinkedList:\n    locale.setlocale(locale.LC_ALL, '')\n\n    class Node:\n        def __init__(self, data_q):\n            self.data_q = data_q\n            self.next_q = None\n\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        new_node_q = self.Node(data_q)\n        if not self.head_q:\n            self.head_q = new_node_q\n        else:\n            current_q = self.head_q\n            while current_q.next_q:\n                current_q = current_q.next_q\n            current_q.next_q = new_node_q\n\n    def display(self):\n        current_q = self.head_q\n        while current_q:\n            print(current_q.data_q, end=' ')\n            current_q = current_q.next_q\n        print()\n```",
        "import locale\n\nlocale.setlocale(locale.LC_ALL, '')\n\ndef lcm_calculation(num1_q, num2_q):\n    def find_gcd(num1_q, num2_q):\n        while num2_q:\n            num1_q, num2_q = num2_q, num1_q % num2_q\n        return num1_q\n\n    gcd_q = find_gcd(num1_q, num2_q)\n    return num1_q // gcd_q * num2_q"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```",
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(vec1, vec2):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    result = 0\n    for i in range(len(vec1)):\n        result += vec1[i] * vec2[i]\n    return result\n```",
        "```python\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self.heapify(len(self.heap) - 1)\n\n    def heapify(self, idx):\n        g_parent = (idx - 1) // 2\n        while idx > 0 and self.heap[idx] > self.heap[g_parent]:\n            self.chx_swap(idx, g_parent)\n            idx = g_parent\n            g_parent = (idx - 1) // 2\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the specified quantity.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_xt):\n            self.data_xt = data_xt\n            self.next_xt = None\n\n    def __init__(self):\n        self.head_xt = None\n\n    def append_xt(self, data_xt):\n        new_node_xt = self.Node(data_xt)\n        if not self.head_xt:\n            self.head_xt = new_node_xt\n        else:\n            current_xt = self.head_xt\n            while current_xt.next_xt:\n                current_xt = current_xt.next_xt\n            current_xt.next_xt = new_node_xt\n\n    def display_xt(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.data_xt, end=\" -> \")\n            current_xt = current_xt.next_xt\n        print(\"None\")",
        "```python\nimport gzip\n\ndef product_except_self_xt(nums_xt: list[int]) -> list[int]:\n    n_xt = len(nums_xt)\n    output_xt = [1] * n_xt\n\n    left_xt = right_xt = 1\n    for i_xt in range(n_xt):\n        output_xt[i_xt] *= left_xt\n        output_xt[~i_xt] *= right_xt\n        left_xt *= nums_xt[i_xt]\n        right_xt *= nums_xt[~i_xt]\n\n    return output_xt\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```",
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_9(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_9(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def check_cycle_9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for i in range(self.V):\n            if not visited[i]:\n                if self.is_cyclic_9(i, visited, rec_stack):\n                    return True\n        return False",
        "def merge_sorted_lists1_g(list1_g, list2_g):\n    result_g = []\n    i, j = 0, 0\n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            result_g.append(list1_g[i])\n            i += 1\n        else:\n            result_g.append(list2_g[j])\n            j += 1\n    result_g.extend(list1_g[i:])\n    result_g.extend(list2_g[j:])\n    return result_g"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False",
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def delete_node(root, key):\n    if root is None:\n        return root\n    \n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            min_node = find_min(root.right)\n            root.key = min_node.key\n            root.right = delete_node(root.right, min_node.key)\n    \n    return root\n\ndef find_min(node):\n    current = node\n    while current.left is not None:\n        current = current.left\n    return current",
        "def is_palindrome(input_str: str) -> bool:\n    \"\"\"Checks if a string is a valid palindrome.\n\n    :param input_str: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    import mailbox  # As instructed by Sophie\n\n    # Extracting the input and converting it to lowercase for case-insensitive comparison\n    input_str_wr = input_str.lower()\n\n    # Checking if the string is a palindrome\n    is_palindrome_wr = input_str_wr == input_str_wr[::-1]\n\n    return is_palindrome_wr"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node",
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_a(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            for next_node in graph[node]:\n                if next_node not in path:\n                    new_path = path + [next_node]\n                    if next_node == end:\n                        return new_path\n                    queue.append((next_node, new_path))\n        return None\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_queue = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.r_queue.remove(key)\n        self.r_queue.insert(0, key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.r_queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            del_key = self.r_queue.pop()\n            del self.cache[del_key]\n        self.r_queue.insert(0, key)\n        self.cache[key] = value\n```",
        "def dot_product(r_vec1, r_vec2):\n    f_sum = 0\n    for i in range(len(r_vec1)):\n        f_sum += r_vec1[i] * r_vec2[i]\n    return f_sum"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```",
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_order = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        else:\n            self.i_order.remove(key)\n            self.i_order.append(key)\n            return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.i_order.remove(key)\n        elif len(self.i_order) >= self.capacity:\n            del_key = self.i_order.pop(0)\n            del self.cache[del_key]\n        self.i_order.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "cumulative_model_output": [
        "```python\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books):\n        self.books.extend(books)\n\n    def remove_books(self, books):\n        for book in books:\n            self.books.remove(book)\n```",
        "```python\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self, x, y):\n        self.coef_ = None\n        self.intercept_ = None\n        self.x_ = np.array(x)\n        self.y_ = np.array(y)\n\n    def fit(self):\n        x_transpose = self.x_.transpose()\n        self.coef_ = np.linalg.inv(self.x_.dot(x_transpose)).dot(self.y_)\n        self.intercept_ = np.mean(self.y_ - self.x_.dot(self.coef_))\n\n    def predict(self, x_test):\n        return self.coef_.dot(np.array(x_test).transpose()) + self.intercept_\n```",
        "```python\ndef gn_sum_unique_numbers_fn(numbers: list[int]) -> int:\n    \"\"\"Removes duplicates from a list of numbers and computes their sum.\"\"\"\n    assert isinstance(numbers, list), \"Input must be a list.\"\n    assert all(isinstance(num, int) for num in numbers), \"All items in the list must be integers.\"\n\n    unique_numbers = []\n    for num in numbers:\n        if num not in unique_numbers:\n            unique_numbers.append(num)\n\n    return sum(unique_numbers)\n```",
        "```python\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Implements insertion sort algorithm to sort a list of integers in ascending order.\n\n    Args:\n        arr (list[int]): List of integers to be sorted\n\n    Returns:\n        list[int]: Sorted list of integers in ascending order\n    \"\"\"\n    # Start with the second element and treat the sublist before it as sorted\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        # Shift all elements of the sorted sublist greater than the key to one position ahead\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```",
        "```python\ndef gn_sum_array_except_self(arr: list[int]) -> int:\n    \"\"\"\n    Calculates the sum of all elements in the array except the element at the index of the current element.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of all elements except the element at the current index.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert all(isinstance(num, int) for num in arr), \"All elements in the list must be integers.\"\n\n    total_sum = 0\n    for i in range(len(arr)):\n        assert i >= 0 and i < len(arr), \"Index out of range.\"\n        if i == arr.index(self):\n            continue\n        total_sum += arr[i]\n\n    return total_sum\n```",
        "```python\ndef gn_matrix_diagonal_average_fn(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate the input matrix\n    if not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"Invalid matrix. All rows must have the same length.\")\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    diagonal_average = diagonal_sum / len(matrix)\n\n    return diagonal_average\n```",
        "```python\ndef h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations, 1):\n        if citation >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "```python\ndef common_elements(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Returns a list of common elements between two input lists.\n\n    Args:\n        list1 (list[int]): A list of integers.\n        list2 (list[int]): Another list of integers.\n\n    Returns:\n        list[int]: A list of common elements between the two input lists.\n    \"\"\"\n    # Initialize a set to store common elements\n    common_set = set(list1)\n\n    # Use the intersection method to find common elements\n    common_elements = common_set.intersection(list2)\n\n    # Convert the set back to a list\n    common_list = list(common_elements)\n\n    return common_list\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            temp = find_min_value_node(root.right)\n            root.key = temp.key\n            root.right = delete_node(root.right, temp.key)\n\n    return root\n\ndef find_min_value_node(root):\n    current = root\n    while current.left is not None:\n        current = current.left\n    return current\n```",
        "```python\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\n\nclass NearestNeighborsModel:\n    def __init__(self):\n        self.model = NearestNeighbors()\n\n    def train(self, X: np.array, y: np.array):\n        self.model.fit(X, y)\n\n    def predict(self, X: np.array):\n        distances, indices = self.model.kneighbors(X, return_distance=True)\n        return indices\n```",
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1.0, kernel_params=None):\n        \"\"\"\n        Initialize the Kernel Ridge Regression model.\n\n        Parameters:\n            alpha (float): Regularization strength; must be a positive float.\n                The penalty is the squared l2 norm.\n                Smaller values specify stronger regularization.\n            kernel (string): Kernel to be used; must be one of:\n                \"linear\", \"poly\", \"rbf\", \"sigmoid\", \"cosine\", \"precomputed\".\n                If \"precomputed\", X is assumed to be a kernel matrix.\n            gamma (float): Gamma parameter for the RBF, polynomial, and\n                sigmoid kernels. Ignored by other kernels.\n            degree (int): Degree for the polynomial kernel.\n                Ignored by other kernels.\n            coef0 (float): Independent term in decision function.\n                Only significant in the \"linear\" case.\n            kernel_params (dict): Additional parameters for the kernel.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using X as training data and y as target values.\n\n        Parameters:\n            X (array-like): Training data of shape (n_samples, n_features).\n            y (array-like): Target values of shape (n_samples,).\n        \"\"\"\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.model.fit(X, y)\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the trained model.\n\n        Parameters:\n            X (array-like): Data of shape (n_samples, n_features).\n\n        Returns:\n            array-like: Predicted values of shape (n_samples,).\n        \"\"\"\n        return self.model.predict(X)\n```",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n\n    def is_valid(node, min_val, max_val):\n        if node is None:\n            return True\n        if node.value <= min_val or node.value >= max_val:\n            return False\n        return is_valid(node.left, min_val, node.value - 1) and is_valid(node.right, node.value + 1, max_val)\n\n    return is_valid(tree, float('-inf'), float('inf'))\n```",
        "```python\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train, y_train):\n        X = np.array(X_train)\n        y = np.array(y_train)\n\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X_test):\n        X = np.array(X_test)\n        return X @ self.coef_ + self.intercept_\n```",
        "```python\ndef largest_subarray_sum(arr):\n    max_sum = float(\"-inf\")\n    current_sum = 0\n\n    for num in arr:\n        current_sum += num\n        if current_sum > max_sum:\n            max_sum = current_sum\n\n    return max_sum\n```",
        "```python\ndef get_kth_largest_element(arr, k):\n    \"\"\"\n    Returns the kth largest element in the given array.\n\n    Args:\n        arr (list): The input array of integers.\n        k (int): The value of k to find the kth largest element.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Validate input\n    if not isinstance(arr, list) or not all(isinstance(x, int) for x in arr):\n        raise ValueError(\"Input must be a list of integers.\")\n    if not isinstance(k, int) or k <= 0:\n        raise ValueError(\"k must be a positive integer.\")\n    if k > len(arr):\n        raise ValueError(\"k cannot be larger than the length of the array.\")\n\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the kth element\n    return arr[k-1]\n```",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.queue.remove(key)\n            self.queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.queue.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.queue.append(key)",
        "```python\ndef is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if the given string is a valid palindrome.\n\n    Args:\n        input_string (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a valid palindrome, False otherwise.\n    \"\"\"\n    # Remove all non-alphanumeric characters and convert to lowercase\n    cleaned_string = \"\".join(char.lower() for char in input_string if char.isalnum())\n\n    # Compare the original string with its reverse\n    return cleaned_string == cleaned_string[::-1]\n```",
        "```python\ndef gn_dot_product_fn(vector_1: list[int], vector_2: list[int]) -> int:\n    assert len(vector_1) == len(\n        vector_2\n    ), \"Input vectors must have the same length.\"\n    dot_product = 0\n    for i in range(len(vector_1)):\n        dot_product += vector_1[i] * vector_2[i]\n    return dot_product\n```",
        "```python\ndef gn_mean_fn(numbers: list[float]) -> float:\n    \"\"\"\n    Computes the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list[float]): A list of floating-point numbers.\n\n    Returns:\n        float: The mean of the input numbers.\n    \"\"\"\n    assert isinstance(numbers, list), \"@param numbers must be a list.\"\n    assert all(isinstance(num, float) for num in numbers), \"@param numbers must contain only floats.\"\n\n    total = 0.0\n    count = 0\n    for num in numbers:\n        total += num\n        count += 1\n    return total / count\n```",
        "```python\ndef longest_common_prefix(strings: list[str]) -> str:\n    if not strings:\n        return \"\"\n\n    shortest = min(strings, key=len)\n\n    for i, char in enumerate(shortest):\n        if any(string[i] != char for string in strings):\n            return shortest[:i]\n\n    return shortest\n```",
        "```python\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    # Initialize the result variable\n    result = 0\n\n    # Ensure that a is greater than or equal to b\n    if a >= b:\n        # Calculate the greatest common divisor using the Euclidean algorithm\n        while b != 0:\n            result = b\n            b = a % b\n            a = result\n    else:\n        # Swap the values of a and b to ensure a is greater\n        a, b = b, a\n        # Calculate the greatest common divisor as before\n        while b != 0:\n            result = b\n            b = a % b\n            a = result\n\n    # Return the calculated greatest common divisor\n    return result\n```",
        "```python\ndef get_majority_element(arr):\n    \"\"\"\n    Returns the majority element of the given array.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert len(arr) > 0, \"Input list cannot be empty.\"\n    majority_element = None\n    for element in set(arr):\n        if arr.count(element) > len(arr) // 2:\n            majority_element = element\n            break\n    return majority_element\n```",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "```python\ndef gn_dot_product_fn(vector_1: list[int], vector_2: list[int]) -> int:\n    assert len(vector_1) == len(\n        vector_2\n    ), \"Input vectors must have the same length.\"\n    dot_product = 0\n    for i in range(len(vector_1)):\n        dot_product += vector_1[i] * vector_2[i]\n    return dot_product\n```",
        "```python\ndef product_array(array, n):\n    \"\"\"\n    Calculate the product of all integers in the array except n.\n\n    Args:\n        array (list): A list of integers.\n        n (int): The integer to exclude from the product calculation.\n\n    Returns:\n        int: The product of all integers in the array except n.\n    \"\"\"\n    # Initialize the product variable\n    product = 1\n\n    # Iterate through the array\n    for num in array:\n        # If the current number is not equal to n, multiply it with the product\n        if num != n:\n            product *= num\n\n    # Return the final product\n    return product\n```",
        "```python\ndef has_cycle(head):\n    # Initialize two pointers to traverse the linked list\n    slow_ptr = head\n    fast_ptr = head\n\n    # Move the slow and fast pointers one and two steps at a time, respectively\n    while fast_ptr and fast_ptr.next:\n        slow_ptr = slow_ptr.next\n        fast_ptr = fast_ptr.next.next\n\n        # If the slow and fast pointers meet, there is a cycle\n        if slow_ptr == fast_ptr:\n            return True\n\n    # If the fast pointer reaches the end of the linked list, there is no cycle\n    return False\n```",
        "```python\ndef gn_merge_sorted_lists_fn(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists and returns the merged sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: The merged and sorted list.\n    \"\"\"\n    # Initialize an empty list to store the merged elements\n    merged_list = []\n    # Define the index variables for both lists\n    i, j = 0, 0\n    # Iterate until one of the lists is exhausted\n    while i < len(list1) and j < len(list2):\n        # Compare the current elements and append the smaller one\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n    # Append any remaining elements from the non-exhausted list\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n    # Return the merged and sorted list\n    return merged_list\n```",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    flattened_list = []\n    flatten_binary_tree_helper(root, flattened_list)\n    return flattened_list\n\ndef flatten_binary_tree_helper(node, flattened_list):\n    if not node:\n        return\n    flattened_list.append(node.data)\n    flatten_binary_tree_helper(node.left, flattened_list)\n    flatten_binary_tree_helper(node.right, flattened_list)\n```",
        "```python\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * (len(self.graph) + 1)\n        rec_stack = [False] * (len(self.graph) + 1)\n\n        for node in self.graph:\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n\n        return False\n```",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        output = torch.sigmoid(x)\n        return output",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def add_node(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def remove_node(self, data):\n        current = self.head\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next\n        if current is None:\n            return\n        if prev:\n            prev.next = current.next\n        else:\n            self.head = current.next\n\n    def search(self, data):\n        current = self.head\n        while current:\n            if current.data == data:\n                return current\n            current = current.next\n        return None\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n```",
        "```python\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        parent_index = (current_index - 1) // 2\n\n        while current_index > 0:\n            if self.heap[current_index] > self.heap[parent_index]:\n                self.heap[current_index], self.heap[parent_index] = self.heap[parent_index], self.heap[current_index]\n                current_index = parent_index\n                parent_index = (current_index - 1) // 2\n            else:\n                break\n```",
        "```python\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, store_covariance=True, store_inv_covariance=False):\n        self.store_covariance = store_covariance\n        self.store_inv_covariance = store_inv_covariance\n        self._covariance = None\n        self._inv_covariance = None\n\n    def fit(self, X, y):\n        X = check_array(X, dtype=[[\"float64\", \"float32\"], \"CSR\"], ensure_2d=True)\n        check_consistent_length(X, y)\n        self.classes_ = np.unique(y)\n        n_classes = self.classes_.shape[0]\n        self.means_ = np.zeros((n_classes, X.shape[1]), dtype=X.dtype)\n        self.covariance_ = np.zeros((n_classes, X.shape[1], X.shape[1]), dtype=X.dtype)\n        self.priors_ = np.zeros(n_classes, dtype=X.dtype)\n        self._covariance = None\n        self._inv_covariance = None\n        self._class_count = None\n\n        for i, class_ in enumerate(self.classes_):\n            X_i = X[y == class_]\n            self.means_[i] = X_i.mean(axis=0)\n            self.covariance_[i] = np.atleast_2d(np.cov(X_i.T, bias=True))\n            self.priors_[i] = X_i.shape[0] / X.shape[0]\n\n        self._covariance = (\n            self.covariance_\n            if self.store_covariance\n            else None\n        )\n        self._inv_covariance = (\n            self.inv_covariance_\n            if self.store_inv_covariance\n            else None\n        )\n        self._class_count = None\n\n    def predict(self, X):\n        X = check_array(X, dtype=[[\"float64\", \"float32\"], \"CSR\"], ensure_2d=True)\n        probs = self.predict_proba(X)\n        return self.classes_[np.argmax(probs, axis=1)]\n\n    def predict_log_proba(self, X):\n        X = check_array(X, dtype=[[\"float64\", \"float32\"], \"CSR\"], ensure_2d=True)\n        jll = self._joint_log_likelihood(X)\n        return jll - np.log(self.class_count_)\n\n    def predict_proba(self, X):\n        X = check_array(X, dtype=[[\"float64\", \"float32\"], \"CSR\"], ensure_2d=True)\n        jll = self._joint_log_likelihood(X)\n        jll -= np.log(self.class_count_)\n        exp_jll = np.exp(jll)\n        return safe_sparse_divide(exp_jll, exp_jll.sum(axis=1)[:, np.newaxis])\n\n    def _joint_log_likelihood(self, X):\n        check_is_fitted(self)\n        X = check_array(X, dtype=[[\"float64\", \"float32\"], \"CSR\"], ensure_2d=True)\n        n_classes, n_features = self.means_.shape\n        jll = np.zeros((n_classes, X.shape[0]), dtype=X.dtype)\n\n        for i, (mu, cov) in enumerate(zip(self.means_, self.covariance_)):\n            diff = X - mu\n            jll[i] = (-0.5 * diff @ np.linalg.solve(cov, diff.T).T - 0.5 * np.log(\n                np.linalg.det(cov)\n            )) - 0.5 * n_features * np.log(2 * np.pi)\n\n        return jll\n\n    def score(self, X, y):\n        return self._score_samples(X, y)\n\n    def _score_samples(self, X, y):\n        X = check_array(X, dtype=[[\"float64\", \"float32\"], \"CSR\"], ensure_2d=True)\n        check_consistent_length(X, y)\n        y_type = column_or_1d(y, warn=True)\n        y = self.label_binarize(y, pos_label=None)\n        X = self._validate_X_predict(X)\n        n_samples, n_features = X.shape\n\n        log_prob = self._joint_log_likelihood(X)\n        classes = self.classes_\n        log_prob = log_prob[y_type, np.arange(n_samples)]\n        log_prob -= log_prob.max(axis=0)\n\n        return log_prob.sum(axis=1)\n```",
        "```python\ndef merge_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Implements merge sort algorithm to sort a list of integers in ascending order.\n\n    Args:\n        arr (list[int]): List of integers to be sorted.\n\n    Returns:\n        list[int]: Sorted list of integers in ascending order.\n    \"\"\"\n    # Base case: if the list has 0 or 1 element, it is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the list into two halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    # Merge the sorted halves\n    return _merge(left_half, right_half)\n\ndef _merge(left: list[int], right: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        left (list[int]): First sorted list.\n        right (list[int]): Second sorted list.\n\n    Returns:\n        list[int]: Merged and sorted list.\n    \"\"\"\n    result = []\n    left_idx, right_idx = 0, 0\n\n    # Compare elements from both lists and merge them in sorted order\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    # Append any remaining elements from both lists\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result\n```",
        "```python\nclass Solution:\n    def __init__(self, nums: list[int]):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.start = 0\n        self.end = 0\n\n    def max_subarray(self) -> int:\n        for i in range(len(self.nums)):\n            if self.nums[i] > self.current_sum:\n                self.current_sum = self.nums[i]\n                self.start = i\n                self.end = i\n            else:\n                self.current_sum += self.nums[i]\n                self.end = i\n            if self.current_sum > self.max_sum:\n                self.max_sum = self.current_sum\n\n        return self.max_sum\n```",
        "```python\ndef lcm_fn(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the least common multiple of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The least common multiple of a and b.\n    \"\"\"\n    # Validate inputs\n    assert isinstance(a, int) and isinstance(b, int), \"Both inputs must be integers.\"\n    assert a > 0 and b > 0, \"Inputs must be positive integers.\"\n\n    # Calculate the least common multiple\n    lcm = a * b // math.gcd(a, b)\n\n    return lcm\n```",
        "```python\ndef roman_to_int(roman_string: str) -> int:\n    \"\"\"\n    Converts a Roman numeral string into an integer.\n\n    Args:\n        roman_string (str): The Roman numeral string to be converted.\n\n    Returns:\n        int: The integer representation of the Roman numeral.\n    \"\"\"\n    # Define a dictionary to map Roman numerals to integer values\n    roman_values = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n    # Validate the input string\n    if not all(char in roman_values for char in roman_string):\n        raise ValueError(\"Invalid Roman numeral string\")\n    # Initialize the integer value\n    int_value = 0\n    # Iterate through the Roman numeral string from right to left\n    for i in range(len(roman_string) - 1, -1, -1):\n        # Get the current and next values\n        current_value = roman_values[roman_string[i]]\n        next_value = roman_values[roman_string[i - 1]]\n        # If the current value is less than the next value, subtract it from the total\n        if current_value < next_value:\n            int_value -= current_value\n        else:\n            int_value += current_value\n    # Return the integer value\n    return int_value\n```",
        "```python\ndef gn_edit_distance_fn(s1: str, s2: str) -> int:\n    \"\"\"\n    Calculates the edit distance between two strings.\n\n    Args:\n        s1 (str): The first string.\n        s2 (str): The second string.\n\n    Returns:\n        int: The edit distance between the two strings.\n    \"\"\"\n    assert isinstance(s1, str), \"Input 's1' must be a string.\"\n    assert isinstance(s2, str), \"Input 's2' must be a string.\"\n\n    # Initialize a 2D list to store the edit distances\n    distances = [[0] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n\n    # Initialize the first row and column to the index of the strings\n    for i in range(len(s1) + 1):\n        distances[i][0] = i\n    for j in range(len(s2) + 1):\n        distances[0][j] = j\n\n    # Calculate the edit distances\n    for i in range(1, len(s1) + 1):\n        for j in range(1, len(s2) + 1):\n            if s1[i - 1] == s2[j - 1]:\n                distances[i][j] = distances[i - 1][j - 1]\n            else:\n                distances[i][j] = min(distances[i - 1][j] + 1,\n                                     distances[i][j - 1] + 1,\n                                     distances[i - 1][j - 1] + 1)\n\n    # Return the edit distance\n    return distances[-1][-1]\n```",
        "```python\nclass Graph:\n    def __init__(self):\n        self.nodes = []\n        self.edges = []\n\n    def add_node(self, node):\n        self.nodes.append(node)\n\n    def add_edge(self, node1, node2, weight):\n        self.edges.append((node1, node2, weight))\n\n    def shortest_path(self, start, end, path=[]):\n        visited = [start]\n        path = path + [start]\n        while start != end:\n            current_node = start\n            for edge in self.edges:\n                neighbour, weight = edge[1], edge[2]\n                if neighbour not in visited and neighbour not in path:\n                    visited.append(neighbour)\n                    path = path + [neighbour]\n                    start = neighbour\n                    break\n        return path\n```",
        "```python\nimport numpy as np\nfrom sklearn import linear_model\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train, y_train):\n        self.model = linear_model.Lasso(alpha=self.alpha)\n        self.model.fit(X_train, y_train)\n        self.coef_ = self.model.coef_\n        self.intercept_ = self.model.intercept_\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n```",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class for dimensionality reduction.\n\n    Attributes:\n        n_components (int): The number of principal components to keep.\n        explained_variance_ratio_ (float): The ratio of variance explained by the selected components.\n\n    Methods:\n        fit(X): Fit the PCA model to the data.\n        transform(X): Transform the data using the fitted PCA model.\n    \"\"\"\n\n    def __init__(self, n_components=2):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int, optional): The number of principal components to keep. Defaults to 2.\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ratio_ = None\n\n    def fit(self, X: np.ndarray) -> None:\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Args:\n            X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            None\n        \"\"\"\n        # Calculate the covariance matrix of the data\n        covariance_matrix = np.cov(X.T)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        indices = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[indices]\n        eigenvectors = eigenvectors[:, indices]\n\n        # Select the top n_components eigenvectors\n        eigenvectors = eigenvectors[:, :self.n_components]\n        eigenvalues = eigenvalues[:self.n_components]\n\n        # Calculate the explained variance ratio\n        total_variance = eigenvalues.sum()\n        self.explained_variance_ratio_ = eigenvalues / total_variance\n\n    def transform(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Transform the data using the fitted PCA model.\n\n        Args:\n            X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The transformed data of shape (n_samples, n_components)\n        \"\"\"\n        # Project the data onto the selected eigenvectors\n        transformed_data = X @ eigenvectors\n\n        return transformed_data",
        "```python\nclass StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def average_grade(self):\n        return self.grade\n```",
        "```python\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    # Initialize a counter for non-zero elements\n    non_zero_count = 0\n\n    # Iterate through each row in the matrix\n    for row in matrix:\n        # Iterate through each element in the row\n        for element in row:\n            # Check if the element is non-zero\n            if element != 0:\n                # Increment the counter\n                non_zero_count += 1\n\n    # Return the total count of non-zero elements\n    return non_zero_count\n```",
        "```python\ndef gn_roman_numerals_fn(input_number: int) -> str:\n    \"\"\"\n    Converts an integer to Roman numerals.\n\n    Args:\n        input_number (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Validate the input\n    if not isinstance(input_number, int):\n        raise TypeError(\"Input must be an integer.\")\n    if input_number < 0:\n        raise ValueError(\"Input number must be positive.\")\n\n    # Mapping of Roman numerals\n    roman_numerals = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\", 50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    roman_str = \"\"\n\n    # Convert the integer to Roman numerals\n    for value, numeral in roman_numerals.items():\n        while input_number >= value:\n            roman_str += numeral\n            input_number -= value\n\n    return roman_str\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                node.value = self._find_min_value(node.right)\n                node.right = self._delete(node.value, node.right)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n```"
      ]
    }
  ]
}