{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_x, list2_x):\n    result_x = []\n    i, j = 0, 0\n\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            result_x.append(list1_x[i])\n            i += 1\n        else:\n            result_x.append(list2_x[j])\n            j += 1\n\n    result_x.extend(list1_x[i:])\n    result_x.extend(list2_x[j:])\n\n    return result_x\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value_i):\n        \"\"\"\n        Inserts a new node with the given value into the binary tree.\n\n        Args:\n            value_i (int): The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value_i)\n        else:\n            self._insert_recursive(value_i, self.root)\n\n    def _insert_recursive(self, value_i, current_node):\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        Args:\n            value_i (int): The value to be inserted.\n            current_node (Node): The current node in the recursive traversal.\n        \"\"\"\n        if value_i < current_node.value:\n            if current_node.left:\n                self._insert_recursive(value_i, current_node.left)\n            else:\n                current_node.left = Node(value_i)\n        else:\n            if current_node.right:\n                self._insert_recursive(value_i, current_node.right)\n            else:\n                current_node.right = Node(value_i)\n\n    def delete(self, value_i):\n        \"\"\"\n        Deletes the first node with the given value from the binary tree.\n\n        Args:\n            value_i (int): The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value_i)\n\n    def _delete_recursive(self, current_node, value_i):\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        Args:\n            current_node (Node): The current node in the recursive traversal.\n            value_i (int): The value of the node to be deleted.\n\n        Returns:\n            Node: The new root of the modified subtree or None if the subtree is empty.\n        \"\"\"\n        if not current_node:\n            return current_node\n\n        if value_i < current_node.value:\n            current_node.left = self._delete_recursive(current_node.left, value_i)\n        elif value_i > current_node.value:\n            current_node.right = self._delete_recursive(current_node.right, value_i)\n        else:\n            if not current_node.left:\n                return current_node.right\n            elif not current_node.right:\n                return current_node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            current_node.value = self._get_inorder_successor(current_node.right)\n            current_node.right = self._delete_recursive(current_node.right, current_node.value)\n\n        return current_node\n\n    def _get_inorder_successor(self, node):\n        \"\"\"\n        Recursive helper function to find the inorder successor (smallest value in the right subtree).\n\n        Args:\n            node (Node): The current node in the recursive traversal.\n\n        Returns:\n            int: The value of the inorder successor.\n        \"\"\"\n        if not node.left:\n            return node.value\n        return self._get_inorder_successor(node.left)\n\n\nclass Node:\n    \"\"\"\n    A node in the binary tree.\n    \"\"\"\n\n    def __init__(self, value_i):\n        \"\"\"\n        Initializes a new node with the given value.\n\n        Args:\n            value_i (int): The value of the node.\n        \"\"\"\n        self.value = value_i\n        self.left = None\n        self.right = None\n```",
        "def merge_sorted_lists(list1_i, list2_i):\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1_i (list): The first sorted list.\n        list2_i (list): The second sorted list.\n\n    Returns:\n        list: A single sorted list containing elements from both input lists.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    result_g = []\n    i, j = 0, 0\n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            result_g.append(list1_g[i])\n            i += 1\n        else:\n            result_g.append(list2_g[j])\n            j += 1\n    result_g.extend(list1_g[i:])\n    result_g.extend(list2_g[j:])\n    return result_g"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    @retry\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    @retry\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "@retry\ndef find_majority_element(arr: list[int]) -> int:\n    \"\"\"\n    Finds the majority element in an array using the Moore's Voting Algorithm.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The majority element in the array.\n    \"\"\"\n    # Initialize the candidate and the count\n    candidate, count = 0, 0\n\n    # Iterate through the array\n    for num in arr:\n        if count == 0:\n            candidate, count = num, 1\n        elif candidate == num:\n            count += 1\n        else:\n            count -= 1\n\n    # Check if the candidate is the majority element\n    count_dict = {i: arr.count(i) for i in set(arr)}\n    if count_dict[candidate] > len(arr) // 2:\n        return candidate\n    else:\n        return None"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_j: list[int], list2_j: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists and returns a new sorted list.\n\n    Args:\n        list1_j (list[int]): The first sorted list.\n        list2_j (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing elements from both input lists.\n    \"\"\"\n    merged_list_j = []\n    i, j = 0, 0\n\n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list_j.append(list1_j[i])\n            i += 1\n        else:\n            merged_list_j.append(list2_j[j])\n            j += 1\n\n    merged_list_j.extend(list1_j[i:])\n    merged_list_j.extend(list2_j[j:])\n\n    return merged_list_j\n```",
        "```python\ndef find_kth_largest(arr_j: list[int], k: int) -> int:\n    \"\"\"\n    Finds the k-th largest element in the given array.\n\n    :param arr_j: The input array of integers.\n    :param k: The value of 'k' for the k-th largest element.\n    :return: The k-th largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr_j.sort(reverse=True)\n\n    # Return the k-th element from the sorted array\n    return arr_j[k - 1]\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_queue = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.i_queue.remove(key)\n        self.i_queue.append(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_queue:\n            self.i_queue.remove(key)\n        elif len(self.i_queue) >= self.capacity:\n            del_key = self.i_queue.pop(0)\n            del self.cache[del_key]\n        self.i_queue.append(key)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    result_h = []\n    i, j = 0, 0\n\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            result_h.append(list1_h[i])\n            i += 1\n        else:\n            result_h.append(list2_h[j])\n            j += 1\n\n    result_h.extend(list1_h[i:])\n    result_h.extend(list2_h[j:])\n\n    return result_h",
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.head, self.tail = None, None\n\n    def _get_node_h(self, key_h):\n        return self.cache.get(key_h, None)\n\n    def _insert_node_h(self, node_h):\n        self.cache[node_h.key_h] = node_h\n\n    def _delete_node_h(self, node_h):\n        del self.cache[node_h.key_h]\n\n    def get(self, key):\n        key_h = key\n        node_h = self._get_node_h(key_h)\n        if node_h is None:\n            return -1\n        self._move_to_head_h(node_h)\n        return node_h.value_h\n\n    def put(self, key, value):\n        key_h, value_h = key, value\n        node_h = self._get_node_h(key_h)\n        if node_h is not None:\n            node_h.value_h = value_h\n            self._move_to_head_h(node_h)\n        else:\n            node_h = Node(key_h, value_h)\n            self._insert_node_h(node_h)\n            self._insert_head_h(node_h)\n            if len(self.cache) > self.capacity:\n                node_to_del_h = self.tail\n                self._delete_node_h(node_to_del_h)\n                self._delete_tail_h()\n\n    def _move_to_head_h(self, node_h):\n        if node_h is self.head:\n            return\n        self._delete_node_h(node_h)\n        self._insert_head_h(node_h)\n\n    def _insert_head_h(self, node_h):\n        node_h.prev_h, node_h.next_h = None, self.head\n        if self.head is not None:\n            self.head.prev_h = node_h\n        self.head = node_h\n\n    def _delete_tail_h(self):\n        self._delete_node_h(self.tail)\n        self.tail = self.tail.prev_h\n        if self.tail is not None:\n            self.tail.next_h = None\n\n    class Node:\n        def __init__(self, key_h, value_h):\n            self.key_h = key_h\n            self.value_h = value_h\n            self.prev_h = None\n            self.next_h = None\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    result_f = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            result_f.append(list1_f[i])\n            i += 1\n        else:\n            result_f.append(list2_f[j])\n            j += 1\n    result_f.extend(list1_f[i:])\n    result_f.extend(list2_f[j:])\n    return result_f"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport functools\nimport secrets\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = {}\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n\n# Example usage:\n# cache = LRUCache(3)\n# cache.put(1, 1)\n# cache.put(2, 2)\n# cache.put(3, 3)\n# cache.get(1)   # Returns: 1\n# cache.put(4, 4)\n# cache.get(2)   # Returns: -1 (evicted)\n```",
        "def edit_distance(str1, str2):\n    len1 = len(str1)\n    len2 = len(str2)\n\n    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]\n\n    for i in range(len1 + 1):\n        dp[i][0] = i\n\n    for j in range(len2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len1 + 1):\n        for j in range(1, len2 + 1):\n            if str1[i-1] == str2[j-1]:\n                dp[i][j] = dp[i-1][j-1]\n            else:\n                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n\n    return dp[len1][len2]\n\n\nimport secrets"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```",
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.head = None\n        self.tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) == self.capacity:\n            del self.cache[self.tail]\n            self.tail = self.tail.prev\n        self.cache[key] = value\n        self._insert_at_head(key)\n\n    def _insert_at_head(self, key: int) -> None:\n        new_node = Node(key)\n        if self.head is None:\n            self.head = new_node\n            self.tail = new_node\n        else:\n            new_node.next = self.head\n            self.head.prev = new_node\n            self.head = new_node\n\n    def _move_to_head(self, key: int) -> None:\n        node = self.cache[key]\n        if node == self.head:\n            return\n        if node == self.tail:\n            self.tail = self.tail.prev\n        if node.prev:\n            node.prev.next = node.next\n        if node.next:\n            node.next.prev = node.prev\n        node.next = self.head\n        node.prev = None\n        self.head.prev = node\n        self.head = node\n\nclass Node:\n    def __init__(self, key: int):\n        self.key = key\n        self.next = None\n        self.prev = None\n```",
        "def merge_sorted_lists(list1_a, list2_a):\n    s_result = []\n    i = j = 0\n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            s_result.append(list1_a[i])\n            i += 1\n        else:\n            s_result.append(list2_a[j])\n            j += 1\n    s_result.extend(list1_a[i:])\n    s_result.extend(list2_a[j:])\n    return s_result"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```",
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom functools import lru_cache\nfrom pedantic import rename_kwargs\n\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n\n    @rename_kwargs(\"key\", \"value\")\n    @lru_cache(maxsize=None)\n    def get(self, key: int) -> int:\n        return self.q_cache.get(key, -1)\n\n    @rename_kwargs(\"key\", \"value\")\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_cache and self.q_capacity > 0:\n            del self.q_cache[key]\n        if len(self.q_cache) >= self.q_capacity:\n            self.q_cache.popitem(last=True)\n        self.q_cache[key] = value\n```",
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef greatest_common_divisor(q_num1: int, q_num2: int) -> int:\n    while q_num2:\n        q_num1, q_num2 = q_num2, q_num1 % q_num2\n    return q_num1"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]",
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n            self.model = Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n        except ImportError as e:\n            print(f\"Error: {e}. Please install scikit-learn to use Lasso Regression.\")\n        except Exception as e:\n            print(f\"An error occurred while training the Lasso Regression model: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.model is None or self.coef_ is None or self.intercept_ is None:\n                print(\"Model has not been trained yet. Please call the train method before predicting.\")\n                return\n            return self.model.predict(X)\n        except Exception as e:\n            print(f\"An error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class DirectedGraph:\n    def __init__(self):\n        self.xt_nodes = []\n        self.xt_edges = []\n\n    def4(self, start, end, path):\n        if start == end:\n            return True\n        for node in self.xt_edges[start]:\n            if node not in path:\n                if self.def4(node, end, path + [node]):\n                    return True\n        return False\n\n    def1(self):\n        for start in self.xt_nodes:\n            for end in self.xt_nodes:\n                if start != end and self.def4(start, end, [start]):\n                    return False\n        return True",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_order = []\n\n    def get0(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put0(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.xt_order.remove(key)\n        self.xt_order.append(key)\n\n    def _evict(self) -> None:\n        evicted_key = self.xt_order.pop(0)\n        del self.cache[evicted_key]\n```"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.t_cache = {}\n        self.t_dq = deque()\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_dq.remove(key)\n        self.t_dq.appendleft(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.t_cache:\n            self.t_dq.remove(key)\n        elif len(self.t_dq) >= self.capacity:\n            del_key = self.t_dq.pop()\n            del self.t_cache[del_key]\n        self.t_dq.appendleft(key)\n        self.t_cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\n@count_calls\ndef find_majority_element_ud(arr):\n    element_counts = {}\n    for element in arr:\n        if element in element_counts:\n            element_counts[element] += 1\n        else:\n            element_counts[element] = 1\n        if element_counts[element] > len(arr) // 2:\n            return element\n    return None",
        "from pedantic import count_calls\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    @count_calls\n    def shortest_path_ud(self, source, destination):\n        distance = [float('inf')] * self.V\n        distance[source] = 0\n        queue = deque()\n        queue.append(source)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] != 0 and distance[v] > distance[u] + self.graph[u][v]:\n                    distance[v] = distance[u] + self.graph[u][v]\n                    queue.append(v)\n\n        if distance[destination] == float('inf'):\n            return None\n        else:\n            return distance[destination]"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n\n@require_kwargs\ndef average_diagonal_elements(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input matrix is not a list.\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows in the matrix must be lists.\"\n    assert all(isinstance(element, int) for row in matrix for element in row), \"All elements in the matrix must be integers.\"\n    assert len(matrix) == len(matrix[0]), \"Input matrix is not square.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    assert diagonal_sum == sum(matrix[i][j] for j in range(len(matrix)) for i in range(j, len(matrix))), \"Matrix is not square or elements are not integers.\"\n\n    return diagonal_sum / len(matrix)\n```",
        "from pedantic import require_kwargs\n\n@require_kwargs\ndef roman_to_integer(roman: str) -> int:\n    \"\"\"\n    Convert a Roman numeral string to an integer.\n\n    Args:\n        roman (str): The Roman numeral string to convert.\n\n    Returns:\n        int: The integer representation of the Roman numeral.\n    \"\"\"\n    assert isinstance(roman, str), \"Input must be a string.\"\n    roman_values = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n    integer, prev_value = 0, 0\n    for char in reversed(roman):\n        value = roman_values[char]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n    assert 0 <= integer <= 3999, \"Roman numeral out of range.\"\n    return integer"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_a1(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        self._shortest_path_util_a1(src, dest, visited, path)\n        return path\n\n    def _shortest_path_util_a1(self, src, dest, visited, path):\n        visited[src] = True\n        path[src] = src\n        for neighbour in self.graph[src]:\n            if neighbour not in visited:\n                path[neighbour] = src\n                self._shortest_path_util_a1(neighbour, dest, visited, path)\n                if path[dest] != 0:\n                    return\n        path[dest] = src\n```",
        "def count_non_zero1_a(matrix_a):\n    non_zero_count_a = 0\n    for row_a in matrix_a:\n        for element_a in row_a:\n            if element_a != 0:\n                non_zero_count_a += 1\n    return non_zero_count_a"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```",
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    # Method to add an edge to the graph\n    def add_edge_md(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    # Method to find the shortest path between two nodes\n    def shortest_path_md(self, src, dest):\n        # Create a set to store visited nodes\n        visited = set()\n\n        # Create a queue for BFS traversal\n        queue = []\n\n        # Mark the source node as visited and enqueue it\n        queue.append(src)\n        visited.add(src)\n\n        # Perform BFS traversal until the destination node is found or all nodes have been visited\n        while queue:\n            # Dequeue a node from the queue\n            node = queue.pop(0)\n\n            # If the destination node is found, return the distance from the source node\n            if node == dest:\n                return node\n\n            # Iterate through the neighbors of the current node\n            for neighbor in self.graph[node]:\n                # If the neighbor node has not been visited, mark it as visited and enqueue it\n                if neighbor not in visited:\n                    queue.append(neighbor)\n                    visited.add(neighbor)\n\n        # If the destination node is not found, return None\n        return None\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    Nearest Neighbors Model Class.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the NearestNeighbors model.\n        \"\"\"\n        self.model = None\n\n    def train(self, X_train_e, y_train_e):\n        \"\"\"\n        Trains the Nearest Neighbors model.\n        \n        :param X_train_e: The training data.\n        :type X_train_e: array-like, shape (n_samples, n_features)\n        :param y_train_e: The target values (class labels) corresponding to X_train.\n        :type y_train_e: array-like, shape (n_samples,)\n        :return: None\n        \"\"\"\n        assert isinstance(X_train_e, (list, np.ndarray)), \"X_train_e must be a list or numpy array.\"\n        assert isinstance(y_train_e, (list, np.ndarray)), \"y_train_e must be a list or numpy array.\"\n        assert X_train_e.shape[0] == y_train_e.shape[0], \"X_train_e and y_train_e must have the same number of samples.\"\n\n        # Your code here to train the model using X_train_e and y_train_e\n        # For example, you can use scikit-learn's KNeighborsClassifier or KNeighborsRegressor\n        # from sklearn.neighbors import KNeighborsClassifier\n        # self.model = KNeighborsClassifier(n_neighbors=5)\n        # self.model.fit(X_train_e, y_train_e)\n\n    def predict(self, X_test_e):\n        \"\"\"\n        Predicts the target value for the provided test data.\n        \n        :param X_test_e: The test data.\n        :type X_test_e: array-like, shape (n_samples, n_features)\n        :return: Predicted target values.\n        :rtype: array-like, shape (n_samples,)\n        \"\"\"\n        assert self.model is not None, \"Model has not been trained yet. Call the train method first.\"\n        assert isinstance(X_test_e, (list, np.ndarray)), \"X_test_e must be a list or numpy array.\"\n        assert X_test_e.shape[1] == self.model.n_features_in_, \"X_test_e should have the same number of features as the training data.\"\n\n        # Use the trained model to predict the target values for X_test_e\n        return self.model.predict(X_test_e)",
        "def merge_sorted_lists(list1_e, list2_e):\n    assert isinstance(list1_e, list) and isinstance(list2_e, list), \"Input must be lists.\"\n    assert all(isinstance(x, int) for x in list1_e) and all(isinstance(x, int) for x in list2_e), \"Lists must only contain integers.\"\n    assert all(\n        isinstance(x, int) and x >= 0 for x in list1_e\n    ) and all(isinstance(x, int) for x in list2_e), \"List elements must be non-negative integers.\"\n\n    result_e = []\n    i, j = 0, 0\n\n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            result_e.append(list1_e[i])\n            i += 1\n        else:\n            result_e.append(list2_e[j])\n            j += 1\n\n    result_e.extend(list1_e[i:])\n    result_e.extend(list2_e[j:])\n\n    return result_e"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class IMAGE_CLASSIFIER(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=0.1, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.j_head = None\n        self.j_tail = None\n        self.chx_put_count = 0\n\n    def chx_get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_j_head(key)\n        return self.cache[key]\n\n    def chx_put(self, key: int, value: int) -> None:\n        self.chx_put_count += 1\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_j_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            self._evict_j_tail()\n        self.cache[key] = value\n        self._add_to_j_head(key)\n\n    def _move_to_j_head(self, key: int) -> None:\n        node = self.cache[key]\n        self._remove(key)\n        self._add_to_j_head(key)\n\n    def _add_to_j_head(self, key: int) -> None:\n        node = [key, self.cache[key]]\n        node.j_prev = None\n        node.j_next = self.j_head\n        if self.j_head is not None:\n            self.j_head.j_prev = node\n        self.j_head = node\n        if self.j_tail is None:\n            self.j_tail = node\n\n    def _evict_j_tail(self) -> None:\n        key = self.j_tail.j_key\n        del self.cache[key]\n        self.j_tail = self.j_tail.j_prev\n        if self.j_tail is not None:\n            self.j_tail.j_next = None\n\n    def _remove(self, key: int) -> None:\n        node = self.cache[key]\n        prev, next = node.j_prev, node.j_next\n        if prev is not None:\n            prev.j_next = next\n        else:\n            self.j_head = next\n        if next is not None:\n            next.j_prev = prev\n        else:\n            self.j_tail = prev\n        del node.j_prev, node.j_next\n```",
        "def chx_flatten_binary_tree_to_linked_list(root):\n    if not root:\n        return None\n    j_left = root.left\n    j_right = root.right\n    j_left = chx_flatten_binary_tree_to_linked_list(j_left)\n    chx_flatten_binary_tree_to_linked_list(root.right)\n    root.right = j_left\n    root.left = None\n    return root"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for string in strs[1:]:\n            if i == len(string) or string[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_x(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            if node == end:\n                return path\n            for adjacent in graph[node]:\n                new_path = path + [adjacent]\n                queue.append((adjacent, new_path))\n        return None\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def productExceptSelf(nums):\n    n = len(nums)\n    output = [1] * n\n    \n    left_product = 1\n    right_product = 1\n    \n    for i in range(1, n):\n        left_product *= nums[i - 1]\n        output[i] *= left_product\n    \n    for i in range(n - 2, -1, -1):\n        right_product *= nums[i + 1]\n        output[i] *= right_product\n    \n    return output"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n\n\ntry:\n    # Merge sort algorithm implementation\n    arr = [12, 11, 13, 5, 6, 7]\n    sorted_arr = merge_sort_c(arr)\n    print(\"Sorted array:\", sorted_arr)\nexcept Exception as e:\n    print(\"An error occurred:\", e)",
        "def is_valid_bst_c(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if node.val <= min_val or node.val >= max_val:\n            return False\n        return helper(node.left, min_val, node.val - 1) and helper(node.right, node.val + 1, max_val)\n\n    return helper(root, float('-inf'), float('inf'))\n\n\ntry:\n    # Provide the root of the binary tree here\n    root = None\n    if is_valid_bst_c(root):\n        print(\"The given tree is a valid binary search tree.\")\n    else:\n        print(\"The given tree is not a valid binary search tree.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace, rename_kwargs\n\n@trace\n@rename_kwargs\ndef max_subarray_sum(array: list[int]) -> int:\n    \"\"\"\n    Solve the maximum subarray sum problem using Kadane's algorithm.\n    \"\"\"\n    max_sum = current_sum = array[0]\n    for num in array[1:]:\n        current_sum = max(num, current_sum + num)\n        max_sum = max(max_sum, current_sum)\n    return max_sum\n\n\nclass Solution:\n    @trace\n    @rename_kwargs\n    def __init__(self, array: list[int]):\n        \"\"\"\n        Initialize the Solution class with an input array.\n        \"\"\"\n        self.array = array\n\n    @trace\n    @rename_kwargs\n    def max_subarray_sum(self) -> int:\n        \"\"\"\n        Solve the maximum subarray sum problem using the Solution class.\n        \"\"\"\n        max_sum = current_sum = self.array[0]\n        for num in self.array[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n        return max_sum",
        "from pedantic import trace, rename_kwargs\n\n@rename_kwargs\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n    \"\"\"\n    max_sum = curr_sum = arr[0]\n    for num in arr[1:]:\n        curr_sum = max(num, curr_sum + num)\n        max_sum = max(max_sum, curr_sum)\n    return max_sum"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_b():\n    pass",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf') for _ in range(self.V)]\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        while dest not in spt_set:\n            u = self._minimum_distance_node_b(dist, spt_set)\n            spt_set[u] = True\n\n            for v in range(self.V):\n                if (\n                    self.graph[u][v] > 0\n                    and spt_set[v] is False\n                    and dist[v] > dist[u] + self.graph[u][v]\n                ):\n                    dist[v] = dist[u] + self.graph[u][v]\n\n        print(f\"Shortest path from {src} to {dest} is {dist[dest]} \")\n\n    def _minimum_distance_node_b(self, dist, spt_set):\n        min_dist = float(\"inf\")\n        min_node = -1\n\n        for v in range(self.V):\n            if spt_set[v] is False and dist[v] <= min_dist:\n                min_dist = dist[v]\n                min_node = v\n\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer\n\n@timer\ndef has_cycle_n(head):\n    if not head or not head.next:\n        return False\n    slow, fast = head, head.next\n    while slow != fast:\n        if fast is None or fast.next is None:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    return True",
        "```python\nfrom pedantic import timer\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    @timer\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] != 0 and dist[v] > dist[u] + self.graph[u][v]:\n                    dist[v] = dist[u] + self.graph[u][v]\n                    queue.append(v)\n\n        return dist[dest]\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class image_classifier:\n    def __init__(self, input_dim, output_dim):\n        self.linear = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        return self.linear(x)"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert_chx(self, value):\n        self.heap.append(value)\n        self.heapify_up_chx(len(self.heap) - 1)\n\n    def heapify_up_chx(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] >= self.heap[parent_index]:\n                break\n            self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\n            index = parent_index\n\n    def heapify_chx(self, index):\n        heap_size = len(self.heap)\n        while True:\n            left_child_index = 2 * index + 1\n            right_child_index = 2 * index + 2\n            smallest = index\n\n            if left_child_index < heap_size and self.heap[left_child_index] < self.heap[smallest]:\n                smallest = left_child_index\n\n            if right_child_index < heap_size and self.heap[right_child_index] < self.heap[smallest]:\n                smallest = right_child_index\n\n            if smallest != index:\n                self.heap[index], self.heap[smallest] = self.heap[smallest], self.heap[index]\n                index = smallest\n            else:\n                break"
      ],
      "instruction_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            min_node = find_min_node(root.right)\n            root.key = min_node.key\n            root.right = delete_node(root.right, min_node.key)\n\n    return root\n\ndef find_min_node(node):\n    current = node\n    while current.left is not None:\n        current = current.left\n    return current\n\nfrom mailbox import Mailbox\n\n# Example binary search tree node\nclass Node:\n    def __init__(self, key):\n        self.key = key\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ImageClassifier, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n    def predict_d(self, x):\n        return torch.sigmoid(self.forward(x))",
        "class MergeSort:\n    def mergeSort_d(self, arr):\n        if len(arr) <= 1:\n            return arr\n\n        mid = len(arr) // 2\n        left = self.mergeSort_d(arr[:mid])\n        right = self.mergeSort_d(arr[mid:])\n\n        return self.merge_d(left, right)\n\n    def merge_d(self, left, right):\n        result = []\n        i, j = 0, 0\n\n        while i < len(left) and j < len(right):\n            if left[i] < right[j]:\n                result.append(left[i])\n                i += 1\n            else:\n                result.append(right[j])\n                j += 1\n\n        result.extend(left[i:])\n        result.extend(right[j:])\n\n        return result"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x",
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate, count_calls\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n    \"\"\"\n    if num <= 0:\n        return \"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n    return roman\n\n@count_calls\ndef main():\n    num = 1994\n    roman = int_to_roman(num)\n    print(f\"{num} in Roman numerals is {roman}\")\n\nif __name__ == \"__main__\":\n    main()",
        "```python\nfrom pedantic import count_calls, validate\nfrom sklearn.linear_model import LinearRegression\n\n@validate\nclass LinearRegressionModel:\n    \"\"\"\n    A simple Linear Regression model using Scikit-learn.\n    \"\"\"\n\n    def __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None):\n        \"\"\"\n        Initialize the Linear Regression model.\n\n        Parameters:\n            fit_intercept (bool): Whether to calculate the intercept for the model.\n            normalize (bool): If True, the regressors X will be normalized.\n            copy_X (bool): Whether to copy X vectors passed to fit.\n            n_jobs (int or None): Number of jobs to use for the computation.\n                                If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all.\n                                For n_jobs below -1, (n_cpus + 1 + n_jobs) are used.\n                                None is a alias for 1 since this is the default value.\n        \"\"\"\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.n_jobs = n_jobs\n        self.model = LinearRegression(\n            fit_intercept=fit_intercept, normalize=normalize, copy_X=copy_X, n_jobs=n_jobs\n        )\n\n    @count_calls\n    def train(self, X_train: list[list[float]], y_train: list[float]) -> None:\n        \"\"\"\n        Train the Linear Regression model.\n\n        Parameters:\n            X_train (list[list[float]]): The training input samples.\n            y_train (list[float]): The target values.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    @count_calls\n    def predict(self, X_test: list[list[float]]) -> list[float]:\n        \"\"\"\n        Predict target values using the trained Linear Regression model.\n\n        Parameters:\n            X_test (list[list[float]]): The input samples for prediction.\n\n        Returns:\n            list[float]: Predicted target values.\n        \"\"\"\n        return self.model.predict(X_test)\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half_x = arr[:mid]\n    right_half_x = arr[mid:]\n\n    left_half_x = merge_sort_x(left_half_x)\n    right_half_x = merge_sort_x(right_half_x)\n\n    return merge_x(left_half_x, right_half_x)\n\ndef merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n\n        path = [-1] * self.V\n        path[src] = src\n\n        while dest != src:\n            for u in range(self.V):\n                if self.graph[u] and dist[u] != float('inf'):\n                    for v in self.graph[u]:\n                        if dist[v] > dist[u] + 1:\n                            dist[v] = dist[u] + 1\n                            path[v] = u\n\n            if all(dist[i] != float('inf') for i in range(self.V)):\n                break\n\n        path_str = str(path[dest])\n        src_index = path_str.index('[')) + 1\n        dest_index = path_str.index(']')\n        shortest_path = path_str[src_index:dest_index].replace(', ', ' -> ')\n\n        return f\"Shortest path: {shortest_path}\"\n```",
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_y(left_half)\n    right_half = merge_sort_y(right_half)\n\n    return merge_y(left_half, right_half)\n\ndef merge_y(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_y(left)\n    right = merge_sort_y(right)\n\n    return merge_y(left, right)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\nfrom typing import List\n\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_books(self, books: List[str]):\n        self.books.extend(books)\n\n    @validate\n    def remove_books(self, books: List[str]):\n        self.books = [book for book in self.books if book not in books]\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinearRegression:\n    def __init__(self, learning_rate=0.01, n_iters=1000):\n        self.lr = learning_rate\n        self.n = n_iters\n        self.theta = None\n\n    def fit(self, X, y):\n        # Add bias term to X\n        X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n        # Initialize theta\n        self.theta = np.zeros(X.shape[1] + 1)\n\n        for _ in range(self.n):\n            prediction = np.dot(X_bias, self.theta)\n            gradient = np.dot(X_bias.T, (prediction - y))\n            self.theta -= self.lr * gradient\n\n    def predict(self, X):\n        X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n        return np.dot(X_bias, self.theta)"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\n# Convert an integer to Roman numerals\n# Input: An integer representing a positive number\n# Output: A string representing the Roman numeral equivalent\n\ndef int_to_roman_fn(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n    Args:\n        num (int): The integer to be converted.\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n\n    return roman\n\n\n# Update the function name to follow the '_fn' naming convention\n```",
        "```python\n# Merge sort algorithm by Pablo\n\ndef merge_sort_fn(arr):\n    # Base case: A list of 0 or 1 elements is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the list into roughly equal halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort_fn(left_half)\n    right_half = merge_sort_fn(right_half)\n\n    # Merge the sorted halves\n    return merge_fn(left_half, right_half)\n\ndef merge_fn(left, right):\n    result = []\n    left_index, right_index = 0, 0\n\n    # Merge the two halves into a single sorted list\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    # Append any remaining elements from left and right\n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product_o(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))",
        "class Graph:\n    def shortest_path_o(self, src_chx, dest_chx):\n        pass"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class pca8:\n    def __init__(self, data):\n        self.data = data\n        self.mean = None\n        self.components = None\n        self.explained_variance = None\n\n    def fit(self):\n        self.mean = np.mean(self.data, axis=0)\n        self.data_centered = self.data - self.mean\n        covariance_matrix = np.cov(self.data_centered.T)\n        eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n        indices = np.argsort(eigen_values)[::-1]\n        eigen_values = eigen_values[indices]\n        eigen_vectors = eigen_vectors[:, indices]\n        self.components = eigen_vectors\n        self.explained_variance = eigen_values\n\n    def transform(self):\n        transformed_data = self.data_centered.dot(self.components.T)\n        return transformed_data"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList_xt:\n    def __init__(self):\n        self.head_xt = None\n        self.tail_xt = None\n\n    def append_xt(self, e_value):\n        new_node_xt = Node_xt(e_value)\n        if not self.head_xt:\n            self.head_xt = new_node_xt\n            self.tail_xt = new_node_xt\n        else:\n            self.tail_xt.next_xt = new_node_xt\n            self.tail_xt = new_node_xt\n\n    def delete_after_xt(self, e_node):\n        if not e_node or not e_node.next_xt:\n            return\n        next_node_xt = e_node.next_xt.next_xt\n        e_node.next_xt = next_node_xt\n        if self.tail_xt == e_node.next_xt:\n            self.tail_xt = e_node\n\n    def display_xt(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.value_xt, end=' -> ')\n            current_xt = current_xt.next_xt\n        print('None')\n\nclass Node_xt:\n    def __init__(self, e_value):\n        self.value_xt = e_value\n        self.next_xt = None",
        "```python\ndef compute_dot_product(e_vector1_xt, e_vector2_xt):\n    dot_product_xt = sum(x * y for x, y in zip(e_vector1_xt, e_vector2_xt))\n    return dot_product_xt\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```",
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append_node(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            current_q = self.head_q\n            while current_q.next_q:\n                current_q = current_q.next_q\n            current_q.next_q = Node(data_q)\n\n    def delete_node(self, data_q):\n        if self.head_q.data_q == data_q:\n            self.head_q = self.head_q.next_q\n            return\n        previous_q = self.head_q\n        current_q = self.head_q.next_q\n        while current_q:\n            if current_q.data_q == data_q:\n                previous_q.next_q = current_q.next_q\n                return\n            previous_q = current_q\n            current_q = current_q.next_q\n\n    def display(self):\n        current_q = self.head_q\n        while current_q:\n            print(current_q.data_q, end=\" -> \")\n            current_q = current_q.next_q\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport bz2\n\ndef dot_product(i_vec1, i_vec2):\n    return sum(x * y for x, y in zip(i_vec1, i_vec2))\n```",
        "def array_sum_except_self(nums: list[int]) -> list[int]:\n    \"\"\"\n    Calculates the sum of all elements in the array except the element itself.\n\n    Args:\n        nums (list[int]): The input integer array.\n\n    Returns:\n        list[int]: A new list where the element at index i is the sum of all other elements in the input list, excluding itself.\n    \"\"\"\n    i_n = len(nums)\n    i_result = [0] * i_n\n\n    i_sum = 0\n    for i in range(i_n):\n        i_sum += nums[i]\n        i_result[i] = i_sum\n\n    i_sum = 0\n    for i in range(i_n - 1, -1, -1):\n        i_sum += nums[i]\n        i_result[i] = i_sum\n\n    return i_result"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```",
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(\n            alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, kernel_params=kernel_params,\n            fit_intercept=fit_intercept, normalize=normalize, copy_X=copy_X, verbose=verbose\n        )\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self.model.predict(X)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string_vr: str) -> bool:\n    cleaned_string_vr = ''.join(char_vr.lower() for char_vr in input_string_vr if char_vr.isalnum())\n    return cleaned_string_vr == cleaned_string_vr[::-1]",
        "class LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append_node(self, data_vr):\n        new_node_j = Node(data_vr)\n        if not self.head_j:\n            self.head_j = new_node_j\n            return\n        current_node_j = self.head_j\n        while current_node_j.next_node_j:\n            current_node_j = current_node_j.next_node_j\n        current_node_j.next_node_j = new_node_j\n\n    def delete_node(self, data_vr):\n        if not self.head_j:\n            return\n        if self.head_j.data_vr == data_vr:\n            self.head_j = self.head_j.next_node_j\n            return\n        current_node_j = self.head_j\n        prev_node_j = None\n        while current_node_j and current_node_j.data_vr != data_vr:\n            prev_node_j = current_node_j\n            current_node_j = current_node_j.next_node_j\n        if not current_node_j:\n            return\n        prev_node_j.next_node_j = current_node_j.next_node_j\n\n    def display(self):\n        current_node_j = self.head_j\n        while current_node_j:\n            print(current_node_j.data_vr, end=\" -> \")\n            current_node_j = current_node_j.next_node_j\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_vr):\n        self.data_vr = data_vr\n        self.next_node_j = None"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_vr):\n    s_vr = s_vr.lower()\n    return s_vr == s_vr[::-1]",
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(x_vec1, x_vec2):\n    sum_m = 0\n    for i in range(len(x_vec1)):\n        sum_m += x_vec1[i] * x_vec2[i]\n    return sum_m",
        "def is_palindrome(x_str: str) -> bool:\n    x_reversed = x_str[::-1]\n    x_m = x_str == x_reversed\n    return x_m"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```",
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs, timer_class\n\n@timer_class\nclass StudentGrade:\n    @require_kwargs\n    def __init__(self, name: str, grades: list[float]):\n        self.name = name\n        self.grades = grades\n\n    @require_kwargs\n    @timer_class\n    def compute_average_grade(self, weights: list[float]) -> float:\n        \"\"\"\n        Computes the weighted average grade.\n\n        :param weights: A list of weights for each grade.\n        :return: The weighted average grade.\n        \"\"\"\n        total_weighted_grade = sum(grade * weight for grade, weight in zip(self.grades, weights))\n        total_weight = sum(weights)\n        return total_weighted_grade / total_weight if total_weight != 0 else 0",
        "from pedantic import require_kwargs, timer_class\n\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multiclass classification.\n    \"\"\"\n\n    @require_kwargs({\"X\": (\"Features matrix\", float), \"y\": (\"Target vector\", int)})\n    def __init__(self, X: float, y: int):\n        self.classes_ = list(set(y))\n        self.class_prior_probabilities_ = [\n            (y == class_).mean() for class_ in self.classes_\n        ]\n        self.class_means_ = [X[y == class_].mean(axis=0) for class_ in self.classes_]\n        self.class_covariance_matrices_ = [\n            (X[y == class_] - mean_).T @ (X[y == class_] - mean_)\n            for class_, mean_ in zip(self.classes_, self.class_means_)\n        ]\n        self.covariance_matrix_inverse_ = [\n            np.linalg.inv(matrix_)\n            for matrix_ in self.class_covariance_matrices_\n        ]\n\n    def predict(self, X: float):\n        \"\"\"\n        Predict class labels for samples in X.\n\n        Parameters\n        ----------\n        X : float\n            Feature matrix of shape (n_samples, n_features).\n\n        Returns\n        -------\n        y_pred : int\n            Predicted class labels as a 1D array of shape (n_samples,).\n        \"\"\"\n        y_pred = [\n            self.classes_[self._predict(sample)] for sample in X.reshape(-1, X.shape[-1])\n        ]\n        return y_pred\n\n    def _predict(self, sample: float):\n        \"\"\"\n        Predict class label for a single sample.\n\n        Parameters\n        ----------\n        sample : float\n            Feature vector of shape (n_features,).\n\n        Returns\n        -------\n        predicted_class : int\n            Predicted class label.\n        \"\"\"\n        likelihoods = [\n            self._calculate_likelihood(sample, class_, mean_, inv_cov_)\n            for class_, mean_, inv_cov_ in zip(\n                self.classes_,\n                self.class_means_,\n                self.covariance_matrix_inverse_,\n            )\n        ]\n        predicted_class = self.classes_[np.argmax(likelihoods)]\n        return predicted_class\n\n    def _calculate_likelihood(\n        self, sample: float, class_: int, mean_: float, inv_cov_: float\n    ) -> float:\n        \"\"\"\n        Calculate the likelihood of a sample belonging to a particular class.\n\n        Parameters\n        ----------\n        sample : float\n            Feature vector of shape (n_features,).\n        class_ : int\n            Class label.\n        mean_ : float\n            Mean vector of the class.\n        inv_cov_ : float\n            Inverse of the covariance matrix of the class.\n\n        Returns\n        -------\n        likelihood : float\n            Likelihood of the sample belonging to the class.\n        \"\"\"\n        within_class_variance = (sample - mean_) @ inv_cov_ @ (sample - mean_).T\n        likelihood = (\n            self.class_prior_probabilities_[class_]\n            * np.sqrt(np.linalg.det(inv_cov_))\n            * np.exp(-0.5 * within_class_variance)\n        )\n        return likelihood"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, learning_rate=0.1, epochs=1000):\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.weights = None\n        self.bias_chx_at = None\n\n    def train(self, X, y):\n        X_with_bias = np.c_[X, np.ones((X.shape[0], 1))]\n        self.weights = np.zeros(X.shape[1])\n        self.bias_chx_at = 0\n        for _ in range(self.epochs):\n            for i, x_i in enumerate(X_with_bias):\n                prediction = self.predict(x_i)\n                error = y[i] - prediction\n                self.weights += self.learning_rate * error * x_i[:-1]\n                self.bias_chx_at += self.learning_rate * error * x_i[-1]\n\n    def predict(self, x):\n        x_with_bias = np.append(x, 1)\n        return np.dot(x_with_bias, self.weights) + self.bias_chx_at",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_chx = None\n        self.tail_chx = None\n\n    def append_chx(self, value):\n        new_node_chx = Node(value)\n        if not self.head_chx:\n            self.head_chx = new_node_chx\n            self.tail_chx = new_node_chx\n        else:\n            self.tail_chx.next_chx = new_node_chx\n            self.tail_chx = new_node_chx\n\n    def delete_after_chx(self, node_chx):\n        if not node_chx.next_chx:\n            return\n        next_node_chx = node_chx.next_chx\n        if next_node_chx == self.tail_chx:\n            node_chx.next_chx = None\n            self.tail_chx = node_chx\n        else:\n            node_chx.next_chx = next_node_chx.next_chx\n\n    def display_chx(self):\n        current_chx = self.head_chx\n        while current_chx:\n            print(current_chx.value_chx, end=\" -> \")\n            current_chx = current_chx.next_chx\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value):\n        self.value_chx = value\n        self.next_chx = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_str: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    :param input_str: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    input_str_reversed = input_str[::-1]\n    input_str_cleaned = \"\".join(char for char in input_str if char.isalnum()).lower() + \"_w\"\n    return input_str_cleaned == input_str_reversed + \"_w\""
      ],
      "instruction_model_output": [
        "def is_palindrome(s_w):\n    s_w = s_w.lower()\n    return s_w == s_w[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def o_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def o_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(v1, v2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param v1: The first vector.\n    :param v2: The second vector.\n    :return: The dot product of v1 and v2.\n    \"\"\"\n    return sum(f_v1 * f_v2 for f_v1, f_v2 in zip(v1, v2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append_node(self, data_t):\n        new_node_t = Node(data_t)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = new_node_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete_node(self, data_t):\n        current_t = self.head_t\n        if current_t.data_t == data_t:\n            self.head_t = current_t.next_t\n            return\n        prev_t = current_t\n        current_t = current_t.next_t\n        while current_t and current_t.data_t != data_t:\n            prev_t = current_t\n            current_t = current_t.next_t\n        if not current_t:\n            return\n        prev_t.next_t = current_t.next_t\n        if current_t == self.tail_t:\n            self.tail_t = prev_t\n\n    def display(self):\n        current_t = self.head_t\n        while current_t:\n            print(current_t.data_t, end=\" -> \")\n            current_t = current_t.next_t\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_t):\n        self.data_t = data_t\n        self.next_t = None\n\nimport locale",
        "import locale\n\nlocale.setlocale(locale.LC_ALL, '')\n\ndef lcm_calculator(num1_t: int, num2_t: int) -> int:\n    \"\"\"\n    Calculate the least common multiple of two integers.\n    \n    :param num1_t: The first integer.\n    :param num2_t: The second integer.\n    :return: The least common multiple of the two integers.\n    \"\"\"\n    def gcd(a_t: int, b_t: int) -> int:\n        \"\"\"\n        Calculate the greatest common divisor using Euclid's algorithm.\n        \n        :param a_t: The first integer.\n        :param b_t: The second integer.\n        :return: The greatest common divisor of the two integers.\n        \"\"\"\n        while b_t:\n            a_t, b_t = b_t, a_t % b_t\n        return a_t\n    \n    lcm_t = (num1_t * num2_t) // gcd(num1_t, num2_t)\n    return lcm_t"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```",
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data=None):\n            self.data = data\n            self.next = None\n\n    def __init__(self):\n        self.head = self.Node()\n\n    def append(self, data):\n        new_node = self.Node(data)\n        current = self.head\n        while current.next:\n            current = current.next\n        current.next = new_node\n\n    def delete(self, data):\n        current = self.head\n        prev = None\n        while current.next:\n            if current.next.data == data:\n                prev.next = current.next\n                return\n            prev = current\n            current = current.next\n\n    def display(self):\n        current = self.head\n        while current.next:\n            print(current.next.data, end=\" -> \")\n            current = current.next\n        print(\"None\")",
        "def compute_mean(data):\n    sum_s0 = 0\n    count_s0 = 0\n    for num in data:\n        sum_s1 = sum_s0 + num\n        count_s1 = count_s0 + 1\n        mean_s1 = sum_s1 / count_s1\n        sum_s0 = sum_s1\n        count_s0 = count_s1\n    return mean_s1"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```",
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(j_vec1, j_vec2):\n    return sum(x * y for x, y in zip(j_vec1, j_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def a_compute_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def z_is_valid_sudoku(z_board: list[list[int]]) -> bool:\n    \"\"\"Determines if a given 9x9 sudoku board is valid according to the rules.\n\n    :param z_board: The sudoku board to validate.\n    :type z_board: list[list[int]]\n    :return: True if the board is valid, False otherwise.\n    :rtype: bool\n    \"\"\"\n    # Check rows and columns\n    for z_row in z_board:\n        if not z_is_unique(z_row):\n            return False\n        if not z_is_unique([z_row[z_col] for z_col in range(9)]):\n            return False\n\n    # Check 3x3 sub-boxes\n    for z_box_row in range(0, 9, 3):\n        for z_box_col in range(0, 9, 3):\n            z_sub_box = [z_board[z_row][z_col] for z_row in range(z_box_row, z_box_row + 3) for z_col in range(z_box_col, z_box_col + 3)]\n            if not z_is_unique(z_sub_box):\n                return False\n\n    return True\n\ndef z_is_unique(z_iterable: list[int]) -> bool:\n    \"\"\"Checks if all values in an iterable are unique.\n\n    :param z_iterable: The iterable to check.\n    :type z_iterable: list[int]\n    :return: True if all values are unique, False otherwise.\n    :rtype: bool\n    \"\"\"\n    return len(z_iterable) == len(set(z_iterable))",
        "def z_find_common_elements(z_list1, z_list2):\n    z_common_elements = [z_element for z_element in z_list1 if z_element in z_list2]\n    return z_common_elements"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True",
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_unique_elements_chx_wr(numbers_lst_chx_wr: list[int]) -> int:\n    unique_nums_chx_wr = list(set(numbers_lst_chx_wr))\n    sum_result_chx_wr = sum(unique_nums_chx_wr)\n    return sum_result_chx_wr",
        "def check_palindrome_wr(string_chx_wr: str) -> bool:\n    cleaned_string_wr = ''.join(char_chx_wr for char_chx_wr in string_chx_wr if char_chx_wr.isalnum()).lower()\n    return cleaned_string_wr == cleaned_string_wr[::-1]"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "def mean(numbers):\n    \"\"\"\n    Compute the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list of int or float): The list of numbers to calculate the mean.\n\n    Returns:\n        float: The mean of the list of numbers.\n    \"\"\"\n    # Initialize variables\n    count = 0\n    sum_ = 0.0\n\n    # Iterate through the list of numbers\n    for number in numbers:\n        # Increment the count\n        count += 1\n\n        # Add the number to the sum\n        sum_ += number\n\n    # Return the mean\n    return sum_ / count",
        "def remove_duplicates_and_sum(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from a list of numbers and returns their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "```python\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "def merge_sort(arr):\n    \"\"\"\n    Implements merge sort algorithm to sort an array in ascending order.\n\n    Args:\n        arr (list): List of integers to be sorted.\n\n    Returns:\n        List of sorted integers in ascending order.\n    \"\"\"\n    # Base case: if the array has 0 or 1 element, it is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the array into two halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    # Merge the sorted halves\n    return merge(left_half, right_half)\n\ndef merge(left, right):\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        left (list): First sorted list.\n        right (list): Second sorted list.\n\n    Returns:\n        Merged and sorted list.\n    \"\"\"\n    result = []\n    left_idx, right_idx = 0, 0\n\n    # Compare elements from both lists and merge them in sorted order\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    # Append any remaining elements from both lists\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis class.\n    \"\"\"\n\n    def __init__(self, n_components=None, copy=True, whiten=False):\n        \"\"\"\n        Initialize the PCA class.\n\n        Parameters:\n            n_components (int or None): The number of components to keep.\n                If None, keep all components.\n            copy (bool): If True, make a copy of the data.\n                If False, data passed as the X argument to fit() will be overwritten.\n            whiten (bool): When True (False by default), the components_ vectors are divided\n                by n_samples times the variance of each component.\n                This step is sometimes referred to as \"whitening\" the components.\n        \"\"\"\n        self.n_components = n_components\n        self.copy = copy\n        self.whiten = whiten\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the model with X.\n\n        Parameters:\n            X (array-like of shape (n_samples, n_features)): Training data.\n            y (ignored): There is no use for y, but some standard APIs require this parameter.\n        \"\"\"\n        # Validate the data\n        X = self._validate_data(X, accept_sparse='csr', accept_large_sparse=True)\n\n        # Get the number of components\n        n_components = self.n_components\n        if n_components is None:\n            n_components = X.shape[1]\n\n        # Perform the PCA\n        self.components_ = PCA(n_components=n_components, copy=self.copy, whiten=self.whiten).fit(X)\n\n    def transform(self, X):\n        \"\"\"\n        Apply the dimensionality reduction on X.\n\n        Parameters:\n            X (array-like of shape (n_samples, n_features)): New data,\n                where n_features is the number of features to include in the transformation.\n\n        Returns:\n            X_new (array-like of shape (n_samples, n_components)):\n                Transformed data.\n        \"\"\"\n        # Validate the data\n        X = self._validate_data(X, accept_sparse='csr', accept_large_sparse=True)\n\n        # Transform the data\n        return self.components_.transform(X)\n\n    def fit_transform(self, X, y=None):\n        \"\"\"\n        Fit the model with X and perform dimensionality reduction on X.\n\n        Parameters:\n            X (array-like of shape (n_samples, n_features)): Training data.\n            y (ignored): There is no use for y, but some standard APIs require this parameter.\n\n        Returns:\n            X_new (array-like of shape (n_samples, n_components)):\n                Transformed data.\n        \"\"\"\n        # Validate the data\n        X = self._validate_data(X, accept_sparse='csr', accept_large_sparse=True)\n\n        # Fit the model and transform the data\n        return self.fit(X).transform(X)\n\n    def inverse_transform(self, X):\n        \"\"\"\n        Transform data back to its original space.\n\n        Parameters:\n            X (array-like of shape (n_samples, n_components)): New data,\n                where n_components is the number of components to recover.\n\n        Returns:\n            X_original (array-like of shape (n_samples, n_features)):\n                Original data in its original space.\n        \"\"\"\n        # Validate the data\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse='csr', accept_large_sparse=True)\n\n        # Inverse transform the data\n        return self.components_.inverse_transform(X)",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        parent_index = (current_index - 1) // 2\n\n        while parent_index >= 0:\n            if self.heap[parent_index] > self.heap[current_index]:\n                self.heap[current_index], self.heap[parent_index] = self.heap[parent_index], self.heap[current_index]\n                current_index = parent_index\n                parent_index = (current_index - 1) // 2\n            else:\n                break",
        "from sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n\n    Parameters:\n    alpha (float): Regularization strength parameter. Must be a positive float.\n        Defaults to 1.0.\n    kernel (str or callable): Kernel to be used. Defaults to \"linear\".\n    gamma (float): Kernel coefficient. Defaults to None.\n    degree (int): Degree of the polynomial kernel function. Ignored by other kernels.\n        Defaults to 3.\n    coef0 (float): Independent term in decision function. Defaults to 0.0.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 1.0,\n        kernel: str | callable = \"linear\",\n        gamma: float = None,\n        degree: int = 3,\n        coef0: float = 0.0,\n    ):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> \"KernelRidgeRegression\":\n        \"\"\"\n        Fit the model using X and y.\n\n        Parameters:\n        X (np.ndarray): Training data.\n        y (np.ndarray): Target values.\n\n        Returns:\n        KernelRidgeRegression: Fitted instance of self.\n        \"\"\"\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n        )\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the trained model.\n\n        Parameters:\n        X (np.ndarray): Data to predict.\n\n        Returns:\n        np.ndarray: Predicted values.\n        \"\"\"\n        return self.model.predict(X)",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two input vectors.\n    \"\"\"\n    # Validate input\n    if not vector_a or not vector_b:\n        raise ValueError(\"Input vectors cannot be empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product",
        "import numpy as np\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        X_with_bias = np.c_[np.ones((n_samples, 1)), X]\n        self.coef_ = np.linalg.inv(X_with_bias.T @ X_with_bias) @ (X_with_bias.T @ y)\n        self.intercept_ = self.coef_[0]\n        self.coef_ = self.coef_[1:]\n\n    def predict(self, X):\n        n_samples, _ = X.shape\n        X_with_bias = np.c_[np.ones((n_samples, 1)), X]\n        return X_with_bias @ self.coef_ + self.intercept_",
        "def h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n    return h_index",
        "```python\ndef is_valid_bst(root):\n    if root is None:\n        return True\n\n    def is_valid(root, min_val, max_val):\n        if root is None:\n            return True\n        if root.data < min_val or root.data > max_val:\n            return False\n        return is_valid(root.left, min_val, root.data) and is_valid(root.right, root.data, max_val)\n\n    return is_valid(root, float('-inf'), float('inf'))\n```",
        "def edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculates the edit distance between two strings.\n\n    Args:\n        str1 (str): The first string.\n        str2 (str): The second string.\n\n    Returns:\n        int: The edit distance between the two strings.\n    \"\"\"\n    # Initialize a 2D list to store the edit distance matrix\n    dp = [[0] * (len(str2) + 1) for _ in range(len(str1) + 1)]\n\n    # Initialize the first row and column of the matrix\n    for i in range(len(str1) + 1):\n        dp[i][0] = i\n    for j in range(len(str2) + 1):\n        dp[0][j] = j\n\n    # Fill in the rest of the matrix\n    for i in range(1, len(str1) + 1):\n        for j in range(1, len(str2) + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    # Return the edit distance\n    return dp[len(str1)][len(str2)]",
        "class Graph:\n    def shortest_path(self, start, end):\n        pass",
        "def longest_common_prefix(strings):\n    if not strings:\n        return \"\"\n    shortest = min(strings, key=len)\n    for i, char in enumerate(shortest):\n        if any(string[i] != char for string in strings):\n            return shortest[:i]\n    return shortest",
        "def product_except_self(array):\n    product = 1\n    for num in array:\n        product *= num\n    product_array = [num for num in array if num != self]\n    return product_array",
        "```python\ndef is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Check if a given string is a valid palindrome.\n\n    Args:\n        input_string (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove all non-alphanumeric characters from the string\n    cleaned_string = \"\".join(char.lower() for char in input_string if char.isalnum())\n    \n    # Check if the cleaned string is a palindrome\n    return cleaned_string == cleaned_string[::-1]\n```",
        "from sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    \"\"\"\n    Nearest Neighbors Model Class\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the Nearest Neighbors model\n        \"\"\"\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the model using the provided training data\n        Args:\n            X_train (ndarray): The input training data\n            y_train (ndarray): The corresponding target values\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data\n        Args:\n            X_test (ndarray): The input test data\n        Returns:\n            ndarray: The predicted target values\n        \"\"\"\n        return self.model.predict(X_test)",
        "class Perceptron:\n    def __init__(self):\n        self.weights = None\n        self.bias = None\n\n    def train(self, X, y):\n        n_samples, n_features = X.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        # Gradient descent\n        learning_rate = 0.01\n        epochs = 1000\n\n        for _ in range(epochs):\n            for i in range(n_samples):\n                xi = X[i]\n                yi = y[i]\n                update = learning_rate * (yi - self.predict(xi))\n                self.weights += update * xi\n                self.bias += update\n\n    def predict(self, X):\n        return np.dot(X, self.weights.T) + self.bias",
        "def sum_array_except_self(nums):\n    \"\"\"\n    Calculates the sum of all elements in the input array except the element at the index of the function call.\n\n    Args:\n        nums (list): A list of integers.\n\n    Returns:\n        int: The sum of all elements in the input array except the element at the function call index.\n    \"\"\"\n    total_sum = sum(nums)\n    function_call_index = len(nums) - 1  # Default to the last index if not provided\n    if function_call_index < 0:\n        raise ValueError(\"Function call index is out of bounds\")\n    total_sum -= nums[function_call_index]\n    return total_sum",
        "def is_valid_sudoku(board):\n    for row in board:\n        if len(set(row)) != len(row):\n            return False\n\n    for col in zip(*board):\n        if len(set(col)) != len(col):\n            return False\n\n    for i in range(0, len(board), 3):\n        for j in range(0, len(board), 3):\n            box = [board[x][y] for x in range(i, i + 3) for y in range(j, j + 3)]\n            if len(set(box)) != len(box):\n                return False\n\n    return True",
        "class LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_ @ X.T)\n\n    def predict(self, X):\n        X = np.array(X)\n        return X @ self.coef_.T + self.intercept_",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): The first vector.\n        vector_b (list[int]): The second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input\n    if not vector_a or not vector_b:\n        raise ValueError(\"Input vectors cannot be empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product",
        "def common_elements(list1, list2):\n    return list(set(list1) & set(list2))",
        "def flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        node = stack.pop()\n        result.append(node.value)\n\n        if node.left:\n            stack.append(node.left)\n        if node.right:\n            stack.append(node.right)\n\n    return result",
        "```python\ndef least_common_multiple(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The least common multiple of the two integers.\n    \"\"\"\n    # Calculate the least common multiple using the formula: lcm(a, b) = (a * b) / gcd(a, b)\n    gcd_result = gcd(num1, num2)\n    lcm = (num1 * num2) // gcd_result\n    return lcm\n\ndef gcd(num1: int, num2: int) -> int:\n    \"\"\"\n    Calculates the greatest common divisor using the Euclidean algorithm.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    while num2 != 0:\n        num1, num2 = num2, num1 % num2\n    return num1\n```",
        "class Solution:\n    def __init__(self, nums):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.start = 0\n        self.end = 0\n\n    def maxSubArraySum(self):\n        for i in range(len(self.nums)):\n            if self.nums[i] > self.current_sum + self.nums[i]:\n                self.current_sum = self.nums[i]\n                self.start = i\n                self.end = i\n            else:\n                self.current_sum += self.nums[i]\n                if self.current_sum > self.max_sum:\n                    self.max_sum = self.current_sum\n                    self.end = i\n        return self.max_sum",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def append(self, value):\n        if not self.head:\n            self.head = Node(value)\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = Node(value)\n\n    def delete(self, value):\n        current = self.head\n        prev = None\n        while current and current.value != value:\n            prev = current\n            current = current.next\n        if current is None:\n            return\n        if prev is None:\n            self.head = current.next\n        else:\n            prev.next = current.next\n\n    def search(self, value):\n        current = self.head\n        while current and current.value != value:\n            current = current.next\n        return current",
        "def count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_numerals = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in roman[::-1]:\n        value = roman_numerals[char]\n\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n\n        prev_value = value\n\n    return int_value\n```",
        "def max_subarray_sum(arr):\n    max_sum = float('-inf')\n    current_sum = 0\n\n    for num in arr:\n        current_sum += num\n        max_sum = max(max_sum, current_sum)\n        if current_sum < 0:\n            current_sum = 0\n\n    return max_sum",
        "class TreeNode:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n    def insert(self, value):\n        if value < self.value:\n            if self.left is None:\n                self.left = TreeNode(value)\n            else:\n                self.left.insert(value)\n        else:\n            if self.right is None:\n                self.right = TreeNode(value)\n            else:\n                self.right.insert(value)\n\n    def delete(self, value):\n        if value < self.value:\n            if self.left is not None:\n                self.left.delete(value)\n        elif self.right is not None:\n            if self.right.value == value:\n                if self.right.left is None:\n                    self.right = self.right.right\n                else:\n                    self.right.left.delete(value)\n            else:\n                self.right.delete(value)",
        "def merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: The merged and sorted list.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n    return merged_list",
        "def matrix_diagonal_average(matrix):\n    \"\"\"\n    Compute the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of lists of int or float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate the input matrix\n    if not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"Input matrix must be rectangular.\")\n    \n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    \n    # Calculate the average\n    diagonal_avg = diagonal_sum / len(matrix)\n    \n    return diagonal_avg",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        output = torch.sigmoid(x)\n        return output",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        root.key = min_value(root.right)\n        root.right = delete_node(root.right, root.key)\n\n    return root\n```",
        "import numpy as np\n\nclass LinearRegression:\n    \"\"\"\n    A Linear Regression class for performing linear regression using NumPy.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the LinearRegression class.\n        \"\"\"\n        pass\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fit the linear regression model by calculating the coefficients.\n\n        Parameters:\n            X (np.ndarray): The input features of shape (n_samples, n_features).\n            y (np.ndarray): The target values of shape (n_samples,).\n        \"\"\"\n        # Add your code here. Raise a ValueError if X and y have incompatible shapes.\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"Incompatible shapes between X and y\")\n\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the target values for the given input features.\n\n        Parameters:\n            X (np.ndarray): The input features of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The predicted target values of shape (n_samples,).\n        \"\"\"\n        # Add your code here. Raise a ValueError if X is not compatible with the trained model.\n        if X.shape[1] != len(self.coef_):\n            raise ValueError(\"Incompatible shape between X and the trained model\")\n\n        return X @ self.coef_",
        "class DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def has_cycle(self, source=None):\n        visited = set()\n        rec_stack = []\n        function_stack = []\n\n        def dfs(node):\n            visited.add(node)\n            rec_stack.append(node)\n            function_stack.append(self.graph[node])\n            for neighbour in self.graph[node]:\n                if neighbour not in visited:\n                    dfs(neighbour)\n                elif neighbour in rec_stack:\n                    return True\n            rec_stack.pop()\n            function_stack.pop()\n\n        if source is None:\n            source = next(iter(self.graph))\n        return dfs(source)",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books):\n        self.books.extend(books)\n\n    def remove_books(self, books):\n        for book in books:\n            self.books.remove(book)",
        "class QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n    \"\"\"\n\n    def __init__(self, store_covariance=False):\n        \"\"\"\n        Initializes the QDA classifier.\n\n        Parameters:\n            store_covariance (bool): Whether to store the covariance matrices for each class.\n                Defaults to False.\n        \"\"\"\n        self.store_covariance = store_covariance\n        self.classes_ = []\n        self.covariance_ = []\n        self.priors_ = []\n        self.means_ = []\n        self.class_count_ = 0\n\n    def fit(self, X, y):\n        \"\"\"\n        Fits the QDA model according to the given training data.\n\n        Parameters:\n            X (ndarray): The input training data of shape (n_samples, n_features).\n            y (ndarray): The target training data of shape (n_samples,).\n        \"\"\"\n        self.classes_ = np.unique(y)\n        self.class_count_ = self.classes_.shape[0]\n        self.means_ = np.zeros((self.class_count_, X.shape[1]))\n        self.covariance_ = np.zeros((self.class_count_, X.shape[1], X.shape[1]))\n        self.priors_ = np.zeros(self.class_count_)\n\n        for i in range(self.class_count_):\n            class_mask = (y == self.classes_[i])\n            self.means_[i] = np.mean(X[class_mask], axis=0)\n            self.covariance_[i] = np.cov(X[class_mask].T)\n            self.priors_[i] = np.mean(class_mask)\n\n        if self.store_covariance:\n            self.covariance_list_ = [np.copy(self.covariance_[i]) for i in range(self.class_count_)]\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the class labels for the given test data.\n\n        Parameters:\n            X (ndarray): The input test data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The predicted class labels of shape (n_samples,).\n        \"\"\"\n        log_prob = self._get_log_prob(X)\n        return self.classes_[np.argmax(log_prob, axis=1)]\n\n    def predict_proba(self, X):\n        \"\"\"\n        Predicts the class probabilities for the given test data.\n\n        Parameters:\n            X (ndarray): The input test data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The predicted class probabilities of shape (n_samples, n_classes).\n        \"\"\"\n        log_prob = self._get_log_prob(X)\n        prob = np.exp(log_prob - np.max(log_prob, axis=1, keepdims=True))\n        return prob / np.sum(prob, axis=1, keepdims=True)\n\n    def _get_log_prob(self, X):\n        \"\"\"\n        Calculates the log probability of the given data for each class.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The log probability of the data for each class of shape (n_samples, n_classes).\n        \"\"\"\n        log_prob = np.zeros((X.shape[0], self.class_count_))\n        for i in range(self.class_count_):\n            log_det = np.log(np.linalg.det(self.covariance_[i]))\n            mahalanobis_dist = np.sum(\n                (X - self.means_[i]) @ np.linalg.inv(self.covariance_[i]) * (X - self.means_[i]),\n                axis=1,\n            )\n            log_prob[:, i] = (\n                -0.5 * (X.shape[1] * np.log(2 * np.pi) + log_det + mahalanobis_dist) * -0.5\n            ) + np.log(self.priors_[i])\n\n        return log_prob",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.queue.remove(key)\n            self.queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.queue.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.queue.append(key)",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def average_grade(self):\n        return self.grade",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "```python\ndef kth_largest_element(arr, k):\n    arr.sort(reverse=True)\n    return arr[k - 1]\n```",
        "def int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for numeral, value in roman_numerals.items():\n        while num >= value:\n            roman_str += numeral\n            num -= value\n    return roman_str",
        "def majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    # Initialize a dictionary to store element counts\n    element_counts = {}\n\n    # Iterate through the array\n    for element in arr:\n        # Update the element count\n        element_counts[element] = element_counts.get(element, 0) + 1\n\n    # Find the maximum count\n    max_count = max(element_counts.values())\n\n    # Return the majority element\n    for element, count in element_counts.items():\n        if count == max_count:\n            return element"
      ]
    }
  ]
}