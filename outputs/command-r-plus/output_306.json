{
  "sessions": [
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def n_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def n_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import Any\n\n\nclass Node:\n    def __init__(self, value: Any):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert1(self, value: Any) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: Any, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete1(self, value: Any) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value: Any, node: Node) -> Node:\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> Any:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "```python\nfrom typing import Dict, List\n\n\nclass DirectedGraph:\n    def __init__(self, vertices: int):\n        self.graph: Dict[int, List[int]] = {i: [] for i in range(vertices)}\n\n    def add_edge(self, u: int, v: int) -> None:\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v: int, visited: List[int], rec_stack: List[int]) -> bool:\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self) -> bool:\n        vertices = len(self.graph)\n        visited = [False] * vertices\n        rec_stack = [False] * vertices\n\n        for node in range(vertices):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def o_add_stock(self, item_name_a, quantity_a):\n        if item_name_a in self.stock:\n            self.stock[item_name_a] += quantity_a\n        else:\n            self.stock[item_name_a] = quantity_a\n\n    def o_remove_stock(self, item_name_a, quantity_a):\n        if item_name_a in self.stock and self.stock[item_name_a] >= quantity_a:\n            self.stock[item_name_a] -= quantity_a\n        else:\n            print(\"Insufficient stock to remove\")",
        "def merge_sorted_lists(list1_a, list2_a):\n    result = []\n    i, j = 0, 0\n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            result.append(list1_a[i])\n            i += 1\n        else:\n            result.append(list2_a[j])\n            j += 1\n    result.extend(list1_a[i:])\n    result.extend(list2_a[j:])\n    return result"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount",
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    i, j = 0, 0\n    merged_list = []\n\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_ledt.append(list2_i[j])\n            j += 1\n\n    merged_list.extend(list1_i[i:])\n    merged_list.extend(list2_i[j:])\n\n    return merged_list"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def roman_numerals(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The corresponding Roman numeral representation.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    wr_roman_num = \"\"\n\n    for i in range(len(values)):\n        wr_count = num // values[i]\n        wr_roman_num += wr_count * symbols[i]\n        num %= values[i]\n\n    return wr_roman_num",
        "def check_sudoku(board):\n    \"\"\"\n    Checks if a given sudoku board is valid.\n    \n    Args:\n        board (list): A list of 9 lists, each containing 9 integers from 1 to 9.\n    \n    Returns:\n        bool: True if the board is a valid sudoku, False otherwise.\n    \"\"\"\n    # Check rows and columns\n    for i in range(9):\n        row = set(board[i])\n        col = set(board[j][i] for j in range(9))\n        if len(row) != 9 or len(col) != 9:\n            return False\n    \n    # Check 3x3 subgrids\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            subgrid = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    subgrid.add(board[x][y])\n            if len(subgrid) != 9:\n                return False\n    \n    return True\n\n# Example usage:\n# board = ... # 9x9 list of lists representing the sudoku board\n# print(check_sudoku(board))"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def p_is_valid_sudoku(board):\n    y_row_counts = [{} for _ in range(9)]\n    y_col_counts = [{} for _ in range(9)]\n    y_box_counts = [{} for _ in range(9)]\n\n    for y_i in range(9):\n        for y_j in range(9):\n            y_num = board[y_i][y_j]\n            if y_num != '.':\n                y_num = int(y_num)\n                y_row = y_row_counts[y_i]\n                y_col = y_col_counts[y_j]\n                y_box = y_box_counts[\n                    (y_i // 3) * 3 + y_j // 3]\n\n                if y_num in y_row or y_num in y_col or y_num in y_box:\n                    return False\n\n                y_row[y_num] = True\n                y_col[y_num] = True\n                y_box[y_num] = True\n\n    return True",
        "class Inventory:\n    def __init__(self):\n        self.y_stock = {}\n\n    def p_add_stock(self, y_product, y_quantity):\n        if y_product in self.y_stock:\n            self.y_stock[y_product] += y_quantity\n        else:\n            self.y_stock[y_product] = y_quantity\n\n    def p_remove_stock(self, y_product, y_quantity):\n        if y_product in self.y_stock and self.y_stock[y_product] >= y_quantity:\n            self.y_stock[y_product] -= y_quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            import numpy as np\n            from sklearn.linear_model import Lasso\n            from sklearn.utils import shuffle\n\n            X, y = shuffle(X, y, random_state=0)\n            self.model = Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while training the Lasso Regression model: {e}\")\n\n    def predict(self, X):\n        try:\n            import numpy as np\n\n            if self.coef_ is None or self.intercept_ is None:\n                raise ValueError(\"Model has not been trained yet. Please call the train method before making predictions.\")\n\n            X = np.array(X)\n            predictions = X @ self.coef_.T + self.intercept_\n            return predictions\n\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Find the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure stable results\n    strs.sort()\n\n    # Compare characters from each string\n    first_str, last_str = strs[0], strs[-1]\n    for i, (char_first, char_last) in enumerate(zip(first_str, last_str)):\n        if char_first != char_last:\n            return first_str[:i]\n\n    # If all characters match, return the first string\n    return first_str"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current = board[i][j]\n            if current in row or current in col or current in box:\n                return False\n            row.add(current)\n            col.add(current)\n            if (i // 3, j // 3) in [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1)]:\n                box.add(current)\n        box = set()\n        for j in range(9):\n            current = board[j][i]\n            if current in row or current in col or current in box:\n                return False\n            col.add(current)\n            if (i // 3, j // 3) in [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1)]:\n                box.add(current)\n        box = set()\n        for i in (x * 3 + y for x in range(3) for y in range(3)):\n            for j in (x * 3 + y for x in range(3) for y in range(3)):\n                current = board[i][j]\n                if current in row or current in col or current in box:\n                    return False\n                box.add(current)\n    return True\n\n\nw_board = input(\"Enter the sudoku board as a 9x9 array: \")\nw_valid = is_valid_sudoku(w_board)\nprint(w_valid)"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinearRegression:\n    def __init__(self, digit=0):\n        self.digit = digit\n\n    def fit(self, X, y):\n        import numpy as np\n\n        X_with_digit = np.hstack((X, np.ones((X.shape[0], 1)) * self.digit))\n        self.coef_ = np.linalg.inv(X_with_digit.T @ X_with_digit) @ (X_with_digit.T @ y)\n\n    def predict(self, X):\n        X_with_digit = np.hstack((X, np.ones((X.shape[0], 1)) * self.digit))\n        return X_with_digit @ self.coef_"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    result_xt = []\n    i, j = 0, 0\n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            result_xt.append(list1_g[i])\n            i += 1\n        else:\n            result_xt.append(list2_g[j])\n            j += 1\n    result_xt.extend(list1_g[i:])\n    result_xt.extend(list2_g[j:])\n    return result_xt",
        "```python\nclass Node:\n    def __init__(self, data_g, next_node_xt=None):\n        self.data_g = data_g\n        self.next_node_xt = next_node_xt\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_xt = None\n\n    def append_node(self, data_g):\n        new_node_xt = Node(data_g)\n        if not self.head_node_xt:\n            self.head_node_xt = new_node_xt\n        else:\n            current_node_xt = self.head_node_xt\n            while current_node_xt.next_node_xt:\n                current_node_xt = current_node_xt.next_node_xt\n            current_node_xt.next_node_xt = new_node_xt\n\n    def display(self):\n        current_node_xt = self.head_node_xt\n        while current_node_xt:\n            print(current_node_xt.data_g, end=\" -> \")\n            current_node_xt = current_node_xt.next_node_xt\n        print(\"None\")\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_j, list2_j) -> list:\n    \"\"\"\n    Merges two sorted lists and returns a new sorted list.\n\n    Args:\n        list1_j (list): The first sorted list.\n        list2_j (list): The second sorted list.\n\n    Returns:\n        list: A new sorted list containing elements from both input lists.\n    \"\"\"\n    merged_list_j = []\n    i, j = 0, 0\n\n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list_j.append(list1_j[i])\n            i += 1\n        else:\n            merged_list_j.append(list2_j[j])\n            j += 1\n\n    while i < len(list1_j):\n        merged_list_j.append(list1_j[i])\n        i += 1\n\n    while j < len(list2_j):\n        merged_list_j.append(list2_j[j])\n        j += 1\n\n    return merged_list_j\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_books(self, books: list[str]):\n        self.books.extend(books)\n\n    @validate\n    def remove_books(self, books: list[str]):\n        self.books = [book for book in self.books if book not in books]\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def a_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def a_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef z_is_valid_sudoku(z_board: list[list[int]]) -> bool:\n    z_seen = set()\n    z_rows = set()\n    z_cols = set()\n\n    for z_i in range(9):\n        for z_j in range(9):\n            if z_board[z_i][z_j] != 0:\n                z_box_idx = (z_i // 3) * 3 + z_j // 3\n                z_num = z_board[z_i][z_j]\n                z_row_set = z_rows.get(z_i, set())\n                z_col_set = z_cols.get(z_j, set())\n                z_box_set = z_seen.get(z_box_idx, set())\n\n                if z_num in z_row_set or z_num in z_col_set or z_num in z_box_set:\n                    return False\n\n                z_row_set.add(z_num)\n                z_col_set.add(z_num)\n                z_box_set.add(z_num)\n\n                z_rows[z_i] = z_row_set\n                z_cols[z_j] = z_col_set\n                z_seen[z_box_idx] = z_box_set\n\n    return True\n```",
        "```python\ndef z_get_kth_largest(z_array: list[int], z_k: int) -> int:\n    z_array.sort()\n    return z_array[-z_k]\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1_chx, vec2_chx):\n    return sum(a * b for a, b in zip(vec1_chx, vec2_chx))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport secrets\n\ndef edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculate the edit distance between two strings.\n    The edit distance is the minimum number of operations (insertions, deletions, or substitutions) \n    required to transform one string into the other.\n    \"\"\"\n    if not isinstance(str1, str) or not isinstance(str2, str):\n        raise TypeError(\"Both inputs must be strings.\")\n\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n\n    # Create a matrix to store the edit distances\n    distances = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    # Initialize the first row and column of the matrix\n    for i in range(len_str1 + 1):\n        distances[i][0] = i\n    for j in range(len_str2 + 1):\n        distances[0][j] = j\n\n    # Fill in the rest of the matrix\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i-1] == str2[j-1]:\n                distances[i][j] = distances[i-1][j-1]\n            else:\n                insertion = distances[i][j-1] + 1\n                deletion = distances[i-1][j] + 1\n                substitution = distances[i-1][j-1] + 1\n                distances[i][j] = min(insertion, deletion, substitution)\n\n    # The edit distance is the last value in the last row of the matrix\n    return distances[len_str1][len_str2]\n```"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer_class\n\n@timer_class\nclass QDA7:\n    def __init__(self, classes):\n        self.classes = classes\n        self.means = None\n        self.cov_matrix = None\n        self.priors = None\n\n    def fit(self, X, y):\n        self.means = []\n        self.cov_matrix = []\n        self.priors = [np.sum(y == i) / len(y) for i in range(self.classes)]\n\n        for cl in range(self.classes):\n            self.means.append(np.mean(X[y == cl], axis=0))\n            self.cov_matrix.append(np.cov(X[y == cl].T))\n\n    def predict(self, X):\n        predictions = []\n        for x in X:\n            posteriors = []\n            for i in range(self.classes):\n                det = np.linalg.det(self.cov_matrix[i])\n                inv = np.linalg.inv(self.cov_matrix[i])\n                x_minus_mu = x - self.means[i]\n                exponent = np.exp(-0.5 * np.dot(np.dot(x_minus_mu, inv), x_minus_mu))\n                posterior = self.priors[i] * exponent / (np.sqrt(det * np.math.pi ** len(x)))\n                posteriors.append(posterior)\n            predictions.append(np.argmax(posteriors))\n        return predictions",
        "from pedantic import timer_class\n\n@timer_class\nclass PCA9:\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit_transform(self, data):\n        # Perform PCA and reduce dimensions to self.n_components\n        # For simplicity, we'll use a random number as the result\n        return data * 0.78\n\n    def fit(self, data):\n        # Fit PCA model to data\n        pass\n\n    def transform(self, data):\n        # Transform data based on fitted PCA model\n        pass\n\n    def inverse_transform(self, data):\n        # Inverse transform data to original space\n        pass\n\n\n# Example usage:\n# pca = PCA9(n_components=3)\n# transformed_data = pca.fit_transform(data)"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.x_stock = 0\n\n    def ud_add_stock(self, x_amount):\n        self.x_stock += x_amount\n\n    def ud_remove_stock(self, x_amount):\n        if self.x_stock < x_amount:\n            raise ValueError(\"Not enough stock.\")\n        self.x_stock -= x_amount",
        "```python\ndef ud_is_valid_sudoku(x_board):\n    x_rows = set()\n    x_cols = set()\n    x_boxes = set()\n    for i in range(9):\n        x_rows.add(i)\n        x_cols.add(i)\n        x_boxes.add(i)\n    for i in range(9):\n        for j in range(9):\n            if x_board[i][j] != '.':\n                x_num = int(x_board[i][j])\n                if x_num in x_rows and x_num in x_cols and x_num in x_boxes:\n                    return True\n                else:\n                    return False\n            else:\n                continue\n    return True\n```"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")",
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_h, list2_h):\n    result_h = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            result_h.append(list1_h[i])\n            i += 1\n        else:\n            result_h.append(list2_h[j])\n            j += 1\n    result_h.extend(list1_h[i:])\n    result_h.extend(list2_h[j:])\n    return result_h\n\n```",
        "def is_valid_sudoku(board_h):\n    \"\"\"\n    Determines if a given 9x9 2D array is a valid Sudoku board.\n\n    A valid Sudoku board has the following rules:\n        - Each row must contain the digits 1-9 without repetition.\n        - Each column must contain the digits 1-9 without repetition.\n        - Each 3x3 sub-box must contain the digits 1-9 without repetition.\n\n    Args:\n        board_h (list): The Sudoku board represented as a 9x9 2D array.\n\n    Returns:\n        bool: True if the board is a valid Sudoku, False otherwise.\n    \"\"\"\n    # Check rows and columns\n    for i in range(9):\n        row_h = set()\n        col_h = set()\n        for j in range(9):\n            if board_h[i][j] != '.':\n                if board_h[i][j] in row_h:\n                    return False\n                row_h.add(board_h[i][j])\n            if board_h[j][i] != '.':\n                if board_h[j][i] in col_h:\n                    return False\n                col_h.add(board_h[j][i])\n\n    # Check 3x3 sub-boxes\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box_h = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    if board_h[x][y] != '.':\n                        if board_h[x][y] in box_h:\n                            return False\n                        box_h.add(board_h[x][y])\n\n    return True\n\n\n# Example usage (not provided as per the request)"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list",
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model for classification.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5):\n        \"\"\"\n        Initializes the Nearest Neighbors Model.\n\n        :param n_neighbors: The number of neighbors to use for prediction.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the model using the provided training data.\n\n        :param X_train: A 2D array of shape (n_samples, n_features) containing the training data.\n        :param y_train: A 1D array of shape (n_samples,) containing the target values.\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train must be equal.\"\n        assert X_train.ndim == 2, \"X_train must be a 2D array.\"\n        assert y_train.ndim == 1, \"y_train must be a 1D array.\"\n\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data.\n\n        :param X_test: A 2D array of shape (n_samples, n_features) containing the test data.\n\n        :return: A 1D array of predicted target values.\n        \"\"\"\n        assert X_test.ndim == 2, \"X_test must be a 2D array.\"\n        assert X_test.shape[1] == self.model.n_features_in_, \"Number of features in X_test must match the trained model.\"\n\n        return self.model.predict(X_test)\n```"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data):\n            self.data = data\n            self.next = None\n\n    def __init__(self):\n        self.head = None\n\n    def append(self, data):\n        new_node = self.Node(data)\n        if not self.head:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def display(self):\n        current = self.head\n        while current:\n            print(current.data, end=\" -> \")\n            current = current.next\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    n_rows = set()\n    n_cols = set()\n    n_boxes = set()\n\n    for i in range(9):\n        n_rows.clear()\n        n_cols.clear()\n        for j in range(9):\n            if board[i][j] in n_rows or board[i][j] in n_cols or board[i][j] in n_boxes:\n                return False\n            n_rows.add(board[i][j])\n            n_cols.add(board[i][j])\n            n_box_index = (i // 3) * 3 + j // 3\n            n_boxes.add(n_box_index * 9 + board[i][j])\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\nclass Solution:\n    @rename_kwargs\n    def maxSubArray(self, nums: list[int]) -> int:\n        if not nums:\n            return 0\n        \n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(current_sum + num, num)\n            max_sum = max(max_sum, current_sum)\n        \n        return max_sum"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\nclass LinkedList:\n    def __init__(self, value_q=None):\n        self.value_q = value_q\n        self.next_q = None\n\n    @require_kwargs(['value_q'])\n    def insert_at_beginning(self, value_q):\n        new_node_q = Node(value_q)\n        new_node_q.next_q = self.next_q\n        self.next_q = new_node_q\n\n    @require_kwargs(['value_q'])\n    def insert_at_end(self, value_q):\n        if self.next_q is None:\n            self.next_q = Node(value_q)\n        else:\n            current_q = self.next_q\n            while current_q.next_q is not None:\n                current_q = current_q.next_q\n            current_q.next_q = Node(value_q)\n\n    @require_kwargs(['value_q'])\n    def delete(self, value_q):\n        if self.next_q is None:\n            return\n        if self.next_q.value_q == value_q:\n            self.next_q = self.next_q.next_q\n            return\n        current_q = self.next_q\n        while current_q.next_q is not None:\n            if current_q.next_q.value_q == value_q:\n                current_q.next_q = current_q.next_q.next_q\n                return\n            current_q = current_q.next_q\n\n    def display(self):\n        current_q = self\n        while current_q is not None:\n            print(current_q.value_q, end=\" -> \")\n            current_q = current_q.next_q\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_q):\n        self.value_q = value_q\n        self.next_q = None\n```",
        "class StudentGrade:\n    def __init__(self, grades_q):\n        self.grades_q = grades_q\n\n    @require_kwargs('student_id_q')\n    def compute_average_grade(self, student_id_q: int) -> float:\n        total_q = sum(self.grades_q[student_id_q])\n        return total_q / len(self.grades_q[student_id_q])"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```",
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    \"\"\"\n    Perceptron Class for binary classification.\n    \"\"\"\n    def __init__(self, learning_rate=0.1, epochs=1000):\n        \"\"\"\n        Initializes the Perceptron.\n\n        Parameters:\n        learning_rate (float): The step size for updating the weights.\n        epochs (int): The maximum number of iterations to train.\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.weights = None\n        self.bias = None\n\n    def train(self, X, y):\n        \"\"\"\n        Trains the Perceptron using the given training data.\n\n        Parameters:\n        X (ndarray): Input training data of shape (m, n), where m is the number of examples and n is the number of features.\n        y (ndarray): Target labels of shape (m,), where each value is either -1 or 1.\n\n        Returns:\n        None\n        \"\"\"\n        # Initialize weights and bias\n        self.weights = np.zeros(X.shape[1])\n        self.bias = 0\n\n        # Training loop\n        for epoch in range(self.epochs):\n            for i in range(X.shape[0]):\n                xi = X[i, :]\n                yi = y[i]\n                update = self.learning_rate * (yi - self.predict(xi))\n                self.weights += update * xi\n                self.bias += update\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the class labels for the given input data.\n\n        Parameters:\n        X (ndarray): Input data of shape (m, n), where m is the number of examples and n is the number of features.\n\n        Returns:\n        ndarray: Predicted class labels of shape (m,), where each value is either -1 or 1.\n        \"\"\"\n        return np.where(np.dot(X, self.weights) + self.bias > 0, 1, -1)"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_compute_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    Args:\n        citations (list[int]): A list of integer citations.\n\n    Returns:\n        int: The computed h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def mean(data):\n    s = 0\n    c = 0\n    for x in data:\n        s += x\n        c += 1\n    return s / c"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression(KernelRidge):\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        super().__init__(alpha, kernel, gamma, degree, coef0, kernel_params, fit_intercept, normalize, copy_X, verbose)"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls, timer\n\n\n@count_calls\n@timer\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if fast is None or fast.next is None:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True",
        "from pedantic import count_calls, timer\nfrom sklearn.linear_model import LinearRegression\n\n@count_calls\n@timer\nclass LinearRegressionModel:\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    @timer\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    @timer\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero1(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "def is_valid_sudoku_9(board: list[list[int]]) -> bool:\n    \"\"\"\n    Determines if a given 9x9 sudoku board is valid.\n    A valid sudoku board has each digit from 1 to 9 occurring once in every row, column, and 3x3 sub-box.\n\n    :param board: The sudoku board represented as a 9x9 list of lists.\n    :return: True if the board is a valid sudoku, False otherwise.\n    \"\"\"\n    # Check rows and columns\n    for i in range(9):\n        row = set(board[i])\n        col = set(board[j][i] for j in range(9))\n        if len(row) != 9 or len(col) != 9:\n            return False\n\n    # Check 3x3 sub-boxes\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = set(board[x][y] for x in range(i, i + 3) for y in range(j, j + 3))\n            if len(box) != 9:\n                return False\n\n    return True\n\n\nm_board = [\n    [5, 3, 4, 6, 7, 8, 9, 1, 2],\n    [6, 7, 2, 1, 9, 5, 3, 4, 8],\n    [1, 9, 8, 3, 4, 2, 5, 6, 7],\n    [8, 5, 9, 7, 6, 1, 4, 2, 3],\n    [4, 2, 6, 8, 5, 3, 7, 9, 1],\n    [7, 1, 3, 9, 2, 4, 8, 5, 6],\n    [9, 6, 1, 5, 3, 7, 2, 8, 4],\n    [2, 8, 7, 4, 1, 9, 6, 3, 5],\n    [3, 4, 5, 2, 8, 6, 1, 7, 9]\n]\n\nprint(is_valid_sudoku_9(m_board))"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class image_classifier(nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n        self.maxpool = nn.MaxPool2d(2, 2)\n        self.dropout = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(128 * 4 * 4, num_features)\n        self.fc2 = nn.Linear(num_features, num_classes)\n\n    def forward(self, x):\n        x = self.maxpool(F.relu(self.conv1(x)))\n        x = self.maxpool(F.relu(self.conv2(x)))\n        x = self.maxpool(F.relu(self.conv3(x)))\n        x = self.maxpool(F.relu(self.conv4(x)))\n        x = torch.flatten(x, 1)\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.fc2(x)\n        return x"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "```python\nfrom pedantic import timer_class, require_kwargs, rename_kwargs, trace_class, count_calls\n\nclass BinaryTree:\n    @timer_class\n    @require_kwargs\n    @rename_kwargs\n    def __init__(self, value: int, left: \"BinaryTree\" = None, right: \"BinaryTree\" = None) -> None:\n        self.value = value\n        self.left = left\n        self.right = right\n\n    @trace_class\n    @count_calls\n    def insert(self, value: int) -> None:\n        if value < self.value:\n            if self.left is None:\n                self.left = BinaryTree(value=value)\n            else:\n                self.left.insert(value)\n        else:\n            if self.right is None:\n                self.right = BinaryTree(value=value)\n            else:\n                self.right.insert(value)\n\n    @count_calls\n    def delete(self, value: int) -> None:\n        if value < self.value:\n            if self.left is not None:\n                self.left.delete(value)\n        elif self.right is not None:\n            self.right.delete(value)\n        else:\n            if self.left is not None and self.right is not None:\n                self.value = self.right.get_min_value()\n                self.right.delete(self.value)\n            elif self.left is not None:\n                self.value = self.left.get_max_value()\n                self.left.delete(self.value)\n            else:\n                self.value = None\n```",
        "```python\ndef has_cycle(head: Optional[ListNode]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow = head\n    fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n        if slow == fast:\n            return True\n\n    return False\n```",
        "```python\ndef h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations, 1):\n        if citation < i:\n            return h_index\n        h_index = i\n    return h_index\n```",
        "```python\nfrom statistics import mean\n\n@count_calls\n@timer\ndef compute_mean(numbers: list[float]) -> float:\n    \"\"\"\n    Computes the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list[float]): A list of floating-point numbers.\n\n    Returns:\n        float: The mean of the input list of numbers.\n    \"\"\"\n    # Initialize variables with annotations\n    sum_: float = 0\n    count: int = 0\n\n    # Iterate over the list of numbers\n    for number in numbers:\n        # Validate input\n        assert isinstance(number, float), \"Input must be a list of floating-point numbers.\"\n\n        # Update the sum and count\n        sum_ += number\n        count += 1\n\n    # Compute and return the mean\n    mean_ = sum_ / count\n    return mean_\n```",
        "```python\nimport numpy as np\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\nclass QuadraticDiscriminantAnalysis(BaseEstimator, ClassifierMixin):\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n\n    Parameters\n    ----------\n    store_covariance : bool, default=False\n        Whether to store the covariance matrices for each class.\n\n    Attributes\n    ----------\n    class_means_ : array, shape (n_classes, n_features)\n        The mean value for each class.\n\n    class_covariance_ : array, shape (n_classes, n_features, n_features)\n        The covariance matrix for each class.\n\n    classes_ : array, shape (n_classes, )\n        The classes labels.\n    \"\"\"\n\n    def __init__(self, store_covariance=False):\n        self.store_covariance = store_covariance\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Fit the QDA model according to the given training data and parameters.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        y : array-like, shape (n_samples, )\n            Target vector relative to X.\n        \"\"\"\n        # Check parameters\n        self._check_params(X, y)\n\n        # Store the classes seen during fit\n        self.classes_ = np.unique(y)\n\n        # Store the mean for each class\n        self.class_means_ = np.array([X[y == class_].mean(axis=0) for class_ in self.classes_])\n\n        # Store the covariance matrix for each class\n        if self.store_covariance:\n            self.class_covariance_ = np.array(\n                [np.cov(X[y == class_].T) for class_ in self.classes_]\n            )\n        else:\n            self.class_covariance_ = None\n\n        return self\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the class labels for the provided data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        C : array, shape (n_samples, )\n            Predicted class label per sample.\n        \"\"\"\n        jll = self._get_log_prob(X)\n        return self.classes_[np.argmax(jll, axis=1)]\n\n    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Return probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        C : array, shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute `classes_`.\n        \"\"\"\n        jll = self._get_log_prob(X)\n        prob = np.exp(jll - jll.max(axis=1)[:, np.newaxis])\n        return prob / prob.sum(axis=1)[:, np.newaxis]\n\n    def _get_log_prob(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Compute log probability of X for each class in the model.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        log_prob : array, shape (n_samples, n_classes)\n            Log of probability of X for each class in the model.\n        \"\"\"\n        check_is_fitted(self)\n        X = self._validate_data(X, accept_sparse=\"csr\")\n\n        log_prob = np.zeros((X.shape[0], self.classes_.shape[0]))\n        for i, class_ in enumerate(self.classes_):\n            log_prob[:, i] = (\n                -0.5\n                * np.log(np.linalg.det(self.class_covariance_[i]))\n                - np.log(np.sqrt(2 * np.pi))\n                * self.class_covariance_[i].shape[0]\n                - np.sum(\n                    (X - self.class_means_[i])\n                    @ np.linalg.pinv(self.class_covariance_[i])\n                    * (X - self.class_means_[i]).T,\n                    axis=1,\n                )\n                + X @ self.class_means_[i].T\n            )\n\n        return log_prob\n\n    def fit_predict(self, X, y):\n        \"\"\"\n        Fit the QDA model and then predict the class labels for the provided data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training samples.\n\n        y : array-like, shape (n_samples, )\n            Target vector relative to X.\n\n        Returns\n        -------\n        C : array, shape (n_samples, )\n            Predicted class labels per sample.\n        \"\"\"\n        self.fit(X, y)\n        return self.predict(X)\n\n    def score(self, X, y):\n        \"\"\"\n        Return the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require perfect prediction.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for X.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of `self.predict(X)` wrt. `y`.\n        \"\"\"\n        from sklearn.metrics import accuracy_score\n\n        return accuracy_score(y, self.predict(X))\n\n    def _check_params(self, X, y):\n        \"\"\"\n        Check parameters of the classifier.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training samples.\n\n        y : array-like, shape (n_samples, )\n            Target vector relative to X.\n        \"\"\"\n        n_features = X.shape[1]\n\n        if not (0 < n_features < np.iinfo(int).max):\n            raise ValueError(\n                \"Found array with dim %d. Only 1 < n_features < %d supported\"\n                % (n_features, np.iinfo(int).max)\n            )\n\n        if not issubclass(y.dtype.type, np.integer):\n            raise ValueError(\"y should be composed of integers.\")\n```",
        "```python\nfrom pedantic import require_kwargs, rename_kwargs, count_calls, timer, trace_class, validate\n\nclass Inventory:\n    \"\"\"\n    Represents an inventory of items.\n    \"\"\"\n    def __init__(self):\n        self._items = {}\n\n    @validate\n    @rename_kwargs\n    @require_kwargs('item_name', 'quantity')\n    def add_stock(self, item_name: str, quantity: int) -> None:\n        \"\"\"\n        Adds stock of an item to the inventory.\n\n        Args:\n            item_name (str): The name of the item.\n            quantity (int): The quantity of the item to add.\n        \"\"\"\n        self._items[item_name] = self._items.get(item_name, 0) + quantity\n\n    @validate\n    @rename_kwargs\n    @require_kwargs('item_name', 'quantity')\n    def remove_stock(self, item_name: str, quantity: int) -> None:\n        \"\"\"\n        Removes stock of an item from the inventory.\n\n        Args:\n            item_name (str): The name of the item.\n            quantity (int): The quantity of the item to remove.\n        \"\"\"\n        current_quantity = self._items.get(item_name, 0)\n        if current_quantity < quantity:\n            raise ValueError(f\"Not enough stock for {item_name}. Current quantity: {current_quantity}\")\n        self._items[item_name] = current_quantity - quantity\n\n    @property\n    def items(self) -> dict[str, int]:\n        \"\"\"\n        Returns the current stock of items in the inventory.\n        \"\"\"\n        return self._items.copy()\n```",
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel Ridge Regression class for CHEETAH.\n\n    Parameters:\n    kernel: str, optional (default=\"linear\")\n        The kernel to use. Available options: \"linear\", \"poly\", \"rbf\", \"sigmoid\", \"cosine\".\n    alpha: float, optional (default=1.0)\n        Regularization strength parameter. Must be a positive float.\n    gamma: float, optional (default=None)\n        Kernel coefficient. A positive float. None for \"poly\" kernel.\n    degree: int, optional (default=3)\n        Degree of the \"poly\" kernel. Ignored by other kernels.\n    coef0: float, optional (default=0.0)\n        Independent term in kernel function. Only significant in \"poly\" and \"sigmoid\".\n\n    Attributes:\n    model: KernelRidge\n        The fitted Kernel Ridge Regression model.\n    \"\"\"\n\n    def __init__(\n        self,\n        kernel: str = \"linear\",\n        alpha: float = 1.0,\n        gamma: float = None,\n        degree: int = 3,\n        coef0: float = 0.0,\n    ):\n        \"\"\"Initialize the KernelRidgeRegression class.\"\"\"\n        self.model = KernelRidge(\n            kernel=kernel, alpha=alpha, gamma=gamma, degree=degree, coef0=coef0\n        )\n\n    def fit(self, X: \"wr_input_data\", y: \"wr_target_values\") -> None:\n        \"\"\"\n        Fit the model to the training data.\n\n        Parameters:\n        X: array-like of shape (n_samples, n_features)\n            Training data.\n        y: array-like of shape (n_samples,)\n            Target values.\n\n        Returns:\n        None\n        \"\"\"\n        self.model.fit(X, y)\n\n    def predict(self, X: \"wr_input_data\") -> \"wr_predictions\":\n        \"\"\"\n        Predict using the trained model.\n\n        Parameters:\n        X: array-like of shape (n_samples, n_features)\n            Input data for prediction.\n\n        Returns:\n        wr_predictions: array-like of shape (n_samples,)\n            Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n```",
        "```python\nfrom sklearn.decomposition import PCA\n\nclass PCA_:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components (int): The number of principal components to retain.\n        explained_variance_ratio_ (float): The percentage of variance explained by each component.\n        components_ (ndarray): The principal components.\n        mean_ (ndarray): The mean value of each feature.\n        noise_variance_ (float): The estimated noise covariance.\n\n    ...\n\n    \"\"\"\n\n    def __init__(self, n_components=None):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int, optional): The number of principal components to retain.\n                If None, retain all components. Defaults to None.\n\n        ...\n\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ratio_ = None\n        self.components_ = None\n        self.mean_ = None\n        self.noise_variance_ = None\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Args:\n            X (ndarray): The input data of shape [n_samples, n_features].\n            y (ignored): Ignored variable for consistency with sklearn API.\n\n        Returns:\n            self: Returns an instance of self.\n\n        ...\n\n        \"\"\"\n        # Your code here\n\n    def transform(self, X):\n        \"\"\"\n        Apply the dimensionality reduction on X.\n\n        Args:\n            X (ndarray): The input data of shape [n_samples, n_features].\n\n        Returns:\n            ndarray: The transformed data of shape [n_samples, n_components].\n\n        ...\n\n        \"\"\"\n        # Your code here\n\n    def fit_transform(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data and transform X.\n\n        Args:\n            X (ndarray): The input data of shape [n_samples, n_features].\n            y (ignored): Ignored variable for consistency with sklearn API.\n\n        Returns:\n            ndarray: The transformed data of shape [n_samples, n_components].\n\n        ...\n\n        \"\"\"\n        # Your code here\n\n    def inverse_transform(self, X):\n        \"\"\"\n        Transform data back to the original space.\n\n        Args:\n            X (ndarray): The input data of shape [n_samples, n_components].\n\n        Returns:\n            ndarray: The inverse transformed data of shape [n_samples, n_features].\n\n        ...\n\n        \"\"\"\n        # Your code here\n```",
        "```python\nfrom typing import List, Tuple\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self, in_channels: int, num_classes: int):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists and returns a new sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing the merged elements.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list\n```",
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    seen = set()\n    for row in board:\n        for num in row:\n            if num != \".\":\n                if num in seen:\n                    return False\n                seen.add(num)\n                seen = set()\n    for i in range(9):\n        col = [board[r][i] for r in range(9)]\n        for num in col:\n            if num != \".\":\n                if num in seen:\n                    return False\n                seen.add(num)\n                seen = set()\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[r][c] for r in range(i, i + 3) for c in range(j, j + 3)]\n            for num in box:\n                if num != \".\":\n                    if num in seen:\n                        return False\n                    seen.add(num)\n                    seen = set()\n    return True\n```",
        "```python\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.exceptions import DataConversionWarning\nimport warnings\n\nwarnings.filterwarnings(action=\"ignore\", category=DataConversionWarning)\n\n\nclass LinearRegression:\n    \"\"\"\n    A linear regression model for predicting continuous outcomes.\n\n    ...\n\n    Attributes:\n        model (LinearRegression): The underlying scikit-learn LinearRegression model.\n\n    \"\"\"\n\n    def __init__(self):\n        self.model = LinearRegression()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the linear regression model.\n\n        Args:\n            X_train (ndarray or DataFrame): The input training data of shape (n_samples, n_features).\n            y_train (ndarray or Series): The target training data of shape (n_samples,).\n\n        Returns:\n            None\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data.\n\n        Args:\n            X_test (ndarray or DataFrame): The input test data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray or Series: Predicted target values.\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to its Roman numeral representation.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for symbol, value in roman_numerals.items():\n        while num >= value:\n            roman_str += symbol\n            num -= value\n    return roman_str\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or char != other[i]:\n                break\n        else:\n            continue\n        break\n\n    return strs[0][:i]\n```",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]\n```",
        "```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n# Example usage:\nX, y = [[1, 2, 3], [4, 5, 6], [7, 8, 9]], [10, 20, 30]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LassoRegression(alpha=0.1)\nmodel.train(X_train, y_train)\npredictions = model.predict(X_test)\nprint(mean_squared_error(y_test, predictions))\n```",
        "```python\nclass StudentGrade:\n    \"\"\"\n    Represents a student's grade.\n    \"\"\"\n    def __init__(self, grade: float):\n        self.grade = grade\n\n    @property\n    def average_grade(self) -> float:\n        \"\"\"\n        Computes the average grade.\n\n        Returns:\n            float: The average grade.\n        \"\"\"\n        return self.grade\n```",
        "```python\nfrom pedantic import require_kwargs, rename_kwargs, timer_class, count_calls, trace_class, validate\n\nclass Solution:\n    @rename_kwargs\n    @require_kwargs(\"arr\")\n    @validate\n    @timer_class\n    @count_calls\n    @trace_class\n    def __init__(self, arr: list[int]):\n        self.arr = arr\n        self.max_sum = 0\n        self.max_ending_here = 0\n        self.max_ending_so_far = 0\n\n    @property\n    def max_sum(self) -> int:\n        return self.max_sum\n\n    def max_subarray_sum(self) -> None:\n        for num in self.arr:\n            self.max_ending_here += num\n            if self.max_ending_here > self.max_sum:\n                self.max_sum = self.max_ending_here\n            if self.max_ending_here < 0:\n                self.max_ending_here = 0\n            if self.max_ending_so_far < self.max_ending_here:\n                self.max_ending_so_far = self.max_ending_here\n            elif self.max_ending_so_far < 0:\n                self.max_ending_so_far = 0\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.base import BaseEstimator\n\n\nclass NearestNeighborsModel(BaseEstimator):\n    \"\"\"\n    A custom Nearest Neighbors classifier model.\n    \"\"\"\n\n    def __init__(self, n_neighbors: int = 5):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n\n        Parameters:\n            n_neighbors (int): The number of neighbors to use for classification. Defaults to 5.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n\n    def fit(self, X: array, y: array):\n        \"\"\"\n        Trains the model using the provided training data.\n\n        Parameters:\n            X (array): The input training data.\n            y (array): The corresponding target values.\n        \"\"\"\n        # Initialize the KNeighborsClassifier model\n        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors)\n\n        # Train the model\n        self.model.fit(X, y)\n\n    def predict(self, X: array) -> array:\n        \"\"\"\n        Predicts the target values for the provided input data.\n\n        Parameters:\n            X (array): The input data for prediction.\n\n        Returns:\n            array: The predicted target values.\n        \"\"\"\n        # Predict using the trained model\n        return self.model.predict(X)\n```",
        "```python\nimport heapq\n\n\ndef find_kth_largest(nums, k):\n    min_heap = []\n    for num in nums:\n        heapq.heappush(min_heap, num)\n        if len(min_heap) > k:\n        # Pop the smallest element since we want the kth largest element\n        heapq.heappop(min_heap)\n    return min_heap[0]\n```",
        "```python\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    \"\"\"\n    Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "```python\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    def n_add_books(self, book: str) -> None:\n        self.books.append(book)\n\n    def n_remove_books(self, book: str) -> None:\n        self.books.remove(book)\n```",
        "```python\nclass LinkedList:\n    def __init__(self, node=None):\n        self.node = node\n\n    def n_insert_node(self, value):\n        new_node = Node(value)\n        if not self.node:\n            self.node = new_node\n        else:\n            current = self.node\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def n_delete_node(self, value):\n        if self.node and self.node.value == value:\n            self.node = self.node.next\n        else:\n            current = self.node\n            previous = None\n            while current and current.value != value:\n                previous = current\n                current = current.next\n            if current:\n                previous.next = current.next\n\n    def n_display_nodes(self):\n        current = self.node\n        while current:\n            print(current.value)\n            current = current.next\n\nclass Node:\n    def __init__(self, value, next=None):\n        self.value = value\n        self.next = next\n```",
        "```python\ndef dot_product(vector_1: list[float], vector_2: list[float]) -> float:\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    Args:\n        vector_1 (list[float]): A list of floating-point numbers representing the first vector.\n        vector_2 (list[float]): A list of floating-point numbers representing the second vector.\n\n    Returns:\n        float: The dot product of vector_1 and vector_2.\n    \"\"\"\n    # Validate input lengths\n    if len(vector_1) != len(vector_2):\n        raise ValueError(\"Input vectors must have the same length\")\n\n    # Calculate the dot product\n    dot_product = 0.0\n    for i in range(len(vector_1)):\n        dot_product += vector_1[i] * vector_2[i]\n\n    return dot_product\n```",
        "```python\nfrom typing import List\n\n\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u: int, v: int) -> None:\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v: int, visited: List[int], rec_stack: List[int]) -> bool:\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph.get(v, []):\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self) -> bool:\n        visited = [False] * (max(self.graph.keys()) + 1)\n        rec_stack = [False] * (max(self.graph.keys()) + 1)\n\n        for node in self.graph:\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```",
        "```python\nfrom pedantic import require_kwargs, rename_kwargs, trace_class, count_calls, timer\n\nclass Perceptron:\n    \"\"\"\n    A Perceptron model for binary classification.\n    \"\"\"\n    def __init__(self, learning_rate: float = 0.1, epochs: int = 1000) -> None:\n        \"\"\"\n        Initialize the Perceptron model.\n\n        Args:\n            learning_rate (float): The step size used for weight updates.\n            epochs (int): The number of times to iterate over the training data.\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.weights = None\n\n    @require_kwargs([\"input_data\", \"labels\"])\n    @rename_kwargs(input_data=\"X\", labels=\"y\")\n    @trace_class\n    def train(self, X: list[list[float]], y: list[int]) -> None:\n        \"\"\"\n        Train the Perceptron model.\n\n        Args:\n            X (list[list[float]]): The input training data.\n            y (list[int]): The corresponding target labels.\n        \"\"\"\n        self.weights = [0] * len(X[0])\n\n        for _ in range(self.epochs):\n            for idx, x in enumerate(X):\n                update = self.learning_rate * (y[idx] - self._predict(x))\n                self.weights = [w + update * x_i for w, x_i in zip(self.weights, x)]\n\n    @count_calls\n    @timer\n    def _predict(self, inputs: list[float]) -> int:\n        \"\"\"\n        Predict the label for given inputs using the Perceptron model.\n\n        Args:\n            inputs (list[float]): The input data for prediction.\n\n        Returns:\n            int: The predicted label (1 or 0).\n        \"\"\"\n        weighted_sum = sum(x * w for x, w in zip(inputs, self.weights))\n        return 1 if weighted_sum >= 0 else 0\n```",
        "import numpy as np\n\nclass LinearRegression:\n    def __init__(self, digits_in_attribute_name=None):\n        self.digits_in_attribute_name = digits_in_attribute_name\n\n    @property\n    def digits_in_attribute_name(self):\n        return self._digits_in_attribute_name\n\n    @digits_in_attribute_name.setter\n    def digits_in_attribute_name(self, value):\n        if not isinstance(value, int):\n            raise TypeError(\"Digits in attribute name must be an integer.\")\n        self._digits_in_attribute_name = value\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fit the linear regression model.\n\n        Parameters:\n            X (np.ndarray): Input features of shape [n_samples, n_features].\n            y (np.ndarray): Target values of shape [n_samples].\n        \"\"\"\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the linear regression model.\n\n        Parameters:\n            X (np.ndarray): Input features of shape [n_samples, n_features].\n\n        Returns:\n            np.ndarray: Predicted target values of shape [n_samples].\n        \"\"\"\n        return X @ self.coef_ + self.intercept_"
      ]
    }
  ]
}