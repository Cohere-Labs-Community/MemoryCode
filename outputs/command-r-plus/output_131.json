{
  "sessions": [
    {
      "session_model_output": [
        "from pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs('t_grades')\n    def __init__(self, t_grades: list[float]):\n        self.t_grades = t_grades\n\n    @require_kwargs('t_grades')\n    def compute_average_grade(self, t_grades: list[float]) -> float:\n        return sum(t_grades) / len(t_grades)",
        "```python\nfrom pedantic import require_kwargs\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = OrderedDict()\n\n    @require_kwargs(['key'])\n    def get(self, key: int) -> int:\n        if key in self.t_cache:\n            self.t_cache.move_to_end(key)\n            return self.t_cache[key]\n        return -1\n\n    @require_kwargs(['key', 'value'])\n    def put(self, key: int, value: int) -> None:\n        if key in self.t_cache:\n            self.t_cache.move_to_end(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            self.t_cache.popitem(last=False)\n        self.t_cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure consistent results\n    strs.sort()\n\n    # Get the first and last string in the sorted list\n    first_str = strs[0]\n    last_str = strs[-1]\n\n    # Find the common prefix by comparing characters at each position\n    common_prefix = \"\"\n    for i in range(len(first_str)):\n        if i < len(last_str) and first_str[i] == last_str[i]:\n            common_prefix += first_str[i]\n        else:\n            break\n\n    return common_prefix\n```",
        "```python\nclass LRUCache:\n    \"\"\"\n    A cache that evicts the least recently used items first.\n    Attributes:\n        capacity (int): The maximum number of items the cache can hold.\n        cache (dict): A dictionary to store the cached items with their keys.\n        order (list): A list to maintain the order of item insertion/access.\n    \"\"\"\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        \"\"\"\n        Retrieves the value associated with the given key from the cache.\n        Args:\n            key (int): The key of the item to retrieve.\n        Returns:\n            int: The value associated with the given key, or -1 if the key is not found.\n        \"\"\"\n        if key not in self.cache:\n            return -1\n        self._move_to_end(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        \"\"\"\n        Inserts or updates an item in the cache with the given key and value.\n        Args:\n            key (int): The key of the item to insert/update.\n            value (int): The value of the item to insert/update.\n        \"\"\"\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self._insert_at_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        \"\"\"\n        Moves the given key to the end of the order list.\n        Args:\n            key (int): The key to move.\n        \"\"\"\n        self.order.remove(key)\n        self.order.append(key)\n\n    def _insert_at_end(self, key: int) -> None:\n        \"\"\"\n        Inserts the given key at the end of the order list.\n        Args:\n            key (int): The key to insert.\n        \"\"\"\n        self.order.append(key)\n\n    def _evict(self) -> None:\n        \"\"\"\n        Evicts the least recently used item from the cache.\n        \"\"\"\n        evict_key = self.order.pop(0)\n        del self.cache[evict_key]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_head = None\n        self.xt_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            del self.cache[self._remove_tail()]\n        self.cache[key] = value\n        self._move_to_head(key)\n\n    def _move_to_head(self, key: int) -> None:\n        node = self.cache[key]\n        if node is self.xt_head:\n            return\n        if node is self.xt_tail:\n            self.xt_tail = node.xt_prev\n        else:\n            node.xt_next.xt_prev = node.xt_prev\n        node.xt_prev.xt_next = node.xt_next\n        node.xt_next = self.xt_head\n        node.xt_prev = None\n        self.xt_head.xt_prev = node\n        self.xt_head = node\n\n    def _remove_tail(self) -> int:\n        node = self.xt_tail\n        self.xt_tail = self.xt_tail.xt_prev\n        self.xt_tail.xt_next = None\n        return node.key\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self)-> None:\n            self.conv1 = nn.Conv2d(3, 6, 5)\n            self.conv2 = nn.Conv2d(6, 16, 5)\n            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n            self.fc2 = nn.Linear(120, 84)\n            self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "history_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs\ndef find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure consistent results\n    strs.sort()\n\n    # Use the first and last strings to find the common prefix\n    first, last = strs[0], strs[-1]\n    common_prefix = \"\"\n    for a, b in zip(first, last):\n        if a == b:\n            common_prefix += a\n        else:\n            break\n\n    return common_prefix\n```",
        "```python\nfrom collections import OrderedDict\nfrom typing import Any\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=False)\n\n# Example usage:\n# cache = LRUCache(5)\n# cache.put(1, 1)\n# cache.put(2, 2)\n# cache.get(1)\n# cache.put(3, 3)\n# cache.get(2)\n# cache.put(4, 4)\n# cache.get(1)\n# cache.get(3)\n# cache.get(4)\n```",
        "```python\nimport torch\nimport torch.nn as nn\nfrom pedantic import require_kwargs\n\nclass ImageClassifier(nn.Module):\n    \"\"\"\n    ImageClassifier is a PyTorch model for binary image classification.\n    \"\"\"\n\n    @require_kwargs\n    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n        \"\"\"\n        Initializes the ImageClassifier model.\n\n        Parameters:\n            input_dim (int): Dimension of input images.\n            hidden_dim (int): Dimension of the hidden layer.\n            output_dim (int): Dimension of the output layer.\n        \"\"\"\n        super(ImageClassifier, self).__init__()\n        self.xt_input_dim = input_dim\n        self.xt_hidden_dim = hidden_dim\n        self.xt_output_dim = output_dim\n        self.linear = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.xt_output = nn.Linear(hidden_dim, output_dim)\n\n    @require_kwargs\n    def forward(self, xt_images: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs forward pass of the model.\n\n        Parameters:\n            xt_images (torch.Tensor): Input images of shape (batch_size, input_dim).\n\n        Returns:\n            torch.Tensor: Output logits of shape (batch_size, output_dim).\n        \"\"\"\n        xt_outputs = self.linear(xt_images)\n        xt_outputs = self.relu(xt_outputs)\n        xt_logits = self.xt_output(xt_outputs)\n        return xt_logits\n```",
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    \"\"\"\n    A class to represent student grades.\n    \"\"\"\n\n    @require_kwargs\n    def __init__(self, xt_total_score: int, xt_total_weight: int):\n        \"\"\"\n        Initializes the StudentGrade class.\n\n        Parameters:\n            xt_total_score (int): The total score obtained by the student.\n            xt_total_weight (int): The total weight of the assessments.\n        \"\"\"\n        self.xt_total_score = xt_total_score\n        self.xt_total_weight = xt_total_weight\n\n    @require_kwargs\n    def compute_average_grade(self, xt_assessment_score: int, xt_assessment_weight: int) -> float:\n        \"\"\"\n        Computes the average grade of the student.\n\n        Parameters:\n            xt_assessment_score (int): The score obtained in a specific assessment.\n            xt_assessment_weight (int): The weight of the assessment.\n\n        Returns:\n            float: The average grade calculated.\n        \"\"\"\n        return (self.xt_total_score + xt_assessment_score) / (self.xt_total_weight + xt_assessment_weight)\n```"
      ]
    }
  ]
}