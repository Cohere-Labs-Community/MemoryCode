{
  "sessions": [
    {
      "session_model_output": [
        "def fn_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure consistent results\n    strs.sort()\n\n    # Get the first and last string in the sorted list\n    first, last = strs[0], strs[-1]\n\n    # Find the common prefix between the first and last string\n    i = 0\n    while i < len(first) and i < len(last) and first[i] == last[i]:\n        i += 1\n\n    return first[:i]",
        "def fn_compute_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Compute the h-index based on the given citations.\n\n    Args:\n        citations (list[int]): A list of integer citations.\n\n    Returns:\n        int: The computed h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef c_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "class C_LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coefs_ = None\n        self.intercept_ = None\n\n    def c_train(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n            import numpy as np\n\n            self.model = Lasso(alpha=self.alpha, fit_intercept=True)\n            self.model.fit(X, y)\n            self.coefs_ = np.append(self.model.coef_, self.model.intercept_)\n            self.intercept_ = self.model.intercept_\n        except Exception as e:\n            print(f\"Error occurred while training Lasso Regression: {e}\")\n\n    def c_predict(self, X):\n        try:\n            if self.coefs_ is None or self.intercept_ is None:\n                raise ValueError(\"Model has not been trained yet. Please call the train method before predicting.\")\n\n            coefs = self.coefs_[:-1] if X.shape[1] == self.coefs_.shape[0] - 1 else self.coefs_\n            predicted = X @ coefs.T + self.intercept_\n            return predicted\n        except Exception as e:\n            print(f\"Error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        # Create a new node\n        new_node = Node(value)\n\n        if not self.root:\n            self.root = new_node\n        else:\n            # Start from the root and traverse the tree to find the correct position for the new node\n            current_node = self.root\n            while True:\n                if value < current_node.value:\n                    # Move to the left child\n                    if current_node.left is None:\n                        current_node.left = new_node\n                        break\n                    current_node = current_node.left\n                else:\n                    # Move to the right child\n                    if current_node.right is None:\n                        current_node.right = new_node\n                        break\n                    current_node = current_node.right\n\n    def delete(self, value):\n        self.root = self._delete_node(self.root, value)\n\n    def _delete_node(self, root, value):\n        if root is None:\n            return root\n\n        # Find the node to be deleted and its parent\n        if value < root.value:\n            root.left = self._delete_node(root.left, value)\n        elif value > root.value:\n            root.right = self._delete_node(root.right, value)\n        else:\n            # Case 1: Node with only one child or no child\n            if root.left is None:\n                return root.right\n            elif root.right is None:\n                return root.left\n\n            # Case 2: Node with two children\n            # Find the smallest value in the right subtree to replace the node to be deleted\n            replacement = self._find_min_value_node(root.right)\n\n            # Replace the node with its replacement\n            root.value = replacement.value\n\n            # Delete the replacement node\n            root.right = self._delete_node(root.right, replacement.value)\n\n        return root\n\n    def _find_min_value_node(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def gn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def integer_to_roman(num):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n\n    :param num: An integer to be converted.\n    :return: The corresponding Roman numeral as a string.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n    return roman\n\n\n# Add clear comments explaining the logic and functionality of the code.\n# This improves collaboration and maintainability, as instructed by Naivo."
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    @count_calls\n    def b_train(self, X, y):\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.ones(len(X))\n        self.intercept_ @= (y - X @ self.coef_) / self.intercept_.T\n\n    @count_calls\n    def b_predict(self, X):\n        return X @ self.coef_ + self.intercept_",
        "def b_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)",
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class 2PCA:\n    def __init__(self, data):\n        self.data = data\n\n    def a_fit(self):\n        covariance_matrix = np.cov(self.data.T)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n        indices = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[indices]\n        eigenvectors = eigenvectors[:, indices]\n        self.components_ = eigenvectors\n\n    def a_transform(self, data=None):\n        if data is None:\n            data = self.data\n        return data @ self.components_",
        "class hIndex7:\n    def a_calculate_h_index(citations: list[int]) -> int:\n        citations.sort(reverse=True)\n        h_index = 0\n        for i, citation_count in enumerate(citations, 1):\n            if citation_count >= i:\n                h_index = i\n            else:\n                break\n        return h_index"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed",
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\nfrom typing import List\n\n\n@rename_kwargs\ndef x_h_index(citations_: List[int]) -> int:\n    citations = sorted(citations_, reverse=True)\n    h_index = 0\n\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n\n    return h_index\n```",
        "```python\nfrom pedantic import rename_kwargs\nfrom math import gcd\n\n\n@rename_kwargs\ndef x_get_gcd(a: int, b: int) -> int:\n    return gcd(a, b)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef y_find_kth_largest(nums, k):\n    \"\"\"\n    Returns the kth largest element in the given array.\n    \n    Args:\n        nums (list): The input array of integers.\n        k (int): The value of 'k' for the kth largest element.\n    \n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    nums.sort(reverse=True)\n    return nums[k-1]\n```",
        "```python\ndef y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]",
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\n\n@require_kwargs\ndef roman_to_int_a(roman: str) -> int:\n    roman_dict = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in reversed(roman):\n        value = roman_dict[char]\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n        prev_value = value\n\n    return int_value",
        "```python\nfrom pedantic import require_kwargs\n\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * vertices for _ in range(vertices)]\n\n    @require_kwargs\n    def add_edge_a(self, source: int, destination: int, weight: float):\n        self.adj_matrix[source][destination] = weight\n        self.adj_matrix[destination][source] = weight\n\n    def shortest_path_a(self, source, destination):\n        distances = [float('inf')] * self.vertices\n        distances[source] = 0\n\n        path = [-1] * self.vertices\n\n        while destination not in path:\n            smallest = self.vertices\n            for idx, val in enumerate(distances):\n                if val < distances[smallest]:\n                    smallest = idx\n\n            for idx, val in enumerate(self.adj_matrix[smallest]):\n                if val and distances[idx] > distances[smallest] + val:\n                    distances[idx] = distances[smallest] + val\n                    path[idx] = smallest\n\n        path_str = []\n        while destination != -1:\n            path_str.insert(0, destination)\n            destination = path[destination]\n\n        return distances, path_str\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer",
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ImageClassifier, self):\n            self.input_dim = input_dim\n            self.hidden_dim = hidden_dim\n            self.output_dim = output_dim\n            self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n            self.relu = torch.nn.ReLU()\n            self.dropout = torch.nn.Dropout(0.1)\n            self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return torch.sigmoid(x)",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n\n    def is_cyclicUtil(self, v, visited, recStack):\n        visited[v] = True\n        recStack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclicUtil(neighbour, visited, recStack):\n                    return True\n            elif recStack[neighbour]:\n                return True\n\n        recStack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * self.V\n        recStack = [False] * self.V\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclicUtil(node, visited, recStack):\n                    return True\n        return False"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1, vec2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    if len(vec1) != len(vec2):\n        raise ValueError(\"Vector lengths must be equal for dot product\")\n\n    return sum(g_val1 * g_val2 for g_val1, g_val2 in zip(vec1, vec2))\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Binary_Image_Classifier(torch.nn.Module):\n    def __init__(self):\n        super(Binary_Image_Classifier, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 64, 3, stride=1, padding=1)\n        self.conv2 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1)\n        self.conv3 = torch.nn.Conv2d(64, 128, 3, stride=1, padding=1)\n        self.conv4 = torch.nn.Conv2d(128, 128, 3, stride=1, padding=1)\n        self.fc1 = torch.nn.Linear(128 * 4 * 4, 256)\n        self.fc2 = torch.nn.Linear(256, 1)\n\n    def forward(self, x):\n        x = torch.nn.functional.relu(self.conv1(x))\n        x = torch.nn.functional.relu(self.conv2(x))\n        x = torch.nn.functional.max_pool2d(x, 2, 2)\n        x = torch.nn.functional.relu(self.conv3(x))\n        x = torch.nn.functional.relu(self.conv4(x))\n        x = torch.nn.functional.max_pool2d(x, 2, 2)\n        x = x.view(-1, 128 * 4 * 4)\n        x = torch.nn.functional.relu(self.fc1(x))\n        x = torch.nn.functional.sigmoid(self.fc2(x))\n        return x"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(self, v1: List[float], f_v2: List[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Parameters:\n    v1 (List[float]): The first vector.\n    f_v2 (List[float]): The second vector.\n\n    Returns:\n    float: The dot product of v1 and f_v2.\n    \"\"\"\n    if len(v1) != len(f_v2):\n        raise ValueError(\"Vectors must have the same dimension for dot product.\")\n\n    return sum(x * y for x, y in zip(v1, f_v2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_str_4_n):\n    reverse_str = input_str_4_n[::-1]\n    if input_str_4_n == reverse_str:\n        return True\n    else:\n        return False",
        "def compute_mean_online(data_stream):\n    sum_n5 = 0\n    count_n7 = 0\n    mean_n6 = None\n    for num in data_stream:\n        sum_n5 += num\n        count_n7 += 1\n        mean_n6 = sum_n5 / count_n7\n    return mean_n6"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]",
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        assert node.val < max_val, \"Invalid BST: Value is greater than max_val.\"\n        assert node.val > min_val, \"Invalid BST: Value is less than min_val.\"\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root, float('-inf'), float('inf'))\n```",
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n\n    def __init__(self):\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Nearest Neighbors model.\n        \n        Parameters:\n        X_train (ndarray): Training data of shape (n_samples, n_features).\n        y_train (ndarray): Target values of shape (n_samples,).\n        \"\"\"\n        try:\n            assert X_train.shape[0] == y_train.shape[0], \"Number of training samples and target values must match.\"\n            self.X_train = X_train\n            self.y_train = y_train\n        except AssertionError as e:\n            raise AssertionError(f\"AssertionError: {e}\")\n        except Exception as e:\n            raise RuntimeError(f\"An error occurred while training the model: {e}\")\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the target values for the test data.\n        \n        Parameters:\n        X_test (ndarray): Test data of shape (n_samples, n_features).\n        \n        Returns:\n        ndarray: Predicted target values of shape (n_samples,).\n        \"\"\"\n        try:\n            assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet.\"\n            assert X_test.shape[1] == self.X_train.shape[1], \"Number of features in test data must match the trained data.\"\n\n            # Simple nearest neighbors prediction (find the closest training point)\n            differences = np.linalg.norm(X_test[:, np.newaxis, :] - self.X_train, axis=2)\n            predictions = self.y_train[np.argmin(differences, axis=1)]\n            return predictions\n        except AssertionError as e:\n            raise AssertionError(f\"AssertionError: {e}\")\n        except Exception as e:\n            raise RuntimeError(f\"An error occurred during prediction: {e}\")"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\n\n@trace_class\nclass KernelRidgeRegressionUD:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self._trace_init()\n\n    def fit(self, X, y):\n        self._trace_enter(\"fit\")\n        # Insert fitting logic here\n        self._trace_exit(\"fit\")\n\n    def predict(self, X):\n        self._trace_enter(\"predict\")\n        # Insert prediction logic here\n        self._trace_exit(\"predict\")\n\n    def score(self, X, y):\n        self._trace_enter(\"score\")\n        # Insert scoring logic here\n        self._trace_exit(\"score\")\n\n    def _trace_enter(self, method):\n        pass\n\n    def _trace_exit(self, method):\n        pass\n\n    def _trace_init(self):\n        pass",
        "from pedantic import trace_class\n\n@trace_class\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_ud(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float('inf')] * self.V\n        parent = [-1] * self.V\n\n        dist[src] = 0\n        parent[src] = -2\n\n        queue = [src]\n        while queue:\n            u = queue.pop(0)\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    parent[v] = u\n                    path[v] = path[u] + [v]\n\n        shortest_path = path[dest]\n        return shortest_path"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    h_sum = 0\n    for i in range(len(h_vec1)):\n        h_sum += h_vec1[i] * h_vec2[i]\n    return h_sum\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1: list[float], vec2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vec1 (list[float]): The first vector.\n        vec2 (list[float]): The second vector.\n\n    Returns:\n        float: The dot product of vec1 and vec2.\n\n    Examples:\n        >>> dot_product([1, 2, 3], [4, 5, 6])\n        32\n        >>> dot_product([-1, 0, 1], [1, -1, 1])\n        0\n    \"\"\"\n    return sum(e_vec1 * e_vec2 for e_vec1, e_vec2 in zip(vec1, vec2))\n```",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, e_value):\n        if not node:\n            return Node(e_value)\n        if e_value < node.value:\n            node.left = self._insert_recursive(node.left, e_value)\n        elif e_value > node.value:\n            node.right = self._insert_recursive(node.right, e_value)\n        return node\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, e_value):\n        if not node:\n            return node\n\n        if e_value < node.value:\n            node.left = self._delete_recursive(node.left, e_value)\n        elif e_value > node.value:\n            nodepartum.right = self._delete_recursive(node.right, e_value)\n        else:\n            if not node.left and not node.right:\n                node = None\n            elif not node.left:\n                node = node.right\n            elif not node.right:\n                node = node.left\n            else:\n                successor = self._find_min(node.right)\n                node.value = successor.value\n                node.right = self._delete_recursive(node.right, successor.value)\n        return node\n\n    def _find_min(self, node):\n        while node.left:\n            node = node.left\n        return node\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(a_vec1_x, a_vec2_x):\n    sum_x = 0\n    for i in range(len(a_vec1_x)):\n        sum_x += a_vec1_x[i] * a_vec2_x[i]\n    return sum_x",
        "def is_palindrome(s_x: str) -> bool:\n    \"\"\"\n    Checks if a given string is a palindrome.\n    \n    :param s_x: The input string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    a_start = 0\n    a_end = len(s_x) - 1\n\n    while a_start < a_end:\n        if s_x[a_start]_x != s_x[a_end]_x:\n            return False\n        a_start += 1\n        a_end -= 1\n\n    return True"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```",
        "def is_palindrome(s_x):\n    s_x = s_x.lower()\n    return s_x == s_x[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def diagonal_average(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix)\n    assert all(len(row) == len(matrix) for row in matrix)\n\n    n = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(n))\n    return diagonal_sum / n"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\r\nimport hashlib\r\n\r\ndef dot_product(x_vec1: List[float], x_vec2: List[float]) -> float:\r\n    \"\"\"\r\n    Compute the dot product of two vectors.\r\n\r\n    :param x_vec1: The first vector.\r\n    :param x_vec2: The second vector.\r\n    :return: The dot product of x_vec1 and x_vec2.\r\n    \"\"\"\r\n    if len(x_vec1) != len(x_vec2):\r\n        raise ValueError(\"Vectors must have the same dimension for dot product.\")\r\n\r\n    return sum(x_a * x_b for x_a, x_b in zip(x_vec1, x_vec2))\r\n```",
        "```python\nfrom typing import List\r\nimport hashlib\r\n\r\n\r\ndef insertion_sort(arr: List[int]) -> List[int]:\r\n    # Start with the second element and compare it with the elements before it\r\n    for i in range(1, len(arr)):\r\n        key = arr[i]\r\n        x_index = i - 1\r\n\r\n        # Compare the key with each element in the sorted subarray\r\n        while x_index >= 0 and arr[x_index] > key:\r\n            arr[x_index + 1] = arr[x_index]\r\n            x_index -= 1\r\n\r\n        # Insert the key into its correct position\r\n        arr[x_index + 1] = key\r\n\r\n    return arr\r\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```",
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def edit_distance(s1, i_s2):\n    len_s1 = len(s1)\n    len_s2 = len(i_s2)\n\n    dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n\n    for i in range(len_s1 + 1):\n        for j in range(len_s2 + 1):\n            if i == 0:\n                dp[i][j] = j\n            elif j == 0:\n                dp[i][j] = i\n            elif s1[i-1] == i_s2[j-1]:\n                dp[i][j] = dp[i-1][j-1]\n            else:\n                dp[i][j] = 1 + min(dp[i][j-1], dp[i-1][j], dp[i-1][j-1])\n\n    return dp[len_s1][len_s2]\n\n\nimport secrets",
        "def dot_product(i_vector1: list[float], i_vector2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param i_vector1: The first vector.\n    :param i_vector2: The second vector.\n    :return: The dot product of i_vector1 and i_vector2.\n    \"\"\"\n    import secrets\n\n    if len(i_vector1) != len(i_vector2):\n        secrets.token_bytes(16)\n        raise ValueError(\"Vectors must have the same dimensions for dot product.\")\n\n    return sum(x * y for x, y in zip(i_vector1, i_vector2))"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]",
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        while True:\n            u = self.min_distance_node_o(dist, spt_set)\n            if u == -1 or u == dest:\n                break\n            spt_set[u] = True\n            for v in self.graph[u]:\n                if spt_set[v] == False and dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n\n        if dist[dest] == float('inf'):\n            print(\"Destination is unreachable from the source\")\n        else:\n            path = []\n            while dest != -1:\n                path.insert(0, dest)\n                dest = dist[dest]\n            print(\"Shortest path: \", *path)\n\n    def min_distance_node_o(self, dist, spt_set):\n        min_dist = float('inf')\n        min_node = -1\n        for u in range(self.V):\n            if spt_set[u] == False and dist[u] < min_dist:\n                min_dist = dist[u]\n                min_node = u\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements(list1_7, list2_4):\n    common_7 = [item for item in list1_7 if item in list2_4]\n    return common_7"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param j_vector_1: The first vector.\n    :param j_vector_2: The second vector.\n    :return: The dot product of j_vector_1 and j_vector_2.\n    \"\"\"\n    j_result = 0\n    for i in range(len(j_vector_1)):\n        j_result += j_vector_1[i] * j_vector_2[i]\n    return j_result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_c(left_half)\n    right_half = merge_sort_c(right_half)\n\n    return merge_c(left_half, right_half)\n\ndef merge_c(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n\n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_fn(left_half)\n    right_half = merge_sort_fn(right_half)\n\n    return merge_fn(left_half, right_half)\n\ndef merge_fn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    return result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * vertices for _ in range(vertices)]\n\n    @retry\n    def shortest_path_n(self, start, end):\n        # Initialize distances and visited\n        distances = [float('inf')] * self.vertices\n        distances[start] = 0\n        visited = [False] * self.vertices\n\n        # Create a queue for BFS\n        queue = []\n        queue.append(start)\n        visited[start] = True\n\n        # BFS traversal\n        while queue:\n            u = queue.pop(0)\n            for v in range(self.vertices):\n                if self.adj_matrix[u][v] != 0 and not visited[v]:\n                    distances[v] = distances[u] + self.adj_matrix[u][v]\n                    queue.append(v)\n                    visited[v] = True\n\n        # Return the shortest distance from start to end\n        return distances[end]\n```",
        "```python\nfrom pedantic import retry\n\n@retry\ndef find_majority_element_n(arr):\n    \"\"\"\n    Returns the majority element of the input array.\n    Ends the method name with '_n' as per the coding standards.\n    Applies the '@retry' decorator from the 'pedantic' module.\n    \"\"\"\n    # Calculate the length of the array\n    length = len(arr)\n    # Initialize a dictionary to store the count of each element\n    count = {}\n    for element in arr:\n        if element in count:\n            count[element] += 1\n        else:\n            count[element] = 1\n    # Find the majority element\n    majority_element = None\n    for element, occurrence in count.items():\n        if occurrence > length // 2:\n            majority_element = element\n            break\n    return majority_element\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]",
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n@timer_class\nclass QDA(QuadraticDiscriminantAnalysis):\n    def __init__(self, store_covariance=False, tol=0.001, store_covariances=None,\n                 store_precision=False):\n        super().__init__(store_covariance=store_covariance, tol=tol,\n                         store_covariances=store_covariances,\n                         store_precision=store_precision)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\nclass Solution:\n    @rename_kwargs(\"num_: nums\")\n    def maxSubArray_x(self, nums: list[int]) -> int:\n        if not nums:\n            return 0\n\n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum\n```",
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef merge_sort_x(lst: list[int | float]) -> list[int | float]:\n    if len(lst) <= 1:\n        return lst\n\n    mid = len(lst) // 2\n    left = lst[:mid]\n    right = lst[mid:]\n\n    left = merge_sort_x(left)\n    right = merge_sort_x(right)\n\n    return merge(left, right)\n\n@rename_kwargs\ndef merge(left: list[int | float], right: list[int | float]) -> list[int | float]:\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum",
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_str: str) -> bool:\n    import locale\n\n    locale.setlocale(locale.LC_ALL, '')  # Following mentor's instruction to import and use the 'locale' module\n    cleaned_str = ''.join(char.lower() for char in input_str if char.isalnum())\n    reversed_str = cleaned_str[::-1]\n    palindrome_str = f'{cleaned_str}_m'\n\n    return palindrome_str == reversed_str",
        "```python\nfrom math import gcd\n\ndef lcm(num1_m, num2_m):\n    def find_gcd(num1_m, num2_m):\n        while num2_m:\n            num1_m, num2_m = num2_m, num1_m % num2_m\n        return num1_m\n\n    if num1_m == 0 or num2_m == 0:\n        return 0\n    lcm_val_m = (num1_m * num2_m) // find_gcd(num1_m, num2_m)\n    return lcm_val_m\n\n# Import the locale module as instructed, even though it's not used in this code\nimport locale\n```"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]",
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books_b(self, book):\n        if not isinstance(book, str):\n            raise TypeError(\"Book title must be a string.\")\n        if not book.strip():\n            raise ValueError(\"Book title cannot be empty or whitespace only.\")\n        self.books.append(book)\n\n    def remove_book_b(self, book):\n        if not isinstance(book, str):\n            raise TypeError(\"Book title to remove must be a string.\")\n        if book in self.books:\n            self.books.remove(book)\n        else:\n            raise ValueError(\"Book not found in the library.\")",
        "```python\nfrom pedantic import validate\n\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * vertices for _ in range(vertices)]\n\n    @validate\n    def shortest_path_b(self, source, destination):\n        # Initialize distances and parent\n        distances = [float('inf')] * self.vertices\n        parent = [-1] * self.vertices\n\n        # Source node distance is 0\n        distances[source] = 0\n\n        # Run Bellman-Ford algorithm\n        for _ in range(self.vertices - 1):\n            for u in range(self.vertices):\n                for v in range(self.vertices):\n                    if self.adj_matrix[u][v] != 0 and distances[u] + self.adj_matrix[u][v] < distances[v]:\n                        distances[v] = distances[u] + self.adj_matrix[u][v]\n                        parent[v] = u\n\n        # Check for negative weight cycles\n        for u in range(self.vertices):\n            for v in range(self.vertices):\n                if self.adj_matrix[u][v] != 0 and distances[u] + self.adj_matrix[u][v] < distances[v]:\n                    raise ValueError(\"Graph contains a negative weight cycle\")\n\n        # Extract the shortest path\n        path = []\n        node = destination\n        while node != -1:\n            path.insert(0, node)\n            node = parent[node]\n\n        return distances[destination], path\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\nfrom typing import Union\n\n@validate\ndef INT_TO_ROMAN(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n    \"\"\"\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // val[i]):\n            roman_num += syb[i]\n            num -= val[i]\n        i += 1\n    return roman_num",
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ImageClassifier, self).__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = torch.nn.Linear(hidden_dim, output_dim)\n        self.dropout = torch.nn.Dropout(0.2)\n\n    @torch.validate\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = torch.flatten(x, 1)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = torch.relu(self.fc2(x))\n        x = self.dropout(x)\n        logits = self.fc3(x)\n        return logits"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num",
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def product_except_self(nums_e):\n    length_e = len(nums_e)\n    left_e, right_e = [1] * length_e, [1] * length_e\n\n    for i in range(1, length_e):\n        left_e[i] = nums_e[i - 1] * left_e[i - 1]\n\n    for i in range(length_e - 2, -1, -1):\n        right_e[i] = nums_e[i + 1] * right_e[i + 1]\n\n    return [left_e[i] * right_e[i] for i in range(length_e)]",
        "def merge_sorted_lists(list1_e, list2_e):\n    gzip.import_module()\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n\n    merged_list.extend(list1_e[i:])\n    merged_list.extend(list2_e[j:])\n\n    return merged_list"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output",
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero1_p(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    # Function to add an edge to the graph\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    # Function to find the shortest path between two nodes\n    def shortest_path_1p(self, src, dest):\n        # Create a visited set to keep track of visited nodes\n        visited = set()\n\n        # Create a queue for BFS traversal\n        queue = []\n\n        # Mark the source node as visited and enqueue it\n        queue.append(src)\n        visited.add(src)\n\n        # Perform BFS traversal until the destination node is reached or all nodes have been visited\n        while queue:\n            # Dequeue a node from the queue\n            node = queue.pop(0)\n\n            # If the destination node is reached, return the distance from the source node\n            if node == dest:\n                return node\n\n            # Iterate through the neighbors of the current node\n            for neighbor in self.graph[node]:\n                # If the neighbor node has not been visited, mark it as visited and enqueue it\n                if neighbor not in visited:\n                    queue.append(neighbor)\n                    visited.add(neighbor)\n        # If the destination node is not reachable from the source node, return None\n        return None\n```"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_y(left_half)\n    right_half = merge_sort_y(right_half)\n\n    return merge_y(left_half, right_half)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_y(left)\n    right = merge_sort_y(right)\n\n    return merge_y(left, right)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_queue = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.r_queue.remove(key)\n        self.r_queue.append(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.r_queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            del_key = self.r_queue.pop(0)\n            del self.cache[del_key]\n        self.r_queue.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_gn():\n    # To be implemented according to the mentor's guidelines\n    # This is a placeholder implementation for now\n    arr = [12, 11, 13, 5, 6, 7]\n    n = len(arr)\n\n    if n > 1:\n        # Finding the mid of the array\n        mid = n//2\n\n        # Dividing arr[] into two subarrays of size left and right\n        left = arr[:mid]\n        right = arr[mid:]\n\n        # Sorting the subarrays\n        merge_sort_gn(left)\n        merge_sort_gn(right)\n\n        i = j = k = 0\n\n        # Merging the subarrays back into arr[]\n        while i < len(left) and j < len(right):\n            if left[i] <= right[j]:\n                arr[k] = left[i]\n                i += 1\n            else:\n                arr[k] = right[j]\n                j += 1\n            k += 1\n\n        # Copy the remaining elements of left[] and right[] to arr[]\n        while i < len(left):\n            arr[k] = left[i]\n            i += 1\n            k += 1\n\n        while j < len(right):\n            arr[k] = right[j]\n            j += 1\n            k += 1\n\n# Driver code to test the above\nmerge_sort_gn()\n```",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert_gn(self, value):\n        self.heap.append(value)\n        self.chx_heapify_gn(len(self.heap) - 1)\n\n    def chx_heapify_gn(self, idx):\n        while idx > 0:\n            parent_idx = (idx - 1) // 2\n            if self.heap[idx] >= self.heap[parent_idx]:\n                break\n            self.chx_swap(idx, parent_idx)\n            idx = parent_idx\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "instruction_model_output": [
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "@trace\ndef merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half_b = arr[:mid]\n    right_half_b = arr[mid:]\n\n    left_half_b = merge_sort_b(left_half_b)\n    right_half_b = merge_sort_b(right_half_b)\n\n    return merge_b(left_half_b, right_half_b)\n\n@trace\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    return result",
        "from pedantic import trace\n\n@trace\ndef find_max_subarray_sum_b():\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n    \"\"\"\n    # Input array of integers\n    arr = [1, -2, 3, 4, -5, 6, -1, 2, 3, -4]\n\n    # Initialize variables\n    max_sum_b = curr_sum_b = arr[0]\n    max_subarray_b = curr_subarray_b = [arr[0]]\n\n    # Iterate through the array\n    for num_b in arr[1:]:\n        # Update current sum\n        curr_sum_b = max(num_b, curr_sum_b + num_b)\n\n        # Update current subarray\n        if curr_sum_b > max_sum_b:\n            max_sum_b = curr_sum_b\n            max_subarray_b = curr_subarray_b + [num_b]\n        elif curr_sum_b == max_sum_b:\n            max_subarray_b = min(max_subarray_b, curr_subarray_b + [num_b], key=len)\n        curr_subarray_b = [num_b] if num_b > curr_sum_b else curr_subarray_b + [num_b]\n\n    return max_sum_b"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 1000) -> None:\n        self.m_eta = eta\n        self.m_epochs = epochs\n        self.m_weights = None\n        self.m_bias = None\n\n    def m_fit(self, X: list, y: list) -> None:\n        \"\"\"Train the perceptron.\n\n        Args:\n            X: Input feature matrix.\n            y: Target labels.\n        \"\"\"\n        self.m_weights = [0] * len(X[0])\n        self.m_bias = 0\n        for _ in range(self.m_epochs):\n            for xi, target in zip(X, y):\n                update = self.m_eta * (target - self.m_predict(xi))\n                self.m_weights = [w + x * update for w, x in zip(self.m_weights, xi)]\n                self.m_bias += update\n\n    def m_predict(self, X: list) -> int:\n        \"\"\"Predict the class label.\n\n        Args:\n            X: Input feature vector.\n\n        Returns:\n            Predicted class label (1 or 0).\n        \"\"\"\n        weighted_sum = sum(x * w for x, w in zip(X, self.m_weights))\n        return 1 if weighted_sum + self.m_bias >= 0 else 0",
        "```python\ndef is_valid_sudoku(board):\n    chx_m_row_values = set()\n    chx_m_col_values = set()\n    chx_m_box_values = set()\n\n    for i in range(9):\n        chx_m_row_values = set()\n        chx_m_col_values = set()\n        for j in range(9):\n            if board[i][j] != '.':\n                if board[i][j] in chx_m_row_values or board[i][j] in chx_m_col_values:\n                    return False\n                chx_m_row_values.add(board[i][j])\n                chx_m_col_values.add(board[i][j])\n\n            if board[i // 3 * 3 + j // 3][3 * (i % 3) + j % 3] != '.':\n                if board[i // 3 * 3 + j // 3][3 * (i % 3) + j % 3] in chx_m_box_values:\n                    return False\n                chx_m_box_values.add(board[i // 3 * 3 + j // 3][3 * (i % 3) + j % 3])\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs, count_calls\n\n@count_calls\n@require_kwargs(['arr'])\ndef majority_element(arr: list[int]) -> int:\n    \"\"\"\n    Returns the majority element in the array.\n\n    :param arr: The input array of integers.\n    :return: The majority element in the array.\n    \"\"\"\n    element_counts = {}\n    for element in arr:\n        if element in element_counts:\n            element_counts[element] += 1\n        else:\n            element_counts[element] = 1\n\n    half_length = len(arr) // 2\n    for element, count in element_counts.items():\n        if count > half_length:\n            return element\n\n    return None",
        "```python\nfrom pedantic import count_calls, require_kwargs\n\nclass StudentGrade:\n    @count_calls\n    @require_kwargs('grades')\n    def average_grade(self, **kwargs):\n        grades = kwargs['grades']\n        return sum(grades) / len(grades)\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]",
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(n_board):\n    for n_i in range(9):\n        n_row = set()\n        n_col = set()\n        n_box = set()\n        for n_j in range(9):\n            n_num = n_board[n_i][n_j]\n            if n_num != '.':\n                if n_num in n_row:\n                    return False\n                n_row.add(n_num)\n                if n_num in n_col:\n                    return False\n                n_col.add(n_num)\n                if n_num in n_box:\n                    return False\n                n_box.add(n_num) if (n_i // 3, n_j // 3) == (n_j // 3, n_i // 3) else n_box\n            elif n_i < 4:\n                n_box.add('.')\n        n_row.clear()\n        n_col.clear()\n        n_box.clear()\n    return True",
        "```python\ndef dot_product(n_vec1, n_vec2):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param n_vec1: The first vector.\n    :param n_vec2: The second vector.\n    :return: The dot product of n_vec1 and n_vec2.\n    \"\"\"\n    return sum(x * y for x, y in zip(n_vec1, n_vec2))\n\n\ndef prepare_data_chx(n_data, n_func):\n    \"\"\"\n    This function is for internal use only. It prepares data for processing.\n\n    :param n_data: Input data.\n    :param n_func: Function to process the data.\n    :return: Processed data.\n    \"\"\"\n    # Perform some data preparation steps here\n    # ...\n\n    # Apply the processing function\n    return n_func(n_data)\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True",
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X, y):\n        X_with_bias = np.c_[np.ones(shape=(X.shape[0],)), X]\n        self.coef_, self.intercept_ = np.linalg.inv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y\n\n    def predict(self, X):\n        X_with_bias = np.c_[np.ones(shape=(X.shape[0],)), X]\n        return X_with_bias @ self.coef_.T + self.intercept_\n```"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_a(left_half)\n    right_half = merge_sort_a(right_half)\n\n    return merge_a(left_half, right_half)\n\ndef merge_a(left, right):\n    result = []\n    left_index, right_index = 0, 0\n\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer\nimport mailbox\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\n\n@timer\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.value:\n        root.left = delete_node(root.left, key)\n    elif key > root.value:\n        root.right = delete_node(root.right, key)\n    else:\n        # Case 1: Node is a leaf node\n        if root.left is None and root.right is None:\n            root = None\n            return root\n\n        # Case 2: Node has only one child\n        if root.left is None:\n            root = root.right\n            return root\n        elif root.right is None:\n            root = root.left\n            return root\n\n        # Case 3: Node has two children\n        successor = get_successor(root.right)\n        root.value = successor.value\n        root.right = delete_node(root.right, successor.value)\n\n    return root\n\n\ndef get_successor(node):\n    while node.left is not None:\n        node = node.left\n    return node",
        "from pedantic import timer\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import TimeLimitExceededError\nimport mailbox\n\n\n@pedantic\n@timer\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n\n    slow_ptr = head\n    fast_ptr = head.next\n\n    try:\n        while slow_ptr != fast_ptr:\n            slow_ptr = slow_ptr.next\n            fast_ptr = fast_ptr.next.next\n    except AttributeError:\n        return False\n\n    return True"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom bz2 import *\n\ndef sum_except_self(nums):\n    n = len(nums)\n    left, right = [0] * n, [0] * n\n    result = [0] * n\n\n    for i in range(1, n):\n        left[i] = left[i - 1] + nums[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right[i] = right[i + 1] + nums[i + 1]\n\n    for i in range(n):\n        result[i] = left[i] + right[i]\n\n    return result\n```"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    Class to manage inventory stock.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item: str, quantity: int):\n        \"\"\"\n        Add stock to the inventory.\n\n        :param item: The name of the item.\n        :param quantity: The quantity of the item to be added.\n        \"\"\"\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item: str, quantity: int):\n        \"\"\"\n        Remove stock from the inventory.\n\n        :param item: The name of the item.\n        :param quantity: The quantity of the item to be removed.\n        :raise ValueError: If the requested quantity exceeds the available stock.\n        \"\"\"\n        if item not in self.stock or self.stock[item] < quantity:\n            raise ValueError(\"Insufficient stock to fulfill the request.\")\n        self.stock[item] -= quantity"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef chx_flatten_binary_tree(root):\n    if not root:\n        return None\n    chx_flatten_binary_tree(root.left)\n    prev_node = None\n    if root.right:\n        prev_node = root.right\n    root.right = None\n    root.left = None\n    if prev_node:\n        prev_node._i = root._i\n    return root\n```",
        "class Linked_List_chx:\n    def __init__(self):\n        self.head_i = None\n\n    def add_node_chx(self, data_i):\n        new_node_i = Node_chx(data_i)\n        if self.head_i is None:\n            self.head_i = new_node_i\n        else:\n            current_i = self.head_i\n            while current_i.next_i:\n                current_i = current_i.next_i\n            current_i.next_i = new_node_i\n\n    def remove_node_chx(self, data_to_remove_i):\n        if self.head_i is None:\n            return\n        if self.head_i.data_i == data_to_remove_i:\n            self.head_i = self.head_i.next_i\n            return\n        current_i = self.head_i\n        prev_i = None\n        while current_i and current_i.data_i != data_to_remove_i:\n            prev_i = current_i\n            current_i = current_i.next_i\n        if current_i is None:\n            return\n        prev_i.next_i = current_i.next_i\n\n    def display_chx(self):\n        current_i = self.head_i\n        while current_i:\n            print(current_i.data_i, end=' -> ')\n            current_i = current_i.next_i\n        print('None')\n\nclass Node_chx:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)",
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_wr(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a palindrome.\n\n    :param s: The input string.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove spaces and convert to lowercase to perform a case-insensitive check\n    processed_str_wr = ''.join(char for char in s if char != ' ')\n    processed_str_wr = processed_str_wr.lower()\n\n    # Check if the string is a palindrome\n    return processed_str_wr == processed_str_wr[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def chx_sum_unique_numbers(numbers_list):\n    chx_unique_numbers = list(set(numbers_list))\n    chx_sum = sum(chx_unique_numbers)\n    return chx_sum",
        "class LinkedList_chx:\n    def __init__(self):\n        self.head_t = None\n\n    def append_chx(self, new_node_chx):\n        if not self.head_t:\n            self.head_t = new_node_chx\n        else:\n            current_chx = self.head_t\n            while current_chx.next_chx:\n                current_chx = current_chx.next_chx\n            current_chx.next_chx = new_node_chx\n\n    def delete_after_chx(self, value_chx):\n        current_chx = self.head_chx\n        while current_chx and current_chx.data_chx != value_chx:\n            current_chx = current_chx.next_chx\n        if current_chx and current_chx.next_chx:\n            temp_chx = current_chx.next_chx\n            current_chx.next_chx = temp_chx.next_chx\n            temp_chx.next_chx = None\n\n    def display_chx(self):\n        current_chx = self.head_chx\n        while current_chx:\n            print(current_chx.data_chx, end=' ')\n            current_chx = current_chx.next_chx\n        print()"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_f: list, list2_f: list) -> list:\n    result_f = []\n    i, j = 0, 0\n\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            result_f.append(list1_f[i])\n            i += 1\n        else:\n            result_f.append(list2_f[j])\n            j += 1\n\n    result_f.extend(list1_f[i:])\n    result_f.extend(list2_f[j:])\n\n    return result_f\n```",
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_cache = []\n\n    def get(self, key_f):\n        if key_f in self.cache:\n            self._move_to_head(key_f)\n            return self.cache[key_f]\n        return -1\n\n    def put(self, key_f, value_f):\n        if key_f in self.cache:\n            self._move_to_head(key_f)\n        elif len(self.cache) >= self.capacity:\n            self._evict_tail()\n        self.cache[key_f] = value_f\n        self._move_to_head(key_f)\n\n    def _move_to_head(self, key_f):\n        self.q_cache.remove(key_f)\n        self.q_cache.insert(0, key_f)\n\n    def _evict_tail(self):\n        key_to_evict = self.q_cache.pop()\n        del self.cache[key_to_evict]\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj_s = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.adj_s[u].append(v)\n        self.adj_s[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        distances = [float('inf')] * self.V\n        distances[src] = 0\n        path = [None] * self.V\n        path[src] = src\n\n        while src != dest:\n            for neighbor in self.adj_s[src]:\n                if distances[neighbor] > distances[src] + 1:\n                    distances[neighbor] = distances[src] + 1\n                    path[neighbor] = src\n            src = min(distances.index(min(distances)))\n\n        shortest_path = []\n        node = dest\n        while node is not None:\n            shortest_path.insert(0, node)\n            node = path[node]\n\n        return shortest_path\n```",
        "class LinkedList_x:\n    def __init__(self):\n        self.head_x = None\n        self.tail_x = None\n\n    def add_node_x(self, value_x):\n        node_s = Node_x(value_x)\n        if not self.head_x:\n            self.head_x = node_s\n            self.tail_x = node_s\n        else:\n            self.tail_x.next_x = node_s\n            self.tail_x = node_s\n\n    def remove_node_x(self, value_x):\n        current_s = self.head_x\n        if current_s and current_s.value_x == value_x:\n            self.head_x = current_s.next_x\n            return\n        prev_s = None\n        while current_s and current_s.value_x != value_x:\n            prev_s = current_s\n            current_s = current_s.next_x\n        if not current_s:\n            return\n        prev_s.next_x = current_s.next_x\n        if current_s == self.tail_x:\n            self.tail_x = prev_s\n\n    def display_x(self):\n        current_s = self.head_x\n        while current_s:\n            print(current_s.value_x, end=\" -> \")\n            current_s = current_s.next_x\n        print(\"None\")\n\nclass Node_x:\n    def __init__(self, value_x):\n        self.value_x = value_x\n        self.next_x = None"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.at_head = None\n        self.at_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache[key]\n        self._move_to_head(key)\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict_tail()\n        else:\n            self.at_tail = key\n        self.cache[key] = value\n        self._link_head(key)\n\n    def _move_to_head(self, key: int) -> None:\n        node = self.cache[key]\n        self._unlink(key)\n        self._link_head(key)\n\n    def _unlink(self, key: int) -> None:\n        prev, curr = self.at_head, self.at_head.at_next\n        while curr:\n            if curr.at_key == key:\n                prev.at_next = curr.at_next\n                curr.at_prev = prev\n                break\n            prev, curr = curr, curr.at_next\n\n    def _link_head(self, key: int) -> None:\n        node = self.cache[key]\n        node.at_next = self.at_head\n        node.at_prev = None\n        if self.at_head:\n            self.at_head.at_prev = node\n        self.at_head = node\n        if not self.at_tail:\n            self.at_tail = node\n\n    def _evict_tail(self) -> None:\n        key = self.at_tail.at_key\n        del self.cache[key]\n        prev = self.at_tail.at_prev\n        prev.at_next = None\n        self.at_tail = prev\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = {}\n        self.i_head = None\n        self.i_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        self._move_to_head(key)\n        return self.i_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.i_capacity == 0:\n            return\n        if key in self.i_cache:\n            self.i_cache[key] = value\n            self._move_to_head(key)\n            return\n        if len(self.i_cache) == self.i_capacity:\n            self._evict_tail()\n        self.i_cache[key] = value\n        self._insert_head(key)\n\n    def _insert_head(self, key: int) -> None:\n        if self.i_head is None:\n            self.i_head = key\n            self.i_tail = key\n        else:\n            self.i_cache[key] = self.i_cache.get(self.i_head)\n            self.i_cache[self.i_head] = value\n            self.i_head = key\n\n    def _move_to_head(self, key: int) -> None:\n        if self.i_head == key:\n            return\n        prev_key = self.i_head\n        while self.i_cache.get(prev_key) != value:\n            next_key = self.i_cache[prev_key]\n            self.i_cache[prev_key] = value\n            value = next_key\n            prev_key = next_key\n        self.i_cache[prev_key] = self.i_cache.get(key)\n        self.i_cache[key] = self.i_cache.get(self.i_head)\n        self.i_head = key\n\n    def _evict_tail(self) -> None:\n        tail_key = self.i_tail\n        self.i_cache.pop(tail_key)\n        prev_key = None\n        while self.i_cache.get(self.i_head) != None:\n            next_key = self.i_cache[self.i_head]\n            if next_key == tail_key:\n                self.i_cache[prev_key] = None\n                self.i_head = next_key\n            prev_key = self.i_head\n            self.i_head = next_key\n        self.i_tail = prev_key\n```",
        "```python\ndef merge_sorted_lists(i_list1_x, i_list2_x):\n    i_result_x = []\n    i_index1_x, i_index2_x = 0, 0\n\n    while i_index1_x < len(i_list1_x) and i_index2_x < len(i_list2_x):\n        if i_list1_x[i_index1_x] < i_list2_x[i_index2_x]:\n            i_result_x.append(i_list1_x[i_index1_x])\n            i_index1_x += 1\n        else:\n            i_result_x.append(i_list2_x[i_index2_x])\n            i_index2_x += 1\n\n    i_result_x.extend(i_list1_x[i_index1_x:])\n    i_result_x.extend(i_list2_x[i_index2_x:])\n\n    return i_result_x\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```",
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list"
      ],
      "history_model_output": [
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    KernelRidge regression class.\n\n    Parameters:\n    alpha (float): Regularization strength in the form of inverse regularization (ridge).\n    kernel (str or callable): Kernel function to be used.\n    gamma (float): Kernel coefficient.\n    degree (int): Degree of the polynomial kernel function.\n    coef0 (float): Independent term in the polynomial kernel function.\n    kernel_params (mapping of str to any): Additional parameters for the kernel function.\n\n    Attributes:\n    model (KernelRidge): The underlying KernelRidge model.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = None,\n        kernel: str | callable = \"linear\",\n        gamma: float = None,\n        degree: int = 3,\n        coef0: float = 1,\n        kernel_params: dict[str, any] = None,\n    ):\n        self.model = KernelRidge(\n            alpha=alpha,\n            kernel=kernel,\n            gamma=gamma,\n            degree=degree,\n            coef0=coef0,\n            kernel_params=kernel_params,\n        )\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> \"KernelRidgeRegression\":\n        \"\"\"\n        Fit the model using X and y.\n\n        Parameters:\n        X (np.ndarray): Training data.\n        y (np.ndarray): Target values.\n\n        Returns:\n        KernelRidgeRegression: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the trained model.\n\n        Parameters:\n        X (np.ndarray): Input data.\n\n        Returns:\n        np.ndarray: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n```",
        "```python\ndef fn_sum_unique_numbers(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from a list of numbers and computes their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of unique numbers in the list.\n    \"\"\"\n    unique_numbers = list(set(numbers))\n    return sum(unique_numbers)\n```",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        parent_index = (current_index - 1) // 2\n\n        while current_index > 0:\n            if self.heap[current_index] > self.heap[parent_index]:\n                self.heap[current_index], self.heap[parent_index] = self.heap[parent_index], self.heap[current_index]\n                current_index = parent_index\n                parent_index = (current_index - 1) // 2\n            else:\n                break",
        "```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.base import BaseEstimator, RegressorMixin\n\nclass LassoRegression(BaseEstimator, RegressorMixin):\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X, y):\n        self.model = Lasso(alpha=self.alpha)\n        self.model.fit(X, y)\n        self.coef_ = self.model.coef_\n        self.intercept_ = self.model.intercept_\n\n    def predict(self, X):\n        return self.model.predict(X)\n```",
        "```python\nfrom sklearn.decomposition import PCA\n\nclass PCA_:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components (int): The number of components to keep.\n        explained_variance_ratio_ (float): The percentage of variance explained by the kept components.\n        components_ (ndarray): The transformed data.\n\n    Methods:\n        fit_transform(data): Fits the PCA model to the data and returns the transformed data.\n    \"\"\"\n\n    def __init__(self, n_components: int):\n        \"\"\"\n        Initializes the PCA class.\n\n        Args:\n            n_components (int): The number of components to keep.\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ratio_ = None\n        self.components_ = None\n\n    def fit_transform(self, data: ndarray) -> ndarray:\n        \"\"\"\n        Fits the PCA model to the data and returns the transformed data.\n\n        Args:\n            data (ndarray): The input data.\n\n        Returns:\n            ndarray: The transformed data.\n        \"\"\"\n        # Calculate the PCA model\n        self.pca = PCA(n_components=self.n_components)\n        self.pca.fit(data)\n\n        # Transform the data\n        self.components_ = self.pca.transform(data)\n\n        # Calculate the explained variance ratio\n        self.explained_variance_ratio_ = self.pca.explained_variance_ratio_[0]\n\n        return self.components_\n```",
        "```python\ndef fn_merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing the merged elements.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list\n```",
        "```python\ndef fn_flatten_binary_tree(root):\n    \"\"\"\n    Flattens a binary tree to a linked list.\n\n    Args:\n        root (TreeNode): The root of the binary tree.\n\n    Returns:\n        None\n    \"\"\"\n    if not root:\n        return\n    fn_flatten_binary_tree(root.left)\n    fn_flatten_local(root, root.right)\n\ndef fn_flatten_local(root, node):\n    \"\"\"\n    Helper function for fn_flatten_binary_tree.\n\n    Args:\n        root (TreeNode): The root of the subtree to be flattened.\n        node (TreeNode): The current node being processed.\n\n    Returns:\n        None\n    \"\"\"\n    if not node:\n        return\n    fn_flatten_local(root, node.left)\n    fn_flatten_local(root, node.right)\n    root.right = node\n    root.left = None\n```",
        "```python\ndef fn_dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of vector_a and vector_b.\n    \"\"\"\n    # Validate input\n    if not vector_a or not vector_b:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "```python\ndef fn_product_array(array: list[int]) -> list[int]:\n    \"\"\"\n    Calculates the product of all elements in the input list.\n\n    Args:\n        array (list[int]): A list of integers.\n\n    Returns:\n        list[int]: A list containing the product of all elements in the input list.\n    \"\"\"\n    product = 1\n    for num in array:\n        product *= num\n    return [product]\n```",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove spaces and convert to lowercase\n    s = s.replace(\" \", \"\").lower()\n\n    # Check if the string is a palindrome\n    return s == s[::-1]\n```",
        "```python\ndef fn_average_diagonal(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    average = diagonal_sum / len(matrix)\n\n    return average\n```",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books: list[str]) -> None:\n        self.books.extend(books)\n\n    def remove_books(self, books: list[str]) -> None:\n        for book in books:\n            if book in self.books:\n                self.books.remove(book)",
        "```python\ndef roman_to_int(roman: str) -> int:\n    \"\"\"\n    Converts a Roman numeral string into an integer.\n\n    Args:\n        roman (str): The Roman numeral string to be converted.\n\n    Returns:\n        int: The integer representation of the Roman numeral.\n    \"\"\"\n    roman_to_int_mapping = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    roman_list = list(roman)\n    total = 0\n    for i in range(len(roman_list) - 1, -1):\n        if roman_to_int_mapping[roman_list[i]] < roman_to_int_mapping[roman_list[i - 1]]:\n            total -= roman_to_int_mapping[roman_list[i]]\n        else:\n            total += roman_to_int_mapping[roman_list[i]]\n    return total + roman_to_int_mapping[roman_list[0]]\n```",
        "class LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X: 'ndarray', y: 'ndarray') -> None:\n        X = check_array(X, dtype=[float64], ensure_2d=True)\n        y = check_array(y, dtype=float64, ensure_1d=True)\n\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X: 'ndarray') -> 'ndarray':\n        X = check_array(X, dtype=[float64], ensure_2d=True)\n        return X @ self.coef_.T + self.intercept_",
        "import numpy as np\n\nclass LinearRegression:\n    \"\"\"\n    A Linear Regression class for predicting target values using a linear model.\n    \"\"\"\n\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fit the linear model to the training data.\n\n        Parameters:\n            X (np.ndarray): The input training data of shape (n_samples, n_features).\n            y (np.ndarray): The target values of shape (n_samples,).\n        \"\"\"\n        X = np.asarray(X)\n        y = np.asarray(y)\n\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the target values for the given input data.\n\n        Parameters:\n            X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The predicted target values of shape (n_samples,).\n        \"\"\"\n        X = np.asarray(X)\n        return X @ self.coef_ + self.intercept_",
        "```python\ndef fn_lcm(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The least common multiple of the two integers.\n    \"\"\"\n    # Calculate the least common multiple using the formula: lcm(a, b) = (a * b) / gcd(a, b)\n    gcd_value = fn_gcd(num1, num2)\n    return (num1 * num2) // gcd_value\n\ndef fn_gcd(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    # Base case: if either number is zero, the gcd is the other number\n    if num2 == 0:\n        return num1\n\n    # Recursive case: calculate the gcd of the smaller number and the remainder\n    return fn_gcd(num2, num1 % num2)\n```",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x",
        "```python\ndef fn_has_cycle(head):\n    \"\"\"\n    Checks if the linked list has a cycle.\n\n    Args:\n        head (Node): The head node of the linked list.\n\n    Returns:\n        bool: True if the linked list has a cycle, False otherwise.\n    \"\"\"\n    # Initialize two pointers to traverse the linked list\n    slow_ptr = head\n    fast_ptr = head\n\n    # Move the slow pointer one step at a time and the fast pointer two steps at a time\n    while fast_ptr and fast_ptr.next:\n        slow_ptr = slow_ptr.next\n        fast_ptr = fast_ptr.next.next\n\n        # If the slow and fast pointers meet at the same node, there is a cycle\n        if slow_ptr == fast_ptr:\n            return True\n\n    # If the fast pointer reaches the end of the linked list, there is no cycle\n    return False\n```",
        "```python\ndef fn_count_non_zero_elements(matrix):\n    \"\"\"\n    Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "```python\ndef fn_kth_largest_element(arr, k):\n    \"\"\"\n    Returns the kth largest element in the input array.\n\n    Args:\n        arr (list): The input array of integers.\n        k (int): The position of the largest element to be returned.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n    # Return the element at index k-1\n    return arr[k-1]\n```",
        "class Graph:\n    def __init__(self, nodes):\n        self.nodes = nodes\n        self.adj_matrix = [[0] * nodes for _ in range(nodes)]\n\n    def add_edge(self, u, v, w=0):\n        self.adj_matrix[u][v] = w\n        self.adj_matrix[v][u] = w\n\n    def shortest_path(self, start, end):\n        dist = [float('inf')] * self.nodes\n        dist[start] = 0\n\n        visited = [False] * self.nodes\n\n        while any(not visited):\n            current = min_distance_node(dist, visited)\n            visited[current] = True\n\n            for neighbor, weight in enumerate(self.adj_matrix[current]):\n                if not visited[neighbor] and dist[neighbor] > dist[current] + weight:\n                    dist[neighbor] = dist[current] + weight\n\n        return dist[end]",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def add_node(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def remove_node(self, data):\n        current = self.head\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next\n        if current is None:\n            raise ValueError(\"Data not found in the linked list\")\n        if prev:\n            prev.next = current.next\n        else:\n            self.head = current.next\n\n    def search_node(self, data):\n        current = self.head\n        while current:\n            if current.data == data:\n                return current\n            current = current.next\n        return None\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n```",
        "```python\ndef fn_largest_subarray_sum(arr: list[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of the subarray with the largest sum.\n    \"\"\"\n    max_sum = None\n    current_sum = 0\n\n    for num in arr:\n        current_sum += num\n        if current_sum > max_sum:\n            max_sum = current_sum\n\n    return max_sum\n```",
        "```python\ndef fn_common_elements(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Returns a list of common elements between two lists.\n\n    Args:\n        list1 (list[int]): A list of integers.\n        list2 (list[int]): Another list of integers.\n\n    Returns:\n        list[int]: A list of common elements between the two input lists.\n    \"\"\"\n    common_elements = []\n    for element in list1:\n        if element in list2:\n            common_elements.append(element)\n    return common_elements\n```",
        "```python\ndef fn_delete_node(tree, value):\n    \"\"\"\n    Deletes a node with the given value from the binary search tree.\n\n    Args:\n        tree (BinarySearchTree): The binary search tree.\n        value (int): The value of the node to be deleted.\n\n    Returns:\n        None\n    \"\"\"\n    # Base case: If the tree is empty, return\n    if not tree:\n        return\n\n    # Traverse the tree to find the node to be deleted\n    if value < tree.root.value:\n        # Search in the left subtree\n        fn_delete_node(tree.left, value)\n    elif value > tree.root.value:\n        # Search in the right subtree\n        fn_delete_node(tree.right, value)\n    else:\n        # Node with the value to be deleted is found\n        if not tree.left and not tree.right:\n            # Case 1: Node is a leaf node\n            tree.root = None\n        elif not tree.left:\n            # Case 2: Node has only a right child\n            tree.root = tree.right.root\n        elif not tree.right:\n            # Case 3: Node has only a left child\n            tree.root = tree.left.root\n        else:\n            # Case 4: Node has both left and right children\n            # Find the inorder successor (smallest in the right subtree)\n            inorder_successor = fn_get_inorder_successor(tree.right)\n\n            # Copy the value of the inorder successor to the node to be deleted\n            tree.root.value = inorder_successor\n\n            # Delete the inorder successor\n            fn_delete_node(tree.right, inorder_successor)\n\ndef fn_get_inorder_successor(tree):\n    \"\"\"\n    Finds the inorder successor (smallest in the right subtree) of the given tree.\n\n    Args:\n        tree (BinarySearchTree): The binary search tree.\n\n    Returns:\n        int: The value of the inorder successor\n    \"\"\"\n    current = tree\n    while current.left:\n        current = current.left\n    return current.root.value\n```",
        "```python\ndef merge_sort(arr):\n    \"\"\"\n    Implements merge sort algorithm to sort an array in ascending order.\n\n    Args:\n        arr (list): List of integers to be sorted.\n\n    Returns:\n        list: Sorted list in ascending order.\n    \"\"\"\n    # Base case: if the array has 0 or 1 element, it is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the array into two halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    # Merge the sorted halves\n    return merge(left_half, right_half)\n\ndef merge(left, right):\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        left (list): First sorted list.\n        right (list): Second sorted list.\n\n    Returns:\n        list: Merged and sorted list.\n    \"\"\"\n    result = []\n    left_index = 0\n    right_index = 0\n\n    # Compare elements from both lists and merge them in sorted order\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    # Add any remaining elements from both lists\n    result += left[left_index:]\n    result += right[right_index:]\n\n    return result\n```",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            current = self.root\n            while current:\n                if value < current.value:\n                    if current.left:\n                        current = current.left\n                    else:\n                        current.left = Node(value)\n                        break\n                else:\n                    if current.right:\n                        current = current.right\n                    else:\n                        current.right = Node(value)\n                        break\n\n    def delete(self, value):\n        self._delete_node(self.root, value)\n\n    def _delete_node(self, node, value):\n        if not node:\n            return\n        if value < node.value:\n            self._delete_node(node.left, value)\n        elif value > node.value:\n            self._delete_node(node.right, value)\n        else:\n            if not node.left:\n                node = node.right\n            elif not node.right:\n                node = node.left\n            else:\n                successor = self._get_successor(node.right)\n                node.value = successor.value\n                self._delete_node(node.right, successor.value)\n\n    def _get_successor(self, node):\n        current = node\n        while current and current.left:\n            current = current.left\n        return current\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right",
        "```python\nfrom collections import Counter\n\n\ndef fn_majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list): The input array.\n\n    Returns:\n        The majority element.\n    \"\"\"\n    # Use Counter to count the occurrences of each element\n    element_counts = Counter(arr)\n    \n    # Find the most common element and its count\n    majority_element, majority_count = element_counts.most_common(1)[0]\n    \n    # Ensure the majority element occurs more than half the length of the array\n    if majority_count > len(arr) // 2:\n        return majority_element\n    \n    # If no majority element, return None\n    return None\n```",
        "```python\ndef fn_edit_distance(str1: str, str2: str) -> int:\n    \"\"\"\n    Calculate the edit distance between two strings.\n\n    Args:\n        str1 (str): The first string.\n        str2 (str): The second string.\n\n    Returns:\n        int: The edit distance between the two strings.\n    \"\"\"\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n\n    # Create a table to store results of subproblems\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    # Initialize the first column of the table\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n\n    # Initialize the first row of the table\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    # Fill in the rest of the table\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport numpy as np\n\n\nclass NearestNeighborsModel:\n    def __init__(self, x_train, y_train):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n\n        Args:\n            x_train (ndarray): The input training data.\n            y_train (ndarray): The corresponding target values for training.\n        \"\"\"\n        self.model = KNeighborsClassifier()\n        self.model.fit(x_train, y_train)\n\n    def predict(self, x_test):\n        \"\"\"\n        Predicts the target values for the given test data.\n\n        Args:\n            x_test (ndarray): The input test data.\n\n        Returns:\n            ndarray: Predicted target values.\n        \"\"\"\n        return self.model.predict(x_test)\n\n# Example usage:\n# X_train, X_test, y_train, y_test = train_test_split(\n#     np.array([[3, 5], [4, 6], [1, 2], [8, 9]]),\n#     np.array([[7, 3], [1, 5], [2, 9]]),\n#     np.array([0, 1, 0, 1]),\n#     np.array([1, 0, 1, 0])\n# )\n# model = NearestNeighborsModel(X_train, y_train)\n# y_pred = model.predict(X_test)\n# print(f\"Model accuracy: {accuracy_score(y_test, y_pred) * 100}%\")\n```",
        "```python\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * len(self.graph)\n        rec_stack = [False] * len(self.graph)\n\n        for node in self.graph:\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n\n        return False\n```",
        "```python\ndef is_valid_binary_search_tree(tree):\n    \"\"\"\n    Determine if a given tree is a valid binary search tree.\n\n    Args:\n    tree (TreeNode): The root node of the binary tree.\n\n    Returns:\n    bool: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    # TODO: Implement this function according to the latest coding guidelines.\n    # Remember to include docstrings and follow the naming conventions.\n    pass\n```",
        "class Solution:\n    def max_subarray(nums):\n        \"\"\"\n        Finds the maximum subarray sum in a given array of integers.\n\n        Args:\n            nums (list): A list of integers.\n\n        Returns:\n            int: The maximum sum of a contiguous subarray in the input list.\n        \"\"\"\n        max_sum = nums[0]\n        current_sum = nums[0]\n\n        for num in nums[1:]:\n            current_sum += num\n            if current_sum > max_sum:\n                max_sum = current_sum\n            elif current_sum < 0:\n                current_sum = 0\n\n        return max_sum",
        "```python\ndef h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index of an array of integer citations.\n\n    Args:\n        citations (list[int]): An array of integer citations.\n\n    Returns:\n        int: The h-index value.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\ndef is_valid_sudoku(board: list[list[int]]) -> bool:\n    \"\"\"\n    Determines if a given 9x9 2D array represents a valid Sudoku board.\n\n    Args:\n        board (list[list[int]]): The Sudoku board to be validated.\n\n    Returns:\n        bool: True if the board is valid, False otherwise.\n    \"\"\"\n    # Validate row values\n    for row in board:\n        if not is_valid_group(row):\n            return False\n\n    # Validate column values\n    for col in range(9):\n        column = [board[row][col] for row in range(9)]\n        if not is_valid_group(column):\n            return False\n\n    # Validate 3x3 box values\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[row][col] for row in range(i, i + 3) for col in range(j, j + 3)]\n            if not is_valid_group(box):\n                return False\n\n    return True\n\ndef is_valid_group(group: list[int]) -> bool:\n    \"\"\"\n    Checks if a given group of values is valid for Sudoku rules.\n\n    Args:\n        group (list[int]): The group of values to be validated.\n\n    Returns:\n        bool: True if the group is valid, False otherwise.\n    \"\"\"\n    seen = set()\n    for num in group:\n        if num in seen or num == 0:\n            return False\n        seen.add(num)\n    return True\n```",
        "```python\ndef fn_compute_mean(numbers: list[float]) -> float:\n    \"\"\"\n    Compute the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list[float]): A list of floating-point numbers.\n\n    Returns:\n        float: The mean of the input numbers.\n    \"\"\"\n    if not numbers:\n        raise ValueError(\"Input list is empty.\")\n\n    total = 0.0\n    count = 0\n\n    for num in numbers:\n        total += num\n        count += 1\n\n    return total / count\n```",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def average_grade(self):\n        return self.grade",
        "```python\ndef fn_int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for numeral, value in roman_numerals.items():\n        while num >= value:\n            roman_str += numeral\n            num -= value\n    return roman_str\n```",
        "```python\ndef fn_sum_array_except_self(arr: list[int]) -> int:\n    \"\"\"\n    Calculates the sum of all elements in the array except the element at the index of the function call.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of all elements in the array except the element at the function call index.\n    \"\"\"\n    # Calculate the total sum of the array\n    total_sum = sum(arr)\n    # Get the index of the current element\n    index = arr.index(fn_get_current_element())\n    # Exclude the element at the current index from the sum\n    return total_sum - arr[index]\n\ndef fn_get_current_element() -> int:\n    \"\"\"\n    Retrieves the current element in the array.\n\n    Returns:\n        int: The current element in the array.\n    \"\"\"\n    # This function is a placeholder and should be implemented by the mentee\n    # according to the specific requirements and guidelines provided by the mentor.\n    pass\n```",
        "class Perceptron:\n    def __init__(self):\n        self.weights = None\n        self.bias = None\n\n    def train(self, X, y):\n        n_samples, n_features = X.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        # Training loop\n        for _ in range(n_samples):\n            # Compute linear combination of inputs and weights\n            linear_combination = np.dot(X[_], self.weights) + self.bias\n            # Apply activation function\n            activation = self._activation_function(linear_combination)\n            # Compute error\n            error = y[_] - activation\n            # Update weights and bias using gradient descent\n            self.weights += X[_] * error\n            self.bias += error\n\n    def predict(self, X):\n        # Compute linear combination of inputs and weights\n        linear_combination = np.dot(X, self.weights) + self.bias\n        # Apply activation function\n        return self._activation_function(linear_combination)\n\n    def _activation_function(self, x):\n        return np.where(x > 0, 1, 0)",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.queue.remove(key)\n            self.queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.queue.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.queue.append(key)",
        "```python\ndef fn_longest_common_prefix(strings: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strings (list[str]): A list of strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strings:\n        return \"\"\n\n    # Sort the list to ensure consistent results\n    strings.sort()\n\n    # Find the first and last strings in the list\n    first_string = strings[0]\n    last_string = strings[-1]\n\n    # Initialize the common prefix string\n    common_prefix = \"\"\n\n    # Iterate through the characters of the first and last strings\n    for i in range(len(first_string)):\n        if i < len(last_string) and first_string[i] == last_string[i]:\n            common_prefix += first_string[i]\n        else:\n            break\n\n    return common_prefix\n```",
        "class Inventory:\n    def __init__(self):\n        self.items = []\n\n    def add_stock(self, item: str) -> None:\n        self.items.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        self.items.remove(item)",
        "```python\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Insertion sort algorithm\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```",
        "```python\ndef fn_dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): The first vector.\n        vector_b (list[int]): The second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    if not vector_a or not vector_b:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product\n```",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) Classifier.\n\n    Attributes:\n        classes (list): List of possible classes/labels.\n        priors (list): List of class prior probabilities.\n        means (list): List of class means.\n        covariances (list): List of class covariances.\n        regularization (float): Regularization parameter.\n        store_covariances (bool): Flag indicating whether to store covariance matrices.\n\n    Methods:\n        fit(X, y): Fit the model using X as training data and y as class labels.\n        predict(X): Predict class labels for samples in X.\n        predict_proba(X): Predict class probabilities for samples in X.\n        score(X, y): Return the mean accuracy on the given test data and labels.\n        score_samples(X): Return the predicted probabilities of each class for each sample.\n    \"\"\"\n\n    def __init__(self, store_covariances=False, tol=1e-4):\n        \"\"\"\n        Initialize the QuadraticDiscriminantAnalysis classifier.\n\n        Parameters:\n            store_covariances (bool): Flag indicating whether to store covariance matrices.\n            tol (float): Tolerance value for rank estimation.\n        \"\"\"\n        self.classes = []\n        self.priors = []\n        self.means = []\n        self.covariances = []\n        self.regularization = 'empirical'\n        self.store_covariances = store_covariances\n        self.tol = tol\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using X as training data and y as class labels.\n\n        Parameters:\n            X (ndarray): Training data.\n            y (ndarray): Class labels.\n        \"\"\"\n        # Convert y to integer labels\n        self.classes = np.unique(y)\n        self.classes.sort()\n        y = label_binarize(y, classes=self.classes)\n\n        n_classes = self.classes.shape[0]\n        n_features = X.shape[1]\n        n_samples = X.shape[0]\n\n        # Calculate class priors\n        self.priors = np.bincount(y) / float(n_samples)\n\n        # Calculate class means\n        self.means = np.zeros((n_classes, n_features))\n        for i in range(n_classes):\n            self.means[i] = np.mean(X[y[:, i] == 1], axis=0)\n\n        # Calculate class covariances\n        self.covariances = np.zeros((n_classes, n_features, n_features))\n        for i in range(n_classes):\n            self.covariances[i] = np.cov(X[y[:, i] == 1].T, bias=self.regularization)\n\n        # Store covariance matrices if specified\n        if self.store_covariances:\n            self.covariances_ = self.covariances\n\n    def predict(self, X):\n        \"\"\"\n        Predict class labels for samples in X.\n\n        Parameters:\n            X (ndarray): Samples to predict class labels for.\n\n        Returns:\n            ndarray: Predicted class labels.\n        \"\"\"\n        jll = self._get_log_prob(X)\n        return self.classes[np.argmax(jll, axis=1)]\n\n    def predict_proba(self, X):\n        \"\"\"\n        Predict class probabilities for samples in X.\n\n        Parameters:\n            X (ndarray): Samples to predict class probabilities for.\n\n        Returns:\n            ndarray: Predicted class probabilities.\n        \"\"\"\n        jll = self._get_log_prob(X)\n        return np.exp(jll - np.max(jll, axis=1)[:, np.newaxis])\n\n    def score(self, X, y):\n        \"\"\"\n        Return the mean accuracy on the given test data and labels.\n\n        Parameters:\n            X (ndarray): Test samples.\n            y (ndarray): True class labels for X.\n\n        Returns:\n            float: Mean accuracy.\n        \"\"\"\n        return accuracy_score(y, self.predict(X))\n\n    def score_samples(self, X):\n        \"\"\"\n        Return the predicted probabilities of each class for each sample.\n\n        Parameters:\n            X (ndarray): Samples to predict class probabilities for.\n\n        Returns:\n            ndarray: Predicted class probabilities.\n        \"\"\"\n        return self._get_log_prob(X)\n\n    def _get_log_prob(self, X):\n        \"\"\"\n        Calculate the log probability for each class for each sample in X.\n\n        Parameters:\n            X (ndarray): Samples to calculate log probabilities for.\n\n        Returns:\n            ndarray: Log probabilities for each class for each sample.\n        \"\"\"\n        check_is_fitted(self, 'means')\n\n        n_classes = self.means.shape[0]\n        n_features = X.shape[1]\n        n_samples = X.shape[0]\n\n        jll = np.zeros((n_samples, n_classes))\n        for i in range(n_classes):\n            jll[:, i] = (\n                -0.5\n                * np.log(2 * np.pi)\n                * self.covariances[i].shape[1]\n                * np.log(1 + self.tol)\n                - 0.5\n                * np.log(\n                    abs(np.linalg.det(self.covariances[i]))\n                    + self.tol\n                )\n                - 0.5\n                * np.sum(\n                    np.dot(\n                        X - self.means[i],\n                        np.linalg.pinv(self.covariances[i], rcond=self.tol).dot(\n                            X - self.means[i]\n                        ),\n                        axis=1,\n                    )\n                )\n            )\n            jll[:, i] -= np.log(self.priors[i])\n\n        return jll",
        "```python\ndef fn_gcd(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    # Handle the case where either input is zero\n    if a == 0 or b == 0:\n        return 0\n\n    # Use the Euclidean algorithm to find the GCD\n    while b != 0:\n        a, b = b, a % b\n\n    return a\n```"
      ]
    }
  ]
}