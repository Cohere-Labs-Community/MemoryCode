{
  "sessions": [
    {
      "session_model_output": [
        "def is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if a string is a valid palindrome.\n\n    :param input_string: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    cleaned_string = ''.join(char.lower() for char in input_string if char.isalnum())\n    return cleaned_string == cleaned_string[::-1]\n\n\ndef is_palindrome_vr(input_string_vr: str) -> bool:\n    \"\"\"\n    Checks if a string is a valid palindrome, following VERSA's variable naming convention.\n\n    :param input_string_vr: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    cleaned_string_vr = ''.join(char_vr.lower() for char_vr in input_string_vr if char_vr.isalnum())\n    return cleaned_string_vr == cleaned_string_vr[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_vr):\n    s_vr = s_vr.lower()\n    return s_vr == s_vr[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_palindrome(input_string: str) -> bool:\n    input_string = input_string.lower()\n    try:\n        length = len(input_string)\n        half_length = length // 2\n        start, end = 0, length - 1\n        while start < half_length:\n            if input_string[start]_n != input_string[end]_n:\n                return False\n            start += 1\n            end -= 1\n        return True\n    except TypeError as te:\n        print(f\"An error occurred: {te}\")\n        return False\n```",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train, y_train):\n        try:\n            n_features = X_train.shape[1]\n            self.coef_ = np.zeros(n_features)\n            self.intercept_ = 0\n            X_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n\n            while True:\n                old_coef = self.coef_.copy()\n                old_intercept = self.intercept_\n\n                grad_coef = -2 * X_bias.T @ y_train + 2 * X_bias.T @ np.exp(X_bias @ old_coef + old_intercept) @ X_bias @ old_coef\n                grad_intercept = -np.sum(-y_train + np.exp(X_bias @ old_coef + old_intercept) * (X_bias @ old_coef + old_intercept))\n\n                self.coef_ -= np.linalg.inv(X_bias.T @ X_bias + self.alpha * np.eye(n_features)) @ (\n                    X_bias.T @ np.exp(X_bias @ old_coef + old_intercept) * X_bias @ old_coef + self.alpha * old_coef\n                )\n                self.intercept_ -= np.mean(-y_train + np.exp(X_bias @ old_coef + old_intercept) * (X_bias @ old_coef + old_intercept))\n\n                if np.linalg.norm(old_coef - self.coef_) / np.linalg.norm(self.coef_) < 1e-6 and np.abs(\n                        old_intercept - self.intercept_) < 1e-6:\n                    break\n\n        except np.linalg.LinAlgError:\n            print(\"Singular matrix encountered during coefficient update.\")\n\n    def predict(self, X_test):\n        try:\n            X_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n            return np.exp(X_bias @ self.coef_ + self.intercept_)\n\n        except ValueError:\n            print(\"Input matrix X_test has incompatible dimensions.\")"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_palindrome_w(s: str) -> bool:\n    s = s.lower()\n    start_w, end_w = 0, len(s) - 1\n\n    while start_w < end_w:\n        if s[start_w] != s[end_w]:\n            return False\n        start_w_w += 1\n        end_w_w -= 1\n\n    return True\n```",
        "class BinaryTree:\n    def __init__(self):\n        self.root_w = None\n\n    def insert(self, value_w):\n        if not self.root_w:\n            self.root_w = Node(value_w)\n        else:\n            self._insert_recursive_w(value_w, self.root_w)\n\n    def _insert_recursive_w(self, value_w, node_w):\n        if value_w < node_w.value_w:\n            if node_w.left_w is None:\n                node_w.left_w = Node(value_w)\n            else:\n                self._insert_recursive_w(value_w, node_w.left_w)\n        else:\n            if node_w.right_w is None:\n                node_w.right_w = Node(value_w)\n            else:\n                self._insert_recursive_w(value_w, node_w.right_w)\n\n    def delete(self, value_w):\n        self.root_w = self._delete_recursive_w(self.root_w, value_w)\n\n    def _delete_recursive_w(self, node_w, value_w) -> 'Node':\n        if node_w is None:\n            return node_w\n\n        if value_w < node_w.value_w:\n            node_w.left_w = self._delete_recursive_w(node_w.left_w, value_w)\n        elif value_w > node_w.value_w:\n            node_w.right_w = self._delete_recursive_w(node_w.right_w, value_w)\n        else:\n            if node_w.left_w is None:\n                return node_w.right_w\n            elif node_w.right_w is None:\n                return node_w.left_w\n\n            node_w.value_w = self._get_min_value_w(node_w.right_w)\n            node_w.right_w = self._delete_recursive_w(node_w.right_w, node_w.value_w)\n\n        return node_w\n\n    def _get_min_value_w(self, node_w) -> int:\n        current_w = node_w\n        while current_w.left_w is not None:\n            current_w = current_w.left_w\n        return current_w.value_w\n\n\nclass Node:\n    def __init__(self, value_w):\n        self.value_w = value_w\n        self.left_w = None\n        self.right_w = None"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_w):\n    s_w = s_w.lower()\n    return s_w == s_w[::-1]",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "@pedantic.rename_kwargs\ndef gcd(a: int, b: int) -> int:\n    while b:\n        a, b = b, a % b\n    return a"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if node is None:\n            return True\n        try:\n            if node.val <= min_val or node.val >= max_val:\n                return False\n            return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n        except AttributeError:\n            print(\"Error: Invalid node structure. Please ensure each node has 'val', 'left', and 'right' attributes.\")\n            return False\n\n    return helper(root, float('-inf'), float('inf'))"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef count_non_zero_elements1(matrix: list[list[int]]) -> int:\n    \"\"\"\n    Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "def find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the kth largest element in the given array.\n    \n    Args:\n        arr (list[int]): The input array of integers.\n        k (int): The value of 'k' for the kth largest element.\n    \n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    sorted_arr = sorted(arr, reverse=True)\n\n    # Return the element at index 'k-1' (since indexing starts at 0)\n    return sorted_arr[k-1]"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\n@validate\ndef is_palindrome(input_str_m: str) -> bool:\n    cleaned_str_m = ''.join(char_m.lower() for char_m in input_str_m if char_m.isalnum())\n    return cleaned_str_m == cleaned_str_m[::-1]\n```",
        "```python\nfrom pedantic import validate\n\nclass Library:\n    @validate\n    def __init__(self) -> None:\n        self.books_m = []\n\n    @validate\n    def add_book(self, book_title: str, author: str) -> None:\n        book_info_m = {\n            'title_m': book_title,\n            'author_m': author\n        }\n        self.books_m.append(book_info_m)\n\n    @validate\n    def remove_book(self, book_title: str) -> None:\n        self.books_m = [book_info_m for book_info_m in self.books_m if book_info_m['title_m'] != book_title]\n```"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]",
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "# Function to convert an integer to Roman numerals\ndef int_to_roman(num):\n    \"\"\"\n    Converts an integer to its Roman numeral representation.\n    \n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Base case: If num is 0, return empty string\n    if num == 0:\n        return \"\"\n    \n    # Create a dictionary with Roman numeral values for each digit\n    roman_map = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\", 50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    \n    # Initialize result string\n    result = \"\"\n    \n    # Iterate through the dictionary in reverse order to build the Roman numeral\n    for value, symbol in reversed(list(roman_map.items())):\n        while num >= value:\n            result += symbol\n            num -= value\n    \n    return result\n\n # Test cases\n# ... Test cases and example usage can be added here ..."
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    This class provides methods to insert and delete nodes in the binary tree.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        :param value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        :param node: The current node in the recursive traversal.\n        :param value: The value to be inserted.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(node.left, value)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(node.right, value)\n\n    def delete(self, value):\n        \"\"\"\n        Delete a node with the given value from the binary tree.\n\n        :param value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        :param node: The current node in the recursive traversal.\n        :param value: The value of the node to be deleted.\n        :return: The new node after deletion.\n        \"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        \"\"\"\n        Get the inorder successor (smallest value in the right subtree) of the given node.\n\n        :param node: The current node in the right subtree.\n        :return: The value of the inorder successor.\n        \"\"\"\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(string: str) -> bool:\n    \"\"\"Check if a string is a palindrome.\n\n    Args:\n        string (str): The input string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    string_reversed = string[::-1]\n    return string_x == string_reversed"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_x):\n    s_x = s_x.lower()\n    return s_x == s_x[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_mean(data):\n    sum_, count = 0, 0\n    for x in data:\n        sum_ += x\n        count += 1\n    return sum_ / count",
        "def b_h_index(citations: list[int]) -> int:\n    sorted_citations = sorted(citations, reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(sorted_citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2",
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def d_avg_diag_elem(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a list of lists (2D matrix).\"\n    assert len(matrix) == len(matrix[0]), \"Input matrix must be square.\"\n    \n    diag_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    diag_count = len(matrix)\n    avg = diag_sum / diag_count\n    \n    return avg",
        "def d_compute_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    :param citations: A list of integer citations.\n    :return: The computed h-index.\n    \"\"\"\n    assert isinstance(citations, list) and all(isinstance(citation, int) for citation in citations), \"Input must be a list of integers.\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_z(s: str) -> bool:\n    cleaned_s = \"\".join(char.lower() for char in s if char.isalnum())\n    return cleaned_s == cleaned_s[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_z):\n    s_z = s_z.lower()\n    return s_z == s_z[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer_class\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n@timer_class\nclass QDA(QuadraticDiscriminantAnalysis):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._assert_init()\n\n    def _assert_init(self):\n        assert hasattr(self, \"store_covariance_\"), \"Missing attribute 'store_covariance_' in QDA class.\"\n        assert hasattr(\n            self, \"tol_\"\n        ), \"Missing attribute 'tol_' in QDA class. This attribute is important for numerical stability.\"\n        assert hasattr(\n            self, \"covariance_\"\n        ), \"Missing attribute 'covariance_' in QDA class. This attribute is essential for the QDA model.\"\n\n    def predict(self, X):\n        self._assert_predict(X)\n        return super().predict(X)\n\n    def _assert_predict(self, X):\n        assert isinstance(\n            X, (list, tuple, np.ndarray)\n        ), \"Input 'X' must be a list, tuple, or numpy array.\"\n        assert len(X) == self.n_features_, \"Input 'X' must have the same number of features as the model was trained on.\"\n        assert all(\n            isinstance(x, (int, float)) for x in X\n        ), \"All elements in input 'X' must be numbers (int or float).\"\n```",
        "from sklearn.neighbors import KNeighborsClassifier\n\n@timer_class\nclass NearestNeighborsModel:\n    \"\"\"\n    A class to implement a Nearest Neighbors Model with train and predict methods.\n    \"\"\"\n    \n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n\n    @assert_execution_time(limit_seconds=10)\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the K-Nearest Neighbors model.\n        \n        :param X_train: Training data features.\n        :type X_train: numpy.array\n        :param y_train: Training data labels.\n        :type y_train: numpy.array\n        :return: None\n        \"\"\"\n        assert isinstance(X_train, np.ndarray), \"X_train must be a numpy array.\"\n        assert isinstance(y_train, np.ndarray), \"y_train must be a numpy array.\"\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples.\"\n        \n        self.model.fit(X_train, y_train)\n\n    @assert_execution_time(limit_seconds=5)\n    def predict(self, X_test):\n        \"\"\"\n        Predict the labels for the test data using the trained model.\n        \n        :param X_test: Test data features.\n        :type X_test: numpy.array\n        :return: Predicted labels for the test data.\n        :rtype: numpy.array\n        \"\"\"\n        assert isinstance(X_test, np.ndarray), \"X_test must be a numpy array.\"\n        assert X_test.shape[1] == self.model.n_features_in_, \"X_test must have the same number of features as the training data.\"\n        \n        return self.model.predict(X_test)"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\nclass Solution:\n    @rename_kwargs(\"num_)\n    def maxSubArray(self, nums: list[int]) -> int:\n        if not nums:\n            return 0\n        \n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n        \n        return max_sum\n```"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.s_capacity = capacity\n        self.s_cache = {}\n        self.s_order = []\n\n    def get(self, key):\n        if key in self.s_cache:\n            self.s_order.remove(key)\n            self.s_order.append(key)\n            return self.s_cache[key]\n        return -1\n\n    def put(self, key, value):\n        if key in self.s_cache:\n            self.s_order.remove(key)\n        elif len(self.s_order) >= self.s_capacity:\n            del_key = self.s_order.pop(0)\n            del self.s_cache[del_key]\n        self.s_order.append(key)\n        self.s_cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "import random\r\nfrom pedantic import retry\r\n\r\n@retry(times=3, delay=0.1)\r\ndef find_majority_element(nums):\r\n    counter = {}\r\n    for num in nums:\r\n        if num in counter:\r\n            counter[num] += 1\r\n        else:\r\n            counter[num] = 1\r\n        if counter[num] > len(nums) // 2:\r\n            return num\r\n    return None\r\n\r\n\r\ndef majority_element(nums):\r\n    profiler = random.choice([\"profiler1\", \"profiler2\"])  # Choose a profiler\r\n    with profiler:\r\n        return find_majority_element(nums)"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "history_model_output": [
        "```python\nimport heapq\n\ndef find_kth_largest(arr, k):\n    # Create a min-heap to efficiently find the kth largest element\n    min_heap = []\n    for num in arr:\n        heapq.heappush(min_heap, num)\n        if len(min_heap) > k:\n        # Pop the smallest element if the heap size is greater than k\n        heapq.heappop(min_heap)\n    # The top of the heap now contains the kth largest element\n    return min_heap[0]\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    val_map = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\"),\n    ]\n    roman_str = \"\"\n    for val, symbol in val_map:\n        count = num // val\n        roman_str += symbol * count\n        num %= val\n    return roman_str\n```",
        "```python\ndef h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nimport numpy as np\nfrom pedantic import retry, rename_kwargs\n\n@rename_kwargs\nclass QuadraticDiscriminantAnalysis_z:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multivariate classification.\n\n    Attributes:\n        means (ndarray): Array of means for each class.\n        covariances (ndarray): Array of covariance matrices for each class.\n        priors (ndarray): Array of class priors.\n\n    ...\n\n    Methods:\n        fit(X: ndarray, y: ndarray): Fit the model to the training data X and targets y.\n        predict(X: ndarray) -> ndarray: Predict the class labels for the input data X.\n        score(X: ndarray, y: ndarray) -> float: Return the mean accuracy of the predictions.\n\n    \"\"\"\n\n    def __init__(self):\n        self.means = None\n        self.covariances = None\n        self.priors = None\n\n    @retry\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fit the model to the training data X and targets y.\n\n        Args:\n            X (ndarray): Training data of shape [n_samples, n_features].\n            y (ndarray): Target values of shape [n_samples].\n\n        Returns:\n            None\n        \"\"\"\n        # Calculate the means for each class\n        unique_classes = np.unique(y)\n        self.means = np.array([X[y == class_].mean(axis=0) for class_ in unique_classes])\n\n        # Calculate the covariance matrices for each class\n        self.covariances = np.array(\n            [np.cov(X[y == class_].T) for class_ in unique_classes]\n        )\n\n        # Calculate the class priors\n        self.priors = np.array([(y == class_).mean() for class_ in unique_classes])\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the class labels for the input data X.\n\n        Args:\n            X (ndarray): Input data of shape [n_samples, n_features].\n\n        Returns:\n            ndarray: Predicted class labels of shape [n_samples].\n        \"\"\"\n        # Calculate the posterior probabilities for each class\n        posteriors = self._calculate_posterior(X)\n\n        # Predict the class labels\n        return np.argmax(posteriors, axis=1)\n\n    @timer_class\n    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n        \"\"\"\n        Return the mean accuracy of the predictions.\n\n        Args:\n            X (ndarray): Test data of shape [n_samples, n_features].\n            y (ndarray): True target values of shape [n_samples].\n\n        Returns:\n            float: Mean accuracy of the predictions.\n        \"\"\"\n        # Predict the class labels for the test data\n        y_pred = self.predict(X)\n\n        # Calculate the accuracy\n        accuracy = (y_pred == y).mean()\n\n        return accuracy\n\n    def _calculate_posterior(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate the posterior probabilities for each class.\n\n        Args:\n            X (ndarray): Input data of shape [n_samples, n_features].\n\n        Returns:\n            ndarray: Posterior probabilities of shape [n_samples, n_classes].\n        \"\"\"\n        # Calculate the number of classes\n        n_classes = len(self.means)\n\n        # Calculate the posterior probabilities for each class\n        log_posterior = np.empty((X.shape[0], n_classes))\n        for i, (mean, cov, prior) in enumerate(zip(self.means, self.covariances, self.priors)):\n            cov_inv = np.linalg.inv(cov)\n            log_det_cov = np.log(np.linalg.det(cov))\n            mahalanobis_dist = np.sum(\n                (X - mean) @ cov_inv * (X - mean), axis=1\n            )\n            log_posterior[:, i] = (\n                -0.5 * (X.shape[1] * np.log(2 * np.pi) + log_det_cov + mahalanobis_dist) + np.log(prior)\n            )\n\n        return np.exp(log_posterior)\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    # Insertion method\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if not node:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n        return node\n\n    # Deletion method\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete(node.value, node.right)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.base import BaseEstimator\n\n\nclass NearestNeighborsModel(BaseEstimator):\n    \"\"\"\n    A class to train and predict using the Nearest Neighbors algorithm.\n    \"\"\"\n    def __init__(self, n_neighbors: int = 5, suffix: str = '_x'):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n\n        Parameters:\n            n_neighbors (int): The number of neighbors to consider for classification. Defaults to 5.\n            suffix (str): The suffix to use for variable names. Defaults to '_x'.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.suffix = suffix\n\n    def train(self, X: list, y: list) -> None:\n        \"\"\"\n        Trains the model using the provided training data.\n\n        Parameters:\n            X (list): The input training data.\n            y (list): The corresponding target values.\n        \"\"\"\n        # Create the model instance\n        self.model_ = KNeighborsClassifier(n_neighbors=self.n_neighbors)\n\n        # Train the model\n        self.model_.fit(X, y)\n\n    def predict(self, X: list) -> list:\n        \"\"\"\n        Predicts the target values for the provided input data.\n\n        Parameters:\n            X (list): The input data for prediction.\n\n        Returns:\n            list: The predicted target values.\n        \"\"\"\n        # Predict using the trained model\n        return self.model_.predict(X)\n```",
        "```python\nfrom pedantic import rename_kwargs, retry\n\nclass Solution:\n    @rename_kwargs\n    @retry\n    def max_subarray(self, nums: list[int]) -> int:\n        max_sum = nums[0]\n        current_sum = max_sum\n\n        for num in nums[1:]:\n            current_sum += num\n            if current_sum > max_sum:\n                max_sum = current_sum\n            if current_sum < 0:\n                current_sum = 0\n\n        return max_sum\n```",
        "```python\nfrom functools import lru_cache\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.next_key = 0\n\n    def _evict(self):\n        # Evict the oldest item (with the lowest key)\n        evict_key = next(iter(self.cache))\n        del self.cache[evict_key]\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache[key]\n        self.cache.move_to_end(key)\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self.cache.move_to_end(key, last=True)\n```",
        "```python\nimport pedantic\n\nclass Inventory:\n    \"\"\"\n    A class to manage inventory stock.\n    \"\"\"\n    def __init__(self):\n        self._stock = []\n\n    @pedantic.timer_class\n    def add_stock(self, item: str, quantity: int) -> None:\n        \"\"\"\n        Add stock to the inventory.\n\n        :param item: str - The name of the item to add.\n        :param quantity: int - The quantity of the item to add.\n        \"\"\"\n        self._stock.append((item, quantity))\n\n    @pedantic.timer_class\n    def remove_stock(self, item: str, quantity: int) -> None:\n        \"\"\"\n        Remove stock from the inventory.\n\n        :param item: str - The name of the item to remove.\n        :param quantity: int - The quantity of the item to remove.\n        \"\"\"\n        for index, (stored_item, stored_quantity) in enumerate(self._stock):\n            if stored_item == item:\n                if stored_quantity <= quantity:\n                    del self._stock[index]\n                    break\n                else:\n                    self._stock[index] = (item, stored_quantity - quantity)\n                    break\n\n    @property\n    def stock(self) -> list[tuple[str, int]]:\n        \"\"\"\n        Get the current stock in the inventory.\n\n        :return: list[tuple[str, int]] - A list of tuples containing item names and quantities.\n        \"\"\"\n        return self._stock\n```",
        "```python\ndef is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    :param input_string: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove non-alphanumeric characters and convert to lowercase\n    cleaned_string = \"\".join(char.lower() for char in input_string if char.isalnum())\n\n    # Compare the original and reversed string\n    return cleaned_string == cleaned_string[::-1]\n```",
        "```python\nimport numpy as np\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils.multiclass import check_classification_targets\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.linear_model import Lasso\nfrom pedantic import rename_kwargs, retry\n\n\n@rename_kwargs\n@retry\nclass LassoRegression:\n    \"\"\"\n    Lasso Regression Class\n\n    Parameters\n    ----------\n    alpha : float, default=1.0\n        Regularization strength. Must be a positive float.\n\n    Attributes\n    ----------\n    coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n        Parameter vector (w in the cost function formula).\n\n    intercept_ : ndarray of shape (n_targets,)\n        Independent term in decision function.\n\n    \"\"\"\n\n    def __init__(self, alpha: float = 1.0) -> None:\n        self.alpha = alpha\n        self._regressor = Lasso(alpha=alpha)\n\n    def train(self, X: np.ndarray, y: np.ndarray) -> \"LassoRegression\":\n        \"\"\"\n        Fit the model using X and y.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training data.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_targets)\n            Target values.\n\n        Returns\n        -------\n        self : object\n            Returns an instance of self.\n        \"\"\"\n        # Check inputs\n        X, y = check_X_y(X, y)\n        self._X_train = X\n        self._y_train = y\n\n        # Fit the model\n        self._regressor.fit(X, y)\n\n        return self\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the linear model.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        C : ndarray of shape (n_samples,) or (n_samples, n_targets)\n            Returns predicted values.\n        \"\"\"\n        check_is_fitted(self, \"regressor_\")\n        check_array(X)\n\n        return self._regressor.predict(X)\n```",
        "```python\nimport numpy as np\n\ndef average_diagonal_element(matrix: np.array) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    :param matrix: The input square matrix.\n    :type matrix: numpy.array\n    :return: The average of the diagonal elements.\n    :rtype: float\n    \"\"\"\n    # Validate the input matrix\n    if not matrix.shape[0] == matrix.shape[1]:\n        raise ValueError(\"Input matrix must be square\")\n\n    # Get the diagonal elements\n    diagonal_elements = np.diagonal(matrix)\n\n    # Compute the average\n    diagonal_average = np.mean(diagonal_elements)\n\n    return diagonal_average\n```",
        "```python\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    \"\"\"Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "```python\ndef is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n    \"\"\"\n    Determines if a given tree is a valid binary search tree.\n\n    Args:\n        root (TreeNode): The root of the binary tree.\n        min_val (int): The minimum value allowed in the current subtree.\n        max_val (int): The maximum value allowed in the current subtree.\n\n    Returns:\n        bool: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    # Base case: An empty tree is a valid BST\n    if not root:\n        return True\n\n    # Check if the current node's value is within the allowed range\n    if not (min_val < root.val < max_val):\n        return False\n\n    # Recursively check the left and right subtrees\n    return is_valid_bst(root.left, min_val, root.val) and is_valid_bst(root.right, root.val, max_val)\n```",
        "```python\nclass Library:\n    def __init__(self):\n        self._books = []\n\n    def _validate_input(self, book):\n        if not isinstance(book, str):\n            raise ValueError(\"Invalid input. Book title must be a string.\")\n\n    def add_book(self, book):\n        self._validate_input(book)\n        self._books.append(book + '_x')\n\n    def remove_book(self, book):\n        self._validate_input(book)\n        self._books.remove(book + '_x')\n```",
        "```python\nfrom pedantic import rename_kwargs, retry\n\nclass Playlist:\n    def __init__(self):\n        self._songs = []\n\n    @retry\n    @rename_kwargs\n    def add_song(self, song_name: str, artist: str, duration: int):\n        \"\"\"\n        Add a song to the playlist.\n\n        :param song_name: str: The name of the song.\n        :param artist: str: The artist of the song.\n        :param duration: int: The duration of the song in seconds.\n        \"\"\"\n        self._songs.append({\"song_name\": song_name, \"artist\": artist, \"duration\": duration})\n\n    @retry\n    @rename_kwargs\n    def remove_song(self, song_name: str, artist: str) -> bool:\n        \"\"\"\n        Remove a song from the playlist.\n\n        :param song_name: str: The name of the song.\n        :param artist: str: The artist of the song.\n        :return: bool: True if the song was found and removed, False otherwise.\n        \"\"\"\n        for song in self._songs:\n            if song[\"song_name\"] == song_name and song[\"artist\"] == artist:\n                self._songs.remove(song)\n                return True\n        return False\n```",
        "```python\nfrom collections import Counter\n\ndef find_majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list): The input array.\n\n    Returns:\n        The majority element, or None if there is no majority element.\n    \"\"\"\n    # Use a counter to count the occurrences of each element\n    element_counts = Counter(arr)\n    \n    # Find the most common element(s)\n    majority_elements = element_counts.most_common(1)\n    \n    # Return the majority element if it exists, otherwise return None\n    return majority_elements[0][0] if majority_elements[0][1] > len(arr) // 2 else None\n```",
        "```python\nfrom statistics import mean\n\ndef calculate_mean(numbers: list[int]) -> int:\n    \"\"\"\n    Computes the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list[int]): A list of integers.\n\n    Returns:\n        int: The mean of the numbers.\n    \"\"\"\n    _sum = 0\n    count = 0\n\n    for num in numbers:\n        _sum += num\n        count += 1\n\n    mean_value = _sum / count\n    return mean_value\n```",
        "```python\nfrom math import gcd\n\ndef find_gcd(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of num1 and num2.\n    \"\"\"\n    return gcd(num1, num2)\n```"
      ]
    }
  ]
}