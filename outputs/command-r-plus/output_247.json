{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string among a list of input strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_i):\n            self.data_i = data_i\n            self.next_i = None\n\n    def __init__(self):\n        self.head_i = None\n\n    def append_node(self, data_i):\n        new_node_i = self.Node(data_i)\n        if not self.head_i:\n            self.head_i = new_node_i\n        else:\n            current_i = self.head_i\n            while current_i.next_i:\n                current_i = current_i.next_i\n            current_i.next_i = new_node_i\n\n    def display(self):\n        current_i = self.head_i\n        while current_i:\n            print(current_i.data_i, end=\" -> \")\n            current_i = current_i.next_i\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class z_LinkedList:\n    def __init__(self):\n        self.head_s = None\n        self.tail_s = None\n\n    def z_add_node(self, value_s):\n        new_node_s = z_Node(value_s)\n        if not self.head_s:\n            self.head_s = new_node_s\n            self.tail_s = new_node_s\n        else:\n            new_node_s.prev_s = self.tail_s\n            self.tail_s.next_s = new_node_s\n            self.tail_s = new_node_s\n\n    def z_remove_node(self, value_s):\n        current_s = self.head_s\n        while current_s:\n            if current_s.value_s == value_s:\n                if current_s.prev_s:\n                    current_s.prev_s.next_s = current_s.next_s\n                else:\n                    self.head_s = current_s.next_s\n\n                if current_s.next_s:\n                    current_s.next_s.prev_s = current_s.prev_s\n                else:\n                    self.tail_s = current_s.prev_s\n\n                return\n\n            current_s = current_s.next_s\n\n    def z_display(self):\n        current_s = self.head_s\n        while current_s:\n            print(current_s.value_s, end=\" -> \")\n            current_s = current_s.next_s\n        print(\"None\")\n\nclass z_Node:\n    def __init__(self, value_s):\n        self.value_s = value_s\n        self.next_s = None\n        self.prev_s = None",
        "def is_valid_sudoku(board_s: list[list[int]]) -> bool:\n    \"\"\"Determines if a given sudoku board is valid.\n\n    :param board_s: The sudoku board to be validated.\n    :type board_s: list[list[int]]\n    :return: True if the board is a valid sudoku, False otherwise.\n    :rtype: bool\n    \"\"\"\n    seen_rows_s = [set() for _ in range(9)]\n    seen_cols_s = [set() for _ in range(9)]\n    seen_boxes_s = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_current_num_s = board_s[z_i][z_j]\n            if z_current_num_s == 0:\n                continue\n            z_box_index_s = (z_i // 3) * 3 + z_j // 3\n\n            if (\n                z_current_num_s in seen_rows_s[z_i]\n                or z_current_num_s in seen_cols_s[z_j]\n                or z_current_num_s in seen_boxes_s[z_box_index_s]\n            ):\n                return False\n\n            seen_rows_s[z_i].add(z_current_num_s)\n            seen_cols_s[z_j].add(z_current_num_s)\n            seen_boxes_s[z_box_index_s].add(z_current_num_s)\n\n    return True"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```",
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n\n    def __init__(self):\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Nearest Neighbors model.\n        :param X_train: Training data.\n        :param y_train: Target values.\n        :return: None\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train do not match\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the target values for the test data.\n        :param X_test: Test data.\n        :return: Predicted target values.\n        \"\"\"\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert X_test.shape[1] == self.X_train.shape[1], \"Number of features in test data does not match training data\"\n\n        # Euclidean distance between two samples\n        def euclidean_distance(sample1, sample2):\n            return np.sqrt(np.sum((sample1 - sample2) ** 2))\n\n        # Predict the target value for a single sample\n        def predict_single(sample):\n            distances = [euclidean_distance(sample, x_train) for x_train in self.X_train]\n            closest_index = np.argmin(distances)\n            return self.y_train[closest_index]\n\n        return [predict_single(sample) for sample in X_test]"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression(KernelRidge):\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        super().__init__(alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0,\n                        kernel_params=kernel_params, fit_intercept=fit_intercept, normalize=normalize,\n                        copy_X=copy_X, verbose=verbose)"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_j):\n            self.data_j = data_j\n            self.next_j = None\n\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        new_node_j = self.Node(data_j)\n        if not self.head_j:\n            self.head_j = new_node_j\n        else:\n            current_j = self.head_j\n            while current_j.next_j:\n                current_j = current_j.next_j\n            current_j.next_j = new_node_j\n\n    def assert_inputs(self, data_j):\n        assert isinstance(data_j, int), \"Only integers are allowed in the linked list.\"\n\n    def display(self):\n        current_j = self.head_j\n        while current_j:\n            print(current_j.data_j, end=\" -> \")\n            current_j = current_j.next_j\n        print(\"None\")",
        "def avg_diag_element_j(matrix_j):\n    assert isinstance(matrix_j, list) and all(isinstance(row, list) for row in matrix_j), \"Input must be a 2D list/matrix.\"\n    assert all(len(row) == len(matrix_j) for row in matrix_j), \"Input matrix must be square.\"\n\n    diag_sum_j = sum(matrix_j[i][i] for i in range(len(matrix_j)))\n    diag_avg_j = diag_sum_j / len(matrix_j)\n\n    return diag_avg_j"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(a_vector1, a_vector2):\n    return sum(x * y for x, y in zip(a_vector1, a_vector2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList_q:\n    @timer_class\n    def __init__(self):\n        self.head_q = None\n\n    def push(self, value_q):\n        node_q = Node_q(value_q)\n        node_q.next_q = self.head_q\n        self.head_q = node_q\n\n    def delete(self, value_q):\n        current_q = self.head_q\n        prev_q = None\n        while current_q is not None:\n            if current_q.value_q == value_q:\n                if prev_q is not None:\n                    prev_q.next_q = current_q.next_q\n                else:\n                    self.head_q = current_q.next_q\n                return\n            prev_q = current_q\n            current_q = current_q.next_q\n\n    def search(self, value_q):\n        current_q = self.head_q\n        while current_q is not None:\n            if current_q.value_q == value_q:\n                return True\n            current_q = current_q.next_q\n        return False\n\n\nclass Node_q:\n    def __init__(self, value_q):\n        self.value_q = value_q\n        self.next_q = None",
        "class QuadraticDiscriminantAnalysis_q:\n    @timer_class\n    def __init__(self, class_cond_prob_q: float, class_prior_prob_q: float, mean_q: List[float], cov_mat_q: np.ndarray):\n        self.class_cond_prob_q_q = class_cond_prob_q\n        self.class_prior_prob_q_q = class_prior_prob_q\n        self.mean_q_q = mean_q\n        self.cov_mat_q_q = cov_mat_q\n\n    @timer_class\n    def fit(self, X_q: np.ndarray, y_q: np.ndarray) -> None:\n        self.classes_q_q = np.unique(y_q)\n        self.class_counts_q_q = {class_: len(np.where(y_q == class_)[0]) for class_ in self.classes_q_q}\n\n        self.class_cond_prob_q_q = {\n            class_: self.class_counts_q_q[class_] / len(y_q) for class_ in self.classes_q_q\n        }\n        self.class_prior_prob_q_q = {\n            class_: self.class_counts_q_q[class_] / len(y_q) for class_ in self.classes_q_q\n        }\n\n        self.mean_q_q = {class_: np.mean(X_q[y_q == class_], axis=0) for class_ in self.classes_q_q}\n        self.cov_mat_q_q = {\n            class_: np.cov(X_q[y_q == class_].T) for class_ in self.classes_q_q\n        }\n\n    @timer_class\n    def predict(self, X_q: np.ndarray) -> np.ndarray:\n        predictions_q_q = np.array([self._predict(x) for x in X_q])\n        return predictions_q_q\n\n    def _predict(self, x_q: np.ndarray) -> int:\n        log_probs_q_q = {\n            class_: self._log_prob(class_, x_q) for class_ in self.classes_q_q\n        }\n        return int(np.argmax(log_probs_q_q))\n\n    def _log_prob(self, class_: int, x_q: np.ndarray) -> float:\n        mean_q_q = self.mean_q_q[class_]\n        cov_mat_q_q = self.cov_mat_q_q[class_]\n        precision_mat_q_q = np.linalg.inv(cov_mat_q_q)\n        log_det_cov_mat_q_q = np.log(np.linalg.det(cov_mat_q_q))\n        inv_cov_mat_x_minus_mean_q_q = np.dot(precision_mat_q_q, x_q - mean_q_q)\n\n        first_term_q_q = -0.5 * np.dot(inv_cov_mat_x_minus_mean_q_q, x_q - mean_q_q)\n        second_term_q_q = -0.5 * log_det_cov_mat_q_q\n        third_term_q_q = 0.5 * len(cov_mat_q_q) * np.log(2 * np.pi)\n        log_prob_q_q = first_term_q_q + second_term_q_q + third_term_q_q\n\n        return log_prob_q_q + np.log(self.class_prior_prob_q_q[class_])"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def chx_sum_of_unique_numbers(numbers_lst_chx):\n    unique_numbers_chx = list(set(numbers_lst_chx))\n    sum_total_chx = sum(unique_numbers_chx)\n    return sum_total_chx",
        "class Linked_List_chx:\n    def __init__(self):\n        self.head_chx = None\n        self.tail_chx = None\n\n    def insert_at_end(self, data_chx):\n        new_node_chx = Node_chx(data_chx)\n        if not self.head_chx:\n            self.head_chx = self.tail_chx = new_node_chx\n        else:\n            self.tail_chchx.next_chx = new_node_chx\n            self.tail_chx = new_node_chx\n\n    def insert_at_beg(self, data_chx):\n        new_node_chx = Node_chx(data_chx)\n        if not self.head_chx:\n            self.head_chx = self.tail_chx = new_node_chx\n        else:\n            new_node_chx.next_chx = self.head_chx\n            self.head_chx = new_node_chx\n\n    def insert_after(self, prev_node_chx, data_chx):\n        if not prev_node_chx:\n            print(\"Previous node cannot be None\")\n            return\n        new_node_chx = Node_chx(data_chx)\n        new_node_chx.next_chx = prev_node_chx.next_chx\n        prev_node_chx.next_chx = new_node_chx\n        if prev_node_chx == self.tail_chx:\n            self.tail_chx = new_node_chx\n\n    def insert_at_pos(self, pos_chx, data_chx):\n        new_node_chx = Node_chx(data_chx)\n        curr_node_chx = self.head_chx\n        if pos_chx == 0:\n            new_node_chx.next_chx = self.head_chx\n            self.head_chx = new_node_chx\n        else:\n            for _ in range(pos_chx - 1):\n                curr_node_chx = curr_node_chx.next_chx\n            new_node_chx.next_chx = curr_node_chx.next_chx\n            curr_node_chx.next_chx = new_node_chx\n        if pos_chx == self.length() + 1:\n            self.tail_chx = new_node_chx\n\n    def delete_node(self, key_chx):\n        curr_node_chx = self.head_chx\n        if curr_node_chx.data_chx == key_chx:\n            self.head_chx = curr_node_chx.next_chx\n            return\n        prev_node_chx = None\n        while curr_node_chx and curr_node_chx.data_chx != key_chx:\n            prev_node_chx = curr_node_chx\n            curr_node_chx = curr_node_chx.next_chx\n        if curr_node_chx is None:\n            return\n        prev_node_chx.next_chx = curr_node_chx.next_chx\n        if curr_node_chx == self.tail_chx:\n            self.tail_chx = prev_node_chx\n\n    def display(self):\n        curr_node_chx = self.head_chx\n        while curr_node_chx:\n            print(curr_node_chx.data_chx, end=\" -> \")\n            curr_node_chx = curr_node_chx.next_chx\n        print(\"None\")\n\n    def length(self):\n        curr_node_chx = self.head_chx\n        count_chx = 0\n        while curr_node_chx:\n            count_chx += 1\n            curr_node_chx = curr_node_chx.next_chx\n        return count_chx\n\nclass Node_chx:\n    def __init__(self, data_chx):\n        self.data_chx = data_chx\n        self.next_chx = None"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(s: str) -> bool:\n    s_reversed = s[::-1]\n    return s == s_reversed + '_wr'",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value_wr: int) -> None:\n        self.root = self._insert_recursive(self.root, value_wr)\n\n    def _insert_recursive(self, node: 'Node', value_wr: int) -> 'Node':\n        if node is None:\n            return Node(value_wr)\n\n        if value_wr < node.value_wr:\n            node.left_wr = self._insert_recursive(node.left_wr, value_wr)\n        elif value_wr > node.value_wr:\n            node.right_wr = self._insert_recursive(node.right_wr, value_wr)\n\n        return node\n\n    def delete(self, value_wr: int) -> None:\n        self.root = self._delete_recursive(self.root, value_wr)\n\n    def _delete_recursive(self, node: 'Node', value_wr: int) -> 'Node':\n        if node is None:\n            return node\n\n        if value_wr < node.value_wr:\n            node.left_wr = self._delete_recursive(node.left_wr, value_wr)\n        elif value_wr > node.value_wr:\n            nodenode.right_wr = self._delete_recursive(node.right_wr, value_wr)\n        else:\n            if node.left_wr is None:\n                return node.right_wr\n            elif node.right_wr is None:\n                return node.left_wr\n\n            min_value_node = self._find_min_value_node(node.right_wr)\n            node.value_wr = min_value_node.value_wr\n            node.right_wr = self._delete_recursive(node.right_wr, min_value_node.value_wr)\n\n        return node\n\n    def _find_min_value_node(self, node: 'Node') -> 'Node':\n        while node.left_wr is not None:\n            node = node.left_wr\n        return node\n\nclass Node:\n    def __init__(self, value_wr: int):\n        self.value_wr = value_wr\n        self.left_wr = None\n        self.right_wr = None"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    \"\"\"\n    Perceptron Class\n    \"\"\"\n\n    def __init__(self, learning_rate: float = 0.1, epochs: int = 1000) -> None:\n        \"\"\"\n        Initializes the Perceptron.\n\n        Parameters:\n            learning_rate (float): The learning rate for training.\n            epochs (int): The number of epochs to train.\n        \"\"\"\n        self.chx_learning_rate = learning_rate\n        self.chx_epochs = epochs\n        self.chx_weights = None\n        self.chx_bias = None\n\n    def train(self, X: list[list[float]], y: list[float]) -> None:\n        \"\"\"\n        Trains the Perceptron.\n\n        Parameters:\n            X (list of list of float): The input training data.\n            y (list of float): The corresponding output labels.\n        \"\"\"\n        self.chx_weights = [0] * len(X[0])\n        self.chx_bias = 0\n\n        for _ in range(self.chx_epochs):\n            for i, x in enumerate(X):\n                prediction = self._predict(x)\n                update = learning_rate * (y[i] - prediction)\n                self.chx_weights = [w + x * update for w, x in zip(self.chx_weights, x)]\n                self.chx_bias += update\n\n    def predict(self, X: list[list[float]]) -> list[float]:\n        \"\"\"\n        Predicts the output for the given input data.\n\n        Parameters:\n            X (list of list of float): The input data.\n\n        Returns:\n            list of float: Predicted output labels.\n        \"\"\"\n        return [self._predict(x) for x in X]\n\n    def _predict(self, x: list[float]) -> float:\n        \"\"\"\n        Internal prediction function.\n\n        Parameters:\n            x (list of float): A single input data point.\n\n        Returns:\n            float: Predicted output.\n        \"\"\"\n        return 1 if sum(w * xi for w, xi in zip(self.chx_weights, x)) + self.chx_bias > 0 else 0",
        "```python\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the k-th largest element from the input list of integers.\n    \n    :param arr: A list of integers\n    :param k: An integer, k\n    :return: The k-th largest element in the list\n    \"\"\"\n    # Sort the list in descending order to easily access the k-th largest element\n    sorted_arr = sorted(arr, reverse=True)\n    \n    # Return the k-th element from the sorted list\n    return sorted_arr[k - 1]\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_xt, next_node_xt=None):\n            self.data_xt = data_xt\n            self.next_node_xt = next_node_xt\n\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data_xt):\n        new_node_xt = self.Node(data_xt)\n        if not self.head_xt:\n            self.head_xt = new_node_xt\n        else:\n            current_xt = self.head_xt\n            while current_xt.next_node_xt:\n                current_xt = current_xt.next_node_xt\n            current_xt.next_node_xt = new_node_xt\n\n    def display(self):\n        current_xt = self.head_xt\n        while current_xt:\n            print(current_xt.data_xt, end=\" -> \")\n            current_xt = current_xt.next_node_xt\n        print(\"None\")\n\n    def length(self):\n        current_xt = self.head_xt\n        count_xt = 0\n        while current_xt:\n            count_xt += 1\n            current_xt = current_xt.next_node_xt\n        return count_xt\n\n    def insert_at_beginning(self, data_xt):\n        new_node_xt = self.Node(data_xt, self.head_xt)\n        self.head_xt = new_node_xt\n\n    def delete_node(self, key_xt):\n        if self.head_xt is None:\n            return\n\n        if self.head_xt.data_xt == key_xt:\n            self.head_xt = self.head_xt.next_node_xt\n            return\n\n        prev_xt = self.head_xt\n        curr_xt = self.head_xt.next_node_xt\n\n        while curr_xt and curr_xt.data_xt != key_xt:\n            prev_xt = curr_xt\n            curr_xt = curr_xt.next_node_xt\n\n        if curr_xt is None:\n            return\n\n        prev_xt.next_node_xt = curr_xt.next_node_xt\n\n    def reverse(self):\n        prev_xt = None\n        current_xt = self.head_xt\n        while current_xt is not None:\n            next_node_xt = current_xt.next_node_xt\n            current_xt.next_node_xt = prev_xt\n            prev_xt = current_xt\n            current_xt = next_node_xt\n        self.head_xt = prev_xt",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if node is None:\n            return True\n        if not node._val_xt >= min_val and node._val_xt <= max_val:\n            return False\n        return helper(node._left_xt, min_val, node._val_xt - 1) and helper(node._right_xt, node._val_xt + 1, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero7(matrix):\n    non_zero_count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                non_zero_count += 1\n    return non_zero_count"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1, vec2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :type vec1: list or tuple\n    :param vec2: The second vector.\n    :type vec2: list or tuple\n    :return: The dot product of vec1 and vec2.\n    :rtype: float\n    \"\"\"\n    i_vec1 = vec1\n    i_vec2 = vec2\n    return sum(x * y for x, y in zip(i_vec1, i_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    Manage inventory stock levels.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, product: str, quantity: int):\n        \"\"\"\n        Add stock for a product.\n\n        :param product: The name of the product.\n        :param quantity: The number of items to add.\n        \"\"\"\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def md_remove_stock(self, product: str, quantity: int):\n        \"\"\"\n        Remove stock for a product.\n\n        :param product: The name of the product.\n        :param quantity: The number of items to remove.\n        :raise ValueError: If there is insufficient stock.\n        \"\"\"\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            raise ValueError(f\"Insufficient stock for {product}.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef greatest_common_divisor(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Parameters:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b:\n        a, b = b, a % b\n    return a"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def check_valid_sudoku(board: list[list[int]]) -> bool:\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num in row or current_num in col or current_num in box:\n                return False\n            row.add(current_num)\n            col.add(current_num)\n            if (i // 3) * 3 + j // 3 not in box:\n                box.add(current_num)\n        row.clear()\n        col.clear()\n        box.clear()\n    \n    for j in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for i in range(9):\n            current_num = board[i][j]\n            if current_num in row or current_num in col or current_num in box:\n                return False\n            row.add(current_num)\n            col.add(current_num)\n            if i // 3 not in box:\n                box.add(current_num)\n        row.clear()\n        col.clear()\n        box.clear()\n    \n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    current_num = board[x][y]\n                    if current_num in box:\n                        return False\n                    box.add(current_num)\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def mean_calculator_1d(data):\n    sum_ = sum(data)\n    return sum_ / len(data)",
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_d(left_half)\n    right_half = merge_sort_d(right_half)\n    \n    return merge_d(left_half, right_half)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2",
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "cumulative_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or strs[0][i] != other[i]:\n                return strs[0][:i]\n\n    return strs[0]\n```",
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure with methods to insert and delete nodes.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if node is None:\n            return Node(value)\n\n        if value < node.value:\n            node.left = self._insert_recursive(value, node.left)\n        else:\n            node.right = self._insert_recursive(value, node.right)\n\n        return node\n\n    def delete(self, value):\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value, node):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete_recursive(node.value, node.right)\n\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n# Add decorator for debugging and performance analysis\n@trace_class\nclass Node:\n    \"\"\"\n    A node in the binary tree with a value and left and right child nodes.\n    \"\"\"\n\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The input string to be checked.\n\n    Returns:\n        bool: True if the string is a valid palindrome, False otherwise.\n    \"\"\"\n    # Initialize variables\n    i = 0\n    j = len(s) - 1\n    chx_wr = \"\"\n\n    # Validate input\n    if not isinstance(s, str):\n        raise TypeError(\"Input must be a string\")\n    if any(ch.isspace() for ch in s):\n        raise ValueError(\"Input string must not contain spaces\")\n\n    # Check for palindrome\n    while i < j:\n        if s[i] != s[j]:\n            return False\n        i += 1\n        j -= 1\n\n    return True\n```",
        "def sum_unique_numbers(numbers: list[int]) -> int:\n    \"\"\"\n    Computes the sum of unique numbers in the given list.\n\n    Args:\n        numbers (list[int]): A list of integers.\n\n    Returns:\n        int: The sum of unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.base import BaseEstimator\n\nclass NearestNeighborsModel(BaseEstimator):\n    \"\"\"\n    Nearest Neighbors Model Class\n\n    Attributes\n    ----------\n    _i_: int\n        Number of neighbors to use.\n\n    Methods\n    -------\n    train(X: array-like, y: array-like)\n        Fit the model using X as training data and y as target values.\n\n    predict(X: array-like)\n        Predict the class labels for the provided data.\n    \"\"\"\n\n    def __init__(self, n_neighbors: int = 5):\n        \"\"\"\n        Initialize the NearestNeighborsModel class\n\n        Parameters\n        ----------\n        n_neighbors : int, default=5\n            Number of neighbors to use.\n        \"\"\"\n        self._i_ = n_neighbors\n\n    def train(self, X: array, y: array) -> None:\n        \"\"\"\n        Fit the model using X as training data and y as target values.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n\n        y : array-like\n            Target values.\n        \"\"\"\n        self.clf = KNeighborsClassifier(n_neighbors=self._i_)\n        self.clf.fit(X, y)\n\n    def predict(self, X: array) -> array:\n        \"\"\"\n        Predict the class labels for the provided data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data for which predictions are to be made.\n\n        Returns\n        -------\n        array\n            Predicted class labels.\n        \"\"\"\n        return self.clf.predict(X)\n```",
        "```python\n# Quadratic Discriminant Analysis Class\n\nfrom pedantic import rename_kwargs, trace_class\n\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multiclass classification.\n    \"\"\"\n    @rename_kwargs\n    def __init__(self, a_tol: float = 1e-05, a_store_covariance: bool = False) -> None:\n        \"\"\"\n        Initialize the QuadraticDiscriminantAnalysis classifier.\n\n        Parameters\n        ----------\n        a_tol : float, optional\n            Tolerance for convergence. Defaults to 1e-05.\n        a_store_covariance : bool, optional\n            Whether to store the covariance matrices for each class. Defaults to False.\n        \"\"\"\n        self.a_tol = a_tol\n        self.a_store_covariance = a_store_covariance\n        self.classes_ = []\n        self.covariances_ = []\n        self.means_ = []\n        self.priors_ = []\n        self.X_ = []\n        self.y_ = []\n        self.z_ = []\n\n    @trace_class\n    def fit(self, X_wr: np.array([]), y_xt: np.array([])) -> \"QuadraticDiscriminantAnalysis\":\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Parameters\n        ----------\n        X_wr : np.array\n            Training vector, where n_samples is the number of samples and n_features is the\n            number of features.\n        y_xt : np.array\n            Target vector relative to X_wr.\n\n        Returns\n        -------\n        QuadraticDiscriminantAnalysis\n            Fitted instance of self.\n        \"\"\"\n        # Check input data\n        y_xt = self._check_X_y(X_wr, y_xt)\n\n        # Store the classes\n        self.classes_ = np.unique(y_xt)\n        n_classes = self.classes_.shape[0]\n\n        # Calculate priors\n        self.priors_ = np.zeros(n_classes)\n        for i in range(n_classes):\n            self.priors_[i] = np.sum(y_xt == self.classes_[i]) / y_xt.shape[0]\n\n        # Calculate means\n        self.means_ = np.zeros((n_classes, X_wr.shape[1]))\n        for i in range(n_classes):\n            self.means_[i] = np.mean(X_wr[y_xt == self.classes_[i]], axis=0)\n\n        # Calculate covariance matrices\n        if self.a_store_covariance:\n            self.covariances_ = np.zeros((n_classes, X_wr.shape[1], X_wr.shape[1]))\n            for i in range(n_classes):\n                self.covariances_[i] = np.cov(X_wr[y_xt == self.classes_[i]].T)\n\n        # Calculate within-class scatter matrix\n        self.X_ = np.zeros((n_classes, X_wr.shape[1], X_wr.shape[1]))\n        for i in range(n_classes):\n            self.X_[i] = np.cov(X_wr[y_xt == self.classes_[i]].T)\n\n        # Calculate between-class scatter matrix\n        self.y_ = np.cov(self.means_.T)\n\n        # Invert covariance matrices\n        self.z_ = np.array([np.linalg.inv(self.X_[i]) for i in range(n_classes)])\n\n        return self\n\n    def predict(self, X: np.array([])) -> np.array([]):\n        \"\"\"\n        Predict the class labels for the provided data.\n\n        Parameters\n        ----------\n        X : np.array\n            Samples.\n\n        Returns\n        -------\n        np.array\n            Predicted class label per sample.\n        \"\"\"\n        # Check input data\n        X = check_array(X)\n\n        # Predict class labels\n        predicted_labels = np.zeros(X.shape[0], dtype=int)\n        for i in range(X.shape[0]):\n            # Calculate posterior probabilities\n            posteriors = self._get_posterior_probabilities(X[i])\n\n            # Predict class label\n            predicted_labels[i] = self.classes_[np.argmax(posteriors)]\n\n        return self.classes_[predicted_labels]\n\n    def _get_posterior_probabilities(self, X: np.array([])) -> np.array([]):\n        \"\"\"\n        Calculate the posterior probabilities for each class.\n\n        Parameters\n        ----------\n        X : np.array\n            Samples.\n\n        Returns\n        -------\n        np.array\n            Posterior probabilities for each class.\n        \"\"\"\n        # Calculate within-class term\n        within_class_term = np.zeros(self.classes_.shape[0])\n        for i in range(self.classes_.shape[0]):\n            diff = X - self.means_[i]\n            within_class_term[i] = np.log(\n                np.sqrt(np.diag(np.dot(np.dot(diff, self.z_[i]), diff.T)))\n            )\n\n        # Calculate between-class term\n        between_class_term = np.log(self.priors_) - 0.5 * np.log(\n            np.diag(np.dot(np.dot(self.z_, self.y_), self.z_.T))\n        )\n\n        # Calculate prior term\n        prior_term = np.log(self.priors_)\n\n        # Calculate posterior probabilities\n        posteriors = within_class_term + between_class_term + prior_term\n\n        return posteriors\n```",
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1, kernel_params=None):\n        \"\"\"\n        :param alpha: float\n            Regularization strength; must be a positive float. Regularization improves the\n            conditioning of the problem and reduces the variance of the estimates. Larger\n            values specify stronger regularization. Alpha corresponds to ``1 / (2C)`` in other linear\n            models such as LogisticRegression or LinearSVC. If an array is passed,\n            ``alpha`` is used to compute the regularization strength ``alpha_i`` for the i-th\n            class.\n\n        :param kernel: string, callable or None (default=\"linear\")\n            Kernel mapping used internally. Passes unchanged to\n            :class:`sklearn.kernel_ridge.KernelRidge`.\n\n            If None is passed, ``kernel`` is set to a linear kernel.\n\n        :param gamma: float, default=None\n            Gamma parameter for the kernel. Passes unchanged to\n            :class:`sklearn.kernel_ridge.KernelRidge`.\n\n        :param degree: int, default=3\n            Degree of the polynomial kernel. Ignored by other kernels.\n\n        :param coef0: float, default=1\n            Independent term in kernel function. Only significant in\n            ``poly`` and ``sigmoid``.\n\n        :param kernel_params: dict of string -> any, default=None\n            Parameters (keyword arguments) and values for kernel passed as callable\n            object.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y):\n        \"\"\"Fit Kernel Ridge model\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data\n\n        :param y: array-like, shape (n_samples,) or (n_samples, n_targets)\n            Target values\n        \"\"\"\n        self.model_ = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.model_.fit(X, y)\n\n    def predict(self, X):\n        \"\"\"Predict using the kernel ridge model\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples\n\n        :return: array, shape (n_samples,) or (n_samples, n_targets)\n        \"\"\"\n        return self.model_.predict(X)\n```",
        "```python\ndef mean(data: list[float]) -> float:\n    \"\"\"\n    Computes the mean of a list of numerical data.\n\n    Args:\n        data (list[float]): A list of numerical data points.\n\n    Returns:\n        float: The mean of the data points.\n    \"\"\"\n    # Initialize variables for the online algorithm\n    n = 0\n    mean_ = 0.0\n\n    # Iterate through the data points\n    for x in data:\n        # Update the variables\n        n += 1\n        mean_ += (x - mean_) / n\n\n    # Return the computed mean\n    return mean_\n```",
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    seen = set()\n    for row in board:\n        if not is_valid(row, seen):\n            return False\n        seen.clear()\n\n    for col in zip(*board):\n        if not is_valid(col, seen):\n            return False\n        seen.clear()\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[r][c] for r in range(i, i + 3) for c in range(j, j + 3)]\n            if not is_valid(box, seen):\n                return False\n            seen.clear()\n\n    return True\n\ndef is_valid(group: list[str], seen: set[str]) -> bool:\n    for num in group:\n        if num != \".\" and num in seen:\n            return False\n        if num != \".\":\n            seen.add(num)\n    return True\n```",
        "```python\nclass LinkedList:\n    \"\"\"\n    A linked list data structure.\n    \"\"\"\n    def __init__(self):\n        self._head = None\n        self._tail = None\n\n    def add_node(self, value):\n        \"\"\"\n        Adds a new node with the given value to the end of the linked list.\n        \"\"\"\n        node = Node(value)\n        if not self._head:\n            self._head = node\n            self._tail = node\n        else:\n            self._tail.next = node\n            self._tail = node\n\n    def remove_node(self, value):\n        \"\"\"\n        Removes the first node with the given value from the linked list.\n        \"\"\"\n        current = self._head\n        prev = None\n        while current and current.value != value:\n            prev = current\n            current = current.next\n\n        if current is None:\n            raise ValueError(\"Value not found in the linked list.\")\n\n        if prev:\n            prev.next = current.next\n        else:\n            self._head = current.next\n\n        if current is self._tail:\n            self._tail = prev\n\n    def search_node(self, value):\n        \"\"\"\n        Searches for a node with the given value in the linked list.\n        \"\"\"\n        current = self._head\n        while current and current.value != value:\n            current = current.next\n\n        return current\n\n    def display(self):\n        \"\"\"\n        Displays the values in the linked list, starting from the head.\n        \"\"\"\n        current = self._head\n        while current:\n            print(current.value, end=\" \")\n            current = current.next\n\nclass Node:\n    \"\"\"\n    A node in the linked list.\n    \"\"\"\n    def __init__(self, value):\n        self.value = value\n        self.next = None\n```",
        "```python\ndef kth_largest_element(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the kth largest element in the input array.\n\n    Args:\n        arr (list[int]): The input array of integers.\n        k (int): The value of 'k' to find the kth largest element.\n\n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the element at index 'k - 1'\n    return arr[k - 1]\n```",
        "```python\ndef dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list representing the first vector.\n        vector_b (list[int]): A list representing the second vector.\n\n    Returns:\n        int: The dot product of vector_a and vector_b.\n    \"\"\"\n    # Validate input lengths\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length\")\n\n    # Calculate the dot product\n    dot_product_result = 0\n    for i in range(len(vector_a)):\n        dot_product_result += vector_a[i] * vector_b[i]\n\n    return dot_product_result\n```",
        "```python\ndef greatest_common_divisor(a_1: int, a_2: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Args:\n        a_1 (int): The first integer.\n        a_2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    assert isinstance(a_1, int) and isinstance(a_2, int), \"Inputs must be integers.\"\n    while a_2:\n        a_1, a_2 = a_2, a_1 % a_2\n    return a_1\n```",
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.1, epochs: int = 10000) -> None:\n        \"\"\"\n        Initialize the perceptron\n\n        Parameters:\n        eta (float): Learning rate (between 0.0 and 1.0)\n        epochs (int): Maximum iterations/epochs\n\n        Returns:\n        None\n        \"\"\"\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.bias = None\n\n    def train(self, X: list, y: list) -> Perceptron:\n        \"\"\"\n        Train the perceptron\n\n        Parameters:\n        X (list): Input training data\n        y (list): Output training labels\n\n        Returns:\n        Perceptron: Trained instance of Perceptron\n        \"\"\"\n        self.weights = [0] * len(X[0])\n        self.bias = 0\n\n        for _ in range(self.epochs):\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self._net_input(xi))\n                self.weights = [w + update * x for w, x in zip(self.weights, xi)]\n                self.bias += update\n\n        return self\n\n    def _net_input(self, X: list) -> float:\n        \"\"\"\n        Compute the net input\n\n        Parameters:\n        X (list): Input data\n\n        Returns:\n        float: Net input\n        \"\"\"\n        return sum(x * w for x, w in zip(X, self.weights)) + self.bias\n\n    def predict(self, X: list) -> list:\n        \"\"\"\n        Predict the output for the given input data\n\n        Parameters:\n        X (list): Input data\n\n        Returns:\n        list: Predicted output labels\n        \"\"\"\n        predictions = []\n        for xi in X:\n            net_input = self._net_input(xi)\n            prediction = 1 if net_input >= 1 else 0\n            predictions.append(prediction)\n\n        return predictions\n```",
        "```python\ndef average_diagonal_element(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): A square matrix containing integer elements.\n\n    Returns:\n        float: The average of the diagonal elements of the matrix.\n\n    \"\"\"\n    # Validate input\n    if not matrix or not all(len(row) == len(matrix) for row in matrix):\n        raise ValueError(\"Input matrix must be a non-empty square matrix\")\n\n    # Calculate sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate average\n    diagonal_average = diagonal_sum / len(matrix)\n\n    return diagonal_average\n```",
        "```python\nclass Inventory:\n    \"\"\"\n    Represents an inventory with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self._stock = []\n\n    def add_stock(self, item: str) -> None:\n        \"\"\"\n        Adds a new item to the inventory stock.\n\n        Args:\n            item (str): The name of the item to be added.\n        \"\"\"\n        self._stock.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        \"\"\"\n        Removes an item from the inventory stock.\n\n        Args:\n            item (str): The name of the item to be removed.\n        \"\"\"\n        self._stock.remove(item)\n```",
        "```python\ndef is_valid_bst(root: TreeNode) -> bool:\n    def helper(node: TreeNode, min_val: int, max_val: int) -> bool:\n        if not node:\n            return True\n        if not (min_val < node.val < max_val):\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root, float(\"-inf\"), float(\"inf\"))\n```",
        "```python\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    \"\"\"\n    Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "```python\ndef merge_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the merge sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Base case: if the list has 0 or 1 elements, it is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the list into two halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    # Merge the sorted halves\n    merged = []\n    left_idx, right_idx = 0, 0\n    while left_idx < len(left_half) and right_idx < len(right_half):\n        if left_half[left_idx] < right_half[right_idx]:\n            merged.append(left_half[left_idx])\n            left_idx += 1\n        else:\n            merged.append(right_half[right_idx])\n            right_idx += 1\n\n    # Add any remaining elements from each half\n    merged.extend(left_half[left_idx:])\n    merged.extend(right_half[right_idx:])\n\n    return merged\n```"
      ]
    }
  ]
}