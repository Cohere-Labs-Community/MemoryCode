{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def compute_diagonal_average_chx(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix)\n    assert all(len(row) == len(matrix) for row in matrix)\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    diagonal_count = len(matrix)\n    average = diagonal_sum / diagonal_count if diagonal_count != 0 else 0\n\n    return average",
        "class Heap:\n    def insert_chx(self, val):\n        assert isinstance(val, (int, float))\n        self._heap.append(val)\n        self._heapify_chx()\n\n    def _heapify_chx(self):\n        assert isinstance(self._heap, list)\n        i = len(self._heap) - 1\n        while i > 0:\n            parent = (i - 1) // 2\n            if self._heap[i] > self._heap[parent]:\n                self._heap[i], self._heap[parent] = self._heap[parent], self._heap[i]\n                i = parent\n            else:\n                break"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        \"\"\"\n        Add stock to the inventory.\n        \"\"\"\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        \"\"\"\n        Remove stock from the inventory.\n        \"\"\"\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def integer_to_roman(num):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n    :param num: The integer to be converted.\n    :return: The corresponding Roman numeral.\n    \"\"\"\n    # Initialize an empty string to store the Roman numeral\n    roman = \"\"\n    \n    # Define a dictionary with Roman numeral values\n    values = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\", 50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    \n    # Iterate through the dictionary keys in descending order\n    for i in sorted(values.keys(), reverse=True):\n        # Append the Roman numeral value while it divides the number\n        while i <= num:\n            roman += values[i]\n            num -= i\n        \n    # Return the Roman numeral\n    return roman\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "\"\"\"\nReturns the longest common prefix string in a list of strings.\n\n:param strings: A list of strings.\n:type strings: list\n:return: The longest common prefix string.\n:rtype: str\n\"\"\"\ndef find_longest_common_prefix(strings: list) -> str:\n    \"\"\"\n    Find the longest common prefix in a list of strings.\n    \n    :param strings: A list of input strings.\n    :type strings: list[str]\n    :return: The longest common prefix.\n    :rtype: str\n    \"\"\"\n    if not strings:\n        raise ValueError(\"Input list must not be empty\")\n    \n    for i, char in enumerate(strings[0]):\n        for other in strings[1:]:\n            if i == len(other) or other[i] != char:\n                return strings[0][:i]\n    return strings[0]\n\n\nclass StringAnalyzer7:\n    \"\"\"\n    A class to analyze and manipulate strings, following the single-digit naming convention.\n    \n    ...\n    \n    Attributes\n    ----------\n    input_strings : list\n        A list of input strings to be analyzed or manipulated.\n    \n    Methods\n    -------\n    find_longest_common_suffix(strings)\n        Find the longest common suffix in a list of input strings.\n    \"\"\"\n\n    def __init__(self, input_strings: list):\n        \"\"\"\n        Initialize the StringAnalyzer7 class with a list of input strings.\n        \n        :param input_strings: A list of strings to be analyzed or manipulated.\n        :type input_strings: list[str]\n        \"\"\"\n        self.input_strings = input_strings\n\n    def find_longest_common_suffix(self, strings: list) -> str:\n        \"\"\"\n        Find the longest common suffix in a list of input strings.\n        \n        :param strings: A list of strings to find the common suffix for.\n        :type strings: list[str]\n        :return: The longest common suffix.\n        :rtype: str\n        \"\"\"\n        reversed_strings = [s[::-1] for s in strings]\n        return find_longest_common_prefix(reversed_strings)[::-1]",
        "class PCA0:\n    \"\"\"\n    Principal Component Analysis (PCA) is a dimensionality-reduction technique.\n    It is used to decompose a multivariate dataset into a set of orthogonal\n    components that capture the maximum amount of variance.\n    \"\"\"\n    def __init__(self, n_components=None):\n        \"\"\"\n        Initialize the PCA model.\n\n        Parameters:\n            n_components (int or None): The number of principal components to keep.\n                If None, all components are kept.\n        \"\"\"\n        self.n_components = n_components\n\n    def fit(self, X):\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            self: Fitted PCA model.\n        \"\"\"\n        # Implement the fitting procedure here\n        # For example, calculate the covariance matrix, perform eigenvalue decomposition, etc.\n        pass\n\n    def transform(self, X):\n        \"\"\"\n        Transform the data using the fitted PCA model.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Transformed data with reduced dimensions.\n        \"\"\"\n        # Implement the data transformation using the fitted model\n        # Apply the projection onto the principal components\n        pass\n\n    def fit_transform(self, X):\n        \"\"\"\n        Fit the PCA model to the data and transform it in one step.\n\n        Parameters:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Transformed data with reduced dimensions.\n        \"\"\"\n        # Fit the model and transform the data\n        pass\n\n    def inverse_transform(self, X):\n        \"\"\"\n        Inverse transform the data back to the original space.\n\n        Parameters:\n            X (ndarray): The transformed data of shape (n_samples, n_reduced_features).\n\n        Returns:\n            ndarray: Original data with the original number of features.\n        \"\"\"\n        # Implement the inverse transformation to map the data back to the original feature space\n        pass\n\n    def get_explained_variance(self):\n        \"\"\"\n        Get the explained variance of each principal component.\n\n        Returns:\n            ndarray: Explained variance of each component.\n        \"\"\"\n        # Return the explained variance of the selected components\n        pass\n\n    def get_component_vectors(self):\n        \"\"\"\n        Get the component vectors (eigenvectors) of the fitted PCA model.\n\n        Returns:\n            ndarray: Component vectors of shape (n_features, n_components).\n        \"\"\"\n        # Return the eigenvectors corresponding to the selected principal components\n        pass"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def n_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def n_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] > quantity:\n            self.stock[item] -= quantity\n        elif item in self.stock and self.stock[item] == quantity:\n            del self.stock[item]\n        else:\n            print(\"Insufficient stock to fulfill the request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        \"\"\"\n        Add stock for a specific item.\n        \"\"\"\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        \"\"\"\n        Remove stock for a specific item.\n        \"\"\"\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def a_insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n        :param value: The value to be inserted.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def a_delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n        :param value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(value, self.root)\n\n    def _delete_recursive(self, value, node):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete_recursive(value, node.left)\n        elif value > node.value:\n            node.right = self._delete_recursive(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                min_value = self._find_min(node.right)\n                node.value = min_value\n                node.right = self._delete_recursive(min_value, node.right)\n        return node\n\n    def _find_min(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None",
        "class Inventory:\n    \"\"\"\n    A class to manage inventory stock.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = []\n\n    def a_add_stock(self, item):\n        \"\"\"\n        Add an item to the inventory stock.\n\n        :param item: The item to be added.\n        \"\"\"\n        self.stock.append(item)\n\n    def a_remove_stock(self, item):\n        \"\"\"\n        Remove an item from the inventory stock.\n\n        :param item: The item to be removed.\n        :return: True if the item was found and removed, False otherwise.\n        \"\"\"\n        if item in self.stock:\n            self.stock.remove(item)\n            return True\n        return False"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "@timer_class\ndef count_non_zero7(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "from sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.linear_model import LogisticRegression\nfrom pedantic import timer_class\n\n@timer_class\nclass QDA1(BaseEstimator, ClassifierMixin):\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier with a single-digit function naming convention and the '@timer_class' decorator.\n    \"\"\"\n\n    def __init__(self):\n        self._classes = []\n        self._means = []\n        self._covariance_matrices = []\n        self._class_priors = []\n        self._logistic = LogisticRegression()\n\n    def fit(self, X, y):\n        # Validate input data\n        X, y = check_X_y(X, y)\n\n        # Store unique classes\n        self._classes = sorted(set(y))\n\n        # Calculate class priors\n        self._class_priors = [\n            (y == class_).mean() for class_ in self._classes\n        ]\n\n        # Calculate class means\n        self._means = [X[y == class_].mean(axis=0) for class_ in self._classes]\n\n        # Calculate pooled covariance matrix\n        cov_ = EmpiricalCovariance().fit(X).covariance_\n\n        # Calculate covariance matrices for each class\n        self._covariance_matrices = [\n            EmpiricalCovariance(store_precision=True).fit(\n                X[y == class_], assume_centered=True\n            ).covariance_\n            for class_ in self._classes\n        ]\n\n        # Fit logistic regression model\n        self._logistic.fit(X, y)\n\n        return self\n\n    def predict(self, X):\n        # Validate input data\n        X = check_array(X)\n\n        # Check if the model is fitted\n        check_is_fitted(self, [\"_classes\", \"_means\"])\n\n        # Predict class labels\n        labels = self._logistic.predict(X)\n        X_transformed = [self._transform(x, label) for x, label in zip(X, labels)]\n        return labels\n\n    def predict_proba(self, X):\n        # Validate input data\n        X = check_array(X)\n\n        # Check if the model is fitted\n        check_is_fitted(self, [\"_classes\", \"_means\", \"_covariance_matrices\", \"_class_priors\"])\n\n        # Predict class probabilities\n        probas = []\n        for x in X:\n            class_probs = []\n            for i, class_ in enumerate(self._classes):\n                prior = self._class_priors[i]\n                mean = self._means[i]\n                cov_matrix = self._covariance_matrices[i]\n                class_probs.append(prior * self._gaussian_pdf(x, mean, cov_matrix))\n            probas.append(class_probs / sum(class_probs))\n        return probas\n\n    def _transform(self, x, label):\n        mean = self._means[label]\n        cov_matrix = self._covariance_matrices[label]\n        inv_cov_matrix = np.linalg.inv(cov_matrix)\n        return (x - mean).T @ inv_cov_matrix @ (x - mean)\n\n    def _gaussian_pdf(self, x, mean, cov_matrix):\n        det_cov = np.linalg.det(cov_matrix)\n        inv_cov_matrix = np.linalg.inv(cov_matrix)\n        x_centered = x - mean\n        return np.exp(-0.5 * x_centered.T @ inv_cov_matrix @ x_centered) / (2 * np.pi * det_cov) ** 0.5"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def b_insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def b_delete(self, value):\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def b_add_stock(self, item: str, quantity: int) -> None:\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def b_remove_stock(self, item: str, quantity: int) -> None:\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock to remove\")"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def o_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def o_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def x_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n        assert item in self.stock, \"Item not added correctly\"\n\n    def x_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the specified quantity.\")\n        assert item in self.stock or quantity == 0, \"Item removal failed\"",
        "class NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model class for training and prediction.\n    \"\"\"\n\n    def x_train(self, data, labels):\n        \"\"\"\n        Trains the Nearest Neighbors model.\n\n        :param data: The training data.\n        :param labels: The corresponding labels for the training data.\n        :return: None\n        \"\"\"\n        # Your training logic here\n        # ...\n\n        # Example assert statement\n        assert self.model is not None, \"Model is not trained properly.\"\n\n    def x_predict(self, data):\n        \"\"\"\n        Predicts the labels for the given data using the trained model.\n\n        :param data: The data for which predictions are to be made.\n        :return: Predicted labels.\n        \"\"\"\n        # Your prediction logic here\n        # ...\n\n        # Example assert statement\n        assert self.model is not None, \"Model is not trained. Call the train method first.\"\n\n        return predicted_labels"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(v1, v2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param v1: The first vector.\n    :param v2: The second vector.\n    :return: The dot product of v1 and v2.\n    \"\"\"\n    g_v1 = v1\n    g_v2 = v2\n    return sum(x * y for x, y in zip(g_v1, g_v2))",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def p_add_stock(self, g_product, g_quantity):\n        if g_product in self.stock:\n            self.stock[g_product] += g_quantity\n        else:\n            self.stock[g_product] = g_quantity\n\n    def p_remove_stock(self, g_product, g_quantity):\n        if g_product in self.stock and self.stock[g_product] >= g_quantity:\n            self.stock[g_product] -= g_quantity\n        else:\n            print(\"Insufficient stock for\", g_product)"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_bst_ud(root, min_val=float(\"-inf\"), max_val=float(\"inf\")):\n    if not root:\n        return True\n\n    try:\n        if root.val <= min_val or root.val >= max_val:\n            return False\n\n        return is_valid_bst_ud(root.left, min_val, root.val) and is_valid_bst_ud(root.right, root.val, max_val)\n\n    except AttributeError:\n        print(\"Error: Invalid tree structure.\")\n        return False\n```",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def min_distance(self, dist, sptSet, u):\n        min = 1000000000000000000\n        for v in range(self.V):\n            if dist[v] < min and sptSet[v] == False:\n                min = dist[v]\n                min_index = v\n        return min_index\n\n    def dijkstra(self, src):\n        dist = [1000000000000000000] * self.V\n        dist[src] = 0\n        sptSet = [False] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance(dist, sptSet, _)\n            sptSet[u] = True\n            for v in range(self.V):\n                if (\n                    self.graph[u][v] > 0\n                    and sptSet[v] == False\n                    and dist[v] > dist[u] + self.graph[u][v]\n                ):\n                    dist[v] = dist[u] + self.graph[u][v]\n\n        return dist\n\n    # Method name ends with '_ud' as per Daniel's instruction\n    def shortest_path_ud(self, edge, src):\n        self.graph = [[0 for _ in range(self.V)] for _ in range(self.V)]\n        weight = edge[0]\n        from_node = edge[1]\n        to_node = edge[2]\n        self.graph[from_node][to_node] = weight\n        self.graph[to_node][from_node] = weight\n\n        dist = self.dijkstra(src)\n\n        minimum_distance = []\n        for i in range(self.V):\n            minimum_distance.append(dist[i])\n\n        return minimum_distance\n```"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    # method to add an edge to the graph\n    def add_edge_n(self, u, v, w):\n        self.graph[u][v] = w\n        self.graph[v][u] = w\n\n    # Dijkstra's algorithm to find the shortest path\n    def shortest_path_n(self, src):\n        dist = [float(\"Inf\")] * self.V\n        dist[src] = 0\n        spt = []\n\n        for _ in range(self.V):\n            # Pick the minimum distance vertex from the set Q\n            # of vertices not yet included in the shortest path tree\n            min_dist_vertex = self._find_min_dist_vertex_n(dist, spt)\n\n            # Add the picked vertex to the shortest path tree\n            spt.append(min_dist_vertex)\n\n            # Update dist value of the adjacent vertices\n            # of the picked vertex only if the current distance is greater\n            # than the new distance and the vertex is not in the spt set\n            for v in range(self.V):\n                if self.graph[min_dist_vertex][v] > 0 and v not in spt:\n                    if dist[min_dist_vertex] != float(\"Inf\") and dist[min_dist_vertex] + self.graph[min_dist_vertex][v] < dist[v]:\n                        dist[v] = dist[min_dist_vertex] + self.graph[min_dist_vertex][v]\n\n        # print all distance\n        for i in range(self.V):\n            print(f\"{i} \\t\\t {dist[i]}\")\n\n        return dist\n\n    # Find the vertex with a minimum distance value\n    # from the set of vertices not yet included in the shortest path tree\n    def _find_min_dist_vertex_n(self, dist, spt):\n        min_dist = float(\"Inf\")\n        min_dist_vertex = -1\n        for v in range(self.V):\n            if dist[v] < min_dist and v not in spt:\n                min_dist = dist[v]\n                min_dist_vertex = v\n\n        return min_dist_vertex\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1: list[float], vec2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    # Validate input vectors\n    if len(vec1) == 0 or len(vec2) == 0:\n        raise ValueError(\"Input vectors cannot be empty.\")\n    if len(vec1) != len(vec2):\n        raise ValueError(\"Input vectors must have the same dimension.\")\n\n    # Initialize variables for dot product calculation\n    dot_prod = 0.0\n\n    # Calculate dot product\n    for i in range(len(vec1)):\n        dot_prod += vec1[i] * vec2[f_i]\n\n    return dot_prod\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def compute_dot_product_p(i_vec1: list[float], i_vec2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param i_vec1: The first vector.\n    :param i_vec2: The second vector.\n    :return: The dot product of i_vec1 and i_vec2.\n    \"\"\"\n    if len(i_vec1) != len(i_vec2):\n        raise ValueError(\"Input vectors must have the same dimensions\")\n\n    return sum(x * y for x, y in zip(i_vec1, i_vec2))",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    # method to add an edge to the graph\n    def add_edge(self, u: int, v: int, w: int):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    # utility function to find the vertex with the minimum distance value\n    def min_distance(self, dist, visited):\n        min_val = float(\"Inf\")\n        min_vertex = -1\n\n        for v in range(self.V):\n            if dist[v] < min_val and visited[v] is False:\n                min_val = dist[v]\n                min_vertex = v\n\n        return min_vertex\n\n    # Dijkstra's algorithm to find the shortest path\n    def shortest_path_p(self, src: int):\n        dist = [float(\"Inf\")] * self.V\n        dist[src] = 0\n        visited = [False] * self.V\n\n        for _ in range(self_V):\n            u = self.min_distance(dist, visited)\n            visited[u] = True\n\n            for v, weight in self.graph[u]:\n                if visited[v] is False and dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n\n        return dist\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1, vec2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    if not len(vec1) == len(vec2):\n        raise ValueError(\"Vectors must have the same dimensions for dot product.\")\n\n    return sum(vec1[i] * vec2[i] for i in range(len(vec1)))\n\n\ndef main():\n    # Update function argument naming convention\n    def compute_dot_product(e_vec1, e_vec2):\n        return dot_product(e_vec1, e_vec2)\n\n\nif __name__ == \"__main__\":\n    main()\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def shortest_path_dijstra(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = set()\n\n        for _ in range(self.V):\n            u = self = [min_dist_node, i] for i in range(self.V) if i not in spt_set][0]\n            spt_set.add(u)\n            for v in self.graph[u]:\n                if v not in spt_set and self.graph[u][v] + dist[u] < dist[v]:\n                    dist[v] = self.graph[u][v] + dist[u]\n\n        return dist _md\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, data_t):\n        self.data_t = data_t\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def append_t(self, data_t):\n        new_node_t = Node(data_t)\n        if not self.head_t:\n            self.head_t = new_node_t\n        else:\n            current_t = self.head_t\n            while current_t.next_t:\n                current_t = current_t.next_t\n            current_t.next_t = new_node_t\n\n    def display_t(self):\n        current_t = self.head_t\n        while current_t:\n            print(current_t.data_t, end=' -> ')\n            current_t = current_t.next_t\n        print('None')",
        "def is_valid_sudoku(board):\n    for i in range(9):\n        for j in range(9):\n            val_i_jt_t = board[i][j]\n            if not is_valid_val(val_i_jt_t, i, j, board):\n                return False\n    return True\n\ndef is_valid_val(val_i_jt_t, i_t, j_t, board):\n    x_row_t = board[i_t]\n    x_col_t = [x[j_t] for x in board]\n    x_box_i_t = board[i_t // 3 * 3: i_t // 3 * 3 + 3][j_t // 3 * 3: j_t // 3 * 3 + 3]\n    return val_i_jt_t not in x_row_t and val_i_jt_t not in x_col_t and val_i_jt_t not in x_box_i_t"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```",
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.s_head_at = None\n        self.s_tail_at = None\n\n    def s_add_node_at(self, value):\n        new_node = Node(value)\n        if not self.s_head_at:\n            self.s_head_at = new_node\n            self.s_tail_at = new_node\n        else:\n            new_node.s_next_at = self.s_head_at\n            self.s_head_at = new_node\n\n    def s_remove_node_at(self, value):\n        current = self.s_head_at\n        if current and current.s_value == value:\n            self.s_head_at = current.s_next_at\n            return\n        prev = None\n        while current and current.s_value != value:\n            prev = current\n            current = current.s_next_at\n        if not current:\n            return\n        prev.s_next_at = current.s_next_at\n        if current == self.s_tail_at:\n            self.s_tail_at = prev\n\n    def s_display_at(self):\n        current = self.s_head_at\n        while current:\n            print(current.s_value, end=\" -> \")\n            current = current.s_next_at\n        print(\"None\")\n\n\nclass Node:\n    def __init__(self, value):\n        self.s_value = value\n        self.s_next_at = None",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity_at = capacity\n        self.s_cache_at = {}\n        self.s_order_at = []\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache_at:\n            return -1\n        self.s_order_at.remove(key)\n        self.s_order_at.append(key)\n        return self.s_cache_at[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache_at:\n            self.s_order_at.remove(key)\n        elif len(self.s_order_at) >= self.s_capacity_at:\n            self.s_cache_at.pop(self.s_order_at[0])\n            self.s_order_at.pop(0)\n        self.s_order_at.append(key)\n        self.s_cache_at[key] = value"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_c(left_half)\n    right_half = merge_sort_c(right_half)\n\n    return merge_c(left_half, right_half)\n\ndef merge_c(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "history_model_output": [
        "from sklearn.decomposition import PCA\n\nclass PCAAnalysis:\n    \"\"\"\n    Perform Principal Component Analysis (PCA) on the given data.\n\n    ...\n\n    Attributes\n    ----------\n    data : ndarray\n        The data on which PCA is performed.\n    components_ : ndarray\n        The principal axes in feature space, representing the directions of highest variance in\n        the data. The components are sorted by explained variance.\n    explained_variance_ : float\n        The amount of variance explained by each of the selected components.\n    explained_variance_ratio_ : float\n        Percentage of variance explained by each of the selected components.\n    singular_values_ : float\n        Singular values corresponding to each of the selected components. The singular values\n        are the square roots of the explained variance.\n    mean_ : float\n        Per-feature empirical mean, computed over the i^th feature dimension.\n    noise_variance_ : float\n        The estimated noise covariance following a biased estimation strategy using\n        `svd`_.\n    n_components_ : int\n        Number of components to keep.\n    n_features_in_ : int\n        Number of features seen during :meth:`fit`.\n    \"\"\"\n\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the model with X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training data to compute the principal components for.\n        y : Ignored\n            There is no use of targets in PCA.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        X = self._check_input(X)\n        self.mean_ = X.mean(axis=0)\n        self.data = X - self.mean_\n        cov = np.dot(self.data.T, self.data) / (X.shape[0] - 1)\n        # For small datasets, add a tiny amount of noise for numerical stability\n        cov += self.noise_variance_ * np.eye(cov.shape[0])\n        # Compute the eigen decomposition of the covariance matrix\n        evals, evecs = np.linalg.eigh(cov)\n        # Sort eigenvectors and eigenvalues in descending order\n        idx = np.argsort(evals)[::-1]\n        evecs = evecs[:, idx]\n        evals = evals[idx]\n        self.components_ = evecs[:, : self.n_components]\n        self.explained_variance_ = evals[: self.n_components]\n        self.explained_variance_ratio_ = (\n            evals[: self.n_components] / np.sum(evals)\n        )\n        self.singular_values_ = np.sqrt(evals[: self.n_components])\n        self.noise_variance_ = self.noise_variance_\n        self.n_features_in_ = X.shape[1]\n        return self\n\n    def transform(self, X, y=None, copy=True):\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n        if self.mean_ is not None:\n            X = X - self.mean_\n        return np.dot(X, self.components_.T)\n\n    def inverse_transform(self, X, y=None, copy=True):\n        check_is_fitted(self)\n        X = check_array(X, accept_sparse=\"csr\")\n        return X @ self.components_ + self.mean_\n\n    def fit_transform(self, X, y=None):\n        \"\"\"\n        Fit the model with X and then transform X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            New data, where n_samples in the number of samples\n            and n_features is the number of features.\n        y : Ignored\n            There is no use of targets in PCA.\n\n        Returns\n        -------\n        X_new : ndarray or sparse matrix of shape (n_samples, n_components)\n\n        \"\"\"\n        return self.fit(X).transform(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : boolean, optional\n            If True, will return the parameters for this estimator and contained\n            subobjects that are estimators.\n\n        Returns\n        -------\n        params : mapping of string to any\n            Parameter names mapped to their values.\n        \"\"\"\n        return {\"mean\": self.mean_, \"components\": self.components_, \"n_components\": self.n_components_}\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        Valid parameter keys can be listed with `get_params()`.\n\n        Returns\n        -------\n        self : object\n            Estimator instance.\n        \"\"\"\n        if not params:\n            # Simple optimization to gain speed (inspect is slow)\n            return self\n        for key, value in params.items():\n            setattr(self, key, value)\n        return self\n\n    def _check_input(self, X, **check_params):\n        \"\"\"Verify that the number of samples given is larger than the number of components.\"\"\"\n        X = check_array(X, accept_sparse=\"csr\", **check_params)\n        n_samples, n_features = X.shape\n        n_components = (\n            self.n_components_\n            if self.n_components_ is not None\n            else n_features\n        )\n        if n_samples < n_components:\n            raise ValueError(\n                \"n_components=%d must be smaller than the number of samples: %d\"\n                % (n_components, n_samples)\n            )\n        self.n_features_in_ = n_features\n        return X",
        "```python\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    assert matrix, \"Matrix is required\"\n    assert all(isinstance(row, list) for row in matrix), \"Invalid matrix format\"\n    assert all(isinstance(element, int) for row in matrix for element in row), \"Matrix must contain only integers\"\n\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n\n    return count\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to its Roman numeral representation.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    assert isinstance(num, int), \"Input must be an integer.\"\n    assert num >= 0, \"Input integer must be non-negative.\"\n\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n\n    for i in range(len(values)):\n        count = num // values[i]\n        roman_num += symbols[i] * count\n        num %= values[i]\n\n    return roman_num\n```",
        "```python\ndef is_valid_sudoku_chx(board: list[list[int]]) -> bool:\n    assert isinstance(board, list), \"Input must be a list.\"\n    assert len(board) == 9 and all(len(row) == 9 for row in board), \"Board must be 9x9.\"\n    assert all(1 <= num <= 9 for row in board for num in row), \"Numbers must be between 1 and 9.\"\n\n    seen = set()\n\n    for row in board:\n        for num in row:\n            if num in seen:\n                return False\n            seen.add(num)\n            seen = set()\n\n    for i in range(9):\n        col = [board[r][i] for r in range(9)]\n        for num in col:\n            if num in seen:\n                return False\n            seen.add(num)\n            seen = set()\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[r][c] for r in range(i, i + 3) for c in range(j, j + 3)]\n            for num in box:\n                if num in seen:\n                    return False\n                seen.add(num)\n                seen = set()\n\n    return True\n```",
        "```python\ndef merge_sort_chx(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the merge sort algorithm.\n\n    Args:\n        arr (list[int]): A list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers in ascending order.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert all(isinstance(num, int) for num in arr), \"Input list must contain only integers.\"\n\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_chx(left_half)\n    right_half = merge_sort_chx(right_half)\n\n    return merge_chx(left_half, right_half)\n\ndef merge_chx(left: list[int], right: list[int]) -> list[int]:\n    \"\"\"\n    Merge two sorted lists into a single sorted list.\n\n    Args:\n        left (list[int]): A sorted list of integers.\n        right (list[int]): Another sorted list of integers.\n\n    Returns:\n        list[int]: A single sorted list containing elements from both input lists.\n    \"\"\"\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result\n```",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.queue.remove(key)\n            self.queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.queue.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.queue.append(key)",
        "```python\ndef dot_product_chx(vector_1: list[float], vector_2: list[float]) -> float:\n    assert len(vector_1) == len(vector_2), \"Input vectors must have the same length\"\n    assert all(isinstance(x, (int, float)) for x in vector_1), \"All elements in vector_1 must be numbers\"\n    assert all(isinstance(x, (int, float)) for x in vector_2), \"All elements in vector_2 must be numbers\"\n\n    dot_product = 0.0\n    for i in range(len(vector_1)):\n        dot_product += vector_1[i] * vector_2[i]\n\n    return dot_product\n```",
        "```python\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self.heapify(len(self.heap) - 1)\n\n    def heapify(self, index):\n        child_index = index\n        while child_index >= 0:\n            parent_index = (child_index - 1) // 2\n            if self.heap[child_index] > self.heap[parent_index]:\n                self.heap[child_index], self.heap[parent_index] = self.heap[parent_index], self.heap[child_index]\n                child_index = parent_index\n            else:\n                break\n```",
        "```python\nimport numpy as np\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\nfrom sklearn.base import clone\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.utils import check_array\nfrom sklearn.exceptions import NotFittedError\n\nclass Quadratic_Discriminant_Analysis:\n    def __init__(self, store_covariance=False, tol=1e-4, store_covariates=True):\n        self.store_covariance = store_covariance\n        self.tol = tol\n        self.store_covariates = store_covariates\n\n    def fit(self, X, y, sample_weight=None):\n        # Check input data\n        X = check_array(X, accept_sparse='csr')\n        y = self._check_target(y)\n\n        # Check parameters\n        self._check_parameters(store_covariance=self.store_covariance,\n                                tol=self.tol,\n                                store_covariates=self.store_covariates)\n\n        # Check sample weights\n        if sample_weight is not None:\n            sample_weight = check_array(sample_weight, ensure_2d=False)\n\n        # Check that y labels are unique\n        classes = unique_labels(y)\n        n_classes = classes.shape[0]\n        self.classes_ = classes\n\n        # Check that the number of samples given is larger than the number of\n        # dimensions.\n        n_features = X.shape[1]\n        n_samples, = X.shape\n        if n_features < 1:\n            raise ValueError(\"X has too few features.\")\n        if n_samples < n_features:\n            raise ValueError(\"X has too few samples to perform QDA.\")\n\n        # Check that the number of samples and number of classes is larger than 1\n        if n_classes < 2:\n            raise ValueError(\"The number of classes has to be greater than one.\")\n        if n_samples < n_classes:\n            raise ValueError(\"The number of samples must be at least equal \"\n                             \"to the number of classes.\")\n\n        # Check that X and y have the same number of samples\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"X and y have inconsistent numbers of samples.\")\n\n        # Store the number of classes\n        self.n_classes_ = n_classes\n\n        # Store the number of features\n        self.n_features_in_ = n_features\n\n        # Store the number of samples\n        self.n_samples_fit_ = n_samples\n\n        # Store the classes\n        self.classes_ = classes\n\n        # Store the sample weights\n        self.sample_weight_ = sample_weight\n\n        # Store the training data\n        if self.store_covariates:\n            self.X_ = X\n\n        # Mean and covariance of each class\n        means = np.atleast_2d(\n            np.asarray([np.mean(X[y == class_, ...], axis=0)\n                        for class_ in classes]))\n\n        # Weighted class means\n        if sample_weight is not None:\n            sw_list = []\n            for class_ in classes:\n                sw_list.append(\n                    np.mean(sample_weight[y == class_], axis=0))\n            sample_weight = np.column_stack(sw_list)\n            means = (means.T * sample_weight).T / sample_weight.sum(axis=1)\n\n        # Weighted covariance for each class\n        covars = []\n        for class_ in classes:\n            Xc = X[y == class_]\n            if sample_weight is not None:\n                sw = sample_weight[y == class_]\n                sw_list = []\n                for feat in range(n_features):\n                    sw_list.append(\n                        np.mean(sw * Xc[:, feat], axis=0))\n                sw = np.column_stack(sw_list)\n                Xc = (Xc.T * sw).T / sw.sum(axis=1)\n            covars.append(np.atleast_2d(np.cov(Xc.T)))\n\n        # Weighted mean and covariance for all classes\n        if sample_weight is not None:\n            sw_list = []\n            for class_ in classes:\n                sw_list.append(\n                    np.mean(sample_weight[y == class_], axis=0))\n            sample_weight = np.column_stack(sw_list)\n            means = (means.T * sample_weight).T / sample_weight.sum(axis=1)\n            covars = [(cov * sw).T / sw + (1 - sw) * cov\n                for cov, sw in zip(covars, sample_weight.T)]\n\n        # Invert the covariances\n        covars = [np.linalg.inv(cov) for cov in covars]\n\n        # Store the weighted means and covariances\n        self.means_ = means\n        self.covars_ = covars\n\n        # Store the weighted covariance across classes\n        if self.store_covariance:\n            self.covariance_ = np.cov(X.T)\n\n        # Store the precision matrices\n        self.priors_ = np.array([cov.sum() for cov in covars]) / (\n            self.priors_.sum() + self.tol)\n        self.scalings_ = np.array([cov.diagonal() for cov in covars])\n        self.log_det_covars_ = np.array(\n            [np.linalg.slogdet(cov)[1] for cov in covars])\n        self._intercept_ = (\n            -0.5 * (np.log(self.scalings_) + self.log_det_covars_))\n\n        return self\n\n    def predict(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n\n        # Compute class probabilities\n        probs = self._predict_proba(X)\n\n        # Return the most probable class\n        return self.classes_.take(np.argmax(probs, axis=1), axis=0)\n\n    def _decision_function(self, X):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        J, n_features = X.shape\n        n_classes = self.means_.shape[0]\n        scores = np.zeros((J, n_classes))\n        dec_func = np.zeros((J, n_classes))\n\n        for k, (prior, mean, covar, log_det_covar, scaling) in enumerate(\n                zip(self.priors_, self.means_, self.covars_,\n                        self.log_det_covars_, self.scalings_)):\n            # Compute the log-likelihood for each class\n            diff = X - mean\n            scores[:, k] = np.sum(diff * diff * covar, axis=1)\n            scores[:, k] = (\n                -0.5 * scores[:, k] - 0.5 * log_det_covar - 0.5 * n_features * np.log(2 * np.pi))\n            dec_func[:, k] = scores[:, k] + np.log(prior)\n\n        return dec_func\n\n    def predict_proba(self, X):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        prob = self._predict_proba(X)\n        return np.exp(prob - self._log_prob_pos(X))\n\n    def _predict_proba(self, X):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        J, n_features = X.shape\n        n_classes = self.means_.shape[0]\n        prob = np.zeros((J, n_classes))\n\n        for k, (prior, mean, covar, log_det_covar, scaling) in enumerate(\n                zip(self.priors_, self.means_, self.covars_,\n                        self.log_det_covars_, self.scalings_)):\n            # Compute the log-likelihood for each class\n            diff = X - mean\n            prob[:, k] = (\n                -np.sum(diff * diff * covar, axis=1)\n                - log_det_covar\n                - n_features * np.log(2 * np.pi))\n            prob[:, k] *= prior\n\n        self._log_prob_pos = np.log(np.sum(np.exp(prob), axis=1))\n        return prob\n\n    def _check_target(self, y):\n        y = check_array(y, ensure_2d=False, dtype=None)\n        if y.ndim == 2 and y.shape[1] != 1:\n            raise ValueError(\"Only one column for y is allowed.\")\n        classes, y = np.unique(y, return_inverse=True)\n        self.classes_ = classes\n        return y\n\n    def _check_parameters(self, store_covariance, tol, store_covariates):\n        if not isinstance(store_covariance, bool):\n            raise TypeError(\"store_covariance must be boolean.\")\n        if not isinstance(tol, (numbers.Real, np.number)):\n            raise TypeError(\"tol must be numeric.\")\n        if not isinstance(store_covariates, bool):\n            raise TypeError(\"store_covariates must be boolean.\")\n\n    def score(self, X, y):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n        y = self._check_target(y)\n\n        # Check is fit had been called\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        return self._score_samples(X, y)\n\n    def _score_samples(self, X, y):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n        y = self._check_target(y)\n\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        # Compute the log-likelihood for each class\n        prob = self._predict_proba(X)\n\n        # Log-likelihood of the true class for each sample\n        ll_true_class = np.log(prob[np.arange(X.shape[0]), y])\n\n        # Log-likelihood of the true class for all samples\n        ll_true_class = ll_true_class.sum()\n\n        # Number of samples\n        n_samples = len(ll_true_class)\n\n        # Return the mean log-likelihood\n        return ll_true_class / n_samples\n\n    def score_samples(self, X):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        # Compute the log-likelihood for each class\n        prob = self._predict_proba(X)\n\n        # Return the log-likelihood for each sample\n        return prob\n\n    def decision_function(self, X):\n        # Input validation\n        X = check_array(X, accept_sparse='csr')\n\n        check_is_fitted(self, ['means_', 'covars_', 'scalings_', 'log_det_covars_',\n                               'priors_', '_intercept_'])\n\n        return self._decision_function(X)\n\n    def get_params(self, deep=True):\n        return {\"store_covariance\": self.store_covariance,\n                \"tol\": self.tol,\n                \"store_covariates\": self.store_covariates}\n\n    def set_params(self, **params):\n        if not params:\n            return self\n        valid_params = self.get_params(deep=False)\n\n        nested_params = {}\n        for key, value in params.items():\n            if key not in valid_params:\n                raise ValueError('Invalid parameter %s for estimator %s. '\n                                 'Check the list of available parameters '\n                                 'with `estimator.get_params().keys()`.' %\n                                 (key, self))\n            nested_params[key] = value\n\n        # Simple parameters are set directly\n        for key, value in nested_params.items():\n            setattr(self, key, value)\n\n        return self\n```",
        "```python\nimport numpy as np\n\n\nclass NearestNeighborsModel:\n    \"\"\"\n    NearestNeighborsModel class for implementing the k-Nearest Neighbors algorithm.\n\n    ...\n\n    Attributes\n    ----------\n    x_train : numpy.ndarray\n        The training data.\n    y_train : numpy.ndarray\n        The target values for the training data.\n\n    Methods\n    -------\n    train(x_train, y_train)\n        Trains the model by storing the training data and target values.\n\n    predict(x_test)\n        Predicts the target values for the test data using the k-Nearest Neighbors algorithm.\n    \"\"\"\n\n    def __init__(self):\n        self.x_train = None\n        self.y_train = None\n\n    def train(self, x_train: np.ndarray, y_train: np.ndarray) -> None:\n        \"\"\"\n        Trains the model by storing the training data and target values.\n\n        Parameters\n        ----------\n        x_train : np.ndarray\n            The training data.\n        y_train : np.ndarray\n            The target values for the training data.\n        \"\"\"\n        assert isinstance(x_train, np.ndarray), \"x_train must be a numpy array.\"\n        assert isinstance(y_train, np.ndarray), \"y_train must be a numpy array.\"\n        assert x_train.shape[0] == y_train.shape[\n            0\n        ], \"x_train and y_train must have the same number of samples.\"\n\n        self.x_train = x_train\n        self.y_train = y_train\n\n    def predict(self, x_test: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predicts the target values for the test data using the k-Nearest Neighbors algorithm.\n\n        Parameters\n        ----------\n        x_test : np.ndarray\n            The test data.\n\n        Returns\n        -------\n        np.ndarray\n            The predicted target values for the test data.\n        \"\"\"\n        assert isinstance(x_test, np.ndarray), \"x_test must be a numpy array.\"\n        assert x_test.shape[1] == self.x_train.shape[\n            1\n        ], \"x_test must have the same number of features as the training data.\"\n\n        distances = np.sqrt(np.sum(np.power(self.x_train - x_test, 2), axis=1))\n        nearest_neighbors = np.argsort(distances)\n\n        return self.y_train[nearest_neighbors[:1]]\n```",
        "```python\ndef get_longest_common_prefix(strings: list[str]) -> str:\n    assert isinstance(strings, list), \"Input must be a list of strings.\"\n    assert all(isinstance(s, str) for s in strings), \"All items in the list must be strings.\"\n\n    if not strings:\n        return \"\"\n\n    strings.sort()\n\n    first, *rest = strings\n\n    for i, char in enumerate(first):\n        if any(s[i] != char for s in rest):\n            return first[:i]\n\n    return first\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str) -> None:\n        self.stock.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        self.stock.remove(item)",
        "```python\ndef ud_matrix_diagonal_average(matrix: list[list[int]]) -> float:\n    assert matrix, \"Input matrix cannot be empty.\"\n    assert all(len(row) == len(matrix[0]) for row in matrix), \"Input must be a square matrix.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    diagonal_count = len(matrix)\n\n    return diagonal_sum / diagonal_count\n```",
        "```python\nclass LinkedList:\n    def __init__(self, data=None, next=None):\n        self.data = data\n        self.next = next\n\n    def __str__(self):\n        return f\"{self.data}\"\n\n    def ud_insert_at_beg(self, data):\n        temp = LinkedList(data, self)\n        self.data = temp.data\n        self.next = temp.next\n\n    def ud_insert_at_end(self, data):\n        temp = LinkedList(data)\n        current = self\n        while current.next:\n            current = current.next\n        current.next = temp\n\n    def ud_delete_from_beg(self):\n        if not self.next:\n            return None\n        temp = self.next\n        self.data = temp.data\n        self.next = temp.next\n        return temp.data\n\n    def ud_delete_from_end(self):\n        current = self\n        while current.next and current.next.next:\n            current = current.next\n        if not current.next:\n            return None\n        temp = current.next\n        current.next = None\n        return temp.data\n\n    def ud_search(self, key):\n        current = self\n        while current:\n            if current.data == key:\n                return current\n            current = current.next\n        return None\n\n    def ud_delete(self, key):\n        current = self\n        prev = None\n        while current and current.data != key:\n            prev = current\n            current = current.next\n        if not current:\n            return None\n        prev.next = current.next\n        return current.data\n\n    def ud_size(self):\n        current = self\n        count = 0\n        while current:\n            count += 1\n            current = current.next\n        return count\n\n    def ud_reverse(self):\n        prev = None\n        current = self\n        while current:\n            next_node = current.next\n            current.next = prev\n            prev = current\n            current = next_node\n        self.data, self.next = prev.data, prev\n```",
        "```python\nclass Graph:\n    \"\"\"\n    A Graph class to represent a graph data structure.\n    \"\"\"\n\n    def __init__(self):\n        self.vertices = []\n        self.edges = []\n\n    def add_vertex(self, vertex):\n        self.vertices.append(vertex)\n\n    def add_edge(self, vertex1, vertex2, weight=0):\n        self.edges.append((vertex1, vertex2, weight))\n\n    def shortest_path(self, start, end, path=[]):\n        \"\"\"\n        Compute the shortest path from 'start' to 'end' using Dijkstra's algorithm.\n        \"\"\"\n        visited = set()  # Keep track of visited nodes\n        dist = {}  # Dictionary to store distances from the start node\n        prev_node = {}  # Dictionary to store the previous node in the path\n\n        # Initialize distances as infinity for all vertices except the start node\n        for vertex in self.vertices:\n            dist[vertex] = float(\"inf\")\n        dist[start] = 0\n\n        # Start node is the current node\n        current = start\n\n        while current != end:\n            # Mark the current node as visited\n            visited.add(current)\n\n            # Explore neighbors of the current node\n            for neighbor, _, weight in self.edges:\n                if neighbor not in visited:\n                    # Update distance if a shorter path is found\n                    if dist[neighbor] > dist[current] + weight:\n                        dist[neighbor] = dist[current] + weight\n                        prev_node[neighbor] = current\n\n            # Find the next node with the smallest distance that hasn't been visited yet\n            next_node = None\n            for vertex in self.vertices:\n                if vertex not in visited:\n                    if next_node is None:\n                        next_node = vertex\n                    elif dist[vertex] < dist[next_node]:\n                        next_node = vertex\n\n            # If there are no unvisited nodes, then we have reached the end or there is no path\n            if next_node is None:\n                break\n            current = next_node\n\n        # Reconstruct the path from the end node to the start node\n        path = [end]\n        while current != start:\n            current = prev_node[current]\n            path.append(current)\n        path.reverse()\n\n        return path\n```",
        "```python\ndef is_valid_bst(root: 'Node') -> 'bool':\n    \"\"\"\n    Determines if a given tree is a valid binary search tree.\n\n    Args:\n        root (Node): The root of the binary tree.\n\n    Returns:\n        bool: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    def helper(node: 'Node', min_val: 'int', max_val: 'int') -> 'bool':\n        \"\"\"\n        Helper function to perform an in-order traversal and check for BST properties.\n\n        Args:\n            node (Node): The current node in the traversal.\n            min_val (int): The minimum value allowed for the current node.\n            max_val (int): The maximum value allowed for the current node.\n\n        Returns:\n            bool: True if the subtree rooted at the current node is a valid BST, False otherwise.\n        \"\"\"\n        if not node:\n            return True\n        assert node.left and node.right, \"Left and right child nodes must be provided.\"\n        assert node.left.data < node.data < node.right.data, \"Left child must be less than parent and parent must be less than right child.\"\n        return helper(node.left, min_val, node.data - 1) and helper(node.right, node.data + 1, max_val)\n\n    return helper(root, float('-inf'), float('inf'))\n```",
        "```python\nclass BinaryTree:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\n    def insert(self, value):\n        if value < self.value:\n            if self.left is None:\n                self.left = BinaryTree(value)\n            else:\n                self.left.insert(value)\n        else:\n            if self.right is None:\n                self.right = BinaryTree(value)\n            else:\n                self.right.insert(value)\n\n    def delete(self, value):\n        if value < self.value:\n            if self.left is not None:\n                self.left.delete(value)\n        elif value > self.value:\n            if self.right is not None:\n                self.right.delete(value)\n        else:\n            if self.left is not None and self.right is not None:\n                self.value = self.right.get_min_value()\n                self.right.delete(self.value)\n            elif self.left is not None:\n                self.value = self.left.get_max_value()\n                self.left.delete(self.value)\n            elif self.left is None and self.right is None:\n                self.value = None\n            else:\n                pass\n\n    def get_min_value(self):\n        if self.left is None:\n            return self.value\n        else:\n            return self.left.get_min_value()\n\n    def get_max_value(self):\n        if self.right is None:\n            return self.value\n        else:\n            return self.right.get_max_value()\n```"
      ]
    }
  ]
}