{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n    if not root:\n        return True\n\n    try:\n        if not min_val <= root.val < max_val:\n            return False\n    except AttributeError:\n        print(f\"Error: Expected 't_val' attribute in node {root}.\")\n        return False\n\n    return is_valid_bst(root.left, min_val, root.val) and is_valid_bst(root.right, root.val, max_val)\n```",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.t_head = None\n        self.t_tail = None\n\n    def get(self, key: int) -> int:\n        try:\n            value = self.cache[key]\n            self._move_to_head(key)\n            return value\n        except KeyError:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict_tail()\n        self.cache[key] = value\n        self._insert_head(key)\n\n    def _move_to_head(self, key: int) -> None:\n        node = self.cache[key]\n        self._remove_node(key)\n        self._insert_head(key)\n\n    def _insert_head(self, key: int) -> None:\n        node = [key, self.cache[key]]\n        node[1].prev = None\n        node[1].next = self.t_head\n        if self.t_head is not None:\n            self.t_head.prev = node[1]\n        self.t_head = node[1]\n        if self.t_tail is None:\n            self.t_tail = node[1]\n\n    def _evict_tail(self) -> None:\n        key = self.t_tail.key\n        self._remove_node(key)\n\n    def _remove_node(self, key: int) -> None:\n        if self.t_head is None:\n            return\n        if self.cache[key].prev is not None:\n            self.cache[key].prev.next = self.cache[key].next\n        else:\n            self.t_head = self.cache[key].next\n        if self.cache[key].next is not None:\n            self.cache[key].next.prev = self.cache[key].prev\n        else:\n            self.t_tail = self.cache[key].prev\n        del self.cache[key]\n```"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.t_capacity = capacity\n        self.t_cache = {}\n        self.t_order = []\n\n    def get(self, key: int) -> int:\n        if key not in self.t_cache:\n            return -1\n        self.t_order.remove(key)\n        self.t_order.append(key)\n        return self.t_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.t_capacity == 0:\n            return\n        if key in self.t_cache:\n            self.t_order.remove(key)\n        elif len(self.t_cache) >= self.t_capacity:\n            del_key = self.t_order.pop(0)\n            del self.t_cache[del_key]\n        self.t_order.append(key)\n        self.t_cache[key] = value"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class\n\n@timer_class\nclass QDA(QuadraticDiscriminantAnalysis):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\n                index = parent_index\n            else:\n                break\n```"
      ],
      "instruction_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef factorial(n: int) -> int:\n    \"\"\"\n    Calculate the factorial of a non-negative integer.\n\n    Args:\n        n (int): The non-negative integer for which to calculate the factorial.\n\n    Returns:\n        int: The factorial of n.\n\n    Raises:\n        AssertionError: If n is negative.\n    \"\"\"\n    assert isinstance(n, int) and n >= 0, \"Input must be a non-negative integer.\"\n\n    fact = 1\n    for i in range(1, n + 1):\n        fact *= i\n    return fact\n```"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_oldest = None\n        self.q_newest = None\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        vr_value = self.cache[key]\n        self._move_to_head(key)\n        return vr_value\n\n    def put(self, key, value):\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self._move_to_head(key)\n\n    def _move_to_head(self, key):\n        vr_value = self.cache.pop(key)\n        if self.q_newest == key:\n            self.q_newest = self.q_oldest\n            self.q_oldest = key\n        else:\n            self.cache[key] = vr_value\n\n    def _evict(self):\n        evicted_key = self.q_oldest\n        self.cache.pop(evicted_key)\n        self.q_oldest = self.q_newest if self.q_oldest == self.q_newest else self.q_oldest\n        return evicted_key\n```",
        "def is_valid_sudoku(board):\n    q_rows = set()\n    q_cols = set()\n    q_boxes = set()\n\n    for q_i in range(9):\n        q_rows.add(f\"r_{q_i}\")\n        q_cols.add(f\"c_{q_i}\")\n        q_boxes.add(f\"b_{q_i // 3}_{q_i % 3}\")\n\n    vr_flat_board = [vr_num for vr_sub in board for vr_num in vr_sub]\n    vr_seen = set(vr_flat_board)\n\n    for vr_num in vr_seen:\n        if not (1 <= int(vr_num) <= 9):\n            return False\n\n        vr_count = vr_flat_board.count(vr_num)\n        vr_row_count = vr_flat_board[9 * int(vr_num) : 9 * int(vr_num) + 9].count(vr_num)\n        vr_col_count = [vr_flat_board[int(vr_num) + 9 * i] for i in range(9)].count(vr_num)\n        vr_box_count = vr_flat_board[int(vr_num) + 9 * (int(vr_num) // 3 + 3 * (int(vr_num) % 3)) : int(vr_num) + 9 + 9 * (int(vr_num) // 3 + 3 * (int(vr_num) % 3))].count(\n            vr_num\n        )\n\n        if vr_count != vr_row_count or vr_count != vr_col_count or vr_count != vr_box_count:\n            return False\n\n    return True"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]",
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "```python\nimport functools\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = {}\n        self.capacity = capacity\n        self.queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.queue.remove(key)\n            self.queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.queue.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.queue.append(key)\n\n# Your mentor Sylvie's coding guidelines:\n# - Include try statements in functions for error handling\n# - Name attributes starting with 't_' to indicate testable entities\n# - Add '@timer_class' decorator from 'pedantic' module to all classes\n# - Name methods including the string 'chx' for custom method identification\n# - Start attribute names with 'q_' for easy identification\n# - Start variable names with 'vr_' for clarity and readability\n\ntry:\n    # Following Sylvie's guidelines for attribute and variable naming\n    q_lru_cache = LRUCache(vr_capacity)\n    # Decorating the class with '@timer_class' as per Sylvie's instruction\n    @functools.lru_cache(None)\n    class TimerLRUCache:\n        def __init__(self, capacity: int):\n            self.t_cache = {}\n            self.t_capacity = capacity\n            self.t_queue = []\n\n        def chx_get(self, key: int) -> int:\n            if key in self.t_cache:\n                self.t_queue.remove(key)\n                self.t_queue.append(key)\n                return self.t_cache[key]\n            return -1\n\n        def chx_put(self, key: int, value: int) -> None:\n            if key in self.t_cache:\n                self.t_queue.remove(key)\n            elif len(self.t_cache) >= self.t_capacity:\n                evict_key = self.t_queue.pop(0)\n                del self.t_cache[evict_key]\n            self.t_cache[key] = value\n            self.t_queue.append(key)\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```",
        "```python\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.utils.validation import check_is_fitted\nfrom pedantic import timer_class\n\n@timer_class\nclass QDA(QuadraticDiscriminantAnalysis):\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class.\n    \"\"\"\n\n    def __init__(self, store_covariances=False, tol=1e-4, cov_regularization=1e-06):\n        \"\"\"\n        Initialize the QDA classifier.\n\n        Parameters:\n            store_covariances (bool): Whether to store covariance matrices for each class.\n            tol (float): Tolerance for rank computations.\n            cov_regularization (float): Regularization factor for covariance estimation.\n        \"\"\"\n        self.store_covariances = store_covariances\n        self.tol = tol\n        self.cov_regularization = cov_regularization\n        self.classes_ = None\n        self.class_prior_ = None\n        self.class_count_ = None\n        self.covariance_ = None\n        self.means_ = None\n        self.priors_ = None\n        self.scales_ = None\n        self.variances_ = None\n        self.x_ = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model according to the given training data.\n\n        Parameters:\n            X (ndarray): Training vector, shape (n_samples, n_features)\n            y (ndarray): Target vector relative to X, shape (n_samples,)\n\n        Returns:\n            self: Fitted estimator\n        \"\"\"\n        X = self._validate_data(\n            X,\n            accept_sparse=\"csr\",\n            dtype=[\n                \"float64\",\n                \"float32\",\n            ],\n            order=\"C\",\n        )\n        check_classification_targets(y)\n        self.x_ = X\n        self._check_multiclass(y)\n        self.classes_ = self._unique_labels(y)\n        self.class_count_ = {}\n        self.class_prior_ = {}\n        self.means_ = {}\n        self.covariance_ = {}\n        self.variances_ = {}\n        self.scales_ = {}\n\n        for class_ in self.classes_:\n            class_idx = np.where(y == class_)\n            self.class_count_[class_] = class_idx[0].shape[0]\n            self.class_prior_[class_] = self.class_count_[class_] / len(y)\n            self.means_[class_] = np.mean(X[class_idx], axis=0)\n            self.covariance_[class_] = np.cov(X[class_idx].T)\n            self.variances_[class_] = np.diag(self.covariance_[class_])\n            self.scales_[class_] = 1 / (2 * np.pi) ** (X.shape[1] / 2) * np.linalg.det(\n                self.covariance_[class_]\n            ) ** (-0.5)\n\n        if not self.store_covariances:\n            self.covariance_ = None\n\n        self.priors_ = self.class_prior_\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Perform classification on samples in X.\n\n        Parameters:\n            X (ndarray): Vector to classify, shape (n_samples, n_features)\n\n        Returns:\n            ndarray: Predicted class label per sample.\n        \"\"\"\n        check_is_fitted(self, [\"means_\", \"scales_\", \"class_prior_\", \"covariance_\"])\n        X = self._validate_data(\n            X,\n            accept_sparse=\"csr\",\n            reset=False,\n            dtype=\"numeric\",\n            order=\"C\",\n        )\n        log_prob = self._get_log_prob(X)\n        return self.classes_[np.argmax(log_prob, axis=1)]\n\n    def predict_log_proba(self, X):\n        \"\"\"\n        Return log-probability estimates for the test vector X.\n\n        Parameters:\n            X (ndarray): Vector to classify, shape (n_samples, n_features)\n\n        Returns:\n            ndarray: Log-probability of the samples for each class in the model.\n                Returns a matrix of shape (n_samples, n_classes).\n        \"\"\"\n        prob = self.predict_proba(X)\n        return np.log(prob)\n\n    def predict_proba(self, X):\n        \"\"\"\n        Return probability estimates for the test vector X.\n\n        Parameters:\n            X (ndarray): Vector to classify, shape (n_samples, n_features)\n\n        Returns:\n            ndarray: Probability of the samples for each class in the model.\n                Returns a matrix of shape (n_samples, n_classes).\n        \"\"\"\n        check_is_fitted(self, [\"means_\", \"scales_\", \"class_prior_\", \"covariance_\"])\n        X = self._validate_data(\n            X,\n            accept_sparse=\"csr\",\n            reset=False,\n            dtype=\"numeric\",\n            order=\"C\",\n        )\n        log_prob = self._get_log_prob(X)\n        prob = np.exp(log_prob)\n        normalizer = np.exp(log_prob).sum(axis=1)[:, np.newaxis]\n        normalizer[normalizer == 0.0] = 1.0\n        prob /= normalizer\n        return prob\n\n    def _get_log_prob(self, X):\n        \"\"\"\n        Compute log probability of X for each class.\n\n        Parameters:\n            X (ndarray): Vector to classify, shape (n_samples, n_features)\n\n        Returns:\n            ndarray: Log probability of the samples for each class in the model.\n                Returns a matrix of shape (n_samples, n_classes).\n        \"\"\"\n        check_is_fitted(self, [\"means_\", \"scales_\", \"class_prior_\", \"covariance_\"])\n        X = self._validate_data(\n            X,\n            accept_sparse=\"csr\",\n            reset=False,\n            dtype=\"numeric\",\n            order=\"C\",\n        )\n        log_det = np.log(np.diag(self.covariance_))\n        log_prob = np.empty((X.shape[0], self.covariance_.shape[0]))\n        for i, class_ in enumerate(self.classes_):\n            log_prob[:, i] = (\n                -0.5\n                * np.log(2 * np.pi)\n                * X.shape[1]\n                - 0.5 * log_det[i]\n                - 0.5\n                * (np.linalg.norm(X - self.means_[class_], axis=1) ** 2)\n                / self.covariance_[i]\n            ) + np.log(self.class_prior_[class_])\n        return log_prob\n\n    def _more_tags(self):\n        return {\"requires_fit\": True, \"X_types\": [\"2darray\", \"csr\"], \"allow_nan\": False}\n```",
        "```python\ndef average_diagonal_element(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n\n    Raises:\n        ValueError: If the input matrix is not square.\n    \"\"\"\n    # Check if the matrix is square\n    if len(matrix) == 0 or len(matrix) != len(matrix[0]):\n        raise ValueError(\"Input matrix is not square.\")\n\n    # Initialize sum and count\n    sum_diag = 0\n    count = 0\n\n    # Iterate through the matrix\n    for i in range(len(matrix)):\n        for j in range(len(matrix[i])):\n            # Check if the element is on the diagonal\n            if i == j:\n                sum_diag += matrix[i][j]\n                count += 1\n\n    # Calculate the average\n    avg = sum_diag / count if count != 0 else 0\n\n    return avg\n```",
        "```python\ndef is_valid_bst(root, min_val=float(\"-inf\"), max_val=float(\"inf\")):\n    if not root:\n        return True\n    if not min_val <= root.val < max_val:\n        return False\n    return is_valid_bst(root.left, min_val, root.val) and is_valid_bst(\n        root.right, root.val, max_val\n    )\n```",
        "```python\nimport heapq\n\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def parent(self, i):\n        return (i - 1) // 2\n\n    def left_child(self, i):\n        return 2 * i + 1\n\n    def right_child(self, i):\n        return 2 * i + 2\n\n    def insert(self, value):\n        heapq.heappush(self.heap, value)\n\n    def heapify(self, i):\n        size = len(self.heap)\n        if i >= size:\n            return\n\n        left = self.left_child(i)\n        right = self.right_child(i)\n        smallest = i\n\n        if left < size and self.heap[left] < self.heap[smallest]:\n            smallest = left\n\n        if right < size and self.heap[right] < self.heap[smallest]:\n            smallest = right\n\n        if smallest != i:\n            self.heap[i], self.heap[smallest] = self.heap[smallest], self.heap[i]\n            self.heapify(smallest)\n```",
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    try:\n        # Check rows and columns\n        for row in board:\n            if not is_unique(row):\n                return False\n\n        for col in range(9):\n            col_elements = [board[i][col] for i in range(9)]\n            if not is_unique(col_elements):\n                return False\n\n        # Check 3x3 subgrids\n        for i in range(0, 9, 3):\n            for j in range(0, 9, 3):\n                subgrid = [board[k][l] for k in range(i, i + 3) for l in range(j, j + 3)]\n                if not is_unique(subgrid):\n                    return False\n\n        return True\n\n    except Exception as e:\n        raise Exception(f\"An error occurred: {e}\")\n\ndef is_unique(elements: list[str]) -> bool:\n    seen = set()\n    for element in elements:\n        if element in seen:\n            return False\n        seen.add(element)\n    return True\n```"
      ]
    }
  ]
}