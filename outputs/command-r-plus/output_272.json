{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef gn_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    :param citations: A list of integer citations.\n    :return: The h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n\n    This class implements the k-Nearest Neighbors (kNN) algorithm for classification. It supports\n    both binary and multiclass classification problems.\n\n    ...\n\n    Attributes\n    ----------\n    X_train : array-like, shape (n_samples, n_features)\n        The training samples.\n\n    y_train : array-like, shape (n_samples,)\n        The target labels for the training samples.\n\n    n_neighbors : int, default=5\n        The number of neighbors to consider for prediction.\n\n    metric : str, default='euclidean'\n        The distance metric to use. Supported metrics: 'euclidean', 'manhattan', 'cosine'.\n\n    weights : str, default='uniform'\n        The method for weighting the contributions of the neighbors. Supported weights: 'uniform', 'distance'.\n\n    p : int, default=2\n        Power parameter for the Minkowski metric. When p = 1, this is equivalent to Manhattan distance.\n        When p = 2, this is equivalent to the Euclidean distance. For arbitrary p, this is the Minkowski\n        distance.\n\n    Methods\n    -------\n    train(X_train, y_train)\n        Trains the Nearest Neighbors classifier.\n\n    predict(X_test)\n        Predicts the labels for the provided test samples.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5, metric='euclidean', weights='uniform', p=2):\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n        self.weights = weights\n        self.p = p\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the Nearest Neighbors classifier.\n\n        Parameters\n        ----------\n        X_train : array-like, shape (n_samples, n_features)\n            The training samples.\n\n        y_train : array-like, shape (n_samples,)\n            The target labels for the training samples.\n        \"\"\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the labels for the provided test samples.\n\n        Parameters\n        ----------\n        X_test : array-like, shape (n_samples, n_features)\n            The test samples for which predictions are to be made.\n\n        Returns\n        -------\n        y_pred : array-like, shape (n_samples,)\n            The predicted labels for the test samples.\n        \"\"\"\n        assert self.X_train is not None and self.y_train is not None, \"Model is not trained yet. Call the train method first.\"\n        assert isinstance(X_test, (list, np.ndarray)), \"X_test must be a list or numpy array.\"\n        assert len(X_test.shape) == 2, \"X_test must be a 2-dimensional array.\"\n\n        # Your code here to implement the prediction logic\n        # ...\n\n        return y_pred",
        "def find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Find the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n\n    Assert Statements:\n        - Assert that the input 'strs' is a list of strings.\n    \"\"\"\n    assert all(isinstance(s, str) for s in strs), \"Input must be a list of strings.\"\n\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n\n    return strs[0]"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def x_insert_at_beginning(self, value):\n        new_node = Node(value)\n        new_node.next = self.head\n        self.head = new_node\n\n    def x_append(self, value):\n        if not self.head:\n            self.head = Node(value)\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = Node(value)\n\n    def x_insert_after_value(self, value_to_find, new_value):\n        current = self.head\n        while current:\n            if current.value == value_to_find:\n                new_node = Node(new_value)\n                new_node.next = current.next\n                current.next = new_node\n                break\n            current = current.next\n\n    def x_delete(self, value):\n        current = self.head\n        prev = None\n        while current:\n            if current.value == value:\n                if prev:\n                    prev.next = current.next\n                else:\n                    self.head = current.next\n                break\n            prev = current\n            current = current.next\n\n    def x_display(self):\n        current = self.head\n        while current:\n            print(current.value, end=\" -> \")\n            current = current.next\n        print(\"None\")\n\n    def x_find(self, value):\n        current = self.head\n        while current:\n            if current.value == value:\n                return True\n            current = current.next\n        return False\n\n    def x_reverse(self):\n        prev = None\n        current = self.head\n        while current:\n            next_node = current.next\n            current.next = prev\n            prev = current\n            current = next_node\n        self.head = prev\n\n    def x_get_middle(self):\n        slow_ptr = self.head\n        fast_ptr = self.head\n        while fast_ptr and fast_ptr.next:\n            slow_ptr = slow_ptr.next\n            fast_ptr = fast_ptr.next.next\n        return slow_ptr.value\n\nclass Node:\n    def __init__(self, value_j):\n        self.value = value_j\n        self.next = None\n```"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class PCA0:\n    \"\"\"\n    Principal Component Analysis (PCA) transformation class.\n    \"\"\"\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        \"\"\"\n        Fit the PCA model to the data and transform the data.\n\n        :param X: Input data of shape (n_samples, n_features).\n        :return: Transformed data with reduced dimensions.\n        \"\"\"\n        # Calculate the mean of each feature\n        mean_X = X.mean(axis=0)\n\n        # Center the data\n        X_centered = X - mean_X\n\n        # Calculate the covariance matrix\n        covariance = X_centered.T @ X_centered / X_centered.shape[0]\n\n        # Perform eigenvalue decomposition\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        sort_indices = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[sort_indices]\n        eigenvectors = eigenvectors[:, sort_indices]\n\n        # Select the top eigenvectors based on n_components\n        eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Transform the data using the selected eigenvectors\n        transformed = X_centered @ eigenvectors\n\n        return transformed"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A class representing a binary tree.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Inserts a new node with the given value into the binary tree.\n\n        :param value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def delete(self, value):\n        \"\"\"\n        Deletes the first node with the given value from the binary tree.\n\n        :param value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for inserting a node.\n\n        :param value: The value to be inserted.\n        :param node: The current node in the recursive traversal.\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(valuepartum_helper function for deleting a node.\n\n            :param value: The value of the node to be deleted.\n            :param node: The current node in the recursive traversal.\n            :return: The new root of the subtree or None if the subtree is empty.\n            \"\"\"\n            if node is None:\n                return None\n\n            # Recursive call on the left subtree\n            if value < node.value:\n                node.left = self._delete_recursive(value, node.left)\n            # Recursive call on the right subtree\n            elif value > node.value:\n                node.right = self._delete_recursive(value, node.right)\n            # If the node is found with only one child or no child\n            else:\n                if node.left is None:\n                    return node.right\n                elif node.right is None:\n                    return node.left\n                # If the node has two children: Get the inorder successor (smallest in the right subtree)\n                else:\n                    node.value = self._get_inorder_successor(node.right)\n                    node.right = self._delete_recursive(node.value, node.right)\n\n            return node\n\n    def _get_inorder_successor(self, node):\n        \"\"\"\n        Recursive helper function to find the inorder successor (smallest value in the right subtree).\n\n        :param node: The current node in the recursive traversal.\n        :return: The value of the inorder successor.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    \"\"\"\n    A class representing a node in the binary tree.\n    \"\"\"\n    def __init__(self, value):\n        \"\"\"\n        Initializes a new node with the given value.\n\n        :param value: The value to be stored in the node.\n        \"\"\"\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "```python\ndef delete_node(root, key):\n    \"\"\"\n    Deletes a node with the given key from the binary search tree.\n\n    Args:\n        root (Node): The root of the binary search tree.\n        key (int): The value of the key to delete.\n\n    Returns:\n        Node: The new root of the binary search tree after deletion.\n    \"\"\"\n    if root is None:\n        return root\n\n    # Recursive deletion\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        # Case 1: No children\n        if root.left is None and root.right is None:\n            root = None\n\n        # Case 2: One child\n        elif root.left is None:\n            root = root.right\n        else:\n            root = root.left\n\n        # Case 3: Two children\n        else:\n            successor = get_successor(root.right)\n            root.key = successor.key\n            root.right = delete_node(root.right, successor.key)\n\n    return root\n\ndef get_successor(node):\n    \"\"\"\n    Finds the successor of the given node in the binary search tree.\n\n    Args:\n        node (Node): The current node.\n\n    Returns:\n        Node: The successor of the given node.\n    \"\"\"\n    while node.left is not None:\n        node = node.left\n    return node\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices + 1)]\n\n    # 2-digit method name with consistent digit placement\n    def add_edge0(self, u, v):\n        self.adj[u].append(v)\n\n    # 1-digit method name as instructed by Harena\n    def dfs1(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for i in self.adj[v]:\n            if not visited[i]:\n                if self.dfs1(i, visited, rec_stack):\n                    return True\n            elif rec_stack[i]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    # 1-digit method name as instructed by Harena\n    def check_cycle1(self):\n        visited = [False] * (self.V + 1)\n        rec_stack = [False] * (self.V + 1)\n\n        for i in range(1, self.V + 1):\n            if not visited[i]:\n                if self.dfs1(i, visited, rec_stack):\n                    return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace_class\n\n\n@trace_class\nclass Matrix:\n    def __init__(self, matrix):\n        self.matrix = matrix\n\n    def get_diagonal_elements(self):\n        size = len(self.matrix)\n        assert size == len(self.matrix[0]), \"Matrix must be square\"\n        diagonal_elements = [self.matrix[i][i] for i in range(size)]\n        return diagonal_elements\n\n    def calculate_average(self):\n        diagonal_elements = self.get_diagonal_elements()\n        assert diagonal_elements, \"Matrix has no diagonal elements\"\n        average = sum(diagonal_elements) / len(diagonal_elements)\n        return average\n```",
        "```python\nfrom pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self._model = KernelRidge(\n            alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, kernel_params=kernel_params,\n            fit_intercept=fit_intercept, normalize=normalize, copy_X=copy_X, verbose=verbose\n        )\n\n    def fit(self, X, y):\n        self._model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self._model.predict(X)\n```"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    @count_calls\n    def append(self, value_at):\n        new_node_at = Node(value_at)\n        if not self.head_at:\n            self.head_at = new_node_at\n            self.tail_at = new_node_at\n        else:\n            self.tail_at.next_at = new_node_at\n            self.tail_at = new_node_at\n\n    @count_calls\n    def delete(self, value_at):\n        current_at = self.head_at\n        if current_at.value_at == value_at:\n            self.head_at = current_at.next_at\n            return\n        prev_at = current_at\n        current_at = current_at.next_at\n        while current_at:\n            if current_at.value_at == value_at:\n                prev_at.next_at = current_at.next_at\n                return\n            prev_at = current_at\n            current_at = current_at.next_at\n\n    @count_calls\n    def search(self, value_at):\n        current_at = self.head_at\n        while current_at:\n            if current_at.value_at == value_at:\n                return True\n            current_at = current_at.next_at\n        return False\n\n    @count_calls\n    def display(self):\n        current_at = self.head_at\n        while current_at:\n            print(current_at.value_at, end=\" -> \")\n            current_at = current_at.next_at\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_at):\n        self.value_at = value_at\n        self.next_at = None\n```",
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef get_majority_element(arr_at: list[int]) -> int:\n    \"\"\"\n    Returns the majority element of the input array.\n    \n    Args:\n        arr_at (list[int]): The input array of integers.\n        \n    Returns:\n        int: The majority element of the array.\n    \"\"\"\n    num_count_at = {}\n    for num_at in arr_at:\n        if num_at in num_count_at:\n            num_count_at[num_at] += 1\n        else:\n            num_count_at[num_at] = 1\n\n    majority_count_at = len(arr_at) // 2\n    for num_at, count_at in num_count_at.items():\n        if count_at > majority_count_at:\n            return num_at\n\n    return -1\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```",
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList_r:\n    def __init__(self):\n        self.head_r = None\n\n    def fn_insert(self, data_r):\n        new_node_r = Node_r(data_r)\n        new_node_r.next_r = self.head_r\n        self.head_r = new_node_r\n\n    def fn_delete(self, data_r):\n        current_r = self.head_r\n        if current_r.data_r == data_r:\n            self.head_r = current_r.next_r\n            current_r = None\n            return\n\n        prev_r = current_r\n        current_r = current_r.next_r\n        while current_r is not None:\n            if current_r.data_r == data_r:\n                prev_r.next_r = current_r.next_r\n                current_r = None\n                return\n            prev_r = current_r\n            current_r = current_r.next_r\n\n    def fn_display(self):\n        current_r = self.head_r\n        while current_r is not None:\n            print(current_r.data_r, end=\" -> \")\n            current_r = current_r.next_r\n        print(\"None\")\n\n\nclass Node_r:\n    def __init__(self, data_r):\n        self.data_r = data_r\n        self.next_r = None",
        "```python\ndef fn_h_index_calculator(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```",
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha_s = alpha\n        self.coefficients_s = None\n        self.intercept_s = None\n\n    def train(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n            self.model_s = Lasso(alpha=self.alpha_s)\n            self.model_s.fit(X, y)\n            self.coefficients_s = self.model_s.coef_\n            self.intercept_s = self.model_s.intercept_\n        except Exception as e:\n            print(f\"An error occurred while training the Lasso model: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coefficients_s is None or self.intercept_s is None:\n                print(\"Model has not been trained yet. Please call the train method first.\")\n                return\n            predicted_values = []\n            for x in X:\n                prediction = self.intercept_s + sum(self.coefficients_s[i] * x[i] for i in range(len(x)))\n                predicted_values.append(prediction)\n            return predicted_values\n        except Exception as e:\n            print(f\"An error occurred while making predictions: {e}\")",
        "class LinkedList:\n    def __init__(self):\n        self.head_s = None\n\n    def append(self, value_s):\n        if self.head_s is None:\n            self.head_s = Node(value_s)\n        else:\n            current_s = self.head_s\n            while current_s.next_s:\n                current_s = current_s.next_s\n            current_s.next_s = Node(value_s)\n\n    def display(self):\n        current_s = self.head_s\n        while current_s:\n            print(current_s.value_s)\n            current_s = current_s.next_s\n\n    def get_at_index(self, index_s):\n        current_s = self.head_s\n        count_s = 0\n        while current_s and count_s < index_s:\n            if count_s == index_s:\n                return current_s.value_s\n            current_s = current_s.next_s\n            count_s += 1\n        return None\n\n\nclass Node:\n    def __init__(self, value_s):\n        self.value_s = value_s\n        self.next_s = None"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from bz2 import BZ2File\n\ndef sum_except_self(nums):\n    length = len(nums)\n    left_sums = [0] * length\n    right_sums = [0] * length\n    total_sum = 0\n\n    for i in range(length):\n        total_sum += nums[i]\n        left_sums[i] = total_sum - nums[i]\n        right_sums[i] = total_sum - left_sums[i] - nums[i]\n\n    return left_sums, right_sums"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\nclass Library:\n    def __init__(self):\n        self.books_xt = []\n\n    @validate\n    def add_books(self, book_title_xt: str, author_xt: str) -> None:\n        book_xt = {\n            'title_xt': book_title_xt,\n            'author_xt': author_xt,\n        }\n        self.books_xt.append(book_xt)\n\n    @validate\n    def remove_book(self, book_title_xt: str) -> None:\n        self.books_xt = [book_xt for book_xt in self.books_xt if book_xt['title_xt'] != book_title_xt]\n```",
        "```python\nfrom pedantic import validate\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    @validate\n    def append(self, value_xt: int) -> None:\n        node_xt = Node(value_xt)\n        if not self.head_xt:\n            self.head_xt = node_xt\n        else:\n            current_xt = self.head_xt\n            while current_xt.next_xt:\n                current_xt = current_xt.next_xt\n            current_xt.next_xt = node_xt\n\n    @validate\n    def delete(self, value_xt: int) -> None:\n        if not self.head_xt:\n            return\n        if self.head_xt.value_xt == value_xt:\n            self.head_xt = self.head_xt.next_xt\n            return\n        prev_xt = self.head_xt\n        current_xt = self.head_xt.next_xt\n        while current_xt:\n            if current_xt.value_xt == value_xt:\n                prev_xt.next_xt = current_xt.next_xt\n                return\n            prev_xt = current_xt\n            current_xt = current_xt.next_xt\n\n    @validate\n    def search(self, value_xt: int) -> bool:\n        current_xt = self.head_xt\n        while current_xt:\n            if current_xt.value_xt == value_xt:\n                return True\n            current_xt = current_xt.next_xt\n        return False\n\n    @property\n    @validate\n    def length(self) -> int:\n        current_xt = self.head_xt\n        count_xt = 0\n        while current_xt:\n            count_xt += 1\n            current_xt = current_xt.next_xt\n        return count_xt\n\nclass Node:\n    def __init__(self, value_xt: int):\n        self.value_xt = value_xt\n        self.next_xt = None\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_xt = data\n        self.next_xt = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_xt = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_xt:\n            self.head_xt = new_node\n            return\n        current = self.head_xt\n        while current.next_xt:\n            current = current.next_xt\n        current.next_xt = new_node\n\n    def delete(self, data):\n        if not self.head_xt:\n            return\n        if self.head_xt.data_xt == data:\n            self.head_xt = self.head_xt.next_xt\n            return\n        current = self.head_xt\n        prev = None\n        while current and current.data_xt != data:\n            prev = current\n            current = current.next_xt\n        if not current:\n            return\n        prev.next_xt = current.next_xt\n\n    def display(self):\n        current = self.head_xt\n        while current:\n            print(current.data_xt, end=\" -> \")\n            current = current.next_xt\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def x_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def x_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove that quantity.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def b_add_stock(self, item: str, quantity: int) -> None:\n        pass\n\n    def b_remove_stock(self, item: str, quantity: int) -> None:\n        pass",
        "```python\nclass b_LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def b_insert_node(self, value_t):\n        new_node_t = Node(value_t)\n        if not self.head_t:\n            self.head_t = self.tail_t = new_node_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def b_delete_node(self, value_t):\n        current_t = self.head_t\n        prev_t = None\n        while current_t and current_t.value_t != value_t:\n            prev_t = current_t\n            current_t = current_t.next_t\n\n        if current_t:\n            if prev_t:\n                prev_t.next_t = current_t.next_t\n            else:\n                self.head_t = current_t.next_t\n\n            if current_t == self.tail_t:\n                self.tail_t = prev_t\n\n    def b_display(self):\n        current_t = self.head_t\n        while current_t:\n            print(current_t.value_t, end=\" -> \")\n            current_t = current_t.next_t\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_t):\n        self.value_t = value_t\n        self.next_t = None\n```"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill the request.\")\n\n    def p_calculate_total_stock(self):\n        total = sum(self.stock.values())\n        return total"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom locale import *\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)\n```"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": [
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n        if self.root is None:\n            self.root = Node(0)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete(node.value, node.right)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n```",
        "```python\ndef gn_average_diagonal(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of list of int or float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input must be a list of lists.\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists.\"\n    assert all(isinstance(element, (int, float)) for row in matrix for element in row), \"All elements must be numeric.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    num_diagonals = len(matrix)\n\n    return diagonal_sum / num_diagonals\n```",
        "```python\nimport numpy as np\n\nclass PCA:\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit(self, X):\n        X = np.array(X)\n        self.mean_ = np.mean(X, axis=0)\n        X -= self.mean_\n        _, _, self.variance_ = np.linalg.svd(X, full_matrices=False)\n\n    def transform(self, X):\n        X = np.array(X)\n        X -= self.mean_\n        return np.dot(X, self.variance_[:self.n_components])\n\n    def fit_transform(self, X):\n        X = np.array(X)\n        self.mean_ = np.mean(X, axis=0)\n        X -= self.mean_\n        _, _, self.variance_ = np.linalg.svd(X, full_matrices=False)\n        return np.dot(X, self.variance_[:self.n_components])\n```",
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1, kernel_params=None):\n        \"\"\"\n        :param alpha: float\n            Regularization strength; must be a positive float. Regularization improves the\n            conditioning of the problem and reduces the variance of the estimates. Larger\n            values specify stronger regularization. Alpha corresponds to ``1 / (2C)``\n            in other linear models such as LogisticRegression or LinearSVC.\n            If an array is passed, penalties are assumed to be specific to the\n            targets. Hence they must correspond in number.\n        :param kernel: string, callable or None (default=\"linear\")\n            Specifies the kernel type to be used in the algorithm.\n            It must be one of:\n                - 'linear': a linear kernel: ``K(x_1, x_2) = x_1 * x_2``\n                - 'poly': a polynomial kernel: ``K(x_1, x_2) =\n                      (gamma * x_1' * x_2' + coef0) ** degree``\n                - 'rbf': a Gaussian Radial Basis Function kernel:\n                      ``K(x_1, x_2) = exp(-gamma * \\|\\|x_1 - x_2\\|^2)``\n                - 'sigmoid': a sigmoid kernel: ``K(x_1, x_2) =\n                      tanh(gamma * x_1' * x_2' + coef0)``\n                - a custom callable: ``K(x_1, x_2) = callable(x_1, x_2)``\n            If None is passed, 'linear' is registered.\n        :param gamma: float\n            Gamma parameter for the kernel. Ignored by the linear kernel.\n            For 'poly' and 'sigmoid', if gamma is ``None`` then '1 / n_features'\n            will be used instead.\n        :param degree: int\n            Degree parameter for polynomial kernel. Ignored by other kernels.\n        :param coef0: float\n            Independent term in kernel function.\n            It is only significant in 'poly' and 'sigmoid'.\n        :param kernel_params: dict of string -> any\n            Parameters (keyword arguments) and values for kernel passed as callable object.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y):\n        \"\"\"Fit Kernel Ridge model\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n        :param y: array-like, shape (n_samples,) or (n_samples, n_targets)\n            Target values.\n        :returns: self : object\n            Returns the instance itself.\n        \"\"\"\n        self.model_ = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.model_.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"Predict using the kernel ridge model\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n        :returns: C {array, sparse matrix}, shape (n_samples,) or (n_samples, n_targets)\n            Returns predicted values.\n        \"\"\"\n        return self.model_.predict(X)\n```",
        "```python\ndef dot_product(vector_1: list[float], vector_2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_1 (list[float]): A list of floating-point numbers representing the first vector.\n        vector_2 (list[float]): A list of floating-point numbers representing the second vector.\n\n    Returns:\n        float: The dot product of the two input vectors.\n    \"\"\"\n    # Validate input\n    if not vector_1 or not vector_2:\n        raise ValueError(\"Input vectors cannot be empty\")\n    if len(vector_1) != len(vector_2):\n        raise ValueError(\"Input vectors must have the same length\")\n\n    # Calculate the dot product\n    dot_product = 0.0\n    for i in range(len(vector_1)):\n        dot_product += vector_1[i] * vector_2[i]\n\n    return dot_product\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.value:\n        root.left = delete_node(root.left, key)\n    elif key > root.value:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n\n        # Node with two children\n        root.value = find_min_value(root.right)\n        root.right = delete_node(root.right, root.value)\n\n    return root\n\ndef find_min_value(node):\n    current = node\n    while current.left is not None:\n        current = current.left\n    return current.value\n```",
        "```python\ndef sum_array_except_self(nums):\n    total_sum = sum(nums)\n    result = [total_sum - num for num in nums]\n    return result\n```",
        "```python\ndef h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\n\n\nclass NearestNeighborsModel:\n    def __init__(self):\n        self.model = NearestNeighbors(n_neighbors=1)\n\n    def train(self, X: np.array, y: np.array):\n        self.model.fit(X, y)\n\n    def predict(self, X: np.array):\n        return self.model.kneighbors(X, return_distance=False)\n```",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def push(self, value):\n        node = Node(value)\n        node.next = self.head\n        self.head = node\n\n    def pop(self):\n        if not self.is_empty():\n            value = self.head.value\n            self.head = self.head.next\n            return value\n        raise IndexError(\"Linked list is empty\")\n\n    def is_empty(self):\n        return self.head is None\n\n    def front(self):\n        if not self.is_empty():\n            return self.head.value\n        raise IndexError(\"Linked list is empty\")\n\n    def size(self):\n        current = self.head\n        count = 0\n        while current:\n            count += 1\n            current = current.next\n        return count\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.next = None",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)",
        "```python\nimport numpy as np\nfrom sklearn.utils import check_random_state\nfrom sklearn.utils.validation import check_array\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.exceptions import NotFittedError\n\nclass LassoRegression(BaseEstimator, RegressorMixin):\n    \"\"\"\n    Lasso linear regression model trained with L1 prior as regularizer.\n    \n    Parameters\n    ----------\n    alpha : float, default=1.0\n        Constant that multiplies the L1 term. \n        alpha = 0 is equivalent to an ordinary least square, \n        solved by the LinearRegression object. \n        For numerical reasons, using alpha = 0 with the \n        Lasso object is not advised. \n        Given this, you should use the LinearRegression object.\n        \n    copy_X : boolean, default=True\n        If True, X will be copied; else, it may be overwritten.\n    \n    random_state : int, RandomState instance or None, default=None\n        The seed of the pseudo random number generator used \n        while shuffling the data for alpha selection. \n        If int, random_state is the seed used by the random number generator; \n        If RandomState instance, random_state is the random number generator; \n        If None, the random number generator is the RandomState instance used \n        by np.random.\n\n    Attributes\n    ----------\n    coef_ : array, shape (n_features,)\n        Parameter vector (w in the cost function formula).\n    \n    intercept_ : array, shape (1,)\n        Independent term in decision function.\n\n    \"\"\"\n    def __init__(self, alpha=1.0, copy_X=True, random_state=None):\n        self.alpha = alpha\n        self.copy_X = copy_X\n        self.random_state = check_random_state(random_state)\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using X as training data and y as target values\n        \n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data\n        \n        y : array-like, shape (n_samples,)\n            Target values\n        \n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # Check parameters\n        if self.alpha < 0:\n            raise ValueError(\"alpha should be positive\")\n\n        # Check X and y\n        X = check_array(X, dtype=[np.float64, np.float32], accept_sparse='csc', copy=self.copy_X)\n        y = check_array(y, ensure_2d=False, dtype=None)\n\n        # Add bias term if X has no intercept\n        if not X.bias:\n            X.bias = np.ones((X.shape[0], 1), dtype=X.dtype.type)\n\n        # Check dimensions\n        n_samples, n_features = X.shape\n        if y.ndim == 1:\n            y = y.reshape(-1)\n        if y.shape[0] != n_samples:\n            raise ValueError(\"X and y have inconsistent dimensions\")\n\n        # Check alpha\n        if self.alpha == 0:\n            w = np.linalg.inv(X.T @ X) @ X.T @ y\n        else:\n            # Shuffle data for alpha selection\n            rng = check_random_state(self.random_state)\n            indices = rng.permutation(n_samples)\n            X_shuffle = X[indices]\n            y_shuffle = y[indices]\n\n            # Compute alpha_max\n            Xy = X_shuffle.T @ y_shuffle\n            Xy_abs_sum = np.sum(np.abs(Xy))\n            alpha_max = np.max(Xy_abs_sum) / n_samples\n\n            # Compute the Lasso coefficients\n            w = np.linalg.inv(X.T @ X) @ X.T @ y\n            w_abs = np.abs(w)\n            nonzero_coef = w_abs > self.alpha * alpha_max / n_samples\n            self.coef_ = np.where(nonzero_coef, w, 0)\n\n            # Set the intercept\n            self.intercept_ = np.mean(y - X.dot(self.coef_))\n\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the linear model\n        \n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Samples.\n        \n        Returns\n        -------\n        y : array, shape (n_samples,)\n            Returns predicted values.\n        \"\"\"\n        # Check is fit had been called\n        check_is_fitted(self)\n\n        # Input validation\n        X = check_array(X, accept_sparse='csc')\n\n        # Add bias term if X has no intercept\n        if not X.bias:\n            X.bias = np.ones((X.shape[0], 1), dtype=X.dtype.type)\n\n        # Return the prediction\n        return X @ self.coef_ + self.intercept_\n```",
        "```python\ndef get_majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list.\"\n    count = {}\n    for num in arr:\n        if num in count:\n            count[num] += 1\n        else:\n            count[num] = 1\n    majority_count = len(arr) // 2\n    for num, freq in count.items():\n        if freq > majority_count:\n            return num\n    return None\n```",
        "```python\ndef lcm(x: int, y: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        x (int): The first integer.\n        y (int): The second integer.\n\n    Returns:\n        int: The least common multiple of x and y.\n    \"\"\"\n    assert x > 0 and y > 0, \"Input integers must be positive.\"\n    # Calculate the greatest common divisor using Euclid's algorithm\n    gcd = lambda a, b: a if not b else gcd(b, a % b)\n    gcd_val = gcd(x, y)\n    # Calculate the least common multiple\n    lcm_val = x * y // gcd_val\n    return lcm_val\n```",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books):\n        self.books.extend(books)\n\n    def remove_books(self, books):\n        for book in books:\n            self.books.remove(book)",
        "```python\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * (max(self.graph.keys()) + 1)\n        rec_stack = [False] * (max(self.graph.keys()) + 1)\n\n        for node in self.graph:\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```",
        "```python\ndef gn_longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n    shortest = min(strs, key=len)\n    for i, char in enumerate(shortest):\n        if any(s[:i + 1] != shortest[:i + 1] for s in strs):\n            return shortest[:i]\n    return shortest\n```"
      ]
    }
  ]
}