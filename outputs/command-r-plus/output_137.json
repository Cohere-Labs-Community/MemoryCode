{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_c(left_half)\n    right_half = merge_sort_c(right_half)\n\n    return merge_c(left_half, right_half)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model for classification or regression.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Nearest Neighbors Model.\n        :param X_train: Training data features.\n        :param y_train: Training data labels.\n        :return: None\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train must be the same.\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the labels for the test data.\n        :param X_test: Test data features.\n        :return: Predicted labels for X_test.\n        \"\"\"\n        assert self.X_train is not None and self.y_train is not None, \"Model must be trained before making predictions.\"\n        assert X_test.shape[1] == self, \"Number of features in X_test must match the training data.\"\n\n        def euclidean_distance(x1, x2):\n            \"\"\"\n            Helper function to calculate Euclidean distance between two samples.\n            :param x1: First sample.\n            :param x2: Second sample.\n            :return: Euclidean distance between x1 and x2.\n            \"\"\"\n            return np.sqrt(np.sum((x1 - x2) ** 2))\n\n        def knn_classify(x):\n            \"\"\"\n            Helper function to classify a single sample using K-Nearest Neighbors.\n            :param x: Test sample.\n            :return: Predicted label for x.\n            \"\"\"\n            distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_neighbors = [self.y_train[i] for i in nearest_indices]\n            most_common = np.bincount(nearest_neighbors).argmax()\n            return most_common\n\n        def knn_regress(x):\n            \"\"\"\n            Helper function to regress a single sample using K-Nearest Neighbors.\n            :param x: Test sample.\n            :return: Predicted value for x.\n            \"\"\"\n            distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n            nearest_indices = np.argsort(distances)[:self.n_neighbors]\n            nearest_values = [self.y_train[i] for i in nearest_indices]\n            return np.mean(nearest_values)\n\n        predictions = np.array([knn_classify(x) if isinstance(self.y_train[0], int) else knn_regress(x) for x in X_test])\n        return predictions\n```",
        "def merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    return merge(left_half, right_half)\n\ndef merge(left, right):\n    result = []\n    left_index, right_index = 0, 0\n\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n\n    return result\n\ndef main_fn():\n    # Example usage:\n    # numbers = [12, 11, 13, 5, 6, 7]\n    # sorted_numbers = merge_sort(numbers)\n    # print(sorted_numbers)\n\n    pass\n\nif __name__ == \"__main__\":\n    main_fn()"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron_x:\n    def __init__(self, eta=0.01):\n        self.eta = eta\n        self.weights = None\n        self.bias = None\n\n    def train(self, inputs, targets):\n        inputs = np.array(inputs)\n        targets = np.array(targets)\n        if self.weights is None:\n            self.weights = np.random.rand(inputs.shape[1])\n            self.bias = 0\n        for i in range(inputs.shape[0]):\n            delta_weights = self.eta * (targets[i] - self.predict(inputs[i])) * inputs[i]\n            self.weights += delta_weights\n            self.bias += delta_weights * 1\n\n    def net_input(self, inputs):\n        return np.dot(inputs, self.weights) + self.bias\n\n    def predict(self, inputs):\n        return np.where(self.net_input(inputs) >= 0, 1, 0)",
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "history_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.1, epochs: int = 1000) -> None:\n        self.eta = eta\n        self.epochs = epochs\n        self.weights = None\n        self.bias_chx_fn = None\n\n    def train(self, X: list, y: list) -> object:\n        \"\"\"\n        Trains the Perceptron model.\n\n        Args:\n            X (list): Input training data.\n            y (list): Output training labels.\n\n        Returns:\n            Perceptron: Trained Perceptron instance.\n        \"\"\"\n        # Initialize weights and bias\n        self.weights = [0] * len(X[0])\n        self.bias_chx_fn = 0\n\n        for _ in range(self.epochs):\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.weights = [w + update * x for w, x in zip(self.weights, xi)]\n                self.bias_chx_fn += update\n\n        return self\n\n    def predict(self, X: list) -> list:\n        \"\"\"\n        Predicts the output for the given input data.\n\n        Args:\n            X (list): Input data.\n\n        Returns:\n            list: Predicted output labels.\n        \"\"\"\n        assert self.weights is not None, \"Model has not been trained yet.\"\n\n        predictions = []\n        for xi in X:\n            linear_output = sum(w * x for w, x in zip(self.weights, xi)) + self.bias_chx_fn\n            prediction = 1 if linear_output >= 0 else 0\n            predictions.append(prediction)\n\n        return predictions\n```",
        "```python\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None, \"Model has not been trained yet.\"\n        assert self.y_train is not None, \"Model has not been trained yet.\"\n        assert len(self.X_train) == len(self.y_train), \"X_train and y_train must have the same number of samples.\"\n        assert len(X_test.shape) == 2, \"X_test should be a 2D array.\"\n        assert X_test.shape[1] == self.X_train.shape[1], \"X_test and X_train should have the same number of features.\"\n\n        distances = self._euclidean_distances(X_test, self.X_train)\n        nearest_neighbors = self._get_nearest_neighbors(distances)\n        return self._get_predictions(nearest_neighbors)\n\n    def _euclidean_distances(self, X, Y):\n        return np.sqrt(((X[:, np.newaxis] - Y) ** 2).sum(axis=2))\n\n    def _get_nearest_neighbors(self, distances):\n        nearest_neighbors = np.argsort(distances, axis=1)[:, :self.n_neighbors]\n        return nearest_neighbors\n\n    def _get_predictions(self, nearest_neighbors):\n        predictions = [self._predict_single(neighbor) for neighbor in nearest_neighbors]\n        return np.array(predictions)\n\n    def _predict_single(self, neighbors):\n        unique, counts = np.unique(neighbors, return_counts=True)\n        most_common = unique[np.argmax(counts)]\n        return self.y_train[most_common]\n```",
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_fn(left_half)\n    right_half = merge_sort_fn(right_half)\n\n    return merge_chx(left_half, right_half)\n\ndef merge_chx(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n\nassert merge_sort_fn([4, 2, 7, 1, 6, 8]) == [1, 2, 4, 6, 7, 8]\n```"
      ]
    }
  ]
}