{
  "sessions": [
    {
      "session_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n        self.q_key = 'q_key'\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.cache.move_to_end(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from gzip import *\n\ndef product_except_self(nums):\n    output = [1] * len(nums)\n    left, right = 0, 0\n    for i in range(len(nums)):\n        if not i: left = 0\n        else: output[i] *= nums[left] * nums[i - 1]\n        if output[i] == 0: right = i\n        if nums[i] == 0: left = i + 1\n        else: right = i\n        output[right] *= nums[i]\n    return output"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class PCA_1:\n    \"\"\"\n    Principal Component Analysis (PCA) Class.\n    \"\"\"\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit(self, X, y=None):\n        \"\"\"\n        Fit the PCA model to the data X.\n        \"\"\"\n        # Calculate the mean of each feature\n        self.mean_ = X.mean(axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Calculate the covariance matrix\n        self.cov_matrix_ = X_centered.T @ X_centered / X_centered.shape[0]\n\n        # Get the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(self.cov_matrix_)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        indices = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[indices]\n        eigenvectors = eigenvectors[:, indices]\n\n        # Keep only the top n_components eigenvectors if specified\n        if self.n_components:\n            eigenvectors = eigenvectors[:, :self.n_components]\n\n        # Store the singular values (square root of eigenvalues)\n        self.singular_values_ = np.sqrt(eigenvalues)\n\n        # The principal components are the eigenvectors\n        self.components_ = eigenvectors\n\n    def transform(self, X):\n        \"\"\"\n        Transform the data X using the fitted PCA model.\n        \"\"\"\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Project the centered data onto the principal components\n        transformed = X_centered @ self.components_.T\n\n        return transformed"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero8(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    # Insert node method with a single digit in the function name for clarity\n    def insert_node1(self, data):\n        if not self.root:\n            self.root = Node(data)\n        else:\n            self._insert_node1(data, self.root)\n\n    def _insert_node1(self, data, node):\n        if data < node.data:\n            if node.left is None:\n                node.left = Node(data)\n            else:\n                self._insert_node1(data, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(data)\n            else:\n                self._insert_node1(data, node.right)\n\n    # Delete node method with annotations for improved readability\n    def delete_node1(self, data):\n        self.root = self._delete_node1(self.root, data)\n\n    def _delete_node1(self, root, data) -> 'Node':\n        if root is None:\n            return root\n\n        # Node to be deleted is the root\n        if root.data == data:\n            # Node has no children\n            if root.left is None and root.right is None:\n                return None\n\n            # Node has one child\n            if root.left is None:\n                return root.right\n            elif root.right is None:\n                return root.left\n\n            # Node has two children: Get the inorder successor (smallest in the right subtree)\n            root.data = self._get_min_value(root.right)\n            root.right = self._delete_node1(root.right, root.data)\n            return root\n\n        # Call the recursive function for the left and right subtrees\n        if data < root.data:\n            root.left = self._delete_node1(root.left, data)\n        else:\n            root.right = self._delete_node1(root.right, data)\n\n        return root\n\n    def _get_min_value(self, node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.data\n\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure with methods to insert and delete nodes.\n    \"\"\"\n\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n        print(f\"Inserted {value} into the binary tree.\")\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete(value, self.root)\n        print(f\"Deleted {value} from the binary tree.\")\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete(node.value, node.right)\n\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from mailbox import Mailbox\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.value:\n        root.left = delete_node(root.left, key)\n    elif key > root.value:\n        root.right = delete_node(root.right, key)\n    else:\n        # Case 1: Node is a leaf node\n        if root.left is None and root.right is None:\n            root = None\n\n        # Case 2: Node has one child\n        elif root.left is None:\n            root = root.right\n        elif root.right is None:\n            root = root.left\n\n        # Case 3: Node has two children\n        else:\n            # Find the in-order successor (smallest in the right subtree)\n            successor = find_successor(root.right)\n            root.value = successor.value\n            root.right = delete_node(root.right, successor.value)\n\n    return root\n\ndef find_successor(node):\n    while node.left is not None:\n        node = node.left\n    return node"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A k-Nearest Neighbors classifier.\n    \"\"\"\n    def __init__(self, k=5):\n        self.k = k\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the k-NN model.\n        \n        :param X_train: Training data of shape (n_samples, n_features).\n        :param y_train: Target labels of shape (n_samples,).\n        :return: None\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train do not match\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the labels for the test data.\n        \n        :param X_test: Test data of shape (n_samples, n_features).\n        :return: Predicted labels of shape (n_samples,).\n        \"\"\"\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert X_test.shape[1] == self.X_train.shape[1], \"Number of features in test data does not match training data\"\n\n        predictions = []\n        for x in X_test:\n            distances = self.calculate_distances(x)\n            nearest = self.find_nearest(distances)\n            predictions.append(self.y_train[nearest].most_common(1)[0][0])\n\n        return predictions\n\n    def calculate_distances(self, x):\n        \"\"\"\n        Calculate the distances between a test sample and all training samples.\n        \n        :param x: A test sample of shape (1, n_features).\n        :return: An array of distances between the test sample and training samples.\n        \"\"\"\n        return np.sqrt(((self.X_train - x) ** 2).sum(axis=1))\n\n    def find_nearest(self, distances):\n        \"\"\"\n        Find the indices of the k-nearest neighbors.\n        \n        :param distances: An array of distances between a test sample and training samples.\n        :return: Indices of the k-nearest neighbors.\n        \"\"\"\n        return np.argsort(distances)[:self.k]",
        "def mean(values: list[float]) -> float:\n    \"\"\"Computes the mean of a list of values using an online algorithm.\n\n    Args:\n        values (list[float]): A list of floating-point values.\n\n    Returns:\n        float: The mean of the input values.\n    \"\"\"\n    assert isinstance(values, list), \"Input must be a list.\"\n    assert all(isinstance(value, (int, float)) for value in values), \"All elements in the list must be numeric.\"\n    assert values, \"List cannot be empty.\"\n\n    n = 0\n    total = 0.0\n\n    for i, value in enumerate(values, 1):\n        assert isinstance(i, int), f\"Index {i} is not an integer.\"\n        assert isinstance(value, (int, float)), f\"Value {value} at index {i} is not numeric.\"\n        n += 1\n        total += value\n\n    mean_value = total / n\n    assert isinstance(mean_value, float), \"Mean value is not a floating-point number.\"\n    return mean_value"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    @retry\n    def b_add_stock(self, amount: int):\n        self.stock += amount\n\n    @retry\n    def b_remove_stock(self, amount: int):\n        if self.stock < amount:\n            raise ValueError(\"Not enough stock to remove the requested amount.\")\n        self.stock -= amount",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def b_add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def b_remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def b_add_stock(self, amount):\n        self.stock += amount\n\n    def b_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount",
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.at_stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.at_stock:\n            self.at_stock[item] += quantity\n        else:\n            self.at_stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.at_stock and self.at_stock[item] >= quantity:\n            self.at_stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.at_queue = []\n\n    def get(self, key):\n        if key in self.cache:\n            self.at_queue.remove(key)\n            self.at_queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.at_queue.remove(key)\n        elif len(self.at_queue) >= self.capacity:\n            del_key = self.at_queue.pop(0)\n            del self.cache[del_key]\n        self.at_queue.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from typing import List\nimport secrets\n\ndef edit_distance(str1: str, str2: str) -> int:\n    len1 = len(str1)\n    len2 = len(str2)\n    \n    dp: List[List[int]] = [[0] * (len2 + 1) for _ in range(len1 + 1)]\n    \n    for i in range(len1 + 1):\n        dp[i][0] = i\n    for j in range(len2 + 1):\n        dp[0][j] = j\n        \n    for i in range(1, len1 + 1):\n        for j in range(1, len2 + 1):\n            cost = 0 if str1[i-1] == str2[j-1] else 1\n            dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost)\n    \n    return dp[len1][len2]",
        "from numpy import arange, array, ones, dot,linalg\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\nimport secrets\n\n\nclass LinearRegression:\n    def __init__(self, digit, polyfit=1):\n        self.digit = digit\n        self.polyfit = polyfit\n        self.theta = None\n\n    def fit(self, X, y):\n        X = arange(self.polyfit).reshape(-1, 1) ** X\n        self.theta = linalg.inv(dot(X.T, X)) * dot(X.T, y)\n\n    def predict(self, X):\n        return dot(X, self.theta).flatten()\n\n    def score(self, X, y):\n        y_pred = self.predict(X)\n        return r2_score(y, y_pred)\n\n    def visualize(self, X, y):\n        y_pred = self.predict(X)\n        plt.scatter(X, y, color='blue')\n        plt.plot(X, y_pred, color='red')\n        plt.xlabel('Independent Variable')\n        plt.ylabel('Dependent Variable')\n        plt.title('Linear Regression Fit')\n        plt.show()\n\n\n# Example usage:\n# X = array([1, 2, 3, 4, 5]).reshape(-1, 1)\n# y = array([2, 4, 6, 8, 10])\n# model = LinearRegression(digit=7, polyfit=1)\n# model.fit(X, y)\n# model.visualize(X, y)\n# score = model.score(X, y)\n# print(f\"Coefficients: {model.theta}\")\n# print(f\"R-squared: {score}\")"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]",
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 64, 3, stride=1, padding=1)\n        self.conv2 = torch.nn.Conv2d(64, 64, 3, stride=1, padding=1)\n        self.conv3 = torch.nn.Conv2d(64, 128, 3, stride=1, padding=1)\n        self.conv4 = torch.nn.Conv2d(128, 128, 3, stride=1, padding=1)\n        self.xt_pooling = torch.nn.MaxPool2d(2, 2)\n        self.xt_dropout = torch.nn.Dropout(0.5)\n        self.fc1 = torch.nn.Linear(128 * 4 * 4, 512)\n        self.fc2 = torch.nn.Linear(512, 2)\n\n    def forward(self, x):\n        x = self.xt_pooling(torch.nn.functional.relu(self.conv1(x)))\n        x = self.xt_pooling(torch.nn.functional.relu(self.conv2(x)))\n        x = self.xt_pooling(torch.nn.functional.relu(self.conv3(x)))\n        x = self.xt_pooling(torch.nn.functional.relu(self.conv4(x)))\n        x = torch.flatten(x, 1)\n        x = self.xt_dropout(torch.nn.functional.relu(self.fc1(x)))\n        x = self.fc2(x)\n        return x",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.xt_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.xt_order.move_to_end(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_order:\n            self.xt_order.move_to_end(key)\n        elif len(self.xt_order) >= self.capacity:\n            self.cache.popitem(last=False)\n            self.xt_order.popitem(last=False)\n        self.cache[key] = value\n        self.xt_order[key] = True"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.xt_capacity = capacity\n        self.xt_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.xt_cache:\n            return -1\n        self.xt_cache.move_to_end(key)\n        return self.xt_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.xt_cache:\n            self.xt_cache.move_to_end(key)\n        elif len(self.xt_cache) >= self.xt_capacity:\n            self.xt_cache.popitem(last=False)\n        self.xt_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_queue = []\n\n    def get(self, key):\n        if key in self.cache:\n            self.i_move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.i_move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            del_key = self.i_queue.pop(0)\n            del self.cache[del_key]\n        self.cache[key] = value\n        self.i_queue.append(key)\n\n    def i_move_to_end(self, key):\n        self.i_queue.remove(key)\n        self.i_queue.append(key)"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace\n\n@trace\ndef find_max_subarray_sum(arr):\n    \"\"\"\n    Finds the subarray with the largest sum in a given array.\n    \n    Args:\n        arr (list): A list of integers\n    \n    Returns:\n        int: The sum of the subarray with the largest sum\n    \"\"\"\n    if not arr:\n        return 0\n    \n    max_sum = current_sum = arr[0]\n    for num in arr[1:]:\n        current_sum = max(num, current_sum + num)\n        max_sum = max(max_sum, current_sum)\n    \n    return max_sum\n```",
        "from pedantic import trace\n\n@trace\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for string in strs[1:]:\n            if i == len(string) or string[i] != char:\n                return strs[0][:i]\n\n    return strs[0]"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n\n@count_calls\ndef find_majority_element(arr: list[int]) -> int:\n    \"\"\"\n    Finds the majority element in an array using the Boyer-Moore Voting Algorithm.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The majority element, or None if there is no majority element.\n    \"\"\"\n    assert isinstance(arr, list), \"Input must be a list.\"\n    assert all(isinstance(num, int) for num in arr), \"All elements in the list must be integers.\"\n\n    count = 0\n    candidate = None\n\n    for num in arr:\n        if count == 0:\n            candidate = num\n        count += (num == candidate) - (num != candidate)\n\n    # Check if the candidate is the majority element\n    total_count = sum(1 for num in arr if num == candidate)\n    assert 0 <= total_count <= len(arr), \"Invalid total count.\"\n    return candidate if total_count > len(arr) // 2 else None\n```",
        "from pedantic import count_calls\n\n@count_calls\ndef diagonal_average(matrix):\n    assert isinstance(matrix, list), \"Input must be a list (matrix)\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows in the matrix must be lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Matrix must be square\"\n    \n    size = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.s_head = None\n        self.s_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_s_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_s_head(key)\n            return\n        if len(self.cache) == self.capacity:\n            del self.cache[self.s_tail]\n            self.s_tail = self._get_prev(self.s_tail)\n        self.cache[key] = value\n        self._add_to_s_head(key)\n\n    def _move_to_s_head(self, key: int) -> None:\n        if self.s_head == key:\n            return\n        prev_key = self._get_prev(key)\n        next_key = self._get_next(key)\n        if prev_key is not None:\n            self.cache[prev_key] = next_key\n        else:\n            self.s_head = next_key\n        if next_key is not None:\n            self.cache[next_key] = prev_key\n        else:\n            self.s_tail = prev_key\n        self.cache[key] = self.s_head\n        self.s_head = key\n\n    def _add_to_s_head(self, key: int) -> None:\n        next_key = self.s_head\n        self.cache[key] = next_key\n        self.cache[next_key] = key\n        self.s_head = key\n\n    def _get_next(self, key: int) -> int:\n        return self.cache.get(key, -1)\n\n    def _get_prev(self, key: int) -> int:\n        for k, v in self.cache.items():\n            if v == key:\n                return k\n        return None",
        "class Inventory:\n    def __init__(self):\n        self.s_items = {}\n\n    def p_add_stock(self, item, quantity):\n        if item in self.s_items:\n            self.s_items[item] += quantity\n        else:\n            self.s_items[item] = quantity\n\n    def p_remove_stock(self, item, quantity):\n        if item in self.s_items and self.s_items[item] >= quantity:\n            self.s_items[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the specified quantity.\")"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class image_classifier(torch.nn.Module):\n    def __init__(self):\n        super(image_classifier, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = torch.nn.Linear(120, 84)\n        self.fc3 = torch.nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = torch.nn.functional.relu(self.conv1(x))\n        x = torch.nn.functional.max_pool2d(x, 2)\n        x = torch.nn.functional.relu(self.conv2(x))\n        x = torch.nn.functional.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = torch.nn.functional.relu(self.fc1(x))\n        x = torch.nn.functional.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef integer_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n    \"\"\"\n    roman_numerals = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\")\n    ]\n    roman = \"\"\n    for value, symbol in roman_numerals:\n        count = num // value\n        roman += symbol * count\n        num %= value\n    return roman"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "class LRUCache_x:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.j_order = []\n\n    def get_x(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.j_order.remove(key)\n        self.j_order.append(key)\n        return self.cache[key]\n\n    def put_x(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.j_order.remove(key)\n        elif len(self.cache) >= self.capacity:\n            del_key = self.j_order.pop(0)\n            del self.cache[del_key]\n        self.j_order.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def sum_array_except_self(nums):\n    \"\"\"\n    Calculates the sum of each element in the array except itself.\n\n    Args:\n        nums (list): Input array of integers.\n\n    Returns:\n        list: Array containing the sum of all elements except the element itself.\n    \"\"\"\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i-1] + nums[i-1]\n    return result"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def a_dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def a_add_stock(self, item_name: str, quantity: int, chx_price: float) -> None:\n        if item_name in self.stock:\n            self.stock[item_name]['quantity'] += quantity\n        else:\n            self.stock[item_name] = {'quantity': quantity, 'chx_price': chx_price}\n\n    def a_remove_stock(self, item_name: str, quantity: int) -> None:\n        if item_name in self.stock:\n            if self.stock[item_name]['quantity'] >= quantity:\n                self.stock[item_name]['quantity'] -= quantity\n            else:\n                print(\"Insufficient stock to remove\")\n        else:\n            print(\"Item not found in inventory\")"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_i):\n            self.data_i = data_i\n            self.next_i = None\n\n    def __init__(self):\n        self.head_i = None\n\n    def append_i(self, data_i):\n        new_node_i = self.Node(data_i)\n        if not self.head_i:\n            self.head_i = new_node_i\n        else:\n            current_i = self.head_i\n            while current_i.next_i:\n                current_i = current_i.next_i\n            current_i.next_i = new_node_i\n\n    def delete_i(self, data_i):\n        if not self.head_i:\n            return\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n        current_i = self.head_i\n        prev_i = None\n        while current_i and current_i.data_i != data_i:\n            prev_i = current_i\n            current_i = current_i.next_i\n        if current_i is None:\n            return\n        prev_i.next_i = current_i.next_i\n\n    def display_i(self):\n        current_i = self.head_i\n        while current_i:\n            print(current_i.data_i, end=\" -> \")\n            current_i = current_i.next_i\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list_e = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list_e.append(list1_e[i])\n            i += 1\n        else:\n            merged_list_e.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list_e.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list_e.append(list2_e[j])\n        j += 1\n    \n    return merged_list_e"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self):\n            self.conv1 = nn.Conv2d(3, 6, 5)\n            self.conv2 = nn.Conv2d(6, 16, 5)\n            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n            self.fc2 = nn.Linear(120, 84)\n            self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer\n\n@timer\ndef is_valid_sudoku(board: list[list[int]]) -> bool:\n    x_row = {}\n    x_col = {}\n    x_box = {}\n\n    for i in range(9):\n        x_row[i] = {}\n        x_col[i] = {}\n        for j in range(9):\n            x_box[(i // 3, j // 3)] = set()\n\n    for i in range(9):\n        for j in range(9):\n            num = board[i][j]\n            if num != 0:\n                x_seen = (x_row[i].get(num, False) or\n                           x_col[j].get(num, False) or\n                           num in x_box[(i // 3, j // 3)])\n                if x_seen:\n                    return False\n                x_row[i][num] = x_col[j][num] = x_box[(i // 3, j // 3)].add(num)\n\n    return True",
        "```python\nfrom pedantic import timer\n\n\n@timer\ndef has_cycle(head: str) -> bool:\n    x_current = head\n    x_walker = head\n\n    while x_current and x_walker and x_walker.next:\n        x_current = x_current.next\n        x_walker = x_walker.next.next\n\n        if x_current == x_walker:\n            return True\n\n    return False\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n\nfrom pedantic import count_calls\n\n@count_calls\ndef x_compute_h_index(citations: list[int]) -> int:\n    return x_h_index(citations)",
        "class LinearRegression:\n    def x_train(self, X, y):\n        self.coef_ = np.linalg.inv(X.T @ X) @ (X.T @ y)\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def x_predict(self, X):\n        return X @ self.coef_ + self.intercept_"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        new_node_q = Node(data_q)\n        if not self.head_q:\n            self.head_q = new_node_q\n        else:\n            current_q = self.head_q\n            while current_q.next_q:\n                current_q = current_q.next_q\n            current_q.next_q = new_node_q\n\n    def display(self):\n        current_q = self.head_q\n        while current_q:\n            print(current_q.data_q, end=\" -> \")\n            current_q = current_q.next_q\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_a(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            if node == end:\n                return path\n            for adjacent in graph[node]:\n                new_path = path + [adjacent]\n                queue.append((adjacent, new_path))"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_j, list2_j):\n    result_j = []\n    i, j = 0, 0\n\n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            result_j.append(list1_j[i])\n            i += 1\n        else:\n            result_j.append(list2_j[j])\n            j += 1\n\n    result_j.extend(list1_j[i:])\n    result_j.extend(list2_j[j:])\n\n    return result_j"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "@pedantic.decorators.rename_kwargs\ndef fn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nfrom pedantic import rename_kwargs\n\n\nclass Solution:\n    @rename_kwargs(\"fn_max_subarray\")\n    def fn_max_subarray(self, nums: list[int]) -> int:\n        if not nums:\n            return 0\n\n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum\n```"
      ],
      "instruction_model_output": [
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\nfrom typing import List\n\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_books(self, book_titles: List[str]) -> None:\n        self.books.extend(book_titles)\n\n    @validate\n    def remove_books(self, book_titles: List[str]) -> None:\n        for title in book_titles:\n            self.books.remove(title)\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1, kernel_params=None,\n                 tol=1e-3, fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.tol = tol\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(\n            alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, kernel_params=kernel_params, tol=tol,\n            fit_intercept=fit_intercept, normalize=normalize, copy_X=copy_X, verbose=verbose\n        )\n\n    def a_fit(self, X, y):\n        self.model.fit(X, y)\n\n    def a_predict(self, X):\n        return self.model.predict(X)",
        "from pedantic import trace_class\n\n@trace_class\nclass HIndexCalculator:\n    def a_calculate_h_index(self, citations: list[int]) -> int:\n        if not citations:\n            return 0\n\n        citations.sort(reverse=True)\n        h_index = 0\n\n        for i, citation_count in enumerate(citations, start=1):\n            if citation_count >= i:\n                h_index = i\n            else:\n                break\n\n        return h_index"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": [
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of vector_a and vector_b.\n    \"\"\"\n    # Import the 'gzip' module as per Luis' instruction\n    import gzip\n\n    # Ensure consistent naming convention for attribute names\n    q_vector_a = vector_a\n    q_vector_b = vector_b\n\n    # Include a single digit in the function name\n    dot_product_1 = sum(x * y for x, y in zip(q_vector_a, q_vector_b))\n\n    return dot_product_1",
        "def h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def product_array(nums, n):\n    product = 1\n    for i in range(n):\n        product *= nums[i]\n    return product",
        "def mean(numbers):\n    \"\"\"Computes the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list): A list of numbers.\n\n    Returns:\n        float: The mean of the numbers.\n    \"\"\"\n    # Import the 'gzip' module as per Luis' instruction\n    import gzip\n\n    # Initialize variables as per Luis' convention\n    _sum = 0\n    count = 0\n\n    # Add the '@timer' decorator from the 'pedantic' module as instructed by Luis\n    @pedantic.timer\n    def _add(number):\n        nonlocal _sum, count\n        _sum += number\n        count += 1\n\n    # Iterate through the list of numbers and apply the online algorithm\n    for number in numbers:\n        _add(number)\n\n    # Return the mean as per the function's purpose\n    return _sum / count",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1, len_str2 = len(str1), len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            cost = 0 if str1[i - 1] == str2[j - 1] else 1\n            dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n\n    return dp[len_str1][len_str2]\n```",
        "def merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list",
        "```python\ndef merge_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the merge sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers in ascending order.\n    \"\"\"\n    # Base case: if the list has 0 or 1 elements, it is already sorted\n    if len(arr) <= 1:\n        return arr\n\n    # Divide the list into two halves\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    # Recursively sort each half\n    left_half = merge_sort(left_half)\n    right_half = merge_sort(right_half)\n\n    # Merge the two halves\n    merged = []\n    left_idx, right_idx = 0, 0\n    while left_idx < len(left_half) and right_idx < len(right_half):\n        if left_half[left_idx] < right_half[right_idx]:\n            merged.append(left_half[left_idx])\n            left_idx += 1\n        else:\n            merged.append(right_half[right_idx])\n            right_idx += 1\n\n    # Add any remaining elements\n    merged.extend(left_half[left_idx:])\n    merged.extend(right_half[right_idx:])\n\n    return merged\n```",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def add_node(self, data):\n        node = Node(data)\n        if not self.head:\n            self.head = node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = node\n\n    def remove_node(self, data):\n        current = self.head\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next\n        if current is None:\n            return\n        if prev:\n            prev.next = current.next\n        else:\n            self.head = current.next\n\n    def search(self, data):\n        current = self.head\n        while current and current.data != data:\n            current = current.next\n        return current\n\n    # Rest of the methods...\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None",
        "class Library:\n    def __init__(self):\n        self.q_books = []\n\n    def add_books(self, book):\n        self.q_books.append(book)\n\n    def remove_books(self, book):\n        self.q_books.remove(book)",
        "import numpy as np\n\nclass LinearRegression:\n    def __init__(self, x: np.ndarray, y: np.ndarray):\n        self.coef_ = np.linalg.inv(x.T @ x) @ x.T @ y\n        self.intercept_ = np.mean(y - self.coef_ @ x, axis=0)\n\n    def predict(self, x: np.ndarray) -> np.ndarray:\n        return self.coef_ @ x + self.intercept_",
        "def compute_diagonal_average(matrix):\n    diagonal_sum = 0\n    diagonal_count = 0\n\n    for i in range(len(matrix)):\n        diagonal_sum += matrix[i][i]\n        diagonal_count += 1\n\n    return diagonal_sum / diagonal_count",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n        if self.root is None:\n            return True\n        return False\n\n    def _delete(self, value, node):\n        if node is None:\n            return None\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                successor = self._find_min(node.right)\n                node.value = successor.value\n                node.right = self._delete(successor.value, node.right)\n        return node\n\n    def _find_min(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current",
        "def sum_array_except_self(nums):\n    n = len(nums)\n    left_sum = [0] * n\n    right_sum = [0] * n\n\n    left_sum[0] = nums[0]\n    for i in range(1, n):\n        left_sum[i] = left_sum[i - 1] + nums[i]\n\n    right_sum[n - 1] = nums[n - 1]\n    for i in range(n - 2, -1, -1):\n        right_sum[i] = right_sum[i + 1] + nums[i]\n\n    return [left_sum[i] + right_sum[i] - nums[i] for i in range(n)]",
        "```python\nfrom pedantic import timer, validate\n\n\n@validate\ndef find_largest_subarray_sum(arr: list[int]) -> int:\n    \"\"\"\n    Finds the subarray with the largest sum and returns its sum.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The sum of the subarray with the largest sum.\n    \"\"\"\n    @timer\n    def _find_largest_sum(arr):\n        max_sum = 0\n        current_sum = 0\n        max_start = 0\n        current_start = 0\n\n        for i in range(len(arr)):\n            current_sum += arr[i]\n            if current_sum > max_sum:\n                max_sum = current_sum\n                max_start = current_start\n\n            if current_sum <= 0:\n                current_sum = 0\n                current_start = i + 1\n\n        return max_sum\n\n    return _find_largest_sum(arr)\n```",
        "def int_to_roman(num: int) -> str:\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n\n    for i in range(len(values)):\n        count = num // values[i]\n        roman_num += symbols[i] * count\n        num %= values[i]\n\n    return roman_num",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.order.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.order.remove(key)\n        self.order.append(key)",
        "class Solution:\n    def __init__(self, nums):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.start = 0\n        self.end = 0\n\n    def maxSubArray(self):\n        for i in range(len(self.nums)):\n            self.current_sum = self.current_sum + self.nums[i]\n            if self.current_sum > self.max_sum:\n                self.max_sum = self.current_sum\n                self.start = 0\n                self.end = i\n            if self.current_sum < 0:\n                self.current_sum = 0\n                self.start = i + 1\n                self.end = i + 1\n\n        if self.max_sum == 0:\n            self.start = 0\n            self.end = 0\n        return self.max_sum, self.start, self.end",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self):\n        super(BinaryImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "```python\nfrom pedantic import decorator\n\n\n@decorator.trace_class\nclass LinkedListCycle:\n    def __init__(self, head):\n        self.head = head\n\n    def has_cycle(self):\n        slow_ptr = self.head\n        fast_ptr = self.head\n\n        while fast_ptr and fast_ptr.next:\n            slow_ptr = slow_ptr.next\n            fast_ptr = fast_ptr.next.next\n\n            if slow_ptr == fast_ptr:\n                return True\n\n        return False\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)",
        "```python\nfrom functools import reduce\n\ndef longest_common_prefix(strs: list[str]) -> str:\n    if not strs:\n        return \"\"\n\n    for i, c in enumerate(zip(*strs)):\n        if len(set(c)) > 1:\n            return reduce(lambda x, y: x + y, strs[0][:i])\n\n    return reduce(lambda x, y: x + y, strs[0])\n```",
        "class NearestNeighborsModel:\n    \"\"\"\n    A class to implement the k-Nearest Neighbors model.\n    \"\"\"\n    def __init__(self, k=5):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n        \n        Parameters:\n            k (int): The number of nearest neighbors to consider. Defaults to 5.\n        \"\"\"\n        self.k = k\n        self.xt_model = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the k-Nearest Neighbors model.\n        \n        Parameters:\n            X_train (ndarray): The input training data.\n            y_train (ndarray): The corresponding target values.\n        \"\"\"\n        # Import the necessary module\n        from sklearn.neighbors import KNeighborsClassifier\n\n        # Create and train the model\n        self.xt_model = KNeighborsClassifier(n_neighbors=self.k)\n        self.xt_model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the given test data.\n        \n        Parameters:\n            X_test (ndarray): The input test data.\n        \n        Returns:\n            ndarray: Predicted target values.\n        \"\"\"\n        # Check if the model has been trained\n        if self.xt_model is None:\n            raise ValueError(\"Model has not been trained. Call the train method first.\")\n\n        # Predict the target values\n        return self.xt_model.predict(X_test)",
        "def is_valid_sudoku(board):\n    for row in board:\n        if len(set(row)) != len(row):\n            return False\n\n    for col in zip(*board):\n        if len(set(col)) != len(col):\n            return False\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[i][j], board[i][j+1], board[i][j+2],\n                  board[i+1][j], board[i+1][j+1], board[i+1][j+2],\n                  board[i+2][j], board[i+2][j+1], board[i+2][j+2]]\n            if len(set(box)) != len(box):\n                return False\n\n    return True",
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def add_edge(self, u, v, w):\n        self.graph[u][v] = w\n\n    def shortest_path(self, src, dest):\n        distances = [float(\"inf\") for _ in range(self.vertices)]\n        distances[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.vertices):\n                if self.graph[u][v] and distances[v] > distances[u] + self.graph[u][v]:\n                    distances[v] = distances[u] + self.graph[u][v]\n                    queue.append(v)\n\n        return distances[dest]\n```",
        "```python\nfrom pedantic import decorator\n\n\n@decorator.trace_class\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\n\n@decorator.validate\ndef delete_node(root: Node, key: int) -> Node:\n    if root is None:\n        return root\n\n    if key < root.value:\n        root.left = delete_node(root.left, key)\n    elif key > root.value:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n\n        root.value = min(root.right.value_list)\n        root.right = delete_node(root.right, root.value)\n\n    return root\n```",
        "def count_non_zero_elements(matrix):\n    \"\"\"\n    Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "from sklearn.decomposition import PCA\n\nclass PCA_:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components (int): The number of principal components to keep.\n        explained_variance_ratio_ (float): The percentage of variance explained by the kept components.\n        components_ (ndarray): The principal axes in feature space, representing the directions of maximum variance in the data.\n        mean_ (ndarray): Per-feature empirical mean, estimated from the training set.\n        noise_variance_ (float): The estimated noise covariance. Only defined when `random_state` is given.\n\n    ...\n\n    \"\"\"\n\n    def __init__(\n        self,\n        n_components: int = None,\n        copy: bool = True,\n        whiten: bool = False,\n        svd_solver: str = \"auto\",\n        tol: float = 0.0,\n        iterated_power: str = \"auto\",\n        random_state: int = None,\n    ):\n        self.n_components = n_components\n        self.copy = copy\n        self.whiten = whiten\n        self.svd_solver = svd_solver\n        self.tol = tol\n        self.iterated_power = iterated_power\n        self.random_state = random_state\n\n    # rest of the class definition is omitted for brevity",
        "```python\nimport numpy as np\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y):\n        self.X_ = X\n        self.y_ = y\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.model.fit(self.X_, self.y_)\n\n    def predict(self, X):\n        return self.model.predict(X)\n```",
        "def majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    from collections import Counter\n\n    counter = Counter(arr)\n    majority_count = len(arr) // 2\n    for num, count in counter.items():\n        if count > majority_count:\n            return num\n    return None",
        "```python\nimport gzip\nimport mailbox\nimport secrets\nfrom pedantic import retry, trace, count_calls, validate, rename_kwargs\n\nclass LinearRegression:\n    def __init__(self, xt_count: int = 0):\n        self.xt_count = xt_count\n        self.j_intercept = 0\n        self.j_slope = 0\n\n    @count_calls\n    @trace\n    @validate\n    def train(self, x_values: list[float], y_values: list[float]) -> None:\n        self.j_slope = self.calculate_slope(x_values, y_values)\n        self.j_intercept = self.calculate_intercept(x_values, y_values, self.j_slope)\n\n    @count_calls\n    @trace\n    def predict(self, x_values: list[float]) -> list[float]:\n        predicted_values = [\n            (self.j_slope * x) + self.j_intercept for x in x_values\n        ]\n        return predicted_values\n\n    def calculate_slope(self, x_values: list[float], y_values: list[float]) -> float:\n        assert len(x_values) == len(\n            y_values\n        ), \"Error: x_values and y_values must be the same length.\"\n        numerator = sum(\n            x * y for x, y in zip(x_values, y_values)\n        ) - sum(x_values) * sum(y_values) / len(x_values)\n        denominator = sum(\n            x**2 for x in x_values\n        ) - sum(x_values) ** 2 / len(x_values)\n        return numerator / denominator\n\n    def calculate_intercept(\n        self, x_values: list[float], y_values: list[float], slope: float\n    ) -> float:\n        assert len(x_values) == len(\n            y_values\n        ), \"Error: x_values and y_values must be the same length.\"\n        return sum(y_values) / len(y_values) - slope * sum(x_values) / len(\n            x_values\n        )\n```"
      ]
    }
  ]
}