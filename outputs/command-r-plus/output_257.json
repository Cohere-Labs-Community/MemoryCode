{
  "sessions": [
    {
      "session_model_output": [
        "def merge_sort_x():\n    pass\n\n\ndef merge_x(arr):\n    pass\n\n\ndef merge_sort_helper_x(arr):\n    pass"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def diagonal_average(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a list of lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Input matrix must be square\"\n    \n    size = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_index, right_index = 0, 0\n\n    while left_index < len(left) and right_index < len(right):\n        if left[left_index] < right[right_index]:\n            result.append(left[left_index])\n            left_index += 1\n        else:\n            result.append(right[right_index])\n            right_index += 1\n\n    result.extend(left[left_index:])\n    result.extend(right[right_index:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\n@timer_class\nclass MergeSort_fn:\n    def __init__(self, array):\n        self.array = array\n\n    def merge(self, left, right):\n        result = []\n        left_index, right_index = 0, 0\n\n        while left_index < len(left) and right_index < len(right):\n            if left[left_index] < right[right_index]:\n                result.append(left[left_index])\n                left_index += 1\n            else:\n                result.append(right[right_index])\n                right_index += 1\n\n        result.extend(left[left_index:])\n        result.extend(right[right_index:])\n\n        return result\n\n    def sort(self, array):\n        if len(array) <= 1:\n            return array\n\n        mid = len(array) // 2\n        left = array[:mid]\n        right = array[mid:]\n\n        left = self.sort(left)\n        right = self.sort(right)\n\n        return self.merge(left, right)\n\n    def execute_sort(self):\n        return self.sort(self.array)\n```",
        "class QDA_fn:\n    @timer_class\n    def __init__(self, classes, means, cov_matrix):\n        self.classes = classes\n        self.means = means\n        self.cov_matrix = cov_matrix\n\n    @timer_class\n    def predict(self, X):\n        pass"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_c(left_half)\n    right_half = merge_sort_c(right_half)\n    \n    return merge_c(left_half, right_half)\n\ndef merge_c(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_c(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_c(left)\n    right = merge_sort_c(right)\n\n    return merge_c(left, right)\n\ndef merge_c(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_d(arr):\n    if len(wr_len) <= 1:\n        return arr\n    \n    wr_mid = len(arr) // 2\n    wr_left = arr[:wr_mid]\n    wr_right = arr[wr_mid:]\n    \n    wr_left = merge_sort_d(wr_left)\n    wr_right = merge_sort_d(wr_right)\n    \n    return merge_d(wr_left, wr_right)\n\ndef merge_d(wr_left, wr_right):\n    wr_result = []\n    wr_i, wr_j = 0, 0\n    \n    while wr_i < len(wr_left) and wr_j < len(wr_right):\n        if wr_left[wr_i] < wr_right[wr_j]:\n            wr_result.append(wr_left[wr_i])\n            wr_i += 1\n        else:\n            wr_result.append(wr_right[wr_j])\n            wr_j += 1\n    \n    wr_result.extend(wr_left[wr_i:])\n    wr_result.extend(wr_right[wr_j:])\n    \n    return wr_result",
        "def is_valid_sudoku_d(board_d):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            if board_d[wr_i][wr_j] != '.':\n                wr_num = int(board_d[wr_i][wr_j])\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = True\n                wr_cols[wr_j][wr_num] = True\n                wr_boxes[wr_box_index][wr_num] = True\n\n    return True"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result",
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n\n    def __init__(self):\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Nearest Neighbors model.\n        \n        :param X_train: Training data of shape (n_samples, n_features).\n        :param y_train: Target values of shape (n_samples,).\n        :return: None\n        \"\"\"\n        assert X_train.shape[0] == y_train.shape[0], \"Number of samples in X_train and y_train do not match.\"\n        assert isinstance(X_train, np.ndarray) and isinstance(y_train, np.ndarray), \"X_train and y_train must be numpy arrays.\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict the target values for the provided test data.\n        \n        :param X_test: Test data of shape (n_samples, n_features).\n        :return: Predicted target values of shape (n_samples,).\n        \"\"\"\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet.\"\n        assert isinstance(X_test, np.ndarray), \"X_test must be a numpy array.\"\n        assert X_test.shape[1] == self.X_train.shape[1], \"Number of features in X_test does not match the trained model.\"\n\n        # Implement your prediction logic here\n        # ...\n        return predicted_labels",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.at_head = None\n        self.at_tail = None\n\n    def _delete_node(self, key):\n        assert key in self.cache\n        node = self.cache[key]\n        assert node is not None\n\n        if node.at_prev:\n            node.at_prev.at_next = node.at_next\n        else:\n            self.at_head = node.at_next\n\n        if node.at_next:\n            node.at_next.at_prev = node.at_prev\n        else:\n            self.at_tail = node.at_prev\n\n        del self.cache[key]\n\n    def _add_node(self, key, value):\n        assert key not in self.cache\n\n        new_node = Node(key, value)\n        self.cache[key] = new_node\n\n        if self.at_head is None:\n            self.at_head = new_node\n            self.at_tail = new_node\n        else:\n            new_node.at_next = self.at_head\n            self.at_head.at_prev = new_node\n            self.at_head = new_node\n\n    def get(self, key):\n        assert isinstance(key, int), \"Invalid key type. Expected int.\"\n\n        if key not in self.cache:\n            return -1\n\n        node = self.cache[key]\n        assert node is not None\n\n        # Move the accessed node to the head\n        self._delete_node(key)\n        self._add_node(key, node.at_value)\n\n        return node.at_value\n\n    def put(self, key, value):\n        assert isinstance(key, int), \"Invalid key type. Expected int.\"\n\n        if key in self.cache:\n            self._delete_node(key)\n\n        if len(self.cache) == self.capacity:\n            delete_key = self.at_tail.at_key\n            self._delete_node(delete_key)\n\n        self._add_node(key, value)\n\n    class Node:\n        def __init__(self, key, value, prev=None, next=None):\n            self.at_key = key\n            self.at_value = value\n            self.at_prev = prev\n            self.at_next = next"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half_b = arr[:mid]\n    right_half_b = arr[mid:]\n\n    left_half_b = merge_sort_b(left_half_b)\n    right_half_b = merge_sort_b(right_half_b)\n\n    return merge_b(left_half_b, right_half_b)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\nfrom collections import OrderedDict\n\n@validate\nclass LRUCache:\n    def __init__(i_self, capacity: int):\n        i_self.capacity = capacity\n        i_self.cache = OrderedDict()\n\n    def get(i_self, key: int) -> int:\n        if key not in i_self.cache:\n            return -1\n        i_self.cache.move_to_end(key)\n        return i_self.cache[key]\n\n    def put(i_self, key: int, value: int) -> None:\n        if key in i_self.cache:\n            i_self.cache.move_to_end(key)\n        elif len(i_self.cache) >= i_self.capacity:\n            i_self.cache.popitem(last=False)\n        i_self.cache[key] = value\n```",
        "@validate\ndef int_to_roman(i_number: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n    :param i_number: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    roman_numerals = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\")\n    ]\n    result = \"\"\n    for i_value, i_symbol in roman_numerals:\n        count = i_number // i_value\n        result += i_symbol * count\n        i_number %= i_value\n    return result"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```",
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.s_queue = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.s_queue.remove(key)\n        self.s_queue.append(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.s_queue.remove(key)\n        elif len(self.s_queue) >= self.capacity:\n            del_key = self.s_queue.pop(0)\n            del self.cache[del_key]\n        self.s_queue.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta=0.1, epochs=1000):\n        self.eta = eta\n        self.epochs = epochs\n        self.weight = None\n        self.bias = None\n\n    def train(self, X, y):\n        X_with_bias = np.c_[X, -np.ones(len(X))]\n        self.weight, self.bias = np.zeros(len(X[0]) + 1), 0\n\n        for _ in range(self.epochs):\n            for xi, target in zip(X_with_bias, y):\n                update = self.eta * (target - self.predict(xi))\n                self.weight += update * xi\n                self.bias += update\n\n    def net_input(self, X):\n        return np.dot(X, self.weight[1:]) + self.bias\n\n    def predict(self, X):\n        return np.where(self.net_input(X) >= 0, 1, 0)"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\n@timer\ndef has_cycle_y(head):\n    if not head or not head.next:\n        return False\n    slow, fast = head, head.next\n    while slow != fast:\n        if fast is None or fast.next is None:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    return True\n```",
        "import time\nfrom pedantic import timer\n\n\n@timer\ndef merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_y(left_half)\n    right_half = merge_sort_y(right_half)\n\n    return merge_y(left_half, right_half)\n\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next",
        "def merge_sort_y(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_y(left)\n    right = merge_sort_y(right)\n\n    return merge_y(left, right)\n\ndef merge_y(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n@count_calls\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    @count_calls\n    def insert(self, value):\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        if not node:\n            return BinaryTreeNode(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    @count_calls\n    def delete(self, value):\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n        return node\n\n    @count_calls\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n@count_calls\nclass BinaryTreeNode:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef majority_element(arr: list[int]) -> int:\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        int: The majority element of the array.\n    \"\"\"\n    count_dict = {}\n    for num in arr:\n        if num in count_dict:\n            count_dict[num] += 1\n        else:\n            count_dict[num] = 1\n\n    for num in count_dict:\n        if count_dict[num] > len(arr) // 2:\n            return num\n\n    return None\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@count_calls\nclass LinearRegressionModel:\n    \"\"\"\n    A class to perform linear regression using Scikit-learn's LinearRegression model.\n    Includes methods for training the model and making predictions.\n    \"\"\"\n\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the linear regression model.\n\n        Parameters:\n        X_train (ndarray): Training input features of shape (n_samples, n_features).\n        y_train (ndarray): Training target values of shape (n_samples,).\n\n        Returns:\n        self: Returns an instance of self.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n        return self\n\n    @count_calls\n    def predict(self, X_test):\n        \"\"\"\n        Make predictions using the trained linear regression model.\n\n        Parameters:\n        X_test (ndarray): Test input features of shape (n_samples, n_features).\n\n        Returns:\n        ndarray: Predicted target values of shape (n_samples,).\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\nfrom pedantic import count_calls\n\nclass BinaryTree:\n    \"\"\"A binary tree data structure.\n\n    This class provides methods to insert and delete nodes in a binary tree.\n    \"\"\"\n\n    @count_calls\n    def __init__(self):\n        \"\"\"Initialize an empty binary tree.\"\"\"\n        self.root = None\n\n    @count_calls\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        if not node:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    @count_calls\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left:\n            current = current.left\n        return current.value\n\nclass Node:\n    \"\"\"A node in the binary tree.\n\n    This class represents a single node in the binary tree and contains the value\n    of the node as well as references to its left and right children.\n    \"\"\"\n\n    def __init__(self, value):\n        \"\"\"Initialize a new node with the given value.\n\n        Args:\n            value: The value to be stored in the node.\n        \"\"\"\n        self.value = value\n        self.left = None\n        self.right = None\n```"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_queue = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self.r_queue.remove(key)\n        self.r_queue.insert(0, key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_queue:\n            self.r_queue.remove(key)\n        elif len(self.r_queue) >= self.capacity:\n            del_key = self.r_queue.pop()\n            del self.cache[del_key]\n        self.r_queue.insert(0, key)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def validate_sudoku(board):\n    vr_row = [0] * 9\n    vr_col = [0] * 9\n    vr_box = [0] * 9\n\n    for i in range(9):\n        for j in range(9):\n            vr_num = board[i][j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_row[i] |= 1 << vr_num\n                vr_col[j] |= 1 << vr_num\n                vr_box[(i // 3) * 3 + j // 3] |= 1 << vr_num\n\n                if (vr_row[i] & vr_col[j]) != 0 or (vr_row[i] & vr_box[(i // 3) * 3 + j // 3]) != 0 or (vr_col[j] & vr_box[(i // 3) * 3 + j // 3]) != 0:\n                    return False\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "history_model_output": [
        "```python\ndef is_valid_sudoku_gn(board: list[list[int]]) -> bool:\n    seen = set()\n    for row in board:\n        for num in row:\n            if num not in seen:\n                seen.add(num)\n            else:\n                return False\n\n    for col in range(9):\n        col_seen = set()\n        for row in range(9):\n            num = board[row][col]\n            if num not in col_seen:\n                col_seen.add(num)\n            else:\n                return False\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box_seen = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    num = board[x][y]\n                    if num not in box_seen:\n                        box_seen.add(num)\n                    else:\n                        return False\n\n    return True\n```",
        "```python\ndef compute_average_diagonal_element_gn(matrix):\n    assert isinstance(matrix, list), \"Input must be a list\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists\"\n    assert all(isinstance(element, int) for row in matrix for element in row), \"All elements must be integers\"\n    assert len(matrix) == len(matrix[0]), \"Matrix must be square\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)\n```",
        "```python\ndef merge_sort_gn(arr: list[int]) -> list[int]:\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return _merge_gn(left_half, right_half)\n\ndef _merge_gn(left: list[int], right: list[int]) -> list[int]:\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    assert len(result) == len(left) + len(right)\n    return result\n```",
        "```python\ndef int_to_roman_gn(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    roman_numerals = {\"M\": 1000, \"CM\": 900, \"D\": 500, \"CD\": 400, \"C\": 100, \"XC\": 90, \"L\": 50, \"XL\": 40, \"X\": 10, \"IX\": 9, \"V\": 5, \"IV\": 4, \"I\": 1}\n    roman_str = \"\"\n    for symbol, value in roman_numerals.items():\n        while num >= value:\n            roman_str += symbol\n            num -= value\n    return roman_str\n```",
        "```python\ndef find_majority_element(_d):\n    assert isinstance(_d, list), \"Input must be a list\"\n    assert _d, \"Input list cannot be empty\"\n\n    _c = {}\n    for _x in _d:\n        if _x in _c:\n            _c[_x] += 1\n        else:\n            _c[_x] = 1\n\n    _y = None\n    for _key, _value in _c.items():\n        if _value > len(_d) // 2:\n            _y = _key\n            break\n\n    return _y\n```",
        "```python\nfrom pedantic import timer, validate\n\nclass Perceptron:\n    def __init__(self, lr=0.1):\n        self.lr = lr\n        self.weights = None\n        self.bias = None\n\n    @validate(lr=float)\n    def train(self, X_train, y_train):\n        n_features = X_train.shape[1]\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        for _ in range(len(X_train)):\n            x, target = X_train[_], y_train[_]\n            update = self.lr * (target - self.predict(x))\n            self.weights += update * x\n            self.bias += update\n\n    def predict(self, X):\n        assert self.weights is not None, \"Model has not been trained yet.\"\n        assert len(self.weights) == X.shape[1], \"Number of features must match.\"\n\n        return np.dot(X, self.weights) + self.bias\n```",
        "```python\nimport math\nfrom pedantic import count_calls, timer, validate\n\nclass QuadraticDiscriminantAnalysis:\n    @validate\n    @timer\n    @count_calls\n    def __init__(self, i_x: list[float], i_y: list[float], i_tol: float = 1e-6):\n        self.at_x = i_x\n        self.at_y = i_y\n        self.vr_tol = i_tol\n        self.wr_mean_x = sum(self.at_x) / len(self.at_x)\n        self.wr_mean_y = sum(self.at_y) / len(self.at_y)\n        self.wr_cov_xy = [[0] * len(self.at_x), [0] * len(self.at_y)]\n        self.wr_var_x = 0\n        self.wr_var_y = 0\n        self.chx_calculate_covariance()\n        self.chx_calculate_variance()\n\n    @validate\n    @count_calls\n    def chx_calculate_covariance(self):\n        for i in range(len(self.at_x)):\n            self.wr_cov_xy[0][i] = (self.at_x[i] - self.wr_mean_x) * (self.at_y[i] - self.wr_mean_y)\n            self.wr_cov_xy[1][i] = self.wr_cov_xy[0][i]\n        self.wr_cov_xy = [sum(self.wr_cov_xy[0]), sum(self.wr_cov_xy[1])]\n\n    @validate\n    @count_calls\n    def chx_calculate_variance(self):\n        for i in range(len(self.at_x)):\n            self.wr_var_x += (self.at_x[i] - self.wr_mean_x) ** 2\n            self.wr_var_y += (self.at_y[i] - self.wr_mean_y) ** 2\n        self.wr_var_x = self.wr_var_x / len(self.at_x)\n        self.wr_var_y = self.wr_var_y / len(self.at_y)\n\n    @validate\n    @count_calls\n    def predict(self, i_x_test: list[float]) -> list[float]:\n        wr_predictions = []\n        for i_x in i_x_test:\n            wr_predictions.append(self.wr_mean_y + self.wr_cov_xy[1] * (i_x - self.wr_mean_x) / self.wr_var_x)\n        return wr_predictions\n\n    @validate\n    @count_calls\n    def get_regression_parameters(self) -> dict[str, float]:\n        wr_b = self.wr_cov_xy[1] / self.wr_var_x\n        wr_a = self.wr_mean_y - wr_b * self.wr_mean_x\n        return {\"wr_intercept\": wr_a, \"wr_slope\": wr_b}\n\n    @validate\n    @count_calls\n    def get_correlation_matrix(self) -> list[list[float]]:\n        wr_correlation_matrix = [[0] * 3, [0] * 3, [0] * 3]\n        wr_correlation_matrix[0] = [1, self.wr_mean_x, self.wr_var_x]\n        wr_correlation_matrix[1] = [self.wr_mean_x, self.wr_mean_x ** 2, self.wr_cov_xy[0]]\n        wr_correlation_matrix[2] = [self.wr_var_x, self.wr_cov_xy[0], self.wr_var_y]\n        return wr_correlation_matrix\n\n    @validate\n    @count_calls\n    def get_covariance_matrix(self) -> list[list[float]]:\n        wr_covariance_matrix = [[0] * 3, [0] * 3, [0] * 3]\n        wr_covariance_matrix[0] = [1, self.wr_mean_x, self.wr_var_x]\n        wr_covariance_matrix[1] = [self.wr_mean_x, self.wr_mean_x ** 2, self.wr_cov_xy[0]]\n        wr_covariance_matrix[2] = [self.wr_var_x, self.wr_cov_xy[0], self.wr_var_y + self.wr_tol]\n        return wr_covariance_matrix\n\n    @validate\n    @count_calls\n    def get_standard_errors(self) -> dict[str, float]:\n        wr_correlation_matrix = self.get_correlation_matrix()\n        wr_covariance_matrix = self.get_covariance_matrix()\n        wr_determinant = wr_correlation_matrix[0][0] * wr_covariance_matrix[1][1] * wr_covariance_matrix[2][2] \\\n            + wr_correlation_matrix[0][1] * wr_covariance_matrix[1][2] * wr_covariance_matrix[2][0] \\\n            + wr_correlation_matrix[0][2] * wr_covariance_matrix[1][0] * wr_covariance_matrix[2][1] \\\n            - wr_correlation_matrix[0][2] * wr_covariance_matrix[1][1] * wr_covariance_matrix[2][0] \\\n            - wr_correlation_matrix[0][1] * wr_covariance_matrix[1][0] * wr_covariance_matrix[2][2] \\\n            - wr_correlation_matrix[0][0] * wr_covariance_matrix[1][2] * wr_covariance_matrix[2][1]\n        wr_standard_errors = {\"wr_intercept\": math.sqrt(wr_covariance_matrix[2][2] / wr_determinant),\n                              \"wr_slope\": math.sqrt(wr_covariance_matrix[0][0] / wr_determinant)}\n        return wr_standard_errors\n\n    @validate\n    @count_calls\n    def get_confidence_interval(self, i_alpha: float = 0.05) -> dict[str, float]:\n        wr_standard_errors = self.get_standard_errors()\n        wr_t_statistic = 1 - i_alpha / 2\n        wr_degrees_of_freedom = len(self.at_x) - 2\n        wr_t_critical = wr_t_statistic * math.sqrt(wr_degrees_of_freedom)\n        wr_confidence_interval = {\"wr_intercept\": wr_standard_errors[\"wr_intercept\"] * wr_t_critical,\n                                  \"wr_slope\": wr_standard_errors[\"wr_slope\"] * wr_t_critical}\n        return wr_confidence_interval\n\n    @validate\n    @count_calls\n    def get_r_squared(self) -> float:\n        wr_sum_squared_errors = sum((self.at_y[i] - self.wr_mean_y) ** 2 for i in range(len(self.at_y)))\n        wr_sum_total_errors = sum((self.at_y[i] - self.predict([self.at_x[i]])[0]) ** 2 for i in range(len(self.at_y)))\n        wr_r_squared = 1 - wr_sum_squared_errors / wr_sum_total_errors\n        return wr_r_squared\n\n    @validate\n    @count_calls\n    def get_adjusted_r_squared(self) -> float:\n        wr_n = len(self.at_x)\n        wr_p = 1\n        wr_adjusted_r_squared = 1 - (1 - self.get_r_squared()) * (wr_n - 1) / (wr_n - wr_p - 1)\n        return wr_adjusted_r_squared\n\n    @validate\n    @count_calls\n    def get_mean_squared_error(self) -> float:\n        wr_mse = sum((self.at_y[i] - self.predict([self.at_x[i]])[0]) ** 2 for i in range(len(self.at_y))) / len(self.at_y)\n        return wr_mse\n\n    @validate\n    @count_calls\n    def get_root_mean_squared_error(self) -> float:\n        wr_rmse = math.sqrt(self.get_mean_squared_error())\n        return wr_rmse\n\n    @validate\n    @count_calls\n    def get_mean_absolute_error(self) -> float:\n        wr_mae = sum(abs(self.at_y[i] - self.predict([self.at_x[i]])[0]) for i in range(len(self.at_y))) / len(self.at_y)\n        return wr_mae\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom pedantic import timer_class, validate\n\n@timer_class\nclass NearestNeighborsModel:\n    \"\"\"\n    A class to train and predict using the Nearest Neighbors algorithm.\n    \"\"\"\n    def __init__(self, n_neighbors: int = 5, prefix: str = 'at_'):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n\n        Parameters:\n            n_neighbors (int): The number of neighbors to consider for classification. Default is 5.\n            prefix (str): A prefix to be added to attribute names. Default is 'at_'.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.prefix = prefix\n\n    @validate\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the model using the provided training data.\n\n        Parameters:\n            X_train: The input training data.\n            y_train: The corresponding target training data.\n        \"\"\"\n        # Add your training logic here\n        # ...\n\n    @validate\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the provided test data.\n\n        Parameters:\n            X_test: The input test data.\n\n        Returns:\n            The predicted target values.\n        \"\"\"\n        # Add your prediction logic here\n        # ...\n```",
        "```python\nfrom functools import lru_cache\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n\n    def get(self, key):\n        if key in self.cache:\n            value = self.cache.pop(key)\n            self.cache[key] = value\n            return value\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.cache.pop(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=None)\n        self.cache[key] = value\n```",
        "```python\ndef has_cycle_fn(head_node):\n    @timer\n    def dfs(node):\n        if not node:\n            return False\n        if node.visited:\n            return True\n        node.visited = True\n        return dfs(node.next)\n\n    for node in head_node:\n        if dfs(node):\n            return True\n    return False\n```",
        "```python\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom pedantic import timer_class, validate, count_calls\n\n\n@timer_class\n@validate\nclass LinearRegressionModel:\n    \"\"\"\n    A class to perform linear regression using scikit-learn's LinearRegression model.\n\n    ...\n\n    Attributes\n    ----------\n    coef_ : str, default='at_coef'\n        The coefficient of the model.\n    intercept_ : str, default='at_intercept'\n        The intercept of the model.\n\n    Methods\n    -------\n    train(X_train, y_train):\n        Trains the linear regression model using the provided training data.\n    predict(X_test):\n        Predicts the target values for the provided test data.\n    \"\"\"\n\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X_train: np.array, y_train: np.array) -> None:\n        \"\"\"\n        Trains the linear regression model using the provided training data.\n\n        Parameters\n        ----------\n        X_train : np.array\n            The input training data.\n        y_train : np.array\n            The target training data.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    @count_calls\n    def predict(self, X_test: np.array) -> np.array:\n        \"\"\"\n        Predicts the target values for the provided test data.\n\n        Parameters\n        ----------\n        X_test : np.array\n            The input test data.\n\n        Returns\n        -------\n        np.array\n            The predicted target values.\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\nclass BinaryTree:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n    def insert(self, value):\n        if value < self.value:\n            if self.left is None:\n                self.left = BinaryTree(value)\n            else:\n                self.left.insert(value)\n        else:\n            if self.right is None:\n                self.right = BinaryTree(value)\n            else:\n                self.right.insert(value)\n\n    def delete(self, value):\n        if value < self.value:\n            if self.left is not None:\n                self.left.delete(value)\n        elif value > self.value:\n            if self.right is not None:\n                self.right.delete(value)\n        else:\n            if self.left is None and self.right is None:\n                self = None\n            elif self.left is None:\n                self = self.right\n            elif self.right is None:\n                self = self.left\n            else:\n                temp = self.right\n                while temp.left is not None:\n                    temp = temp.left\n                self.value = temp.value\n                self.right.delete(temp.value)\n```"
      ]
    }
  ]
}