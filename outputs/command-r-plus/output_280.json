{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if node.val <= min_val or node.val >= max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root, float('-inf'), float('inf'))\n```"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf') for _ in range(self.V)]\n        dist[src] = 0\n        spt_set = set()\n\n        while dest not in spt_set:\n            u = self.min_distance_node_ud(dist, spt_set)\n            spt_set.add(u)\n            for v in range(self.V):\n                if self.graph[u][v] > 0 and v not in spt_set:\n                    dist[v] = dist[u] + self.graph[u][v]\n\n        return dist[dest]\n\n    def min_distance_node_ud(self, dist, spt_set):\n        min_dist = float('inf')\n        min_node = -1\n\n        for u in range(self.V):\n            if dist[u] < min_dist and u not in spt_set:\n                min_dist = dist[u]\n                min_node = u\n\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\nclass Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    @retry\n    def add_stock(self, item: str, quantity: int):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    @retry\n    def x_remove_stock(self, item: str, quantity: int):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            raise ValueError(f\"Insufficient stock for {item}\")\n```",
        "```python\nfrom pedantic import retry\n\n\n@retry\ndef x_find_majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list): The input array.\n\n    Returns:\n        int or float: The majority element in the array.\n    \"\"\"\n    if not arr:\n        return None\n    arr.sort()\n    count = 1\n    candidate = arr[0]\n    for i in range(1, len(arr)):\n        if arr[i] == arr[i - 1]:\n            count += 1\n        else:\n            if count > len(arr) // 2:\n                return candidate\n            count = 1\n            candidate = arr[i]\n    if count > len(arr) // 2:\n        return candidate\n    return None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```",
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef n_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Find the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nclass Inventory:\n    \"\"\"\n    Represents a product inventory.\n    \"\"\"\n\n    def __init__(self):\n        self.stock = {}\n\n    def n_add_stock(self, product: str, quantity: int) -> None:\n        \"\"\"\n        Add product stock.\n\n        Args:\n            product (str): Name of the product.\n            quantity (int): Amount of product to add.\n\n        Returns:\n            None\n        \"\"\"\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def n_remove_stock(self, product: str, quantity: int) -> None:\n        \"\"\"\n        Remove product stock.\n\n        Args:\n            product (str): Name of the product.\n            quantity (int): Amount of product to remove.\n\n        Returns:\n            None\n        \"\"\"\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock.\")\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n            self.model = Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while training Lasso Regression: {e}\")\n\n    def predict(self, X):\n        try:\n            if self.coef_ is None or self.intercept_ is None:\n                raise ValueError(\"Model has not been trained yet. Please call the train method before predicting.\")\n            return self.model.predict(X)\n        except Exception as e:\n            raise RuntimeError(f\"Error occurred while making predictions: {e}\")"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.secrets = importlib.import_module('secrets')\n        self.stock = {}\n\n    def p_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def p_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")",
        "```python\nfrom typing import List\nimport secrets\n\ndef p_edit_distance(str1: str, str2: str) -> int: \n    len1 = len(str1)\n    len2 = len(str2)\n    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)] \n\n    for i in range(len1 + 1): \n        for j in range(len2 + 1): \n            if i == 0: \n                dp[i][j] = j \n            elif j == 0: \n                dp[i][j] = i \n            elif str1[i-1] == str2[j-1]: \n                dp[i][j] = dp[i-1][j-1]\n            else: \n                dp[i][j] = 1 + min(dp[i][j-1], dp[i-1][j], dp[i-1][j-1])\n\n    return dp[len1][len2]\n```"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount",
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    vr_row = [{} for _ in range(9)]\n    vr_col = [{} for _ in range(9)]\n    vr_box = [{} for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            if board[vr_i][vr_j] != '.':\n                vr_num = board[vr_i][vr_j]\n                vr_box_index = (vr_i // 3) * 3 + vr_j // 3\n                if vr_num in vr_row[vr_i] or vr_num in vr_col[vr_j] or vr_num in vr_box[vr_box_index]:\n                    return False\n                vr_row[vr_i][vr_num] = vr_row[vr_i].get(vr_num, 0) + 1\n                vr_col[vr_j][vr_num] = vr_col[vr_j].get(vr_num, 0) + 1\n                vr_box[vr_box_index][vr_num] = vr_box[vr_box_index].get(vr_num, 0) + 1\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    # Insert a value into the binary tree\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    # Delete a value from the binary tree\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: get the inorder successor (smallest in the right subtree)\n            node.value = self._get_successor(node.right)\n            node.right = self._delete(node.value, node.right)\n\n        return node\n\n    def _get_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_f, list2_f):\n    result_chx = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            result_chx.append(list1_f[i])\n            i += 1\n        else:\n            result_chx.append(list2_f[j])\n            j += 1\n    result_chx.extend(list1_f[i:])\n    result_chx.extend(list2_f[j:])\n    return result_chx\n```",
        "def sum_unique_elements(numbers_list_f, *args, **kwargs):\n    unique_nums_lst = list(dict.fromkeys(numbers_list_f))\n    sum_chx = sum(unique_nums_lst)\n    return sum_chx"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list",
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\n\n\ndef insertion_sort(arr: List[int]) -> List[int]:\n    \"\"\"\n    Sort an array using the insertion sort algorithm.\n\n    Args:\n        arr (List[int]): The input array to be sorted.\n\n    Returns:\n        List[int]: The sorted array.\n    \"\"\"\n    import hashlib  # As instructed by Sylvie\n\n    # Hash the input array for security purposes\n    hash_obj = hashlib.sha256()\n    hash_obj.update(str(arr).encode())\n    hash_value = hash_obj.hexdigest()\n\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n\n    return arr\n```"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock_n = {}\n\n    def add_stock(self, product_name, quantity):\n        self.stock_n[product_name] = self.stock_n.get(product_name, 0) + quantity\n\n    def remove_stock(self, product_name, quantity):\n        if self.stock_n.get(product_name, 0) < quantity:\n            raise ValueError(\"Insufficient stock to remove\")\n        self.stock_n[product_name] -= quantity",
        "```python\ndef a_check_palindrome(input_string: str) -> bool:\n    input_string = input_string.lower()\n    start, end = 0, len(input_string) - 1\n\n    while start < end:\n        if input_string[start] != input_string[end]:\n            return False\n        start += 1\n        end -= 1\n\n    return True\n\n\ndef a_main():\n    input_str_1_n = \"racecar\"\n    input_str_2_n = \"racecars\"\n\n    result_1_n = a_check_palindrome(input_string=input_str_1_n)\n    result_2_n = a_check_palindrome(input_string=input_str_2_n)\n\n    return result_1_n, result_2_n\n\n\nif __name__ == \"__main__\":\n    result_1_n, result_2_n = a_main()\n    print(f\"Is '{input_str_1_n}' a palindrome? {result_1_n}\")\n    print(f\"Is '{input_str_2_n}' a palindrome? {result_2_n}\")\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```",
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@count_calls\ndef train(self, X: np.ndarray, y: np.ndarray) -> None:\n    self.model = LinearRegression()\n    self.model.fit(X, y)\n\n@count_calls\ndef predict(self, X: np.ndarray) -> np.ndarray:\n    return self.model.predict(X)\n\nclass LinearRegression:\n    def __init__(self):\n        self.model = None\n\n    train: callable = train\n    predict: callable = predict\n```",
        "```python\nfrom pedantic import count_calls\nfrom typing import List\n\n\n@count_calls\ndef find_kth_largest(nums: List[int], k: int) -> int:\n    \"\"\"\n    Finds the k-th largest element in a list of integers.\n\n    Args:\n        nums (List[int]): The input list of integers.\n        k (int): The value of 'k' for the k-th largest element.\n\n    Returns:\n        int: The k-th largest element in the list.\n    \"\"\"\n    nums.sort(reverse=True)\n    return nums[k-1]\n```"
      ],
      "instruction_model_output": [
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def compute_mean1(data):\n    \"\"\"Computes the mean of a dataset using an online algorithm.\n\n    Args:\n        data (list or tuple): The input dataset.\n\n    Returns:\n        float: The mean of the dataset.\n    \"\"\"\n    if not data:\n        raise ValueError(\"Input data is empty\")\n\n    sum1, count = 0, 0\n    for x in data:\n        sum1 += x\n        count += 1\n    return sum1 / count"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_chx_palindrome_y(strng_y: str) -> bool:\n    strng_y = strng_y.lower().replace(\" \", \"\")\n    return strng_y == strng_y[::-1]",
        "```python\ndef chx_flatten_binary_tree_to_linked_list_y(root_nody):\n    if not root_nody:\n        return None\n\n    lefty = root_nody.left\n    righty = root_nody.right\n    root_nody.right = chx_flatten_binary_tree_to_linked_list_y(lefty)\n    root_nody.left = None\n    if righty:\n        temp_y = chx_flatten_binary_tree_to_linked_list_y(righty)\n        while root_nody.right:\n            righty = root_nody.right\n            root_nody.right = righty.left\n            temp_y.left = righty\n            temp_y = righty\n\n    return root_nody\n```"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def b_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef validate_sudoku_board(board):\n    y_flat_list = [item for sublist in board for item in sublist]\n    unique_nums = set(y_flat_list)\n    if len(unique_nums) != len(y_flat_list):\n        return False\n\n    for i in range(9):\n        row = board[i]\n        if not is_unique(row):\n            return False\n\n        col = [board[x][i] for x in range(9)]\n        if not is_unique(col):\n            return False\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[x][y] for x in range(i, i + 3) for y in range(j, j + 3)]\n            if not is_unique(box):\n                return False\n\n    return True\n\ndef is_unique(lst):\n    y_set = set(lst)\n    return len(lst) == len(y_set)\n```",
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    # Method to add an edge to the graph\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    # Method to find the shortest path between two nodes\n    def shortest_path_p(self, src, dest):\n        # Create a visited set for tracking visited nodes\n        visited_y = set()\n\n        # Create a queue for BFS traversal\n        queue = []\n\n        # Mark the source node as visited and enqueue it\n        visited_y.add(src)\n        queue.append(src)\n\n        # Perform BFS traversal until the destination node is visited or all nodes have been visited\n        while queue:\n            # Dequeue a node from the queue and get its neighbors\n            node = queue.pop(0)\n            for neighbour in self.graph[node]:\n                # If the neighbour node has not been visited, mark it as visited and enqueue it\n                if neighbour not in visited_y:\n                    visited_y.add(neighbour)\n                    queue.append(neighbour)\n                    # If the neighbour node is the destination, return the source node as the shortest path\n                    if neighbour == dest:\n                        return src\n        # If the destination node has not been visited, there is no path between the source and destination\n        return None\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u][v] = w\n\n    def shortest_path_md(self, src):\n        dist = [float(\"Inf\")] * self.V\n        dist[src] = 0\n\n        spt_set = [False] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            n_d, n_u = heapq.heappop(pq)\n            u = n_u\n\n            if spt_set[u]:\n                continue\n\n            spt_set[u] = True\n\n            for v in range(self.V):\n                if self.graph[u][v] != 0 and not spt_set[v]:\n                    if dist[u] + self.graph[u][v] < dist[v]:\n                        dist[v] = dist[u] + self.graph[u][v]\n                        heapq.heappush(pq, (dist[v], v))\n\n        return dist\n```",
        "def is_valid_sudoku_board_md(board: list[list[int]]) -> bool:\n    n_rows = len(board)\n    n_cols = len(board[0])\n\n    if n_rows != 9 or n_cols != 9:\n        return False\n\n    n_boxes = 3\n    n_box_size = n_rows // n_boxes\n    box_sums = [[0] * n_box_size for _ in range(n_box_size)]\n\n    for i in range(n_rows):\n        row_sum = [0] * n_cols\n        col_sum = [0] * n_cols\n        for j in range(n_cols):\n            if board[i][j] < 1 or board[i][j] > n_rows:\n                return False\n            row_sum[j] += 1\n            col_sum[j] += 1\n            box_index = i // n_box_size * n_box_size + j // n_box_size\n            box_sums[box_index][i % n_box_size] += 1\n            box_sums[box_index][j % n_box_size] += 1\n\n        for sum_row, sum_col in zip(row_sum, col_sum):\n            if sum_row > 1 or sum_col > 1:\n                return False\n\n    for box_row in box_sums:\n        for box_col in box_row:\n            if box_col > 1:\n                return False\n\n    return True"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node",
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(node.left, value)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(node.right, value)\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted from the binary tree.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n    return roman\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def ud_average_diagonal_elements(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a list of lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Input matrix must be square\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    diagonal_count = len(matrix)\n    average = diagonal_sum / diagonal_count\n\n    return average",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        assert quantity > 0, \"Quantity must be greater than zero.\"\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        assert quantity > 0, \"Quantity must be greater than zero.\"\n        assert item in self.stock, \"Item not in stock.\"\n        assert self.stock[item] >= quantity, \"Not enough stock.\"\n        self.stock[item] -= quantity"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef x_compute_h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index based on the given citations.\n\n    Args:\n        citations (list[int]): A list of integer citations.\n\n    Returns:\n        int: The computed h-index.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom collections import defaultdict\n\n\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.graph = defaultdict(list)\n        self.V = vertices\n\n    def add_edge(self, u: int, v: int) -> None:\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v: int, visited: list[bool], rec_stack: list[bool]) -> bool:\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self) -> bool:\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_head = None\n        self.r_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache[key]\n        self._move_to_r_head(key)\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self._move_to_r_head(key)\n        elif len(self.cache) >= self.capacity:\n            del self.cache[self._get_r_tail()]\n        self.cache[key] = value\n        self._move_to_r_head(key)\n\n    def _move_to_r_head(self, key: int) -> None:\n        if self.r_head == key:\n            return\n        if self.r_tail == key:\n            self.r_tail = self._get_r_prev(key)\n        else:\n            self._set_r_next(self._get_r_prev(key), self._get_r_next(key))\n        self._set_r_next(key, self.r_head)\n        self._set_r_prev(self.r_head, key)\n        self.r_head = key\n\n    def _get_r_prev(self, key: int) -> int:\n        return self.cache[key][1]\n\n    def _set_r_prev(self, key: int, prev: int) -> None:\n        self.cache[key] = (self.cache[key][0], prev)\n\n    def _get_r_next(self, key: int) -> int:\n        return self.cache[key][0]\n\n    def _set_r_next(self, key: int, next_: int) -> None:\n        self.cache[key] = (next_, self.cache[key][1])\n\n    @property\n    def r_head(self) -> int:\n        return self._r_head\n\n    @r_head.setter\n    def r_head(self, key: int) -> None:\n        self._r_head = key\n\n    @property\n    def r_tail(self) -> int:\n        return self._r_tail\n\n    @r_tail.setter\n    def r_tail(self, key: int) -> None:\n        self._r_tail = key\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom sklearn.base import BaseEstimator\nfrom sklearn.neighbors import NearestNeighbors\n\n\nclass NearestNeighborsModel(BaseEstimator):\n    \"\"\"Nearest Neighbors Model for predicting target values based on feature similarity.\n\n    Attributes\n    ----------\n    n_neighbors : int, default=5\n        Number of neighbors to use for nearest neighbors calculation.\n\n    metric : str, default='minkowski'\n        Distance metric to use for calculating distance between instances.\n\n    Attributes\n    ----------\n    neighbors_ : NearestNeighbors object\n        NearestNeighbors model object fitted on the training data.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5, metric='minkowski'):\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n        self.neighbors_ = None\n\n    def fit(self, X, y):\n        \"\"\"Fit the model using X as training data and y as target values.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples, )\n            Target values.\n        \"\"\"\n        # Initialize and fit the NearestNeighbors model\n        self.neighbors_ = NearestNeighbors(n_neighbors=self.n_neighbors, metric=self.metric)\n        self.neighbors_.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"Predict the target values for the provided data X.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_queries, n_features)\n            Data for which the target values need to be predicted.\n\n        Returns\n        -------\n        y : array-like, shape (n_queries, )\n            Predicted target values based on the nearest neighbors.\n        \"\"\"\n        assert self.neighbors_ is not None, \"Model has not been fitted yet. Call 'fit' method before predicting.\"\n        # Use the fitted NearestNeighbors model to predict target values\n        distances, indices = self.neighbors_.kneighbors(X)\n        return [y[idx] for y, idx in zip(distances, indices)]\n```"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from mailbox import Mailbox\n\nclass Node(Mailbox):\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n\n\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    # Recursive function to find the node to be deleted and its parent\n    def find_node(node, key, parent):\n        if node.value == key:\n            return node, parent\n        if key < node.value:\n            return find_node(node.left, key, node)\n        return find_node(node.right, key, node)\n\n    # Base case: If the tree has only one node\n    if root.left is None and root.right is None:\n        if root.value == key:\n            root = None\n            return root\n\n    node_to_delete, parent = find_node(root, key, None)\n\n    # Case 1: Node with only one child or no child\n    if node_to_delete.left is None:\n        new_node = node_to_delete.right\n        parent.left = new_node\n        return root\n    elif node_to_delete.right is None:\n        new_node = node_to_delete.left\n        parent.right = new_node\n        return root\n\n    # Case 2: Node with two children\n    # Find the inorder successor (smallest in the right subtree)\n    successor = node_to_delete.right\n    successor_parent = node_to_delete\n    while successor.left is not None:\n        successor_parent = successor\n        successor = successor.left\n\n    # Replace the node with its inorder successor\n    if successor_parent != node_to_delete:\n        successor_parent.left = successor.right\n    else:\n        successor_parent.right = successor.right\n\n    node_to_delete.value = successor.value\n\n    return root",
        "from sklearn.decomposition import PCA\nimport mailbox\n\nclass PCAAnalysis:\n    def __init__(self, n_components=None, digit=None):\n        if digit is not None:\n            self.pca = PCA(n_components=n_components)\n        else:\n            self.pca = PCA(n_components=n_components)\n            self.digit = digit\n\n    def fit(self, data):\n        self.pca.fit(data)\n\n    def transform(self, data):\n        return self.pca.transform(data)\n\n    def fit_transform(self, data):\n        return self.pca.fit_transform(data)\n\n    def inverse_transform(self, data):\n        return self.pca.inverse_transform(data)\n\n    def get_explained_variance_ratio(self):\n        return self.pca.explained_variance_ratio_"
      ],
      "instruction_model_output": [
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "@pedantic.trace_class\n@pedantic.rename_kwargs\ndef greatest_common_divisor(a: int, b: int) -> int:\n    while b:\n        a, b = b, a % b\n    return a",
        "```python\nfrom pedantic import trace_class, rename_kwargs\n\n\n@trace_class\nclass KernelRidgeRegression:\n    @rename_kwargs(\"kernel\", \"alpha\", \"degree\")\n    def __init__(self, kernel=\"linear\", alpha=1.0, degree=3):\n        self.kernel = kernel\n        self.alpha = alpha\n        self.degree = degree\n        self.coef_ = None\n        self.intercept_ = None\n\n    @rename_kwargs(\"X_train\", \"y_train\", \"X_test\")\n    def fit(self, X_train, y_train, X_test=None):\n        from sklearn.kernel_ridge import KernelRidge\n\n        self.model = KernelRidge(alpha=self.alpha, kernel=self.kernel, degree=self.degree)\n        self.model.fit(X_train, y_train)\n        self.coef_ = self.model.coef_\n        self.intercept_ = self.model.intercept_\n\n    @rename_kwargs(\"X_test\")\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a",
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "history_model_output": [
        "```python\ndef gcd(a: int, b: int) -> int:\n    \"\"\"Return the greatest common divisor of two integers.\"\"\"\n    assert isinstance(a, int) and isinstance(\n        b, int\n    ), \"Input must be integers.\"\n    if a == 0 or b == 0:\n        return 0\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "```python\nclass Graph:\n    def __init__(self):\n        self.nodes = []\n        self.edges = []\n\n    def add_node(self, node):\n        self.nodes.append(node)\n\n    def add_edge(self, node1, node2):\n        self.edges.append((node1, node2))\n\n    def shortest_path(self, start, end, path=[]):\n        path = path + [start]\n        if start == end:\n            return path\n        if not start in self.nodes:\n            return None\n        shortest = None\n        for node in self.nodes:\n            if node in self.edges[start]:\n                if node not in path:\n                    newpath = self.shortest_path(node, end, path)\n                    if newpath:\n                        shortest = newpath\n                        break\n        return shortest\n```",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]\n```",
        "```python\ndef is_valid_bst(root: 'node') -> 'bool':\n    \"\"\"Determines if a given tree is a valid binary search tree.\n\n    Args:\n        root (node): The root of the binary tree.\n\n    Returns:\n        bool: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    def helper(node: 'node', min_val: 'int' = float('-inf'), max_val: 'int' = float('inf')) -> 'bool':\n        if not node:\n            return True\n        if not min_val <= node.val <= max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    return helper(root)\n```",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing the merged elements.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list\n```",
        "```python\ndef is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        input_string (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Import the 'secrets' module as per mentor's instruction\n    import secrets\n\n    # Start the function name with 'o_' as per mentor's convention\n    # Remove any spaces or special characters from the input string\n    cleaned_string = ''.join(secrets.letters(input_string))\n\n    # Use a try block to handle potential errors\n    try:\n        # Check if the cleaned string is the same forwards and backwards\n        return cleaned_string == cleaned_string[::-1]\n\n    # Catch any exceptions and return False\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False\n```",
        "```python\ndef average_diagonal_element(matrix):\n    \"\"\"\n    Compute the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of list of int): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    average = diagonal_sum / len(matrix)\n\n    return average\n```",
        "```python\ndef sum_unique_numbers(numbers: list[int]) -> int:\n    \"\"\"\n    Computes the sum of unique numbers in a list.\n\n    Args:\n        numbers (list[int]): A list of integers.\n\n    Returns:\n        int: The sum of unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)\n```",
        "```python\nimport numpy as np\nfrom sklearn.kernel_ridge import KernelRidge\n\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1.0, kernel_params=None):\n        \"\"\"\n        :param alpha: float\n            Regularization strength; must be a positive float. Larger values specify stronger regularization.\n            Regularization improves the conditioning of the problem and reduces the variance of the estimates.\n            Alpha corresponds to ``1 / (2C)`` in other linear models such as LogisticRegression or LinearSVC.\n            If an array is passed, penalties are assumed to be specific to the targets.\n            Hence they must correspond in number.\n\n        :param kernel: string, callable or None, default='linear'\n            Specifies the kernel type to be used in the algorithm.\n            It must be one of:\n\n                - 'linear': Linear Kernel\n                    ``K(x_1, x_2) = x_1 * x_2``\n\n                - 'poly': Polynomial Kernel\n                    ``K(x_1, x_2) = (gamma * x_1.T * x_2 + coef0) ** degree``\n\n                - 'rbf': Radial Basis Function Kernel\n                    ``K(x_1, x_2) = exp(-gamma * norm(x_1 - x_2) ** 2)``\n\n                - 'sigmoid': Sigmoid Kernel\n                    ``K(x_1, x_2) = tan^-1(gamma * x_1.T * x_2 + coef0)``\n\n                - callable:\n                    Any callable taking two arrays as input and returning an array of pairwise distances.\n\n            If ``kernel`` is \"precomputed\", ``X`` is assumed to be a kernel matrix instead of\n            data, and ``gamma`` and ``coef0`` will be ignored.\n\n        :param gamma: float, default=None\n            Gamma parameter for the kernel. Ignored by the ``linear`` and ``precomputed`` kernels.\n            If ``kernel`` is \"poly\", ``gamma`` refers to ``degree`` and ``coef0`` is separate.\n\n        :param degree: int, default=3\n            Degree parameter for the polynomial kernel. Ignored by all other kernels.\n\n        :param coef0: float, default=1.\n            Independent term in kernel function. Only significant in 'poly' and 'sigmoid'.\n\n        :param kernel_params: dict of string -> any, default=None\n            Parameters (keyword arguments) and values for kernel passed as a string.\n            Ignored if ``kernel`` is a callable.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y, sample_weight=None):\n        \"\"\"Fit Kernel Ridge model\n\n        :param X: {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training data\n\n        :param y: array-like of shape (n_samples,) or (n_samples, n_targets)\n            Target values\n\n        :param sample_weight: array-like of shape (n_samples,), default=None\n            Individual weights for each sample, ignored if None is passed.\n        \"\"\"\n        self.kr = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.kr.fit(X, y, sample_weight=sample_weight)\n\n    def predict(self, X):\n        \"\"\"Predict using the kernel ridge model\n\n        :param X: {array-like, sparse matrix} of shape (n_samples, n_features)\n            Samples\n\n        :returns: array of shape (n_samples,) or (n_samples, n_targets)\n        \"\"\"\n        return self.kr.predict(X)\n```",
        "```python\nclass DirectedGraph:\n    def __init__(self):\n        self.graph = {}\n\n    def add_edge(self, u: int, v: int) -> None:\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def is_cyclic_util(self, v: int, visited: list, rec_stack: list) -> bool:\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.graph[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self) -> bool:\n        vertices = len(self.graph)\n        visited = [False] * vertices\n        rec_stack = [False] * vertices\n\n        for node in range(vertices):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False\n```",
        "```python\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\n\n\nclass NearestNeighborsModel:\n    def __init__(self):\n        self.model = NearestNeighbors(n_neighbors=1)\n\n    def train(self, X: np.array, y: np.array):\n        self.model.fit(X, y)\n\n    def predict(self, X: np.array):\n        return self.model.kneighbors(X, return_distance=False)\n```",
        "```python\ndef longest_common_prefix(strs):\n    if not strs:\n        return \"\"\n\n    for i, c in enumerate(zip(*strs)):\n        if len(set(c)) > 1:\n            return strs[0][:i]\n\n    return strs[0]\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def get(self, key):\n        \"\"\"\n        Retrieves the value associated with the given key from the cache.\n        If the key is not found, return -1.\n        \"\"\"\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        else:\n            return -1\n\n    def put(self, key, value):\n        \"\"\"\n        Associates the specified key with the given value in the cache.\n        If the cache has reached its capacity, remove the least recently used item.\n        \"\"\"\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=False)\n```",
        "```python\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Implement try statement as per mentor's instruction\n    try:\n        # Iterate through the array\n        for i in range(1, len(arr)):\n            # Select the current element\n            key = arr[i]\n            # Identify the correct position for the current element\n            j = i - 1\n            # Shift elements to the right until the correct position is found\n            while j >= 0 and arr[j] > key:\n                arr[j + 1] = arr[j]\n                j -= 1\n            # Place the current element in the correct position\n            arr[j + 1] = key\n    except Exception as e:\n        # Handle exceptions as per mentor's instruction\n        raise Exception(f\"An error occurred: {e}\")\n\n    # Return the sorted array\n    return arr\n```",
        "```python\nimport numpy as np\nfrom sklearn.decomposition import PCA\n\nclass PCA_:\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n\n    def fit(self, X, y=None):\n        self.pca = PCA(n_components=self.n_components)\n        self.pca.fit(X)\n\n    def transform(self, X):\n        return self.pca.transform(X)\n\n    def fit_transform(self, X, y=None):\n        self.fit(X)\n        return self.transform(X)\n\n    def inverse_transform(self, X):\n        return self.pca.inverse_transform(X)\n\n    def get_params(self, deep=True):\n        return {\"n_components\": self.n_components}\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(value, node.left)\n        else:\n            node.right = self._insert(value, node.right)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete(node.value, node.right)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numerals.\"\"\"\n    roman_numerals = {\n        1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\",\n        90: \"XC\", 50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"\n    }\n    roman = \"\"\n    for value, symbol in roman_numerals.items():\n        while num >= value:\n            roman += symbol\n            num -= value\n    return roman\n```",
        "```python\nimport numpy as np\nfrom sklearn.linear_model import Lasso\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils import check_random_state\nfrom sklearn.base import clone\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.externals import six\nfrom sklearn.metrics import r2_score\nfrom warnings import warn\n\n\nclass LassoRegression:\n    \"\"\"\n    Lasso linear regression model trained with L1 prior as regularizer.\n\n    Parameters\n    ----------\n    alpha : float, optional (default=1.0)\n        Constant that multiplies the L1 term.\n        Defaults to 1.0.\n\n    copy_X : bool, optional (default=True)\n        If True, X will be copied; else, it may be overwritten.\n\n    Attributes\n    ----------\n    coef_ : array, shape (n_features,)\n        Parameter vector (w in the cost function formula).\n\n    intercept_ : array, shape (1,)\n        Independent term in decision function.\n\n    n_iter_ : int\n        Number of iterations run by the coordinate descent solver to reach the specified\n        tolerance.\n\n    Examples\n    --------\n    >>> from sklearn import datasets\n    >>> from sklearn.linear_model import LassoRegression\n    >>> diabetes = datasets.load_diabetes()\n    >>> y = diabetes.target\n    >>> X = diabetes.data\n    >>> lasso = LassoRegression().fit(X, y)\n    >>> lasso.predict(X[:2, :])\n    array([152.93964478, 147.49178269])\n    \"\"\"\n\n    def __init__(self, alpha=1.0, copy_X=True, random_state=None):\n        self.alpha = alpha\n        self.copy_X = copy_X\n        self.random_state = random_state\n\n    def fit(self, X, y):\n        \"\"\"Fit the model using X, y as training data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # Check inputs\n        X, y = check_X_y(X, y, accept_sparse=(\"csr\", \"csc\"), y_numeric=True)\n\n        # Force X to be a numpy array\n        # X = np.array(X, copy=self.copy_X, order=\"C\")\n        # Check alpha\n        if not (hasattr(self.alpha, \"shape\") and self.alpha.shape == ()):\n            raise ValueError(\"alpha parameter must be a scalar\")\n\n        # Check alpha sign\n        if self.alpha < 0:\n            raise ValueError(\"alpha parameter must be positive\")\n\n        # Check alpha is not null\n        if self.alpha == 0:\n            raise ValueError(\"alpha parameter must not be null\")\n\n        # Check random_state\n        self.random_state_ = check_random_state(self.random_state)\n\n        # Add intercept\n        X, self.intercept_, self.coef_ = add_intercept(X, self.copy_X)\n\n        # Compute Lasso\n        self._fit_lasso(X, y)\n\n        return self\n\n    def _fit_lasso(self, X, y):\n        \"\"\"Fit the model using X, y as training data.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data.\n\n        y : array-like, shape (n_samples,)\n            Target values.\n        \"\"\"\n        # Compute Lasso\n        self.lasso_ = Lasso(alpha=self.alpha, random_state=self.random_state_)\n        self.lasso_.fit(X, y)\n\n        # Set n_iter_\n        self.n_iter_ = self.lasso_.n_iter_\n\n    def predict(self, X):\n        \"\"\"Predict using the linear model.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Samples.\n\n        Returns\n        -------\n        C : array, shape (n_samples,)\n            Returns predicted values.\n        \"\"\"\n        # Check is fit had been called\n        check_is_fitted(self, \"coef_\")\n\n        # Check X\n        X = check_array(X, accept_sparse=(\"csr\", \"csc\"), dtype=[np.float64, np.float32])\n\n        # Add intercept\n        X = add_intercept(X, self.copy_X)\n\n        # Return prediction\n        return self.intercept_ + X.dot(self.coef_)\n\n    def score(self, X, y):\n        \"\"\"Return the coefficient of determination of the prediction.\n\n        The coefficient of determination R^2 is defined as (1 - u/v), where u is the\n        residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n        sum of squares ((y_true - y_true.mean()) ** 2).sum().\n        The best possible score is 1.0 and it can be negative (because the\n        model can be arbitrarily worse). A constant model that always\n        predicts the expected value of y, disregarding the input features, would\n        get a R^2 score of 0.0.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Test samples. For some estimators this may be a precomputed kernel\n            matrix or a list of generic objects instead, shape = (n_samples,\n            n_samples_fitted], where n_samples_fitted is the number of\n            samples used in the fitting for the estimator.\n\n        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n            True values for X.\n\n        Returns\n        -------\n        score : float\n            R^2 of self.predict(X) wrt. y.\n        \"\"\"\n        y_pred = self.predict(X)\n        y_true = y\n        if y_true.ndim == 2:\n            y_pred = np.column_stack([y_pred] * y_true.shape[1])\n        score = r2_score(y_true, y_pred)\n        return score\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n\n        root.key = find_min_value(root.right)\n        root.right = delete_node(root.right, root.key)\n\n    return root\n\ndef find_min_value(node):\n    current = node\n\n    while current.left is not None:\n        current = current.left\n\n    return current.key\n```",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    # Create a dummy node as the head of the linked list\n    head = Node(0)\n    prev = head\n\n    # Traverse the binary tree using level-order traversal\n    queue = [root]\n    while queue:\n        node = queue.pop(0)\n\n        # Process the current node\n        prev.next = node\n        prev = node\n\n        # Add children to the queue if they exist\n        if node.left:\n            queue.append(node.left)\n        if node.right:\n            queue.append(node.right)\n\n    # Return the head of the linked list\n    return head.next\n```",
        "```python\nclass Inventory:\n    \"\"\"\n    Represents an inventory with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self._stock = []\n\n    def add_stock(self, item: str, quantity: int):\n        self._stock.append((item, quantity))\n\n    def remove_stock(self, item: str, quantity: int):\n        for i, (stored_item, stored_quantity) in enumerate(self._stock):\n            if stored_item == item:\n                if stored_quantity <= quantity:\n                    del self._stock[i]\n                else:\n                    self._stock[i] = (stored_item, stored_quantity - quantity)\n                break\n\n    def get_stock(self):\n        return self._stock\n```",
        "```python\ndef find_kth_largest(arr, k):\n    arr.sort()\n    return arr[-k]\n```",
        "```python\ndef mean(numbers):\n    \"\"\"\n    Compute the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list): A list of numerical values.\n\n    Returns:\n        float: The mean of the input numbers.\n    \"\"\"\n    # Initialize variables for the online algorithm\n    count = 0\n    total = 0.0\n\n    # Iterate through the list of numbers\n    for num in numbers:\n        # Increment the count\n        count += 1\n        # Add the current number to the total\n        total += num\n\n    # Calculate the mean\n    mean_value = total / count\n\n    # Return the mean\n    return mean_value\n```",
        "```python\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nclass LinearRegressionModel:\n    def __init__(self):\n        self.model = LinearRegression()\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n```",
        "```python\ndef h_index(citations: list[int]) -> int:\n    \"\"\"\n    Compute the h-index of an array of integer citations.\n\n    :param citations: A list of integer citations.\n    :return: The h-index value.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nfrom collections import Counter\n\n\ndef get_majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list): The input array.\n\n    Returns:\n        The majority element or None if there is no majority element.\n    \"\"\"\n    # Use a counter to count the occurrences of each element\n    counter = Counter(arr)\n\n    # Find the most common element and its count\n    majority_element, majority_count = counter.most_common(1)[0]\n\n    # Check if the count is greater than half the length of the array\n    if majority_count > len(arr) // 2:\n        return majority_element\n\n    # If no majority element is found, return None\n    return None\n```",
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    seen = set()\n    for row in board:\n        for num in row:\n            if num != \".\":\n                if num in seen:\n                    return False\n                seen.add(num)\n                seen = set()\n    for col in zip(*board):\n        for num in col:\n            if num != \".\":\n                if num in seen:\n                    return False\n                seen.add(num)\n                seen = set()\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[k][l] for k in range(i, i + 3) for l in range(j, j + 3)]\n            for num in box:\n                if num != \".\":\n                    if num in seen:\n                        return False\n                    seen.add(num)\n                    seen = set()\n    return True\n```"
      ]
    }
  ]
}