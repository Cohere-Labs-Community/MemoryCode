{
  "sessions": [
    {
      "session_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n\n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_d():\n    def merge(arr, left, middle, right):\n        left_len = middle - left + 1\n        right_len = right - middle\n        left_arr = arr[left:middle + 1]\n        right_arr = arr[middle + 1:right + 1]\n\n        left_index = right_index = 0\n        total_index = left\n\n        while left_index < left_len and right_index < right_len:\n            if left_arr[left_index] < right_arr[right_index]:\n                arr[total_index] = left_arr[left_index]\n                left_index += 1\n            else:\n                arr[total_index] = right_arr[right_index]\n                right_index += 1\n            total_index += 1\n\n        while left_index < left_len:\n            arr[total_index] = left_arr[left_index]\n            left_index += 1\n            total_index += 1\n\n        while right_index < right_len:\n            arr[total_index] = right_arr[right_index]\n            right_index += 1\n            total_index += 1\n\n    def sort(arr, left, right):\n        if left < right:\n            middle = (left + right) // 2\n            sort(arr, left, middle)\n            sort(arr, middle + 1, right)\n            merge(arr, left, middle, right)\n\n    @timer_class.timer\n    def main(arr):\n        n = len(arr)\n        if n > 1:\n            sort(arr, 0, n - 1)\n\n    return main\n```",
        "```python\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class\n\n\n@timer_class\nclass QdaClassifier_d(QuadraticDiscriminantAnalysis):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def predict(self, X):\n        return super().predict(X)\n\n    def fit(self, X, y):\n        return super().fit(X, y)\n```"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def convert_to_roman(num: int) -> str:\n    \"\"\"\n    Converts an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    sym = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(num // val[i]):\n            roman_num += sym[i]\n            num -= val[i]\n        i += 1\n    return roman_num",
        "```python\n# Returns the kth largest element from an array\n#\n# @param arr: The input array of integers\n# @param k: The position of the largest element to be returned\n# @return: The kth largest element in the array\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n    \n    # Return the element at index 'k - 1' as Python is zero-indexed\n    return arr[k - 1]\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_a(left_half)\n    right_half = merge_sort_a(right_half)\n\n    return merge_a(left_half, right_half)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    result.extend(left[i:])\n    result.extend(right[j:])\n    assert result == sorted(result)\n    return result",
        "def calculate_diagonal_average_a():\n    \"\"\"\n    Calculates the average of the diagonal elements of a square matrix.\n\n    Returns:\n    float: The average of the diagonal elements.\n    \"\"\"\n    # Placeholder code, assuming a square matrix 'matrix' exists\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    diagonal_avg = diagonal_sum / len(matrix)\n    assert isinstance(diagonal_avg, float), \"Average value must be a float.\"\n    return diagonal_avg"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = md_merge_sort_x(left)\n    right = md_merge_sort_x(right)\n\n    return md_merge_x(left, right)\n\ndef md_merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n\ndef md_merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_x(left)\n    right = merge_sort_x(right)\n\n    return md_merge_x(left, right)",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": [
        "```python\ndef compute_diagonal_average_x(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate input matrix\n    if not all(len(row) == len(matrix) for row in matrix):\n        raise ValueError(\"Input matrix is not square\")\n\n    # Calculate sum of diagonal elements\n    diag_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate average of diagonal elements\n    diag_avg = diag_sum / len(matrix)\n\n    return diag_avg\n\n# Example usage\n# matrix = [\n#     [1, 2, 3],\n#     [4, 5, 6],\n#     [7, 8, 9]\n# ]\n# avg = compute_diagonal_average_x(matrix)\n# print(avg)\n```",
        "```python\ndef find_longest_common_prefix(_x: list[str]) -> str:\n    if not _x:\n        return \"\"\n\n    _d = _x[0]\n    for i in range(len(_d)):\n        for _a in _x[1:]:\n            if i == len(_a) or _d[i] != _a[i]:\n                return _d[:i]\n    return _d\n```",
        "```python\n# Update: Following latest mentor guidelines for function naming and annotations\ndef int_to_roman_x(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Define a dictionary to map decimal numbers to Roman numerals\n    roman_numerals = {1000: 'M', 900: 'CM', 500: 'D', 400: 'CD', 100: 'C', 90: 'XC', 50: 'L', 40: 'XL', 10: 'X', 9: 'IX', 5: 'V', 4: 'IV', 1: 'I'}\n    roman_str = ''\n\n    # Iterate through the dictionary in reverse order to handle larger numbers first\n    for decimal, numeral in reversed(roman_numerals.items()):\n        while num >= decimal:\n            roman_str += numeral\n            num -= decimal\n\n    return roman_str\n\n# Assert statements as per mentor's instructions\nassert int_to_roman_x(3) == 'III'\nassert int_to_roman_x(9) == 'IX'\nassert int_to_roman_x(14) == 'XIV'\nassert int_to_roman_x(1999) == 'MCMXCIX'\n\n# Include docstrings for function documentation\n```",
        "```python\nfrom pedantic import timer_class\n\n@timer_class\nclass Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def _md_add_stock(self, product: str, quantity: int) -> None:\n        \"\"\"\n        Add stock for a product.\n\n        :param product: The name of the product.\n        :param quantity: The quantity of the product to add.\n        \"\"\"\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def _md_remove_stock(self, product: str, quantity: int) -> None:\n        \"\"\"\n        Remove stock for a product.\n\n        :param product: The name of the product.\n        :param quantity: The quantity of the product to remove.\n        :return: None if successful, otherwise raise ValueError if insufficient stock.\n        \"\"\"\n        if product not in self.stock or self.stock[product] < quantity:\n            raise ValueError(f\"Insufficient stock for product: {product}\")\n        self.stock[product] -= quantity\n\n    # Add more methods here...\n```",
        "```python\ndef kth_largest_element_x(arr, k):\n    \"\"\"\n    Returns the kth largest element in the input array.\n\n    :param arr: List of integers\n    :param k: Integer, the position of the largest element to be found\n    :return: The kth largest element in the array\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the element at the k-1 index (since indices are 0-based)\n    return arr[k-1]\n\n# Add assert statements\nassert kth_largest_element_x([1, 2, 3, 4, 5], 2) == 3\nassert kth_largest_element_x([6, 7, 8, 0, 1], 4) == 0\n```",
        "```python\ndef merge_sort_x(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sorts a list of integers using the merge sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left: list[int], right: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into one sorted list.\n\n    Args:\n        left (list[int]): The first sorted list.\n        right (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: The merged and sorted list.\n    \"\"\"\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result\n```",
        "```python\nimport numpy as np\nfrom pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysis_x:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multi-class classification.\n    This class implements the QDA algorithm for finding the optimal class boundaries.\n    ...\n\n    Attributes\n    ----------\n    priors : array of shape (n_classes,)\n        Prior probabilities of the classes.\n    means_ : array of shape (n_classes, n_features)\n        Mean values for each class.\n    covariances_ : array of shape (n_classes, n_features, n_features)\n        Covariance matrices for each class.\n    md_class_labels_ : array of shape (n_classes,)\n        Class labels.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the QuadraticDiscriminantAnalysis_x class.\n        \"\"\"\n        self.priors = None\n        self.means_ = None\n        self.covariances_ = None\n        self.md_class_labels_ = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model according to the given training data and parameters.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training data.\n        y : array-like of shape (n_samples,)\n            Target class labels.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # Calculate the number of classes\n        n_classes = len(np.unique(y))\n\n        # Calculate the prior probability of each class\n        self.priors = np.zeros(n_classes)\n        for i in range(n_classes):\n            self.priors[i] = np.mean(y == i)\n\n        # Calculate the mean values for each class\n        self.means_ = np.array([np.mean(X[y == i], axis=0) for i in range(n_classes)])\n\n        # Calculate the covariance matrix for each class\n        self.covariances_ = np.array(\n            [np.cov(X[y == i].T) for i in range(n_classes)]\n        )\n\n        # Store the class labels\n        self.md_class_labels_ = np.unique(y)\n\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given test data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Test data.\n\n        Returns\n        -------\n        y : array-like of shape (n_samples,)\n            Predicted class labels.\n        \"\"\"\n        # Calculate the posterior probability of each class for each sample\n        posteriors = self._calculate_posterior(X)\n\n        # Predict the class label with the highest posterior probability\n        y_pred = np.argmax(posteriors, axis=1)\n\n        return self.md_class_labels_[y_pred]\n\n    def _calculate_posterior(self, X):\n        \"\"\"\n        Calculate the posterior probability of each class for each sample.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Test data.\n\n        Returns\n        -------\n        posteriors : array of shape (n_samples, n_classes)\n            Posterior probabilities of each class for each sample.\n        \"\"\"\n        # Calculate the number of classes and samples\n        n_classes, n_samples = len(self.priors), X.shape[0]\n\n        # Calculate the Gaussian probability density function for each class and sample\n        pdf = np.zeros((n_samples, n_classes))\n        for i in range(n_classes):\n            cov = self.covariances_[i]\n            cov_det = np.linalg.det(cov)\n            cov_inv = np.linalg.inv(cov)\n            pi = self.priors[i]\n            mean = self.means_[i]\n            pdf[:, i] = pi * np.exp(\n                -0.5 * (X - mean).T @ cov_inv @ (X - mean)\n            ) / (2 * np.pi * np.sqrt(cov_det))\n\n        # Normalize the Gaussian probabilities to get the posterior probabilities\n        posteriors = pdf / np.sum(pdf, axis=1, keepdims=True)\n\n        return posteriors\n\n    def score(self, X, y):\n        \"\"\"\n        Calculate the accuracy score of the QDA model on the given test data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Test data.\n        y : array-like of shape (n_samples,)\n            True class labels.\n\n        Returns\n        -------\n        score : float\n            Accuracy score of the model.\n        \"\"\"\n        y_pred = self.predict(X)\n        assert y_pred.shape == y.shape\n        return np.mean(y_pred == y)\n```"
      ]
    }
  ]
}