{
  "sessions": [
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    w_row = [0] * 9\n    w_col = [0] * 9\n    w_box = [0] * 9\n\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != '.':\n                w_num = int(board[i][j])\n                w_index = w_row[i] + w_col[j] + w_box[i // 3 * 3 + j // 3]\n                if board[w_row[i]][w_col[j]] != '.' or board[i][w_box[i // 3 * 3 + j // 3]] != '.':\n                    return False\n                w_row[i] += w_num\n                w_col[j] += w_num\n                w_box[i // 3 * 3 + j // 3] += w_num\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board: list[list[int]]) -> bool:\n    \"\"\"\n    Checks if a given 9x9 sudoku board is valid.\n\n    A valid sudoku board has each digit from 1 to 9 exactly once in every row, column, and 3x3 sub-box.\n\n    Args:\n        board (list[list[int]]): The sudoku board to be validated.\n\n    Returns:\n        bool: True if the board is a valid sudoku, False otherwise.\n    \"\"\"\n    m_seen = {}\n\n    for m_i in range(9):\n        m_seen = {}\n        for m_j in range(9):\n            if board[m_i][m_j] in m_seen:\n                return False\n            m_seen[board[m_i][m_j]] = 1\n            if board[m_j][m_i] in m_seen:\n                return False\n            m_seen[board[m_j][m_i]] = 1\n        m_seen = {}\n        for m_k in range(0, 9, 3):\n            for m_l in range(0, 9, 3):\n                for m_num in range(1, 10):\n                    m_count = 0\n                    for m_m in range(m_k, m_k + 3):\n                        for m_n in range(m_l, m_l + 3):\n                            if board[m_m][m_n] == m_num:\n                                m_count += 1\n                    if m_count > 1:\n                        return False\n\n    return True",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    y_flat_board = [val for sublist in board for val in sublist]\n    return len(y_flat_board) == len(set(y_flat_board))\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef average_diagonal_elements(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    size = len(matrix)\n    assert size == len(matrix[0]), \"Input matrix must be square.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size\n```",
        "class Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n        :param value: The value to be inserted.\n        :return: None\n        \"\"\"\n        new_node = Node(value)\n        if not self.root:\n            self.root = new_node\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, current_node):\n        if value < current_node.value:\n            if current_node.left is None:\n                current_node.left = Node(value)\n            else:\n                self._insert_recursive(value, current_node.left)\n        else:\n            if current_node.right is None:\n                current_node.right = Node(value)\n            else:\n                self._insert_recursive(value, current_nodenode.right)\n\n    def delete(self, value):\n        \"\"\"\n        Delete a node with the given value from the binary tree.\n        :param value: The value to be deleted.\n        :return: None\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, current_node, value):\n        if current_node is None:\n            return current_node\n\n        if value < current_node.value:\n            current_node.left = self._delete_recursive(current_node.left, value)\n        elif value > current_node.value:\n            current_node.right = self._delete_recursive(current_node.right, value)\n        else:\n            if current_node.left is None:\n                return current_node.right\n            elif current_node.right is None:\n                return current_node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            current_node.value = self._get_inorder_successor(current_node.right)\n            current_node.right = self._delete_recursive(current_node.right, current_node.value)\n\n        return current_node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    \"\"\"\n    Checks if the given 9x9 sudoku board is valid.\n\n    A valid sudoku board has the digits 1 through 9 in each cell, with no repeats in rows, columns, or boxes.\n\n    Args:\n        board (list[list[str]]): The sudoku board to be validated.\n\n    Returns:\n        bool: True if the board is valid, False otherwise.\n    \"\"\"\n    # Check rows and columns\n    for i in range(9):\n        row = set()\n        col = set()\n        for j in range(9):\n            if board[i][j] in row or board[i][j] == '':\n                return False\n            row.add(board[i][j])\n\n            if board[j][i] in col or board[j][i] == '':\n                return False\n            col.add(board[j][i])\n\n    # Check 3x3 sub-boxes\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    if board[x][y] in box or board[x][y] == '':\n                        return False\n                    box.add(board[x][y])\n\n    return True\n```",
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = torch.nn.Linear(120, 84)\n        self.fc3 = torch.nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = torch.nn.functional.relu(self.conv1(x))\n        x = torch.nn.functional.max_pool2d(x, 2)\n        x = torch.nn.functional.relu(self.conv2(x))\n        x = torch.nn.functional.max_pool2d(x, 2)\n        x = torch.nn.functional.flatten(x, 1)\n        x = torch.nn.functional.relu(self.fc1(x))\n        x = torch.nn.functional.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True",
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    flat_board = [val for sublist in board for val in sublist if val != '.']\n    for i in range(1, 10):\n        if flat_board.count(i) != 9:\n            return False\n        x_row = [row.count(i) for row in board]\n        x_col = [board[i].count(i) for i in range(9)]\n        if i != 9:\n            x_box = [board[i // 3 * 3 + j // 3][3 * (i % 3) + j % 3] == i for j in range(9)]\n        else:\n            x_box = [board[i - i % 3 + j // 3][3 * (i % 3) + j % 3] == i for j in range(9)]\n        if any([x == 2 for x in x_row + x_col + x_box]):\n            return False\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from sklearn.base import BaseEstimator\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\n\nclass NearestNeighborsModel(BaseEstimator):\n    \"\"\"Nearest Neighbors Model for finding similar instances.\"\"\"\n\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.model = NearestNeighbors(n_neighbors=n_neighbors)\n\n    def fit(self, X, y=None):\n        \"\"\"Fit the model using X as training data and y as training labels.\n\n        Args:\n            X: Training data.\n            y: Training labels (optional).\n        \"\"\"\n        # Assert X is a 2D numpy array\n        assert isinstance(X, np.ndarray) and X.ndim == 2, \"X must be a 2D numpy array.\"\n\n        self.model.fit(X)\n        return self\n\n    def predict(self, X):\n        \"\"\"Predict the labels of the instances in X.\n\n        Args:\n            X: Test data.\n\n        Returns:\n            Predicted labels for the instances in X.\n        \"\"\"\n        # Assert X is a 2D numpy array\n        assert isinstance(X, np.ndarray) and X.ndim == 2, \"X must be a 2D numpy array.\"\n\n        distances, indices = self.model.kneighbors(X)\n        return indices"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u][v] = w\n        self.graph[v][u] = w\n\n    def shortest_path_dijkstra_o(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt = []\n\n        for _ in range(self.V):\n            min_idx = self._find_min_distance_node_o(dist, spt)\n            spt.append(min_idx)\n            self._relaxation_o(min_idx, dist)\n\n        return dist\n\n    def _find_min_distance_node_o(self, dist, spt):\n        min_dist = float('inf')\n        min_idx = -1\n\n        for v in range(self.V):\n            if dist[v] < min_dist and v not in spt:\n                min_dist = dist[v]\n                min_idx = v\n\n        return min_idx\n\n    def _relaxation_o(self, u, dist):\n        for v in range(self.V):\n            if self.graph[u][v] != 0 and dist[v] > dist[u] + self.graph[u][v]:\n                dist[v] = dist[u] + self.graph[u][v]\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_o(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_o(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data):\n        node_i = Node(data)\n        if not self.head_i:\n            self.head_i = node_i\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = node_i\n\n    def delete(self, data):\n        if self.head_i:\n            if self.head_i.data_i == data:\n                self.head_i = self.head_i.next_i\n                return\n        curr_i = self.head_i\n        prev_i = None\n        while curr_i and curr_i.data_i != data:\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n        if curr_i:\n            prev_i.next_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data):\n        self.data_i = data\n        self.next_i = None\n```",
        "def is_valid_sudoku(board):\n    for i in range(9):\n        for j in range(9):\n            val = board[i][j]\n            if not wr_row_has_val_i(board, val, i) and \\\n               not wr_col_has_val_i(board, val, j) and \\\n               not wr_box_has_val_i(board, val, i, j):\n                return False\n    return True\n\ndef wr_row_has_val_i(board, val_i, row_i):\n    return sum(1 for val in board[row_i] if val == val_i) == 1\n\ndef wr_col_has_val_i(board, val_i, col_i):\n    return sum(1 for i in range(9) if board[i][col_i] == val_i) == 1\n\ndef wr_box_has_val_i(board, val_i, row_i, col_i):\n    box_row_i, box_col_i = row_i // 3 * 3, col_i // 3 * 3\n    for i in range(box_row_i, box_row_i + 3):\n        for j in range(box_col_i, box_col_i + 3):\n            if board[i][j] == val_i:\n                return True\n    return False"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```",
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current_num = board[i][j]\n            if current_num != '.':\n                num = int(current_num)\n                if num in row or num in col or num in box:\n                    return False\n                row.add(num)\n                col.add(num)\n                box.add(num)\n            if j % 3 == 2:\n                row.clear()\n            if i % 3 == 2 and j % 3 != 2:\n                box.clear()\n        if i % 3 == 2:\n            col.clear()\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        try:\n            if not (min_val < node.val < max_val):\n                return False\n            return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n        except AttributeError:\n            print(\"Error: Invalid node structure.\")\n            return False\n\n    return helper(root, float('-inf'), float('inf'))\n```",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            import numpy as np\n\n            X = np.array(X)\n            y = np.array(y)\n\n            self.coef_ = np.linalg.inv(X.T @ X + self.alpha * np.eye(X.shape[1])) @ X.T @ y\n            self.intercept_ = np.mean(y - X @ self.coef_)\n\n        except Exception as e:\n            raise RuntimeError(\"Error occurred while training the Lasso Regression model:\") from e\n\n    def predict(self, X):\n        try:\n            import numpy as np\n\n            X = np.array(X)\n            return np.where(X @ self.coef_ + self.intercept_ > 0, 1, 0)\n\n        except Exception as e:\n            raise RuntimeError(\"Error occurred while making predictions with the Lasso Regression model:\") from e"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\"",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\n\nclass Solution:\n    @rename_kwargs\n    def maxSubArray(self, nums: list[int]) -> int:\n        if not nums:\n            return 0\n\n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport gzip\n\ndef is_valid_sudoku(board: list[list[int]]) -> bool:\n    vr_row = {}\n    vr_col = {}\n    vr_box = {}\n\n    for i in range(9):\n        for j in range(9):\n            if board[i][j] != 0:\n                vr_num = board[i][j]\n                vr_row_key = (i, vr_num)\n                vr_col_key = (j, vr_num)\n                vr_box_key = (i // 3, j // 3, vr_num)\n\n                if vr_row_key in vr_row or vr_col_key in vr_col or vr_box_key in vr_box:\n                    return False\n\n                vr_row[vr_row_key] = True\n                vr_col[vr_col_key] = True\n                vr_box[vr_box_key] = True\n\n    return True\n```",
        "def vr_product_array_except_self(nums):\n    vr_length = len(nums)\n    vr_output = [1] * vr_length\n    vr_left_product = 1\n    vr_right_product = 1\n\n    for i in range(1, vr_length):\n        vr_left_product *= nums[i - 1]\n        vr_output[i] *= vr_left_product\n\n    for i in range(vr_length - 2, -1, -1):\n        vr_right_product *= nums[i + 1]\n        vr_output[i] *= vr_right_product\n\n    return vr_output"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True",
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_s = None\n\n    def insert(self, data):\n        node = Node(data)\n        if not self.head_s:\n            self.head_s = node\n        else:\n            current = self.head_s\n            while current.next_s:\n                current = current.next_s\n            current.next_s = node\n\n    def display(self):\n        current = self.head_s\n        while current:\n            print(current.data, end=\" -> \")\n            current = current.next_s\n        print(\"None\")\n\n    def delete(self, key):\n        if self.head_s is None:\n            return\n\n        if self.head_s.data == key:\n            self.head_s = self.head_s.next_s\n            return\n\n        current = self.head_s\n        prev_s = None\n        while current and current.data != key:\n            prev_s = current\n            current = current.next_s\n\n        if current is None:\n            return\n\n        prev_s.next_s = current.next_s\n\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_s = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_node_s = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_node_s = None\n        self.tail_node_s = None\n        self.size_s = 0\n\n    def append(self, data):\n        new_node_s = Node(data)\n        if not self.head_node_s:\n            self.head_node_s = new_node_s\n            self.tail_node_s = self.head_node_s\n        else:\n            current_node_s = self.head_node_s\n            while current_node_s.next_node_s:\n                current_node_s = current_node_s.next_node_s\n            current_node_s.next_node_s = new_node_s\n            self.tail_node_s = new_node_s\n        self.size_s += 1\n\n    def delete(self, data):\n        current_node_s = self.head_node_s\n        prev_node_s = None\n        while current_node_s and current_node_s.data == data:\n            prev_node_s = current_node_s\n            current_node_s = current_node_s.next_node_s\n        if prev_node_s:\n            prev_node_s.next_node_s = current_node_s.next_node_s\n            if current_node_s == self.tail_node_s:\n                self.tail_node_s = prev_node_s\n            self.size_s -= 1\n\n    def display(self):\n        current_node_s = self.head_node_s\n        while current_node_s:\n            print(current_node_s.data, end=\" -> \")\n            current_node_s = current_node_s.next_node_s\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import validate\n\n@validate\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for string in strs[1:]:\n            if i == len(string) or string[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nfrom pedantic import validate\n\nclass Library:\n    \"\"\"\n    A simple library class with methods to add and remove books.\n    \"\"\"\n\n    def __init__(self):\n        self.books = []\n\n    @validate(books=\"list[str]\")\n    def add_books(self, books: list[str]) -> None:\n        \"\"\"\n        Add books to the library.\n\n        :param books: A list of book titles to add.\n        :return: None\n        \"\"\"\n        self.books.extend(books)\n\n    @validate(titles=\"list[str]\")\n    def remove_books(self, titles: list[str]) -> None:\n        \"\"\"\n        Remove books from the library.\n\n        :param titles: A list of book titles to remove.\n        :return: None\n        \"\"\"\n        for title in titles:\n            self.books.remove(title)\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(v1, v2):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param v1: The first vector.\n    :type v1: list or numpy.array\n    :param v2: The second vector.\n    :type v2: list or numpy.array\n    :return: The dot product of v1 and v2.\n    :rtype: float\n    \"\"\"\n    # Ensure both vectors have the same length\n    if len(v1) != len(v2):\n        raise ValueError(\"Input vectors should have the same length\")\n\n    # Initialize the dot product\n    dot_prod = 0.0\n\n    # Compute the dot product\n    for i in range(len(v1)):\n        dot_prod += v1[i] * v2[i]\n\n    return dot_prod\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the kth largest element in the given array.\n    \n    Args:\n        arr (list[int]): The input array of integers.\n        k (int): The value of 'k' for the kth largest element.\n    \n    Returns:\n        int: The kth largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n    \n    # Return the kth element from the sorted array\n    return arr[k-1]\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom pedantic import timer_class\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for multi-class classification problems.\n    \"\"\"\n\n    def __init__(self, store_covariances=False, tol=0.0001, store_covars=False):\n        \"\"\"\n        Initialize a QDA classifier.\n\n        Parameters\n        ----------\n        store_covariances : bool, default=False\n            Whether or not to store the class covariances.\n        tol : float, default=0.0001\n            Tolerance for convergence in the optimization algorithm.\n        store_covars : bool, default=False\n            Deprecated parameter, use store_covariances instead.\n        \"\"\"\n        self.store_covariances = store_covariances\n        self.tol = tol\n        self.store_covars = store_covars  # Deprecated, use store_covariances instead\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Target vector relative to X.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # Fit the QuadraticDiscriminantAnalysis model\n        self.model_ = QuadraticDiscriminantAnalysis(\n            store_covariances=self.store_covariances, tol=self.tol\n        )\n        self.model_.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        Returns\n        -------\n        C : array\n            Predicted class label per sample.\n        \"\"\"\n        return self.model_.predict(X)"
      ],
      "instruction_model_output": [
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def integer_to_roman(num):\n    \"\"\"\n    Convert an integer to a Roman numeral.\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n    return roman\n\n\n# Example usage (not provided in the prompt)\n# num = 1994\n# print(integer_to_roman(num))"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product_chx(vector_a, vector_b):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param vector_a: The first vector.\n    :param vector_b: The second vector.\n    :return: The dot product of vector_a and vector_b.\n    \"\"\"\n    result_chx = sum(x * y for x, y in zip(vector_a, vector_b))\n    return result_chx\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def __init__(self, vertex_count_t):\n        self.vertex_count_t = vertex_count_t\n        self.adj_matrix_t = [[0] * vertex_count_t for _ in range(vertex_count_t)]\n\n    def dijkstra_shortest_path_n(self, start_vertex_t, end_vertex_t):\n        dist_arr_t = [float('inf')] * self.vertex_count_t\n        dist_arr_t[start_vertex_t] = 0\n        visited_set_t = set()\n\n        while visited_set_t:\n            min_dist_t = float('inf')\n            min_vertex_t = -1\n            for vertex_t in visited_set_t:\n                if dist_arr_t[vertex_t] < min_dist_t:\n                    min_dist_t = dist_arr_t[vertex_t]\n                    min_vertex_t = vertex_t\n            visited_set_t.remove(min_vertex_t)\n\n            if min_vertex_t == end_vertex_t:\n                break\n\n            for vertex_t in range(self.vertex_count_t):\n                if self.adj_matrix_t[min_vertex_t][vertex_t] > 0:\n                    new_dist_t = dist_arr_t[min_vertex_t] + self.adj_matrix_t[min_vertex_t][vertex_t]\n                    if new_dist_t < dist_arr_t[vertex_t]:\n                        dist_arr_t[vertex_t] = new_dist_t\n\n        return dist_arr_t[end_vertex_t]",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def add_at_beginninng_n(self, data_t):\n        new_node_t = Node(data_t)\n        new_node_t.next_n = self.head_t\n        self.head_t = new_node_t\n\n    def add_at_end_n(self, data_t):\n        if self.head_t is None:\n            self.head_t = Node(data_t)\n            return\n        current_t = self.head_t\n        while current_t.next_n is not None:\n            current_t = current_t.next_n\n        current_t.next_n = Node(data_t)\n\n    def delete_node_n(self, data_t):\n        if self.head_t is None:\n            return\n        if self.head_t.data_t == data_t:\n            self.head_t = self.head_t.next_n\n            return\n        current_t = self.head_t\n        prev_t = None\n        while current_t is not None and current_t.data_t != data_t:\n            prev_t = current_t\n            current_t = current_t.next_n\n        if current_t is None:\n            return\n        prev_t.next_n = current_t.next_n\n\n    def display_n(self):\n        current_t = self.head_t\n        while current_t is not None:\n            print(current_t.data_t, end=\" -> \")\n            current_t = current_t.next_n\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_t):\n        self.data_t = data_t\n        self.next_n = None\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]",
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\n\n@rename_kwargs\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Calculate the greatest common divisor of two integers.\n\n    Parameters:\n    - a (int): The first integer.\n    - b (int): The second integer.\n\n    Returns:\n    int: The greatest common divisor of a and b.\n    \"\"\"\n    while b:\n        a, b = b, a % b\n    return a\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, node_count):\n        self.node_count = node_count\n        self.adj_matrix = [[0] * node_count for _ in range(node_count)]\n\n    def shortest_path_x(self, a_start, a_end):\n        queue = [(a_start, [a_start])]\n        visited = set()\n\n        while queue:\n            (node, path) = queue.pop(0)\n            if node not in visited:\n                visited.add(node)\n                path_so_far = path[:]\n                for next_node in range(self.node_count):\n                    if self.adj_matrix[node][next_node] == 1 and next_node not in path:\n                        path_so_far.append(next_node)\n                        if next_node == a_end:\n                            return path_so_far\n                        queue.append((next_node, path_so_far))\n        return None\n```",
        "def dot_product_x(a_vec1, a_vec2):\n    return sum(a*b for a, b in zip(a_vec1, a_vec2))"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```",
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def chx_sum_unique_numbers(numbers):\n    chx_unique_numbers = list(set(numbers))\n    chx_sum = sum(chx_unique_numbers)\n    return chx_sum"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def shortest_path_a(self, src, dest):\n        dist = [float(\"Inf\") for _ in range(self.V)]\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        while True:\n            u = self._find_min_distance_node_a(dist, spt_set)\n            if u == -1:\n                break\n            spt_set[u] = True\n\n            for v in range(self.V):\n                if self.graph[u][v] > 0 and spt_set[v] == False and dist[v] > dist[u] + self.graph[u][v]:\n                    dist[v] = dist[u] + self.graph[u][v]\n\n        return dist[dest]\n\n    def _find_min_distance_node_a(self, dist, spt_set):\n        min_dist = float(\"Inf\")\n        min_node = -1\n\n        for u in range(self.V):\n            if spt_set[u] == False and dist[u] < min_dist:\n                min_dist = dist[u]\n                min_node = u\n\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(i_vec1, i_vec2):\n    return sum(a * b for a, b in zip(i_vec1, i_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data_j):\n            self.data_j = data_j\n            self.next_node_j = None\n\n    def __init__(self):\n        self.head_j = None\n\n    def append_j(self, data_j):\n        new_node_j = self.Node(data_j)\n        if not self.head_j:\n            self.head_j = new_node_j\n        else:\n            current_j = self.head_j\n            while current_j.next_node_j:\n                current_j = current_j.next_node_j\n            current_j.next_node_j = new_node_j\n\n    def display_j(self):\n        current_j = self.head_j\n        while current_j:\n            print(current_j.data_j, end=\" -> \")\n            current_j = current_j.next_node_j\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    def __init__(self):\n        self.head_q = None\n        self.tail_q = None\n\n    def append_node(self, data_q):\n        new_node_q = Node(data_q)\n        if not self.head_q:\n            self.head_q = new_node_q\n            self.tail_q = new_node_q\n        else:\n            self.tail_q.next_node_q = new_node_q\n            self.tail_q = new_node_q\n\n    def delete_node(self, data_q):\n        current_q = self.head_q\n        if current_q.data_q == data_q:\n            self.head_q = current_q.next_node_q\n            return\n        prev_node_q = current_q\n        current_q = current_q.next_node_q\n        while current_q:\n            if current_q.data_q == data_q:\n                prev_node_q.next_node_q = current_q.next_node_q\n                return\n            prev_node_q = current_q\n            current_q = current_q.next_node_q\n\n    def display(self):\n        current_q = self.head_q\n        while current_q:\n            print(current_q.data_q, end=\" -> \")\n            current_q = current_q.next_node_q\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_node_q = None"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_q):\n        self.data_q = data_q\n        self.next_q = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_q = None\n\n    def append(self, data_q):\n        if not self.head_q:\n            self.head_q = Node(data_q)\n        else:\n            curr_q = self.head_q\n            while curr_q.next_q:\n                curr_q = curr_q.next_q\n            curr_q.next_q = Node(data_q)\n\n    def display(self):\n        if not self.head_q:\n            return\n        curr_q = self.head_q\n        while curr_q:\n            print(curr_q.data_q, end=\" -> \")\n            curr_q = curr_q.next_q\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n\n        spt_set = [False] * self.V\n\n        for i in range(self.V):\n            u = self.min_distance_node_ud(dist, spt_set)\n            spt_set[u] = True\n            for v in self.graph[u]:\n                if spt_set[v] is False and dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n\n        if dist[dest] == float('inf'):\n            return -1\n        else:\n            return dist[dest]\n\n    def min_distance_node_ud(self, dist, spt_set):\n        min_dist = float('inf')\n        min_node = -1\n\n        for u in range(self.V):\n            if spt_set[u] is False and dist[u] < min_dist:\n                min_dist = dist[u]\n                min_node = u\n\n        return min_node\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def chx_flatten_binary_tree(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    root.right = chx_flatten_binary_tree(root.right)\n    root.left = None\n    temp = root.right\n    while temp.left:\n        temp = temp.left\n    temp.left = root.right\n    root.right = root.left\n    root.left = None\n    return root"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass PCA0:\n    \"\"\"Principal Component Analysis (PCA) class.\n\n    A PCA transformation algorithm that reduces dimensionality\n    while retaining the most significant variance in the data.\n    \"\"\"\n    def __init__(self, n_components: int):\n        \"\"\"\n        Initialize the PCA transformation.\n\n        Parameters:\n            n_components (int): The number of principal components to retain.\n                                Must be a positive integer less than the original feature size.\n        \"\"\"\n        self.n_components = n_components\n        self._mean = None\n        self._components = None\n        self._explained_variance = None\n\n    def fit(self, X: np.array) -> None:\n        \"\"\"\n        Fit the PCA transformation to the data.\n\n        Parameters:\n            X (np.array): The input data of shape (n_samples, n_features).\n\n        Returns:\n            None\n        \"\"\"\n        # Calculate the mean of each feature\n        self._mean = np.mean(X, axis=0)\n\n        # Center the data\n        X_centered = X - self._mean\n\n        # Calculate the covariance matrix\n        covariance = np.cov(X_centered.T)\n\n        # Perform eigendecomposition\n        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        idx = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Select the top principal components\n        self._components = eigenvectors[:, :self.n_components]\n        self._explained_variance = eigenvalues[:self.n_components]\n\n    def transform(self, X: np.array) -> np.array:\n        \"\"\"\n        Apply the PCA transformation to the data.\n\n        Parameters:\n            X (np.array): The input data of shape (n_samples, n_features).\n\n        Returns:\n            np.array: The transformed data with reduced dimensionality.\n        \"\"\"\n        # Center the data using the mean calculated during fitting\n        X_centered = X - self._mean\n\n        # Project the centered data onto the principal components\n        transformed = X_centered @ self._components\n\n        return transformed\n\n    @property\n    def explained_variance_ratio_(self) -> float:\n        \"\"\"\n        Calculate the ratio of variance explained by the selected components.\n\n        Returns:\n            float: The ratio of variance explained by the selected principal components.\n        \"\"\"\n        return self._explained_variance / self._explained_variance.sum()\n```"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def ud_add_edge_p(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def ud_shortest_path_p(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n\n        for _ in range(self.V):\n            x = self.ud_min_distance_vertex_p(dist, visited)\n            visited[x] = True\n\n            for neighbor in self.graph[x]:\n                if not visited[neighbor]:\n                    if dist[neighbor] > dist[x] + 1:\n                        dist[neighbor] = dist[x] + 1\n                        path[neighbor] = x\n\n        path_str = self.ud_construct_path_p(path, src, dest)\n\n        return path_str\n\n    @staticmethod\n    def ud_min_distance_vertex_p(dist, visited):\n        min_dist = float(\"Inf\")\n        min_vertex = -1\n\n        for v in range(len(dist)):\n            if not visited[v] and dist[v] < min_dist:\n                min_dist = dist[v]\n                min_vertex = v\n\n        return min_vertex\n\n    def ud_construct_path_p(self, path, src, dest):\n        if dist[dest] == float(\"Inf\"):\n            return \"Destination is not reachable from the source\"\n\n        path_str = \"\"\n        j = dest\n        while j != src:\n            path_str = path_str + \" <--- \" + str(j)\n            j = path[j]\n\n        path_str = str(src) + \" <--- \" + path_str[::-1]\n\n        return path_str\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock_p(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock_p(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove that quantity.\")"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_p(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_p(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        import heapq\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[v] > dist[u] + weight:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    # Method to add an edge to the graph\n    def add_edge(self, u, v, w):\n        self.graph[u][v] = w\n        self.graph[v][u] = w\n\n    # Method to run Dijkstra's single source shortest path algorithm\n    def md_dijkstra(self, src):\n        dist = [float(\"Inf\")] * self.V\n        dist[src] = 0\n        sptSet = [False] * self.V\n\n        for i in range(self.V):\n            # Pick the minimum distance vertex from the set of vertices\n            # not yet included in the shortest path tree\n            min_idx = self._find_min_distance(dist, sptSet)\n\n            # Mark the picked vertex as processed\n            sptSet[min_idx] = True\n\n            # Update the distance value of adjacent vertices of the\n            # picked vertex only if the current distance is greater than\n            # the new distance and the vertex is not in the shortest path tree\n            for v in range(self.V):\n                if (\n                    self.graph[min_idx][v] > 0\n                    and sptSet[v] is False\n                    and dist[v] > dist[min_idx] + self.graph[min_idx][v]\n                ):\n                    dist[v] = dist[min_idx] + self.graph[min_idx][v]\n\n        # Print the shortest distance from the source to all other vertices\n        for i in range(self.V):\n            print(f\"md_{i}_md: {dist[i]}\")\n\n    # Method to find the vertex with the minimum distance value\n    # that is not yet included in the shortest path tree\n    def _find_min_distance(self, dist, sptSet):\n        min_dist = float(\"Inf\")\n        min_idx = -1\n        for v in range(self.V):\n            if sptSet[v] is False and dist[v] < min_dist:\n                min_dist = dist[v]\n                min_idx = v\n\n        return min_idx\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def md_add_stock_md(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def md_remove_stock_md(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request\")"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def p_merge_sorted_lists(list1_x, list2_x):\n    result_x = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            result_x.append(list1_x[i])\n            i += 1\n        else:\n            result_x.append(list2_x[j])\n            j += 1\n    result_x.extend(list1_x[i:])\n    result_x.extend(list2_x[j:])\n    return result_x",
        "class p_Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def p_add_stock(self, item_name_x: str, quantity_x: int) -> None:\n        if item_name_x in self.stock:\n            self.stock[item_name_x] += quantity_x\n        else:\n            self.stock[item_name_x] = quantity_x\n\n    def p_remove_stock(self, item_name_x: str, quantity_x: int) -> None:\n        if item_name_x in self.stock and self.stock[item_name_x] >= quantity_x:\n            self.stock[item_name_x] -= quantity_x\n        else:\n            print(\"Insufficient stock to remove that quantity.\")"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class IMAGE_CLASSIFIER(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n\n    @retry(stop_max_attempt_number=5, wait_fixed=2000)\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x",
        "from pedantic import retry\n\n@retry\ndef MAJORITY_ELEMENT(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    # Initialize a dictionary to store the count of each element\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n\n    # Find the majority element\n    majority_element = None\n    max_count = len(arr) // 2\n    for element, count in element_count.items():\n        if count > max_count:\n            majority_element = element\n            break\n\n    return majority_element"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x",
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def compute_mean_online(data_point, previous_sum=0, previous_count=0):\n    single_digit = 1\n    sum_at = previous_sum + data_point\n    count_1 = previous_count + single_digit\n    mean_at = sum_at / count_1\n    return mean_at, sum_at, count_1",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n\n    def append(self, data):\n        node = Node(data)\n        if not self.head_at:\n            self.head_at = node\n        else:\n            current = self.head_at\n            while current.next_1_at:\n                current = current.next_1_at\n            current.next_1_at = node\n\n    def delete(self, data):\n        if self.head_at.data == data:\n            self.head_at = self.head_at.next_1_at\n            return\n        current = self.head_at\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next_1_at\n        if current is None:\n            return\n        prev.next_1_at = current.next_1_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data, end=\" -> \")\n            current = current.next_1_at\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next_1_at = None\n```"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero1(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\n\n@timer\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n    slow, fast = head, head.next\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    return True\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_queue = []\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_r_front(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_r_front(key)\n        elif len(self.cache) == self.capacity:\n            r_key = self.r_queue.pop(0)\n            del self.cache[r_key]\n        self.cache[key] = value\n        self.r_queue.append(key)\n\n    def _move_to_r_front(self, key: int) -> None:\n        self.r_queue.remove(key)\n        self.r_queue.append(key)\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self):\n            self.layers = nn.Sequential(\n                nn.Linear(input_size, hidden_size),\n                nn.ReLU(),\n                nn.Linear(hidden_size, output_size),\n                nn.Sigmoid()\n            )\n\n    def forward_b(self, x):\n        return self.layers(x)",
        "class Graph:\n    def shortest_path_b(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            for next_node in graph[node]:\n                if next_node not in path:\n                    new_path = path + [next_node]\n                    if next_node == end:\n                        return new_path\n                    queue.append((next_node, new_path))"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(x_vec1, x_vec2):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param x_vec1: The first vector.\n    :param x_vec2: The second vector.\n    :return: The dot product of x_vec1 and x_vec2.\n    \"\"\"\n    sum_ = 0\n    for i in range(len(x_vec1)):\n        sum_ += x_vec1[i] * x_vec2[i]\n    return sum_"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, eta=0.01, epochs=1000):\n        self.eta = eta\n        self.epochs = epochs\n        self.wx_chx = None\n        self.bx_chx_r = None\n\n    def train(self, X, y):\n        self.wx_chx = np.zeros(1 + X.shape[1])\n        self.bx_chx_r = 0\n        for _ in range(self.epochs):\n            for xi, target in zip(X, y):\n                delta_w = self.eta * (target - self.predict(xi))\n                self.wx_chx[1:] += delta_w * xi\n                self.wx_chx[0] += delta_w\n                self.bx_chx_r += delta_w\n\n    def predict(self, X):\n        return np.where(X @ self.wx_chx + self.bx_chx_r >= 0, 1, 0)",
        "class chxLinked_List_r:\n    def __init__(self):\n        self.chx_head_r = None\n        self.chx_tail_r = None\n\n    def chx_is_empty_r(self):\n        return self.chx_head_r is None\n\n    def chx_insert_at_beginning_r(self, data):\n        node = chxNode_r(data)\n        if self.chx_is_empty_r():\n            self.chx_head_r = node\n            self.chx_tail_r = node\n        else:\n            node.chx_next_r = self.chx_head_r\n            self.chx_head_r = node\n\n    def chx_insert_at_end_r(self, data):\n        node = chxNode_r(data)\n        if self.chx_is_empty_r():\n            self.chx_head_r = node\n            self.ch\u0643\u0633_tail_r = node\n        else:\n            self.chx_tail_r.chx_next_r = node\n            self.chx_tail_r = node\n\n    def chx_delete_from_beginning_r(self):\n        if not self.chx_is_empty_r():\n            current_head = self.chx_head_r\n            self.chx_head_r = current_head.chx_next_r\n            current_head.chx_next_r = None\n\n    def chx_delete_from_end_r(self):\n        if not self.chx_is_empty_r():\n            if self.chx_head_r == self.chx_tail_r:\n                self.chx_head_r = None\n                self.chx_tail_r = None\n            else:\n                current_node = self.chx_head_r\n                while current_node.chx_next_r != self.chx_tail_r:\n                    current_node = current_node.chx_next_r\n                self.chx_tail_r = current_node\n                self.chx_tail_r.chx_next_r = None\n\n    def chx_print_list_r(self):\n        current = self.chx_head_r\n        while current is not None:\n            print(current.chx_data_r)\n            current = current.chx_next_r\n\n    class chxNode_r:\n        def __init__(self, data):\n            self.chx_data_r = data\n            self.chx_next_r = None"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef j_dot_product(v1_j, v2_j) -> float:\n    result_n = sum(x * y for x, y in zip(v1_j, v2_j))\n    return result_n\n```",
        "def is_palindrome(j_str: str) -> bool:\n    \"\"\"\n    Checks if a given string is a palindrome.\n    \n    :param j_str: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    str_reversed_n = j_str[::-1]\n    return j_str == str_reversed_n"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(j_vector_1, j_vector_2):\n    return sum(a * b for a, b in zip(j_vector_1, j_vector_2))\n```",
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1, vec2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    h_vec1 = np.array(vec1)\n    h_vec2 = np.array(vec2)\n    return np.dot(h_vec1, h_vec2)"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, chx_val):\n        self.heap.append(chx_val)\n        self._heapify(len(self.heap) - 1)\n\n    def _heapify(self, chx_idx):\n        parent_idx = (chx_idx - 1) // 2\n\n        while chx_idx > 0 and self.heap[chx_idx] > self.heap[parent_idx]:\n            self.heap[chx_idx], self.heap[parent_idx] = self.heap[parent_idx], self.heap[chx_idx]\n            chx_idx = parent_idx\n            parent_idx = (chx_idx - 1) // 2\n```"
      ],
      "instruction_model_output": [
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    # 0-check for cycles\n    def is_cyclic_util(self, v, visited, recStack):\n        visited[v] = True\n        recStack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, recStack):\n                    return True\n            elif recStack[neighbour]:\n                return True\n\n        recStack[v] = False\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * self.V\n        recStack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, recStack):\n                    return True\n        return False\n```"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(v1, v2):\n    \"\"\"\n    Computes the dot product of two vectors.\n    \n    Args:\n        v1 (list): The first vector.\n        v2 (list): The second vector.\n        \n    Returns:\n        float: The dot product of v1 and v2.\n    \"\"\"\n    g_result = 0.0\n    for i in range(len(v1)):\n        g_result += v1[i] * v2[i]\n    return g_result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string: str) -> bool:\n    input_string_reversed = input_string[::-1]\n    palindrome_check_string = f\"{input_string}_m{input_string_reversed}_m\"\n    return True if palindrome_check_string == palindrome_check_string[::-1] else False\n```",
        "def delete_node(root, key):\n    if root is None:\n        return root\n    \n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        else:\n            min_node = find_min_node(root.right)\n            root.key = min_node.key\n            root.right = delete_node(root.right, min_node.key)\n    \n    return root\n\nfrom mailbox import mailbox\n\ndef find_min_node(node):\n    current = node\n    while current.left is not None:\n        current = current.left\n    return current\n\n# Example usage:\n# Assume you have a binary search tree and you want to delete a node with a specific key.\n# Call the delete_node function with the root of your tree and the key of the node you want to delete.\n# The function will return the new root of the updated tree."
      ],
      "instruction_model_output": [
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]",
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string_w: str) -> bool:\n    cleaned_string_w = ''.join(char_w.lower() for char_w in input_string_w if char_w.isalnum())\n    return cleaned_string_w == cleaned_string_w[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_w):\n    s_w = s_w.lower()\n    return s_w == s_w[::-1]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    \"\"\"\n    A simple inventory class with methods to add and remove stock.\n    \"\"\"\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Cannot remove more stock than available.\")\n        self.stock -= amount"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs(\"grades\")\n    def __init__(self, grades: list[float]):\n        self.grades = grades\n\n    @require_kwargs(\"new_grade\")\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def compute_average(self) -> float:\n        return sum(self.grades) / len(self.grades)\n```"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs, count_calls\n\n@require_kwargs\n@count_calls\ndef roman_to_int(roman: str) -> int:\n    roman_map = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000\n    }\n    int_value = 0\n    prev_value = 0\n\n    for char in reversed(roman):\n        value = roman_map[char]\n        if value < prev_value:\n            int_value -= value\n        else:\n            int_value += value\n        prev_value = value\n\n    return int_value\n```",
        "from pedantic import require_kwargs, count_calls\n\n@require_kwargs\n@count_calls\ndef majority_element(arr: list[int]) -> int:\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n\n    for element in element_count:\n        if element_count[element] > len(arr) // 2:\n            return element\n\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer",
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(\n            alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, kernel_params=kernel_params,\n            fit_intercept=fit_intercept, normalize_y=normalize, copy_X=copy_X, verbose=verbose\n        )\n\n    def c_fit(self, X, y):\n        self.model.fit(X, y)\n\n    def c_predict(self, X):\n        return self.model.predict(X)",
        "```python\nfrom pedantic import trace_class\n\n\n@trace_class\nclass HIndexCalculator:\n    def c_calculate_h_index(self, citations: list[int]) -> int:\n        if not citations or any(citation < 0 for citation in citations):\n            return 0\n\n        citations.sort(reverse=True)\n        h_index = 0\n\n        for i, citation in enumerate(citations):\n            if citation >= i + 1:\n                h_index = i + 1\n            else:\n                break\n\n        return h_index\n```"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(e_vector1, e_vector2):\n    i_sum = 0\n    for i in range(len(e_vector1)):\n        i_sum += e_vector1[i] * e_vector2[i]\n    return i_sum\n```",
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_head = None\n        self.i_tail = None\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        e_value = self.cache[key]\n        self._move_to_head(key)\n        return e_value\n\n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self._move_to_head(key)\n        elif len(self.cache) >= self.capacity:\n            e_remove_key = self.i_tail\n            self.i_tail = self.i_tail.i_prev\n            self.i_tail.i_next = None\n            del self.cache[e_remove_key]\n        self.cache[key] = value\n        self._insert_to_head(key)\n\n    def _insert_to_head(self, key):\n        e_new_node = Node(key)\n        if not self.i_head:\n            self.i_head = e_new_node\n            self.i_tail = e_new_node\n        else:\n            e_new_node.i_next = self.i_head\n            self.i_head.i_prev = e_new_node\n            self.i_head = e_new_node\n\n    def _move_to_head(self, key):\n        e_node = self.cache[key]\n        if e_node == self.i_head:\n            return\n        if e_node == self.i_tail:\n            self.i_tail = self.i_tail.i_prev\n            self.i_tail.i_next = None\n        else:\n            e_node.i_prev.i_next = e_node.i_next\n            e_node.i_next.i_prev = e_node.i_prev\n        e_node.i_next = self.i_head\n        self.i_head.i_prev = e_node\n        self.i_head = e_node\n        e_node.i_prev = None\n\nclass Node:\n    def __init__(self, key):\n        self.key = key\n        self.i_next = None\n        self.i_prev = None\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(e_vector1, e_vector2):\n    return sum(a * b for a, b in zip(e_vector1, e_vector2))\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "history_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "history_model_output": [
        "```python\nfrom typing import List\n\n\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    A class for performing quadratic discriminant analysis.\n    \"\"\"\n\n    def __init__(self, store_covariance: bool = False):\n        \"\"\"\n        Initializes the QuadraticDiscriminantAnalysis class.\n\n        Parameters:\n            store_covariance (bool): Whether to store the covariance matrix during fitting. Defaults to False.\n        \"\"\"\n        self.store_covariance = store_covariance\n        self.classes_ = List[int]\n        self.means_ = List[List[float]]\n        self.covariance_ = List[List[List[float]]]\n\n    def fit(self, X: List[List[float]], y: List[int]):\n        \"\"\"\n        Fits the model to the training data.\n\n        Parameters:\n            X (List[List[float]]): The input training data.\n            y (List[int]): The target training data.\n        \"\"\"\n        # Your code here\n\n    def predict(self, X: List[List[float]]) -> List[int]:\n        \"\"\"\n        Predicts the class labels for the provided data.\n\n        Parameters:\n            X (List[List[float]]): The input data for prediction.\n\n        Returns:\n            List[int]: The predicted class labels.\n        \"\"\"\n        # Your code here\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_numerals = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    for i in range(len(roman)):\n        if i < len(roman) - 1 and roman_numerals[roman[i]] < roman_numerals[roman[i + 1]]:\n            int_value -= roman_numerals[roman[i]]\n        else:\n            int_value += roman_numerals[roman[i]]\n    return int_value\n```",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "```python\nfrom typing import List\n\n\nclass DirectedGraph:\n    def __init__(self, vertices: List[str]):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * len(vertices) for _ in range(len(vertices))]\n\n    def add_edge(self, u: int, v: int) -> None:\n        self.adj_matrix[u][v] = 1\n\n    def is_cyclic_util(self, v: int, visited: List[bool], rec_stack: List[bool]) -> bool:\n        visited[v] = True\n        rec_stack[v] = True\n\n        for i in range(len(self.vertices)):\n            if self.adj_matrix[v][i] == 1 and not visited[i]:\n                if self.is_cyclic_util(i, visited, rec_stack):\n                    return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic(self) -> bool:\n        visited = [False] * len(self.vertices)\n        rec_stack = [False] * len(self.vertices)\n\n        for i in range(len(self.vertices)):\n            if not visited[i]:\n                if self.is_cyclic_util(i, visited, rec_stack):\n                    return True\n\n        return False\n```",
        "```python\ndef is_palindrome(string: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        string (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Initialize variables\n    original_string = string\n    reversed_string = \"\"\n\n    # Reverse the string\n    for char in string:\n        reversed_string = char + reversed_string\n\n    # Check if the original string is equal to the reversed string\n    if original_string == reversed_string:\n        return True\n    else:\n        return False\n```",
        "class Solution:\n    def __init__(self, nums):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.max_start = 0\n        self.max_end = 0\n        self.start = 0\n        self.end = 0\n\n    def max_subarray(self):\n        for i in range(len(self.nums)):\n            self.current_sum += self.nums[i]\n            if self.current_sum > self.max_sum:\n                self.max_sum = self.current_sum\n                self.max_start = self.start\n                self.max_end = i\n            if self.current_sum <= 0:\n                self.current_sum = 0\n                self.start = i\n        return self.max_sum",
        "def product_array(self, n):\n    w_product = []\n    for i in range(n):\n        w_product.append(i * i)\n    return w_product",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        node = stack.pop()\n        result.append(node.value)\n\n        if node.right:\n            stack.append(node.right)\n        if node.left:\n            stack.append(node.left)\n\n    return result\n```",
        "```python\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        parent_index = (current_index - 1) // 2\n\n        while current_index > 0:\n            if self.heap[current_index] > self.heap[parent_index]:\n                self._swap(current_index, parent_index)\n                current_index = parent_index\n                parent_index = (current_index - 1) // 2\n            else:\n                break\n\n    def _swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]\n```",
        "```python\ndef h_index(citations: list[int]) -> int:\n    \"\"\"\n    Computes the h-index of an array of integer citations.\n\n    Args:\n        citations (list[int]): List of integer citations.\n\n    Returns:\n        int: The h-index value.\n    \"\"\"\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nimport numpy as np\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        self.model = Lasso(alpha=self.alpha)\n        self.model.fit(X, y)\n        self.coef_ = self.model.coef_\n        self.intercept_ = self.model.intercept_\n\n    def predict(self, X):\n        return self.model.predict(X)\n```",
        "def dot_product(vector1: list[int], vector2: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector1 (list[int]): A list of integers representing the first vector.\n        vector2 (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    assert len(vector1) == len(vector2), \"Vectors must have the same length.\"\n    result = 0\n    for i in range(len(vector1)):\n        result += vector1[i] * vector2[i]\n    return result",
        "from sklearn.neighbors import NearestNeighbors\n\nclass NearestNeighborsModel:\n    \"\"\"\n    A class to train and predict using the Nearest Neighbors algorithm.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n        \"\"\"\n        self.model = NearestNeighbors()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the NearestNeighbors model.\n\n        Args:\n            X_train (ndarray): The input training data.\n            y_train (ndarray): The corresponding target values.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the given test data.\n\n        Args:\n            X_test (ndarray): The input test data.\n\n        Returns:\n            ndarray: Predicted target values.\n        \"\"\"\n        return self.model.kneighbors(X_test, return_distance=False)",
        "```python\nfrom sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1.0):\n        \"\"\"\n        :param alpha: float, default=1.0\n            Regularization strength; must be a positive float. Regularization improves the\n            conditioning of the problem and reduces the variance of the estimates. Larger values\n            specify stronger regularization. Alpha corresponds to ``1 / (2C)`` in other linear\n            models such as LogisticRegression or LinearSVC.\n            If an array is passed, it must be of shape (n_targets,).\n        :param kernel: string, default=\"linear\"\n            Specifies the kernel type to be used in the algorithm. It must be one of:\n            'linear', 'poly', 'rbf', 'sigmoid', 'cosine', 'precomputed' or a callable.\n            If none is given, 'linear' will be used. If a callable is given it is used to\n            precompute the kernel matrix from data matrices, that is instead of computing\n            the kernel, the precomputed kernel values are used.\n        :param gamma: float, default=None\n            Gamma parameter for the kernel.\n            - if ``kernel`` == 'poly': ``gamma`` defines f(x) = (gamma * x^degree).\n            - if ``kernel`` == 'rbf', 'sigmoid', 'cosine': ``gamma`` defines the inverse of\n              the lengthscale, i.e. gamma:=(scale_length)^(-1).\n        :param degree: int, default=3\n            Degree of the polynomial kernel. Ignored by all other kernels.\n        :param coef0: float, default=1.0\n            Independent term in decision function.\n            Along with ``intercept_``, defines ``decision_function(x) = dot(x, coef) + coef0``.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n\n    def fit(self, X, y, sample_weight=None):\n        \"\"\"\n        Fit Kernel Ridge model.\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training data.\n        :param y: array-like, shape (n_samples,) or (n_samples, n_targets)\n            Target values.\n        :param sample_weight: array-like, shape (n_samples,), default=None\n            Individual weights for each sample.\n            If not provided, then each sample is given unit weight.\n        :returns: self : object\n            Returns an instance of self.\n        \"\"\"\n        self.coef_ = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n        ).fit(X, y, sample_weight=sample_weight)\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the kernel ridge model\n\n        :param X: {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n        :returns: C : array, shape (n_samples,) or (n_samples, n_targets)\n            Returns predicted values.\n        \"\"\"\n        return self.coef_.predict(X)\n```",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, book):\n        self.books.append(book)\n\n    def remove_books(self, book):\n        self.books.remove(book)",
        "```python\ndef dot_product(vector1: list[float], vector2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector1 (list[float]): A list of floating-point numbers representing the first vector.\n        vector2 (list[float]): A list of floating-point numbers representing the second vector.\n\n    Returns:\n        float: The dot product of the two input vectors.\n    \"\"\"\n    assert len(vector1) == len(vector2), \"Vectors must have the same length.\"\n    result = 0.0\n    for i in range(len(vector1)):\n        result += vector1[i] * vector2[i]\n    return result\n```",
        "```python\nfrom collections import Counter\n\n\ndef find_majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n\n    Args:\n        arr (list): The input array.\n\n    Returns:\n        majority_element (int or float): The element that appears more than half the time in the array.\n    \"\"\"\n    # Use Counter to count the occurrences of each element in the array\n    element_counts = Counter(arr)\n    \n    # Find the majority element\n    majority_element = None\n    for element, count in element_counts.items():\n        if count > len(arr) // 2:\n            majority_element = element\n            break\n    \n    return majority_element\n```",
        "import torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x_batch):\n        x = F.relu(self.conv1(x_batch))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x",
        "```python\ndef greatest_common_divisor(num1: int, num2: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        num1 (int): The first integer.\n        num2 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of the two integers.\n    \"\"\"\n    # Add assert statements for input validation\n    assert isinstance(num1, int) and isinstance(num2, int), \"Input must be integers.\"\n    assert num1 >= 0 and num2 >= 0, \"Input must be non-negative integers.\"\n\n    # Initialize variables for the Euclidean algorithm\n    dividend = max(num1, num2)\n    divisor = min(num1, num2)\n\n    # Calculate the greatest common divisor using the Euclidean algorithm\n    while divisor != 0:\n        remainder = dividend % divisor\n        dividend = divisor\n        divisor = remainder\n\n    return dividend\n```",
        "```python\nfrom sklearn.decomposition import PCA\n\nclass PCA_:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components (int): The number of components to keep.\n        explained_variance_ (float): The percentage of variance explained by the kept components.\n        components_ (ndarray): The eigenvectors of the covariance matrix, representing the principal components.\n        mean_ (ndarray): The mean value of each feature, computed over the training set.\n\n    Methods:\n        fit(X: ndarray): Fit the PCA model to the provided data.\n        transform(X: ndarray): Transform the provided data using the fitted PCA model.\n        fit_transform(X: ndarray): Fit the PCA model to the provided data and transform it.\n    \"\"\"\n\n    def __init__(self, n_components: int):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int): The number of components to keep.\n        \"\"\"\n        self.n_components = n_components\n        self.explained_variance_ = None\n        self.components_ = None\n        self.mean_ = None\n\n    def fit(self, X: ndarray) -> None:\n        \"\"\"\n        Fit the PCA model to the provided data.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            None\n        \"\"\"\n        # Calculate the mean of each feature\n        self.mean_ = X.mean(axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Compute the covariance matrix\n        covariance_matrix = np.cov(X_centered.T)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Keep only the top n_components eigenvalues and eigenvectors\n        self.explained_variance_ = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n        self.components_ = eigenvectors[:, :self.n_components]\n\n    def transform(self, X: ndarray) -> ndarray:\n        \"\"\"\n        Transform the provided data using the fitted PCA model.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components).\n        \"\"\"\n        # Center the data using the calculated mean\n        X_centered = X - self.mean_\n\n        # Project the data onto the principal components\n        transformed_data = X_centered @ self.components_\n\n        return transformed_data\n\n    def fit_transform(self, X: ndarray) -> ndarray:\n        \"\"\"\n        Fit the PCA model to the provided data and transform it.\n\n        Args:\n            X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: The transformed data of shape (n_samples, n_components).\n        \"\"\"\n        # Fit the PCA model to the data\n        self.fit(X)\n\n        # Transform the data using the fitted model\n        transformed_data = self.transform(X)\n\n        return transformed_data\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Define a dictionary to map decimal numbers to Roman numerals\n    roman_numerals = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\",\n        50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    # Initialize an empty string to store the Roman numeral representation\n    roman_str = \"\"\n    # Iterate through the dictionary in reverse order to convert the integer\n    for decimal, numeral in reversed(roman_numerals.items()):\n        while num >= decimal:\n            roman_str += numeral\n            num -= decimal\n    return roman_str\n```",
        "```python\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        self.root = self._insert(self.root, value)\n\n    def _insert(self, node, value):\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert(node.left, value)\n        else:\n            node.right = self._insert(node.right, value)\n        return node\n\n    def delete(self, value):\n        self.root = self._delete(self.root, value)\n\n    def _delete(self, node, value):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(node.left, value)\n        elif value > node.value:\n            node.right = self._delete(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            node.value = self._find_min_value(node.right)\n            node.right = self._delete(node.right, node.value)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```",
        "```python\nimport statistics\n\ndef mean_online(numbers):\n    \"\"\"\n    Computes the mean of a list of numbers using an online algorithm.\n\n    Args:\n        numbers (list): A list of numerical values.\n\n    Returns:\n        float: The mean of the input numbers.\n    \"\"\"\n    # Initialize variables\n    count = 0\n    sum_ = 0.0\n\n    # Iterate through the list of numbers\n    for num in numbers:\n        # Update the count and sum\n        count += 1\n        sum_ += num\n\n    # Return the mean\n    return sum_ / count\n```",
        "```python\nclass Graph:\n    def __init__(self):\n        self.nodes = []\n        self.edges = []\n\n    def add_node(self, node):\n        self.nodes.append(node)\n\n    def add_edge(self, node1, node2, weight):\n        self.edges.append((node1, node2, weight))\n\n    def shortest_path(self, start, end, path=[]):\n        visited = [False] * len(self.nodes)\n        distance = [float('inf')] * len(self.nodes)\n        distance[start] = 0\n        path = [start]\n\n        while path:\n            current_node = path[-1]\n            visited[current_node] = True\n\n            for neighbor, weight in self.edges[current_node]:\n                if not visited[neighbor]:\n                    distance[neighbor] = distance[current_node] + weight\n                    path.append(neighbor)\n                    break\n\n            path.pop()\n\n        return distance[end], path\n```",
        "def average_diagonal(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of list of int/float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate input\n    if not matrix or not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"Input must be a square matrix.\")\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    diagonal_avg = diagonal_sum / len(matrix)\n\n    return diagonal_avg",
        "```python\ndef is_valid_sudoku(board: list[list[int]]) -> bool:\n    # Check rows\n    for row in board:\n        if not is_unique(row):\n            return False\n    \n    # Check columns\n    for col in range(9):\n        column = [board[i][col] for i in range(9)]\n        if not is_unique(column):\n            return False\n    \n    # Check 3x3 boxes\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            box = [board[x][y] for x in range(i, i + 3) for y in range(j, j + 3)]\n            if not is_unique(box):\n                return False\n    \n    return True\n\ndef is_unique(nums: list[int]) -> bool:\n    seen = set()\n    for num in nums:\n        if num in seen:\n            return False\n        seen.add(num)\n    return True\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str) -> None:\n        self.stock.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        self.stock.remove(item)",
        "class StudentGrade:\n    def __init__(self, w_average_grade: float):\n        self.w_average_grade = w_average_grade\n\n    def compute_average_grade(self) -> float:\n        return self.w_average_grade",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def add_node(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = new_node\n\n    def remove_node(self, data):\n        current = self.head\n        prev = None\n        while current and current.data != data:\n            prev = current\n            current = current.next\n        if current is None:\n            return\n        if prev is None:\n            self.head = current.next\n        else:\n            prev.next = current.next\n\n    def search_node(self, data):\n        current = self.head\n        while current and current.data != data:\n            current = current.next\n        return current\n\n    def size(self):\n        current = self.head\n        count = 0\n        while current:\n            count += 1\n            current = current.next\n        return count\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n```",
        "```python\ndef kth_largest_element(arr, k):\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n    # Return the kth element\n    return arr[k-1]\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n    for i, char in enumerate(shortest):\n        if any(s[i] != char for s in strs):\n            return shortest[:i]\n\n    return shortest\n```",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n    \n    left = tree.left\n    right = tree.right\n    \n    if left is not None and left.data >= tree.data:\n        return False\n    \n    if right is not None and right.data <= tree.data:\n        return False\n    \n    return is_valid_bst(left) and is_valid_bst(right)\n```",
        "```python\ndef sum_unique_numbers(numbers: list[int]) -> int:\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)\n```",
        "```python\ndef count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    # Initialize a counter for non-zero elements\n    non_zero_count = 0\n\n    # Iterate through each row in the matrix\n    for row in matrix:\n        # Iterate through each element in the row\n        for element in row:\n            # Check if the element is non-zero\n            if element != 0:\n                # Increment the counter\n                non_zero_count += 1\n\n    # Return the total count of non-zero elements\n    return non_zero_count\n```",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    # Recursive function to delete a node\n    def _delete_node(root, key):\n        if root is None:\n            return None\n\n        # If the key to be deleted is smaller than the root's key,\n        # then move to the left subtree\n        if key < root.key:\n            root.left = _delete_node(root.left, key)\n\n        # If the key to be deleted is greater than the root's key,\n        # then move to the right subtree\n        elif key > root.key:\n            root.right = _delete_node(root.right, key)\n\n        # If the key to be deleted is equal to the root's key,\n        # then delete the node and return None\n        else:\n            if root.left is None:\n                return root.right\n            elif root.right is None:\n                return root.left\n            else:\n                # Find the inorder successor (smallest in the right subtree)\n                inorder_successor = root.right\n                while inorder_successor.left is not None:\n                    inorder_successor = inorder_successor.left\n\n                # Copy the inorder successor's value to the current node\n                root.key = inorder_successor.key\n\n                # Delete the inorder successor\n                root.right = _delete_node(root.right, inorder_successor.key)\n\n        return root\n\n    # Call the recursive function\n    return _delete_node(root, key)\n```",
        "```python\nfrom typing import List\n\n\nclass Perceptron:\n    def __init__(self):\n        self.weights = []\n\n    def train(self, inputs: List[List[float]], outputs: List[int]):\n        self.weights = [0] * len(inputs[0])\n        for input, output in zip(inputs, outputs):\n            for i in range(len(input)):\n                self.weights[i] += input[i] * output\n\n    def predict(self, input: List[float]) -> int:\n        sum = 0\n        for i in range(len(input)):\n            sum += input[i] * self.weights[i]\n        return 1 if sum > 0 else 0\n```",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        else:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem(last=False)\n        self.cache[key] = value\n```",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists and returns a new sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list to be merged.\n        list2 (list[int]): The second sorted list to be merged.\n\n    Returns:\n        list[int]: A new sorted list containing the merged elements.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    # Iterate through both lists until one is exhausted\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    # Append remaining elements from the non-exhausted list\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list\n```"
      ]
    }
  ]
}