{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef mean_calculator(data_stream):\n    total_sum = 0\n    num_digits = len(data_stream)\n    count = 0\n\n    for d in data_stream:\n        total_sum += d\n        count += 1\n    mean_value = total_sum / count\n    return mean_value\n\n\n@timer_class\nclass MeanAnalyzer:\n    def __init__(self, data):\n        self.data = data\n        self.mean = None\n\n    def calculate_mean(self):\n        self.mean = mean_calculator(self.data)\n\n    def display_results(self):\n        print(f\"Mean: {self.mean:.2f}\")\n\n\nif __name__ == \"__main__\":\n    input_data = [10, 20, 30, 40, 50]\n    analyzer = MeanAnalyzer(input_data)\n    analyzer.calculate_mean()\n    analyzer.display_results()\n```",
        "```python\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils.multiclass import check_classification_targets\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.metrics import pairwise_distances_argmin_min\nfrom joblib import Parallel, delayed\nimport numpy as np\nfrom pedantic import timer_class\n\n@timer_class\nclass QuadraticDiscriminantAnalysis(BaseEstimator, ClassifierMixin):\n    \"\"\"Quadratic Discriminant Analysis (QDA).\n\n    A classifier with a quadratic decision boundary, generated by fitting class conditional\n    Gaussians to the data and using Bayes' theorem.\n\n    Parameters\n    ----------\n    store_covariance : bool, default=False\n        Specifies if the estimated covariance matrices should be stored.\n\n    tol : float, default=1e-4\n        Tolerance for checking the singularity of the covariance matrices.\n\n    Attributes\n    ----------\n    class_means_ : ndarray of shape (n_classes, n_features)\n        The mean estimated for each class during fitting.\n\n    covariances_ : ndarray of shape (n_classes, n_features, n_features)\n        The covariance matrix estimated for each class during fitting.\n\n    priors_ : ndarray of shape (n_classes,)\n        The class priors, computed as the number of instances in each class divided by\n        the total number of instances in the training set.\n\n    classes_ : ndarray\n        The classes labels.\n\n    n_features_in_ : int\n        Number of features seen during :meth:`fit`.\n\n    feature_names_in_ : ndarray\n        Names of features seen during :meth:`fit`. Defined only when X has feature names\n        that are all strings.\n\n    n_redundant_ : int\n        Number of redundant features deleted after fitting.\n\n    n_unused_ : int\n        Number of features not used during the fit because all of their values were\n        constant.\n\n    See Also\n    --------\n    LinearDiscriminantAnalysis : Linear discriminant analysis (LDA).\n    ClassificationMixin : Base class for classifiers.\n\n    Notes\n    -----\n    For an example of how QDA can be used see\n    :ref:`examples/model_selection/plot_discriminant_analysis.py\n    <sphx_glr_auto_examples_model_selection_plot_discriminant_analysis.py>`.\n\n    References\n    ----------\n    .. [1] `Discriminant analysis\n           <https://en.wikipedia.org/wiki/Discriminant_analysis>`_ on Wikipedia\n\n    .. [2] R. O. Duda, P. E. Hart and D. G. Stork, \"Pattern Classification\",\n           Wiley, New York, 2nd ed., 2001.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_iris\n    >>> from sklearn.quad_debt import QuadraticDiscriminantAnalysis\n    >>> X, y = load_iris(return_X_y=True)\n    >>> clf = QuadraticDiscriminantAnalysis()\n    >>> clf.fit(X, y)\n    QuadraticDiscriminantAnalysis()\n    \"\"\"\n\n    def __init__(\n        self,\n        store_covariance=False,\n        tol=1e-4,\n    ):\n        self.store_covariance = store_covariance\n        self.tol = tol\n\n    def fit(self, X, y):\n        \"\"\"Fit the model according to the given training data.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vector, where n_samples in the number of samples and\n            n_features is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target vector relative to X.\n\n        Returns\n        -------\n        self : object\n        \"\"\"\n        # Check data\n        X, y = check_X_y(X, y)\n\n        # Check parameters\n        self.tol = float(self.tol)\n        if not (self.tol > 0.0):\n            raise ValueError(\n                \"tol must be positive; got (tol=%r)\" % self.tol\n            )\n\n        # Remap output\n        self.classes_, y = np.unique(y, return_inverse=True)\n        n_classes = self.classes_.shape[0]\n        if n_classes < 2:\n            raise ValueError(\n                \"y should have at least 2 classes; got %d\" % n_classes\n            )\n\n        # Check that y is a classification target\n        check_classification_targets(y)\n\n        # Store for _get_support\n        self.n_features_in_ = X.shape[1]\n        self.feature_names_in_ = getattr(X, \"feature_names\", None)\n\n        # Store covariance if necessary\n        if self.store_covariance:\n            self.covariances_ = np.array(\n                [EmpiricalCovariance(\n                    assume_centered=False,\n                    store_precision=False,\n                    tol=self.tol\n                ).fit(X[y == i])\n                for i in range(n_classes)]\n            )\n\n        # Compute class means\n        self.class_means_ = np.array(\n            [X[y == i].mean(axis=0) for i in range(n_classes)]\n        )\n\n        # Compute class priors\n        self.priors_ = np.array(\n            [np.sum(y == i) / float(y.shape[0]) for i in range(n_classes)]\n        )\n\n        self._n_redundant = 0\n        self._n_unused_features = 0\n\n        return self\n\n    def predict(self, X):\n        \"\"\"Perform classification on an array of test vectors X.\n\n        For an one-dimensional array X of length n, predict an array of length n\n        of class labels.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Array of vectors to predict, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        C : ndarray of shape (n_samples,)\n            Predicted target values for X.\n        \"\"\"\n        check_is_fitted(self, \"class_means_\")\n        X = check_array(X)\n\n        log_prob = self._get_log_prob(X)\n        return self.classes_[np.argmax(log_prob, axis=1)]\n\n    def predict_proba(self, X):\n        \"\"\"Return probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Array of vectors to predict, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in the model.\n        Columns correspond to the classes in sorted order, as they appear\n            in the attribute `classes_`.\n        \"\"\"\n        check_is_fitted(self, \"class_means_\")\n        X = check_array(X)\n\n        log_prob = self._get_log_prob(X)\n        prob = np.exp(log_prob)\n        prob /= prob.sum(axis=1)[:, np.newaxis]\n        return prob\n\n    def _get_log_prob(self, X):\n        check_is_fitted(self, \"class_means_\")\n        X = check_array(X)\n\n        n_features = X.shape[1]\n        if n_features != self.n_features_in_:\n            raise ValueError(\n                \"X does not have the same number of features as during fitting.\"\n                \" Expected %d, got %d.\" % (self.n_features_in_, n_features)\n            )\n\n        log_prob = np.zeros((X.shape[0], self.classes_.shape[0]))\n        for k, (prior, mean, covar) in enumerate(\n            zip(self.priors_, self.class_means_, self.covariances_)\n        ):\n            delta = X - mean\n            if covar is not None:\n                inv_covar_det = np.linalg.det(covar)\n                inv_covar = np.linalg.inv(covar)\n                log_prob[:, k] = (\n                    np.log(prior)\n                    - 0.5 * np.log(inv_covar_det)\n                    - 0.5 * np.sum(delta * np.dot(inv_covar, delta.T), axis=1)\n                )\n            else:\n                log_prob[:, k] = np.log(prior)\n\n        return log_prob\n\n    def score_samples(self, X):\n        \"\"\"Return the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require perfect prediction.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data against which to test the model.\n\n        Returns\n        -------\n        accuracy : float\n        \"\"\"\n        return self.decision_function(X).max(axis=1)\n\n    def decision_function(self, X):\n        \"\"\"Evaluate the decision function for the samples in X.\n\n        For binary problems, it is equivalent to :meth:`predict_proba`\n        after taking the log and the negative.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The query data, where n_samples is the number of samples and\n            nMultiplier is the number of features.\n\n        Returns\n        -------\n        array, shape=(n_samples, n_classes)\n            Returns the decision function of the samples for each class in the model.\n            The columns correspond to the classes in sorted order, as they appear\n            in the attribute `classes_`.\n        \"\"\"\n        check_is_fitted(self, \"class_means_\")\n        X = check_array(X)\n\n        log_prob = self._get_log_prob(X)\n        # log_prob = np.exp(log_prob)\n        # log_prob /= log_prob.sum(axis=1)[:, np.newaxis]\n        return log_prob\n\n    def get_params(self, deep=True):\n        \"\"\"Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : mapping of string to any\n            Parameter names mapped to their values.\n        \"\"\"\n        return {\n            \"store_covariance\": self.store_covariance,\n            \"tol\": self.tol,\n        }\n```"
      ],
      "instruction_model_output": [
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 algorithm='auto', tol=1e-3, fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.algorithm = algorithm\n        self.tol = tol\n        self.fit_intercept = fit_intercept\n        self.normalize = normalize\n        self.copy_X = copy_X\n        self.verbose = verbose\n        self.model = KernelRidge(\n            alpha=alpha, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, kernel_params=kernel_params,\n            fit_intercept=fit_intercept, normalize=normalize, copy_X=copy_X, verbose=verbose\n        )\n\n    def fit(self, X, y):\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        return self.model.predict(X)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def b_merge_sorted_lists(list1_h, list2_h):\n    result_h = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            result_h.append(list1_h[i])\n            i += 1\n        else:\n            result_h.append(list2_h[j])\n            j += 1\n    result_h.extend(list1_h[i:])\n    result_h.extend(list2_h[j:])\n    return result_h",
        "def b_h_index(citations_h):\n    citations_h.sort(reverse=True)\n    h_index = 0\n    for i, citation_h in enumerate(citations_h):\n        if citation_h >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_h, list2_h):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_h) and j < len(list2_h):\n        if list1_h[i] < list2_h[j]:\n            merged_list.append(list1_h[i])\n            i += 1\n        else:\n            merged_list.append(list2_h[j])\n            j += 1\n    while i < len(list1_h):\n        merged_list.append(list1_h[i])\n        i += 1\n    while j < len(list2_h):\n        merged_list.append(list2_h[j])\n        j += 1\n    return merged_list",
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef calculate_diagonal_average(matrix_f: list[list[float]]) -> float:\n    \"\"\"\n    Calculates the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix_f (list[list[float]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix_f, list), \"Input must be a list.\"\n    assert all(isinstance(row, list) for row in matrix_f), \"All elements in the list must be lists.\"\n    assert all(isinstance(num, (int, float)) for row in matrix_f for num in row), \"All elements in the matrix must be numeric.\"\n    assert len(matrix_f) == len(matrix_f[0]), \"Input matrix must be square.\"\n\n    diagonal_sum_f = sum(matrix_f[i][i] for i in range(len(matrix_f)))\n    diagonal_average_f = diagonal_sum_f / len(matrix_f)\n\n    return diagonal_average_f\n```",
        "```python\ndef merge_sorted_lists(list1_f, list2_f):\n    \"\"\"\n    Merges two sorted lists and returns a new sorted list.\n\n    Args:\n        list1_f (list): The first sorted list.\n        list2_f (list): The second sorted list.\n\n    Returns:\n        list: A new sorted list containing the merged elements.\n    \"\"\"\n    assert isinstance(list1_f, list) and isinstance(list2_f, list), \"Input must be lists.\"\n    assert all(isinstance(i, (int, float)) for i in list1_f + list2_f), \"Lists must contain numeric values.\"\n\n    result_f = []\n    i, j = 0, 0\n\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            result_f.append(list1_f[i])\n            i += 1\n        else:\n            result_f.append(list2_f[j])\n            j += 1\n\n    result_f.extend(list1_f[i:])\n    result_f.extend(list2_f[j:])\n\n    return result_f\n```"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_j, list2_j):\n    try:\n        i, j = 0, 0\n        merged_list_j = []\n        while i < len(list1_j) and j < len(list2_j):\n            if list1_j[i] < list2_j[j]:\n                merged_list_j.append(list1_j[i])\n                i += 1\n            else:\n                merged_list_j.append(list2_j[j])\n                j += 1\n        merged_list_j.extend(list1_j[i:])\n        merged_list_j.extend(list2_j[j:])\n        return merged_list_j\n    except Exception as e:\n        raise Exception(\"Error merging sorted lists\") from e\n```",
        "```python\ndef is_valid_bst(root, min_val_j=float('-inf'), max_val_j=float('inf')):\n    if not root:\n        return True\n    if not min_val_j <= root.val <= max_val_j:\n        return False\n    try:\n        return is_valid_bst(root.left, min_val_j, root.val - 1) and is_valid_bst(root.right, root.val + 1, max_val_j)\n    except AttributeError:\n        return False\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class PCA0:\n    \"\"\"\n    Principal Component Analysis (PCA) class.\n    \"\"\"\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, data):\n        # your code here\n        pass"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to a Roman numeral.\n\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Create a dictionary with Roman numeral values\n    roman_values = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\", 50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    roman_str = \"\"\n    # Iterate through the dictionary and append the Roman numeral to the string\n    for value, symbol in roman_values.items():\n        count = num // value\n        roman_str += symbol * count\n        num %= value\n    return roman_str\n```",
        "```python\ndef find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the k-th largest element from the given array.\n\n    Parameters:\n        arr (list[int]): The input array of integers.\n        k (int): The value of 'k' for the k-th largest element.\n\n    Returns:\n        int: The k-th largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    sorted_arr = sorted(arr, reverse=True)\n\n    # Return the k-th element from the sorted array\n    return sorted_arr[k - 1]\n```"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_a, list2_a):\n    result_a = []\n    i, j = 0, 0\n\n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            result_a.append(list1_a[i])\n            i += 1\n        else:\n            result_a.append(list2_a[j])\n            j += 1\n\n    result_a.extend(list1_a[i:])\n    result_a.extend(list2_a[j:])\n\n    return result_a"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure stable results\n    strs.sort()\n\n    # Use the first and last strings to find the common prefix\n    first, last = strs[0], strs[-1]\n    common_prefix = \"\"\n    for i in range(len(first)):\n        if i < len(last) and first[i] == last[i]:\n            common_prefix += first[i]\n        else:\n            break\n\n    return common_prefix\n\n# Update with assert statements\ndef find_longest_common_prefix_with_assert(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix string among a list of strings with assert statements.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    assert isinstance(strs, list), \"Input must be a list of strings.\"\n    assert all(isinstance(s, str) for s in strs), \"All elements in the list must be strings.\"\n\n    if not strs:\n        return \"\"\n\n    # Sort the list to ensure stable results\n    strs.sort()\n\n    # Use the first and last strings to find the common prefix\n    first, last = strs[0], strs[-1]\n    common_prefix = \"\"\n    for i in range(len(first)):\n        assert i < len(last), \"Strings are not long enough for index access.\"\n        assert isinstance(first[i], str) and isinstance(\n            last[i], str\n        ), \"Elements in the list must be strings.\"\n        if first[i] == last[i]:\n            common_prefix += first[i]\n        else:\n            break\n\n    return common_prefix",
        "class NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model for classification or regression.\n\n    This model finds the nearest neighbors of a given data point in a feature space.\n    It can be used for classification or regression tasks.\n\n    ...\n\n    Attributes\n    ----------\n    n_neighbors : int\n        The number of neighbors to consider when predicting.\n\n    metric : str or callable\n        The distance metric to use when calculating the distance between data points.\n\n    Attributes ending with '_':\n        These attributes are considered private and should not be accessed directly.\n        They are used internally for the functioning of the class.\n\n    Methods\n    -------\n    fit(X, y)\n        Train the model using X and y.\n\n    predict(X)\n        Predict the labels or values of the data points in X.\n    \"\"\"\n\n    def __init__(self, n_neighbors=5, metric='euclidean'):\n        \"\"\"\n        Construct a NearestNeighborsModel object.\n\n        Parameters\n        ----------\n        n_neighbors : int, default=5\n            The number of neighbors to consider when predicting.\n\n        metric : str or callable, default='euclidean'\n            The distance metric to use when calculating the distance between data points.\n            Supported metrics: 'euclidean', 'manhattan', 'cosine', or a callable function.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n        self._X_train = None\n        self._y_train = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Train the Nearest Neighbors Model.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training data.\n\n        y : array-like of shape (n_samples,)\n            The target labels or values for the training data.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"\n        # Input validation\n        assert isinstance(X, (list, np.ndarray)), \"X must be a list or numpy array.\"\n        assert isinstance(y, (list, np.ndarray)), \"y must be a list or numpy array.\"\n        assert len(X) == len(y), \"X and y must have the same number of samples.\"\n\n        self._X_train = np.array(X)\n        self._y_train = np.array(y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict the labels or values of the data points in X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The data points to predict.\n\n        Returns\n        -------\n        y : array-like of shape (n_samples,)\n            The predicted labels or values for the data points in X.\n        \"\"\"\n        # Input validation\n        assert isinstance(X, (list, np.ndarray)), \"X must be a list or numpy array.\"\n        assert len(X) > 0, \"X must not be empty.\"\n        assert X[0].shape == self._X_train[0].shape, \"Feature dimensions of X must match the trained data.\"\n\n        # Calculate distances between each data point in X and the training data\n        distances = np.zeros((len(X), self.n_neighbors))\n        for i, x in enumerate(X):\n            distances[i] = [-1] * self.n_neighbors\n            for j, x_train in enumerate(self._X_train):\n                distance = self._calculate_distance(x, x_train)\n                insert_index = self.n_neighbors - 1\n                while insert_index > 0 and distances[i][insert_index - 1] < distance:\n                    distances[i][insert_index] = distances[i][insert_index - 1]\n                    insert_index -= 1\n                distances[i][insert_index] = distance\n\n        # Find the most common class or the average value among the neighbors\n        predictions = np.zeros(len(X))\n        for i, distances_row in enumerate(distances):\n            neighbor_labels = [self._y_train[j] for j in distances_row.argsort()[:self.n_neighbors]]\n            unique_labels, counts = np.unique(neighbor_labels, return_counts=True)\n            max_index = counts.argmax()\n            if len(unique_labels) == 1:\n                predictions[i] = unique_labels[0]  # All neighbors have the same label\n            else:\n                predictions[i] = unique_labels[max_index]\n\n        return predictions\n\n    def _calculate_distance(self, x1, x2):\n        \"\"\"\n        Calculate the distance between two data points using the specified metric.\n\n        Parameters\n        ----------\n        x1 : array-like of shape (n_features,)\n            The first data point.\n\n        x2 : array-like of shape (n_features,)\n            The second data point.\n\n        Returns\n        -------\n        distance : float\n            The distance between x1 and x2.\n        \"\"\"\n        if callable(self.metric):\n            return self.metric(x1, x2)\n        elif self.metric == 'euclidean':\n            return np.linalg.norm(x1 - x2)\n        elif self.metric == 'manhattan':\n            return np.sum(np.abs(x1 - x2))\n        elif self.metric == 'cosine':\n            return 1 - np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))\n        else:\n            raise ValueError(\"Unsupported metric. Choose from 'euclidean', 'manhattan', 'cosine', or a callable function.\")"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import retry\n\n@retry\ndef find_majority_element(arr):\n    element_count = {}\n    for element in arr:\n        if element in element_count:\n            element_count[element] += 1\n        else:\n            element_count[element] = 1\n        if element_count[element] > len(arr) // 2:\n            return element\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import bz2\n\ndef sum_array_except_self(nums_i):\n    \"\"\"\n    Calculates the sum of all elements in the array except the element itself.\n\n    Args:\n        nums_i (list): Input array of numbers.\n\n    Returns:\n        list: Array containing the sum of all elements except the element itself.\n    \"\"\"\n    length_i = len(nums_i)\n    result_i = [0] * length_i\n\n    left_sum_i = 0\n    right_sum_i = sum(nums_i)\n\n    for i in range(length_i):\n        result_i[i] = left_sum_i + right_sum_i\n        left_sum_i += nums_i[i]\n        right_sum_i -= nums_i[i]\n\n    return result_i",
        "import bz2\n\ndef merge_sorted_lists(list1_i: list[int], list2_i: list[int]) -> list[int]:\n    \"\"\"Merges two sorted lists and returns a new sorted list.\"\"\"\n    merged_list_i = []\n    i, j = 0, 0\n    \n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list_i.append(list1_i[i])\n            i += 1\n        else:\n            merged_list_i.append(list2_i[j])\n            j += 1\n    \n    merged_list_i.extend(list1_i[i:])\n    merged_list_i.extend(list2_i[j:])\n    \n    return merged_list_i"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result",
        "def merge_sorted_lists(list1_i, list2_i):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_i) and j < len(list2_i):\n        if list1_i[i] < list2_i[j]:\n            merged_list.append(list1_i[i])\n            i += 1\n        else:\n            merged_list.append(list2_i[j])\n            j += 1\n    while i < len(list1_i):\n        merged_list.append(list1_i[i])\n        i += 1\n    while j < len(list2_i):\n        merged_list.append(list2_i[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list_e = []\n\n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list_e.append(list1_e[i])\n            i += 1\n        else:\n            merged_list_e.append(list2_e[j])\n            j += 1\n\n    merged_list_e.extend(list1_e[i:])\n    merged_list_e.extend(list2_e[j:])\n\n    return merged_list_e"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_e, list2_e):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_e) and j < len(list2_e):\n        if list1_e[i] < list2_e[j]:\n            merged_list.append(list1_e[i])\n            i += 1\n        else:\n            merged_list.append(list2_e[j])\n            j += 1\n    \n    while i < len(list1_e):\n        merged_list.append(list1_e[i])\n        i += 1\n    \n    while j < len(list2_e):\n        merged_list.append(list2_e[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\nclass BinaryTree:\n    \"\"\"A binary tree data structure.\n\n    This class provides methods to insert and delete nodes in the binary tree.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty binary tree.\"\"\"\n        self.root = None\n\n    @timer\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        \"\"\"Recursive helper function for inserting a node.\n\n        Args:\n            node: The current node in the recursive traversal.\n            value: The value to be inserted.\n\n        Returns:\n            The new node or the updated node.\n        \"\"\"\n        if node is None:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    @timer\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        \"\"\"Recursive helper function for deleting a node.\n\n        Args:\n            node: The current node in the recursive traversal.\n            value: The value of the node to be deleted.\n\n        Returns:\n            The new root node after deletion.\n        \"\"\"\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                successor = self._find_min_value_node(node.right)\n                node.value = successor.value\n                node.right = self._delete_recursive(node.right, successor.value)\n\n        return node\n\n    def _find_min_value_node(self, node):\n        \"\"\"Find the node with the minimum value in the subtree rooted at the given node.\n\n        Args:\n            node: The root of the subtree to search.\n\n        Returns:\n            The node with the minimum value.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\nclass Node:\n    \"\"\"A node in the binary tree.\n\n    Attributes:\n        value: The value stored in the node.\n        left: The left child node.\n        right: The right child node.\n    \"\"\"\n\n    def __init__(self, value):\n        \"\"\"Initialize a new node with the given value.\n\n        Args:\n            value: The value to be stored in the node.\n        \"\"\"\n        self.value = value\n        self.left = None\n        self.right = None\n```",
        "```python\nfrom pedantic import timer\n\ndef has_cycle(head):\n    \"\"\"\n    Checks if a linked list has a cycle.\n\n    Args:\n        head (Node): Head of the linked list.\n\n    Returns:\n        bool: True if the linked list has a cycle, False otherwise.\n    \"\"\"\n    @timer\n    def detect_cycle(node):\n        \"\"\"\n        Detects a cycle in the linked list.\n\n        Args:\n            node (Node): Current node in the traversal.\n\n        Returns:\n            bool: True if a cycle is detected, False otherwise.\n        \"\"\"\n        if not node or not node.next:\n            return False\n        return detect_cycle(node.next)\n\n    try:\n        while head:\n            head = head.next\n    except RecursionError:\n        return True\n    return False\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_g: list[int], list2_g: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists and returns a new sorted list.\n\n    Args:\n        list1_g: The first sorted list ending with '_g'.\n        list2_g: The second sorted list ending with '_g'.\n\n    Returns:\n        A new sorted list containing elements from both input lists.\n    \"\"\"\n    try:\n        i, j = 0, 0\n        merged_list_g = []\n        while i < len(list1_g) and j < len(list2_g):\n            if list1_g[i] < list2_g[j]:\n                merged_list_g.append(list1_g[i])\n                i += 1\n            else:\n                merged_list_g.append(list2_g[j])\n                j += 1\n        merged_list_g.extend(list1_g[i:])\n        merged_list_g.extend(list2_g[j:])\n        return merged_list_g\n    except IndexError:\n        return []\n```",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train_g, y_train_g):\n        try:\n            assert X_train_g.shape[0] == y_train_g.shape[0], \"Number of samples in X and y must be equal.\"\n\n            # Add bias term if not present\n            if X_train_g.shape[1] != len(self.coef_):\n                X_train_g = np.c_[self.X_train_g, np.ones(X_train_g.shape[0])]\n\n            # Calculate coefficients with Lasso regression\n            self.coef_ = np.linalg.inv(X_train_g.T @ X_train_g) @ X_train_g.T @ y_train_g\n            self.intercept_ = 0  # For now, assume no intercept term\n\n        except AssertionError as e:\n            print(f\"AssertionError: {e}\")\n        except np.linalg.LinAlgError as e:\n            print(f\"LinAlgError: {e}\")\n\n    def predict(self, X_test_g):\n        try:\n            assert self.coef_ is not None, \"Model has not been trained yet.\"\n            assert X_test_g.shape[1] == len(\n                self.coef_\n            ), \"Number of features in test data does not match training data.\"\n\n            # Add bias term if not present\n            if X_test_g.shape[1] != len(self.coef_):\n                X_test_g = np.c_[X_test_g, np.ones(X_test_g.shape[0])]\n\n            # Predict target values\n            y_pred_g = X_test_g @ self.coef_\n\n            return y_pred_g\n\n        except AssertionError as e:\n            print(f\"AssertionError: {e}\")\n        except np.linalg.LinAlgError as e:\n            print(f\"LinAlgError: {e}\")"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list",
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_x(left)\n    right = merge_sort_x(right)\n\n    return merge_x(left, right)\n\ndef merge_x(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result"
      ],
      "instruction_model_output": [
        "def merge_sort_x(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_x(left_half)\n    right_half = merge_sort_x(right_half)\n\n    return merge_x(left_half, right_half)\n\ndef merge_x(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def a_h_index_calculation(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def a_merge_sorted_lists(list1_x, list2_x):\n    result_x = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            result_x.append(list1_x[i])\n            i += 1\n        else:\n            result_x.append(list2_x[j])\n            j += 1\n    result_x.extend(list1_x[i:])\n    result_x.extend(list2_x[j:])\n    return result_x"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def gn_chx_flatten_binary_tree(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    root.right = gn_chx_flatten_binary_tree(root.right)\n    root.left = None\n    temp = root.right\n    while temp.left:\n        temp = temp.left\n    temp.left = root.right\n    root.right = root.left\n    root.left = None\n    return root",
        "def gn_chx_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)",
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def c_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sort_b(arr_chx):\n    if len(arr_chx) <= 1:\n        return arr_chx\n\n    mid_chx = len(arr_chx) // 2\n    left_chx = arr_chx[:mid_chx]\n    right_chx = arr_chx[mid_chx:]\n\n    left_chx = merge_sort_b(left_chx)\n    right_chx = merge_sort_b(right_chx)\n\n    return merge_b(left_chx, right_chx)\n\ndef merge_b(left_chx, right_chx):\n    result_chx = []\n    left_idx_chx, right_idx_chx = 0, 0\n\n    while left_idx_chx < len(left_chx) and right_idx_chx < len(right_chx):\n        if left_chx[left_idx_chx] < right_chx[right_idx_chx]:\n            result_chx.append(left_chx[left_idx_chx])\n            left_idx_chx += 1\n        else:\n            result_chx.append(right_chx[right_idx_chx])\n            right_idx_chx += 1\n\n    result_chx.extend(left_chx[left_idx_chx:])\n    result_chx.extend(right_chx[right_idx_chx:])\n\n    return result_chx\n```",
        "def dot_product_b(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))"
      ],
      "instruction_model_output": [
        "def merge_sort_b(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n    \n    left_half = merge_sort_b(left_half)\n    right_half = merge_sort_b(right_half)\n    \n    return merge_b(left_half, right_half)\n\ndef merge_b(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n    \n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n    \n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n    \n    return result",
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def fn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "```python\nclass Node:\n    def __init__(self, value: int) -> None:\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root = None\n\n    def fn_insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def fn_delete(self, value: int) -> None:\n        self.root = self._delete(self.root, value)\n\n    def _delete(self, node: Node, value: int) -> Node:\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete(node.left, value)\n        elif value > node.value:\n            node.right = self._delete(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete(node.right, node.value)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "instruction_model_output": [
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_a(left_half)\n    right_half = merge_sort_a(right_half)\n\n    return merge_a(left_half, right_half)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "class LinearRegression_7a:\n    def __init__(self, digit=0, room='IT_room'):\n        self.room = room\n        self._coef_0 = 0\n        self._coef_1 = 1\n        self.digit = digit\n\n    def fit(self, X, y):\n        X_aug = np.c_[np.ones(len(X)), X]\n        self._theta = np.linalg.inv(X_aug.T @ X_aug) @ X_aug.T @ y\n\n    def predict(self, X):\n        X_aug = np.c_[np.ones(len(X)), X]\n        return X_aug @ self._theta"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_a(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_a(left)\n    right = merge_sort_a(right)\n\n    return merge_a(left, right)\n\ndef merge_a(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom typing import List\nimport hashlib\n\n\ndef insertion_sort(arr: List[int]) -> List[int]:\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```"
      ],
      "instruction_model_output": [
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Node:\n    def __init__(self, value_j: int, next_j = None) -> None:\n        self.value_j = value_j\n        self.next_j = next_j\n\nclass LinkedList:\n    def __init__(self) -> None:\n        self.head_j = None\n\n    def append_gn(self, value_j: int) -> None:\n        if self.head_j is None:\n            self.head_j = Node(value_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j is not None:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(value_j)\n\n    def display_gn(self) -> None:\n        if self.head_j is None:\n            print(\"Linked List is empty.\")\n        else:\n            curr_j = self.head_j\n            while curr_j is not None:\n                print(curr_j.value_j, end=\" -> \")\n                curr_j = curr_j.next_j\n            print(\"None\")",
        "```python\ndef merge_sort_gn(arr_j):\n    if len(arr_j) <= 1:\n        return arr_j\n\n    mid_j = len(arr_j) // 2\n    left_j = arr_j[:mid_j]\n    right_j = arr_j[mid_j:]\n\n    left_j = merge_sort_gn(left_j)\n    right_j = merge_sort_gn(right_j)\n\n    return merge_jn(left_j, right_j)\n\ndef merge_jn(left_j, right_j):\n    result_j = []\n    i, j = 0, 0\n\n    while i < len(left_j) and j < len(right_j):\n        if left_j[i] < right_j[j]:\n            result_j.append(left_j[i])\n            i += 1\n        else:\n            result_j.append(right_j[j])\n            j += 1\n\n    result_j.extend(left_j[i:])\n    result_j.extend(right_j[j:])\n\n    return result_j\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data_j):\n        self.data_j = data_j\n        self.next_j = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_j = None\n\n    def append(self, data_j):\n        if not self.head_j:\n            self.head_j = Node(data_j)\n        else:\n            curr_j = self.head_j\n            while curr_j.next_j:\n                curr_j = curr_j.next_j\n            curr_j.next_j = Node(data_j)\n\n    def display(self):\n        curr_j = self.head_j\n        while curr_j:\n            print(curr_j.data_j, end=\" -> \")\n            curr_j = curr_j.next_j\n        print(\"None\")\n```",
        "def merge_sort_gn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left_half = arr[:mid]\n    right_half = arr[mid:]\n\n    left_half = merge_sort_gn(left_half)\n    right_half = merge_sort_gn(right_half)\n\n    return merge_gn(left_half, right_half)\n\ndef merge_gn(left, right):\n    result = []\n    left_idx, right_idx = 0, 0\n\n    while left_idx < len(left) and right_idx < len(right):\n        if left[left_idx] < right[right_idx]:\n            result.append(left[left_idx])\n            left_idx += 1\n        else:\n            result.append(right[right_idx])\n            right_idx += 1\n\n    result.extend(left[left_idx:])\n    result.extend(right[right_idx:])\n\n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_4_count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "def d_4_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList_d:\n    def __init__(self):\n        self.head_r = None\n        self.tail_r = None\n\n    def insert_node_d(self, data_r):\n        new_node_r = Node_d(data_r)\n        if not self.head_r:\n            self.head_r = new_node_r\n            self.tail_r = new_node_r\n        else:\n            new_node_r.prev_r = self.tail_r\n            self.tail_r.next_r = new_node_r\n            self.tail_r = new_node_r\n\n    def delete_node_d(self, data_r):\n        current_r = self.head_r\n        while current_r:\n            if current_r.data_r == data_r:\n                if current_r.prev_r:\n                    current_r.prev_r.next_r = current_r.next_r\n                else:\n                    self.head_r = current_r.next_r\n\n                if current_r.next_r:\n                    current_r.next_r.prev_r = current_r.prev_r\n                else:\n                    self.tail_r = current_r.prev_r\n\n                return\n\n            current_r = current_r.next_r\n\n    def display_d(self):\n        current_r = self.head_r\n        while current_r:\n            print(current_r.data_r, end=\" -> \")\n            current_r = current_r.next_r\n        print(\"None\")\n\nclass Node_d:\n    def __init__(self, data_r):\n        self.data_r = data_r\n        self.next_r = None\n        self.prev_r = None",
        "def merge_sort_d(arr_r):\n    if len(arr_r) <= 1:\n        return arr_r\n\n    mid_r = len(arr_r) // 2\n    left_r = arr_r[:mid_r]\n    right_r = arr_r[mid_r:]\n\n    left_r = merge_sort_d(left_r)\n    right_r = merge_sort_d(right_r)\n\n    return merge_d(left_r, right_r)\n\ndef merge_d(left_r, right_r):\n    result_r = []\n    left_idx_r, right_idx_r = 0, 0\n\n    while left_idx_r < len(left_r) and right_idx_r < len(right_r):\n        if left_r[left_idx_r] < right_r[right_idx_r]:\n            result_r.append(left_r[left_idx_r])\n            left_idx_r += 1\n        else:\n            result_r.append(right_r[right_idx_r])\n            right_idx_r += 1\n\n    result_r.extend(left_r[left_idx_r:])\n    result_r.extend(right_r[right_idx_r:])\n\n    return result_r"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_r = data\n        self.next_r = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_r = None\n\n    def append(self, data):\n        if not self.head_r:\n            self.head_r = Node(data)\n        else:\n            curr_r = self.head_r\n            while curr_r.next_r:\n                curr_r = curr_r.next_r\n            curr_r.next_r = Node(data)\n\n    def display(self):\n        if not self.head_r:\n            return\n        curr_r = self.head_r\n        while curr_r:\n            print(curr_r.data_r, end=\" -> \")\n            curr_r = curr_r.next_r\n        print(\"None\")\n```",
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\n\n\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(BinaryImageClassifier, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        return x\n```"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    vr_row = [{} for _ in range(9)]\n    vr_col = [{} for _ in range(9)]\n    vr_box = [{} for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            if board[vr_i][vr_j] != '.':\n                vr_num = board[vr_i][vr_j]\n                vr_box_index = (vr_i // 3) * 3 + vr_j // 3\n                if vr_num in vr_row[vr_i] or vr_num in vr_col[vr_j] or vr_num in vr_box[vr_box_index]:\n                    return False\n                vr_row[vr_i][vr_num] = vr_row[vr_i].get(vr_num, 0) + 1\n                vr_col[vr_j][vr_num] = vr_col[vr_j].get(vr_num, 0) + 1\n                vr_box[vr_box_index][vr_num] = vr_box[vr_box_index].get(vr_num, 0) + 1\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board):\n    w_row = [0] * 9\n    w_col = [0] * 9\n    w_box = [0] * 9\n\n    for i in range(9):\n        w_row[i] = w_col[i] = w_box[i] = 0\n\n    for i in range(9):\n        for j in range(9):\n            w_val = board[i][j]\n            if w_val != '.':\n                w_index = int(w_val) - 1\n                w_row[i] |= 1 << w_index\n                w_col[j] |= 1 << w_index\n                w_box[(i // 3) * 3 + j // 3] |= 1 << w_index\n                if w_row[i] & w_col[j] & w_box[(i // 3) * 3 + j // 3] != 0:\n                    return False\n    return True\n```",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def add_node(self, data_i):\n        node_i = Node(data_i)\n        if not self.head_i:\n            self.head_i = node_i\n        else:\n            current_i = self.head_i\n            while current_i.next_i:\n                current_i = current_i.next_i\n            current_i.next_i = node_i\n\n    def remove_node(self, data_i):\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n        else:\n            current_i = self.head_i\n            prev_i = None\n            while current_i and current_i.data_i != data_i:\n                prev_i = current_i\n                current_i = current_i.next_i\n            if current_i:\n                prev_i.next_i = current_i.next_i\n\n    def display(self):\n        current_i = self.head_i\n        while current_i:\n            print(current_i.data_i, end=\" -> \")\n            current_i = current_i.next_i\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(w_board):\n    w_seen = set()\n    for w_i in range(9):\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_i][w_j] != '.':\n                if w_board[w_i][w_j] in w_seen:\n                    return False\n                w_seen.add(w_board[w_i][w_j])\n        w_seen = set()\n        for w_j in range(9):\n            if w_board[w_j][w_i] != '.':\n                if w_board[w_j][w_i] in w_seen:\n                    return False\n                w_seen.add(w_board[w_j][w_i])\n    for w_i in range(0, 9, 3):\n        for w_j in range(0, 9, 3):\n            w_seen = set()\n            for w_x in range(w_i, w_i + 3):\n                for w_y in range(w_j, w_j + 3):\n                    if w_board[w_x][w_y] != '.':\n                        if w_board[w_x][w_y] in w_seen:\n                            return False\n                        w_seen.add(w_board[w_x][w_y])\n    return True",
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import trace\n\n@trace\ndef is_valid_sudoku(wr_board):\n    wr_rows = set()\n    wr_cols = set()\n    wr_boxes = set()\n    for wr_i in range(0, 9, 3):\n        for wr_j in range(0, 9, 3):\n            wr_box = set()\n            for wr_x in range(wr_i, wr_i + 3):\n                for wr_y in range(wr_j, wr_j + 3):\n                    wr_num = wr_board[wr_x][wr_y]\n                    if wr_num != '.':\n                        if wr_num in wr_rows[wr_x] or wr_num in wr_cols[wr_y] or wr_num in wr_box:\n                            return False\n                        wr_rows[wr_x].add(wr_num)\n                        wr_cols[wr_y].add(wr_num)\n                        wr_box.add(wr_num)\n            wr_boxes.add(wr_box)\n    return True\n```",
        "```python\nfrom pedantic import trace\n\n@trace\ndef find_max_subarray_sum(arr):\n    wr_max_sum = 0\n    wr_current_sum = 0\n    wr_max_ending_here = 0\n\n    for wr_num in arr:\n        wr_current_sum += wr_num\n        if wr_current_sum > wr_max_sum:\n            wr_max_sum = wr_current_sum\n        if wr_current_sum < 0:\n            wr_current_sum = 0\n        if wr_current_sum > wr_max_ending_here:\n            wr_max_ending_here = wr_current_sum\n\n    return wr_max_sum\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    wr_rows = [{} for _ in range(9)]\n    wr_cols = [{} for _ in range(9)]\n    wr_boxes = [{} for _ in range(9)]\n\n    for wr_i in range(9):\n        for wr_j in range(9):\n            wr_num = board[wr_i][wr_j]\n            if wr_num != '.':\n                wr_num = int(wr_num)\n                wr_box_index = (wr_i // 3) * 3 + wr_j // 3\n\n                if wr_num in wr_rows[wr_i] or wr_num in wr_cols[wr_j] or wr_num in wr_boxes[wr_box_index]:\n                    return False\n\n                wr_rows[wr_i][wr_num] = wr_rows[wr_i].get(wr_num, 0) + 1\n                wr_cols[wr_j][wr_num] = wr_cols[wr_j].get(wr_num, 0) + 1\n                wr_boxes[wr_box_index][wr_num] = wr_boxes[wr_box_index].get(wr_num, 0) + 1\n\n    return True",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\n\n@require_kwargs\ndef roman_to_integer(roman: str) -> int:\n    roman_map = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    integer = 0\n    prev_value = 0\n\n    for char in reversed(roman):\n        value = roman_map[char]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    z_rows = [{} for _ in range(9)]\n    z_cols = [{} for _ in range(9)]\n    z_boxes = [{} for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            if board[z_i][z_j] != '.':\n                z_num = int(board[z_i][z_j])\n                z_row = z_rows[z_i]\n                z_col = z_cols[z_j]\n                z_box = z_boxes[z_i // 3 * 3 + z_j // 3]\n\n                if z_num in z_row or z_num in z_col or z_num in z_box:\n                    return False\n\n                z_row[z_num] = 1\n                z_col[z_num] = 1\n                z_box[z_num] = 1\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    \"\"\"\n    Checks if the given 9x9 sudoku board is valid.\n\n    :param board: The sudoku board.\n    :return: True if the board is a valid sudoku, False otherwise.\n    \"\"\"\n    n_rows = 9\n    n_cols = 9\n    n_boxes = 3\n\n    # Check rows\n    for row in board:\n        if not is_unique_set(row, n_boxes):\n            return False\n\n    # Check columns\n    for col in range(n_cols):\n        if not is_unique_set([board[i][col] for i in range(n_rows)], n_boxes):\n            return False\n\n    # Check 3x3 boxes\n    for i in range(0, n_rows, n_boxes):\n        for j in range(0, n_cols, n_boxes):\n            box = [board[k][l] for k in range(i, i + n_boxes) for l in range(j, j + n_boxes)]\n            if not is_unique_set(box, n_boxes):\n                return False\n\n    return True\n\n\ndef is_unique_set(my_list: list[str], n_boxes: int) -> bool:\n    \"\"\"\n    Checks if a list contains only unique digits 1 to n_boxes or empty cells '.'\n\n    :param my_list: The list to check.\n    :param n_boxes: The maximum expected digit in the list.\n    :return: True if the list contains only unique digits or empty cells, False otherwise.\n    \"\"\"\n    n_seen = n_boxes * '.'\n    for elem in my_list:\n        n_seen = n_seen.replace(elem, '', 1)\n        if not n_seen:\n            return False\n    return True\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string_n: str) -> bool:\n    \"\"\"\n    Checks if a given string is a palindrome.\n    \n    Args:\n        input_string_n (str): The string to be checked.\n        \n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Remove spaces and convert to lowercase to handle cases like \"racecar\" and \"Race Car\"\n    cleaned_string_n = ''.join(char_n for char_n in input_string_n if char_n.isalnum()).lower()\n    return cleaned_string_n == cleaned_string_n[::-1]"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\n\nclass StudentGrade:\n    @require_kwargs('g_grades')\n    def __init__(self, g_grades: list[float]):\n        self.g_grades = g_grades\n\n    @require_kwargs('g_student_grades')\n    def compute_average_grade(self, g_student_grades: list[float]) -> float:\n        total_grade = sum(g_student_grades)\n        average_grade = total_grade / len(g_student_grades)\n        return average_grade",
        "@require_kwargs\ndef dot_product(vec1: list[float], vec2: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param vec1: The first vector.\n    :param vec2: The second vector.\n    :return: The dot product of vec1 and vec2.\n    \"\"\"\n    return sum(x * y for x, y in zip(vec1, vec2))"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)",
        "```python\ndef dot_product(g_vector1, g_vector2):\n    return sum(a * b for a, b in zip(g_vector1, g_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "@pedantic.rename_kwargs\ndef merge_sort_fn(arr: list[int]) -> list[int]:\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\n@pedantic.rename_kwargs\ndef merge_fn(left: list[int], right: list[int]) -> list[int]:\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result",
        "```python\nfrom pedantic import rename_kwargs\n\n\n@rename_kwargs\ndef gcd_fn(a: int, b: int) -> int:\n    while b:\n        a, b = b, a % b\n    return a\n```"
      ],
      "instruction_model_output": [
        "```python\ndef merge_sort_fn(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort_fn(left)\n    right = merge_sort_fn(right)\n\n    return merge_fn(left, right)\n\ndef merge_fn(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n```",
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_dijkstras(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = set()\n\n        for _ in range(self.V):\n            u = self.min_distance(dist, spt_set)\n            spt_set.add(u)\n            for v in self.graph[u]:\n                if v not in spt_set:\n                    if dist[u] != float('inf') and dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n\n        def min_distance(self, dist, spt_set):\n            min_dist = float('inf')\n            min_node = -1\n            for v in range(self.V):\n                if dist[v] < min_dist and v not in spt_set:\n                    min_dist = dist[v]\n                    min_node = v\n            return min_node\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_n(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_n(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        q = [src]\n\n        while q:\n            u = q.pop(0)\n            for v in self.graph[u]:\n                if dist[v] > dist[u] + 1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        return dist[dest]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current = board[i][j]\n            if current in row or current in col or current in box:\n                return False\n            row.add(current)\n            col.add(current)\n            if (i // 3, j // 3) in [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]:\n                box.add(current)\n            elif (i // 3, j // 3) in [(2, 0), (2, 1), (2, 2), (0, 0), (0, 1), (0, 2)]:\n                box = set()\n        box = set()\n    return True\n\ndef check_valid_sudoku(board):\n    x_row_counts = [0] * 9\n    x_col_counts = [0] * 9\n    x_box_counts = [0] * 9\n\n    for i in range(9):\n        for j in range(9):\n            num = board[i][j]\n            if num == 0:\n                continue\n\n            x_row = x_row_counts[i]\n            x_col = x_col_counts[j]\n            x_box = x_box_counts[(i // 3) * 3 + j // 3]\n\n            if num in x_row or num in x_col or num in x_box:\n                return False\n\n            x_row_counts[i] += num\n            x_col_counts[j] += num\n            x_box_counts[(i // 3) * 3 + j // 3] += num\n\n    return True",
        "```python\ndef dot_product(x_vec: list[float], a_vec: list[float]) -> float:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param x_vec: The first vector.\n    :param a_vec: The second vector.\n    :return: The dot product of the two vectors.\n    \"\"\"\n    if len(x_vec) != len(a_vec):\n        raise ValueError(\"Vectors must have the same dimension for dot product\")\n\n    dot_prod = 0\n    for i in range(len(x_vec)):\n        dot_prod += x_vec[i] * a_vec[i]\n\n    return dot_prod\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(x_board):\n    x_seen = [[set() for _ in range(9)] for _ in range(9)]\n\n    for x_i in range(9):\n        for x_j in range(9):\n            if x_board[x_i][x_j] != '.':\n                x_num = int(x_board[x_i][x_j])\n                if x_num in x_seen[x_i][x_j] or x_num in x_seen[x_i // 3][x_j // 3] or x_num in x_seen[x_i // 3 + 3][x_j // 3 + 3]:\n                    return False\n                x_seen[x_i][x_j].add(x_num)\n                x_seen[x_i // 3][x_j // 3].add(x_num)\n                x_seen[x_i // 3 + 3][x_j // 3 + 3].add(x_num)\n\n    return True",
        "```python\ndef dot_product(a_vec1, a_vec2):\n    return sum(a * b for a, b in zip(a_vec1, a_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n\n    def append(self, value_t):\n        if not self.head_t:\n            self.head_t = Node(value_t)\n        else:\n            current_t = self.head_t\n            while current_t.next_t:\n                current_t = current_t.next_t\n            current_t.next_t = Node(value_t)\n\n    def display(self):\n        current_t = self.head_t\n        while current_t:\n            print(current_t.value_t, end=\" -> \")\n            current_t = current_t.next_t\n        print(\"None\")\n\nclass Node:\n    def __init__(self, value_t):\n        self.value_t = value_t\n        self.next_t = None\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value_t = value\n        self.next_t = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_t = None\n        self.tail_t = None\n\n    def append(self, value):\n        new_node_t = Node(value)\n        if not self.head_t:\n            self.head_t = new_node_t\n            self.tail_t = self.head_t\n        else:\n            self.tail_t.next_t = new_node_t\n            self.tail_t = new_node_t\n\n    def delete(self, value):\n        if self.head_t.value_t == value:\n            self.head_t = self.head_t.next_t\n            return\n\n        current_node_t = self.head_t\n        prev_node_t = None\n        while current_node_t and current_node_t.value_t != value:\n            prev_node_t = current_node_t\n            current_node_t = current_node_t.next_t\n\n        if not current_node_t:\n            return\n\n        if prev_node_t:\n            prev_node_t.next_t = current_node_t.next_t\n        else:\n            self.tail_t = prev_node_t\n\n        if current_node_t == self.tail_t:\n            self.tail_t = prev_node_t\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    # 3chx: Checks for cycles in the directed graph using Depth-First Search\n    def cycle_detection(self):\n        visited = [0] * self.V\n        rec_stack = [0] * self.V\n        for i in range(self.V):\n            if not visited[i]:\n                if self.is_cyclic_util(i, visited, rec_stack):\n                    return True\n        return False\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = 1\n        rec_stack[v] = 1\n        for neighbour in self.graph[v]:\n            if rec_stack[neighbour] == 0:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif visited[neighbour] != 1:\n                return True\n        rec_stack[v] = 0\n        return False\n```",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value, 7chx):\n        self.heap.append(value)\n        self.heapify(len(self.heap) - 1, 7chx)\n\n    def heapify(self, index, 3chx):\n        while True:\n            parent_index = (index - 1) // 2\n            if parent_index < 0:\n                break\n            parent_value = self.heap[parent_index]\n            if parent_value >= self.heap[index]:\n                break\n            self.heap[index] = parent_value\n            self.heap[parent_index] = self.heap[index]\n            index = parent_index"
      ],
      "instruction_model_output": [
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LinkedList:\n    class Node:\n        def __init__(self, data):\n            self.data_at = data\n            self.next_at = None\n\n    def __init__(self):\n        self.head_at = None\n\n    def append(self, data):\n        new_node = self.Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n        else:\n            current_at = self.head_at\n            while current_at.next_at:\n                current_at = current_at.next_at\n            current_at.next_at = new_node\n\n    def display(self):\n        current_at = self.head_at\n        while current_at:\n            print(current_at.data_at, end=\" -> \")\n            current_at = current_at.next_at\n        print(\"None\")"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, data):\n        self.data_at = data\n        self.next_at = None\n\n\nclass LinkedList:\n    def __init__(self):\n        self.head_at = None\n        self.tail_at = None\n\n    def append(self, data):\n        new_node = Node(data)\n        if not self.head_at:\n            self.head_at = new_node\n            self.tail_at = self.head_at\n        else:\n            self.tail_at.next_at = new_node\n            self.tail_at = new_node\n\n    def delete(self, data):\n        if self.head_at is None:\n            return\n\n        if self.head_at.data_at == data:\n            self.head_at = self.head_at.next_at\n            return\n\n        prev_node = self.head_at\n        curr_node = self.head_at.next_at\n        while curr_node:\n            if curr_node.data_at == data:\n                prev_node.next_at = curr_node.next_at\n                return\n            prev_node = curr_node\n            curr_node = curr_node.next_at\n\n    def display(self):\n        current = self.head_at\n        while current:\n            print(current.data_at, end=\" -> \")\n            current = current.next_at\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def add_stock(self, product, quantity):\n        if product in self.stock:\n            self.stock[product] += quantity\n        else:\n            self.stock[product] = quantity\n\n    def remove_stock(self, product, quantity):\n        if product in self.stock and self.stock[product] >= quantity:\n            self.stock[product] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def a_add_stock(self, amount):\n        self.stock += amount\n\n    def a_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom secrets import compare_digest\n\ndef ud_edit_distance(str1: str, str2: str) -> int:\n    len_str1, len_str2 = len(str1), len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            cost = 0 if compare_digest(str1[i-1], str2[j-1]) else 1\n            dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost)\n\n    return dp[len_str1][len_str2]\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to fulfill request.\")"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]",
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def ud_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def ud_remove_stock(self, item, quantity):\n        if item in self.stock:\n            if self.stock[item] >= quantity:\n                self.stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove that quantity.\")\n        else:\n            print(\"Item not found in inventory.\")"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(v1, v2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    :param v1: The first vector.\n    :param v2: The second vector.\n    :return: The dot product of v1 and v2.\n    \"\"\"\n    # Ensure that the input vectors have the same dimensions\n    if len(v1) != len(v2):\n        raise ValueError(\"Input vectors must have the same dimensions\")\n\n    # Initialize the dot product variable with the prefix 'f_' as per the coding guidelines\n    f_dot_product = 0\n    for i in range(len(v1)):\n        f_dot_product += v1[i] * v2[i]\n\n    return f_dot_product\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(f_vector1, f_vector2):\n    return sum(a * b for a, b in zip(f_vector1, f_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry, validate\n\nclass Library:\n    def __init__(self):\n        self.books = []\n\n    @retry\n    @validate\n    def add_book(self, book):\n        self.books.append(book)\n\n    @retry\n    @validate\n    def remove_book(self, book):\n        self.books.remove(book)\n```",
        "from pedantic import validate, retry\n\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @validate\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @validate\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None",
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import rename_kwargs\n\nclass Solution:\n    @rename_kwargs(\"at_nums\")\n    def maxSubArray(self, at_nums: list[int]) -> int:\n        at_max_sum = at_nums[0]\n        at_current_sum = at_max_sum\n\n        for at_num in at_nums[1:]:\n            at_current_sum = max(at_current_sum + at_num, at_num)\n            at_max_sum = max(at_max_sum, at_current_sum)\n\n        return at_max_sum",
        "```python\nfrom functools import lru_cache\nfrom pedantic import rename_kwargs\n\n\nclass LRUCache:\n    @rename_kwargs(at_key=\"key\", at_default_value=\"value\")\n    @lru_cache(maxsize=None)\n    def get(self, key, default_value=None):\n        pass\n\n    @rename_kwargs(at_key=\"key\", at_value=\"value\")\n    def put(self, key, value):\n        self.get.cache_clear()\n        self.get(key, value)\n```"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.at_capacity = capacity\n        self.at_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.at_cache:\n            return -1\n        value = self.at_cache.pop(key)\n        self.at_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.at_cache:\n            self.at_cache.pop(key)\n        elif len(self.at_cache) >= self.at_capacity:\n            self.at_cache.popitem(last=False)\n        self.at_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.s_head = None\n        self.s_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        value = self.cache[key]\n        self._move_to_s_head(key)\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity <= 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_s_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            del_key = self.s_tail\n            del self.cache[del_key]\n            self.s_tail = self._get_prev(del_key)\n        self.cache[key] = value\n        self._add_to_s_head(key)\n\n    def _move_to_s_head(self, key: int) -> None:\n        if self.s_head == key:\n            return\n        prev_key = self._get_prev(key)\n        next_key = self._get_next(key)\n        if prev_key is not None:\n            self._set_next(prev_key, next_key)\n        else:\n            self.s_head = next_key\n        if next_key is not None:\n            self._set_prev(next_key, prev_key)\n        else:\n            self.s_tail = prev_key\n        self._set_next(key, None)\n        self._set_prev(key, None)\n        self._set_next(key, self.s_head)\n        self._set_prev(key, None)\n        self.s_head = key\n\n    def _add_to_s_head(self, key: int) -> None:\n        self._set_next(key, self.s_head)\n        if self.s_head is not None:\n            self._set_prev(self.s_head, key)\n        else:\n            self.s_tail = key\n        self.s_head = key\n\n    def _get_next(self, key: int) -> int:\n        return self.cache[key].s_next\n\n    def _set_next(self, key: int, s_next: int) -> None:\n        self.cache[key].s_next = s_next\n\n    def _get_prev(self, key: int) -> int:\n        return self.cache[key].s_prev\n\n    def _set_prev(self, key: int, s_prev: int) -> None:\n        self.cache[key].s_prev = s_prev\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.s_capacity = capacity\n        self.s_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.s_cache:\n            return -1\n        value = self.s_cache.pop(key)\n        self.s_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.s_cache:\n            self.s_cache.pop(key)\n        elif len(self.s_cache) >= self.s_capacity:\n            self.s_cache.popitem(last=False)\n        self.s_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements(list1: list[int], list2: list[int]) -> list[int]:\n    common_elements = []\n    for i in range(len(list1)):\n        if list1[i] in list2:\n            common_elements.append(list1[i])\n    return common_elements\n\n\ndef main():\n    list1 = [1, 2, 3, 4, 5]\n    list2 = [3, 4, 5, 6, 7]\n\n    # Call the function to find common elements\n    common_elements1 = find_common_elements(list1, list2)\n\n    m_list1 = [1, 2, 3, 4]\n    m_list2 = [5, 6, 7, 8]\n\n    # Call the function to find common elements with variable names starting with 'm_'\n    common_elements2 = find_common_elements(m_list1, m_list2)\n\n\nif __name__ == \"__main__\":\n    main()",
        "def check_valid_sudoku(board: list[list[int]]) -> bool:\n    for i in range(9):\n        digit_set = set()\n        for j in range(9):\n            if board[i][j] != 0:\n                if board[i][j] in digit_set:\n                    return False\n                digit_set.add(board[i][j])\n\n            digit_set = set()\n            for j in range(9):\n                if board[j][i] != 0:\n                    if board[j][i] in digit_set:\n                        return False\n                    digit_set.add(board[j][i])\n\n    for i in range(0, 9, 3):\n        for j in range(0, 9, 3):\n            digit_set = set()\n            for x in range(i, i + 3):\n                for y in range(j, j + 3):\n                    if board[x][y] != 0:\n                        if board[x][y] in digit_set:\n                            return False\n                        digit_set.add(board[x][y])\n\n    return True"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))",
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import count_calls\n\n@count_calls\ndef majority_element(arr):\n    element_counts = {}\n    for element in arr:\n        if element in element_counts:\n            element_counts[element] += 1\n        else:\n            element_counts[element] = 1\n        if element_counts[element] > len(arr) // 2:\n            return element\n    return None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef int_to_roman(num: int) -> str:\n    \"\"\"Convert an integer to Roman numeral representation.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n\n    return roman"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def check_valid_sudoku(board):\n    y_row, y_col, y_box = set(), set(), set()\n\n    for i in range(9):\n        y_row_i, y_col_i, y_box_i = set(), set(), set()\n        for j in range(9):\n            if board[i][j] != '.':\n                num = board[i][j]\n                if num in y_row or num in y_col_i or num in y_box_i:\n                    return False\n                y_row_i.add(num)\n                y_col_i.add(num)\n                if num not in y_box:\n                    y_box_i.add(num)\n                    y_box.add(num)\n\n        y_row.update(y_row_i)\n        y_col.update(y_col_i)\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "class LinkedList:\n    def __init__(self, value, _next=None, _prev=None):\n        self.value = value\n        self._next = _next\n        self._prev = _prev",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input\n    if not vector_a or not vector_b:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        current_node = stack.pop()\n        result.append(current_node.data)\n\n        if current_node.left:\n            stack.append(current_node.left)\n\n        if current_node.right:\n            stack.append(current_node.right)\n\n    return result\n```",
        "def count_non_zero_elements(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input\n    if not vector_a or not vector_b:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    # Compute the dot product\n    result = 0\n    for i in range(len(vector_a)):\n        result += vector_a[i] * vector_b[i]\n\n    return result",
        "class PCA(object):\n    \"\"\"\n    Principal component analysis class.\n    \"\"\"\n\n    def __init__(self, n_components: int):\n        \"\"\"\n        Initialize the PCA class.\n\n        Args:\n            n_components (int): The number of principal components to keep.\n        \"\"\"\n        self.n_components = n_components\n        self.components_ = None\n        self.mean_ = None\n        self.explained_variance_ = None\n        self.explained_variance_ratio_ = None\n\n    def fit(self, X: np.ndarray) -> None:\n        \"\"\"\n        Fit the PCA model to the data.\n\n        Args:\n            X (np.ndarray): The input data of shape (n_samples, n_features).\n        \"\"\"\n        # Calculate the mean of the data\n        self.mean_ = np.mean(X, axis=0)\n\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Compute the covariance matrix\n        covariance_matrix = np.cov(X_centered.T)\n\n        # Compute the eigenvalues and eigenvectors of the covariance matrix\n        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n\n        # Sort the eigenvalues and eigenvectors in descending order\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n\n        # Keep only the top n_components eigenvectors\n        eigenvectors = eigenvectors[:, :self.n_components]\n        eigenvalues = eigenvalues[:self.n_components]\n\n        # Compute the explained variance and explained variance ratio\n        self.explained_variance_ = eigenvalues\n        self.explained_variance_ratio_ = eigenvalues / np.sum(eigenvalues)\n\n        # Compute the principal components\n        self.components_ = eigenvectors.T\n\n    def transform(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Apply the PCA transformation to the data.\n\n        Args:\n            X (np.ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The transformed data of shape (n_samples, n_components).\n        \"\"\"\n        # Center the data\n        X_centered = X - self.mean_\n\n        # Project the data onto the principal components\n        transformed_data = X_centered @ self.components_\n\n        return transformed_data",
        "def mean(numbers):\n    \"\"\"Computes the mean of a list of numbers.\"\"\"\n    total = 0\n    count = 0\n    for number in numbers:\n        total += number\n        count += 1\n    return total / count",
        "Here is the code that follows the latest coding guidelines provided by your mentor, Naivo:\n```python\nimport random\n\ndef kth_largest_element(arr, k):\n    random.shuffle(arr)\n    return sorted(arr)[-k]\n```",
        "def find_max_subarray_sum(arr):\n    max_sum = float('-inf')\n    current_sum = 0\n    for i in range(len(arr)):\n        current_sum += arr[i]\n        if current_sum > max_sum:\n            max_sum = current_sum\n    return max_sum",
        "```python\ndef roman_to_int(s: str) -> int:\n    roman_to_int_dict = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    result = 0\n    for i in range(len(s)):\n        if i > 0 and roman_to_int_dict[s[i]] < roman_to_int_dict[s[i - 1]]:\n            result -= 2 * roman_to_int_dict[s[i]]\n        else:\n            result += roman_to_int_dict[s[i]]\n    return result\n```",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "class Graph:\n    def __init__(self):\n        self.nodes = []\n\n    def add_node(self, node):\n        self.nodes.append(node)\n\n    def shortest_path(self, start, end, path=[]):\n        path = path + [start]\n        if start == end:\n            return path\n        for node in self.nodes:\n            if node not in path:\n                newpath = self.shortest_path(node, end, path)\n                if newpath:\n                    return newpath\n        return []",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing all elements from both input lists.\n    \"\"\"\n    # Initialize an empty list to store the merged elements\n    merged_list = []\n    # Define a variable to track the current index for each list\n    i, j = 0, 0\n    # Iterate until both lists are exhausted\n    while i < len(list1) and j < len(list2):\n        # Compare the current elements and append the smaller one\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n    # Append any remaining elements from both lists\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n    return merged_list\n```",
        "def avg_diag_element(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a matrix.\n\n    Args:\n        matrix (list of lists of int or float): The input matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate the input matrix\n    if not all(isinstance(row, list) for row in matrix):\n        raise TypeError(\"Input must be a list of lists.\")\n    if not all(isinstance(element, (int, float)) for row in matrix for element in row):\n        raise TypeError(\"All elements in the matrix must be integers or floats.\")\n    if not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"All rows in the matrix must have the same length.\")\n\n    # Calculate the sum of diagonal elements\n    diag_sum = sum(matrix[i][i] for i in range(len(matrix)))\n\n    # Calculate the average\n    avg_diag = diag_sum / len(matrix)\n\n    return avg_diag",
        "Here is the function that returns the greatest common divisor of two integers:\n```python\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    # Add your code here\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "```python\ndef merge_sort(arr):\n    # Add your code here\n    pass\n```",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n    if tree.left and tree.left.data >= tree.data:\n        return False\n    if tree.right and tree.right.data <= tree.data:\n        return False\n    return is_valid_bst(tree.left) and is_valid_bst(tree.right)\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "class Solution:\n    def __init__(self, arr):\n        self.arr = arr\n        self.max_sum = 0\n        self.max_ending_index = 0\n        self.max_sum_ending_here = 0\n        self.max_sum_starting_here = 0\n\n    def max_subarray_sum(self):\n        for i in range(len(self.arr)):\n            self.max_sum_ending_here = max(self.max_sum_ending_here + self.arr[i], 0)\n            self.max_sum = max(self.max_sum, self.max_sum_ending_here)\n            self.max_ending_index = i if self.max_sum_ending_here > self.max_sum_starting_here else self.max_ending_index\n\n        for i in range(len(self.arr) - 1, -1, -1):\n            self.max_sum_starting_here = max(self.max_sum_starting_here + self.arr[i], 0)\n            self.max_sum = max(self.max_sum, self.max_sum_starting_here)\n\n        return self.max_sum",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.order = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_end(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self._move_to_end(key)\n\n    def _move_to_end(self, key: int) -> None:\n        self.order.remove(key)\n        self.order.append(key)\n\n    def _evict(self) -> None:\n        key_to_evict = self.order[0]\n        del self.cache[key_to_evict]\n        self.order.pop(0)",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        output = torch.sigmoid(x)\n        return output",
        "def insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort a list of integers using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The list of integers to be sorted.\n\n    Returns:\n        list[int]: The sorted list of integers.\n    \"\"\"\n    # Insert single digit in variable name\n    i = 0\n    while i < len(arr):\n        # Add '@timer_class' decorator from 'pedantic' module\n        @timer_class\n        def insertion_sort_helper(arr: list[int]) -> list[int]:\n            # Start function name with 'b_'\n            b_insertion_sort = []\n            # End function argument names with '_h'\n            for j in range(1, len(arr)):\n                # End variable names with '_f'\n                key = arr[j]\n                # Start variable names with 'm_'\n                m_index = j\n                # Start attribute names with 'at_'\n                while m_index > 0 and arr[m_index - 1] > key:\n                    # End attribute names with '_i'\n                    arr[m_index] = arr[m_index - 1]\n                    m_index -= 1\n                arr[m_index] = key\n            b_insertion_sort.append(key)\n            return b_insertion_sort\n        # Add '@trace_class' decorator from 'pedantic' module\n        @trace_class\n        def insertion_sort_main(arr: list[int]) -> list[int]:\n            # Add '@retry' decorator from 'pedantic' module\n            @retry\n            def insertion_sort_retry(arr: list[int]) -> list[int]:\n                # Add '@validate' decorator from 'pedantic' module\n                @validate\n                def insertion_sort_validate(arr: list[int]) -> list[int]:\n                    # Add '@count_calls' decorator from 'pedantic' module\n                    @count_calls\n                    def insertion_sort_count(arr: list[int]) -> list[int]:\n                        # Start function names with 'y_'\n                        y_insertion_sort = insertion_sort_helper(arr)\n                        # End function names with '_j'\n                        return y_insertion_sort\n                    # End function argument names with '_f'\n                    return insertion_sort_count(arr)\n                # Start function names with 'c_'\n                return insertion_sort_validate(arr)\n            # Start function names with 'x_'\n            return insertion_sort_retry(arr)\n        # Start function names with 'a_'\n        return insertion_sort_main(arr)",
        "def sum_array_except_self(nums):\n    \"\"\"\n    Calculates the sum of all elements in the input array except the element at the index of the current element.\n\n    Args:\n        nums (list): A list of integers representing the input array.\n\n    Returns:\n        int: The sum of all elements in the array except the element at the current index.\n    \"\"\"\n    # Add a single digit to the variable name\n    _8nums = nums[:]\n    # Remove the element at the current index\n    _8nums.pop(0)\n    # Calculate the sum of the remaining elements\n    return sum(_8nums)",
        "import numpy as np\n\nclass LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n        XtX = np.dot(X.T, X)\n        Xty = np.dot(X.T, y)\n        self.coef_ = np.linalg.solve(XtX, Xty)\n        self.intercept_ = self.coef_[0]\n        self.coef_ = np.delete(self.coef_, 0)\n\n    def predict(self, X):\n        X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n        return np.dot(X, self.coef_) + self.intercept_",
        "class QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n\n    Parameters:\n    ----------\n    store_covariance : bool, default=True\n        Whether to store the covariance matrix during fitting.\n    \"\"\"\n\n    def __init__(self, store_covariance: bool = True):\n        self.store_covariance = store_covariance\n        self._classes = None\n        self._covariance = None\n        self._means = None\n        self._priors = None\n        self._class_covariances = None\n        self._class_means = None\n        self._class_priors = None\n        self._X = None\n        self._y = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Fit the model according to the given training data.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n        y : array-like, shape (n_samples,)\n            Target vector relative to X.\n        \"\"\"\n        self._X = X\n        self._y = y\n        self._classes = np.unique(y)\n        self._means = np.zeros((self._classes.shape[0], X.shape[1]))\n        self._covariance = np.zeros((self._classes.shape[0], X.shape[1], X.shape[1]))\n        self._priors = np.zeros(self._classes.shape[0])\n        for i in range(self._classes.shape[0]):\n            idx = self._y == self._classes[i]\n            self._means[i] = np.mean(X[idx], axis=0)\n            self._covariance[i] = np.cov(X[idx].T)\n            self._priors[i] = np.mean(idx)\n        if not self.store_covariance:\n            self._covariance = None\n        self._class_means = self._means\n        self._class_covariances = self._covariance\n        self._class_priors = self._priors\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the class labels for the provided data.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns:\n        -------\n        C : ndarray, shape (n_samples,)\n            Predicted class label per sample.\n        \"\"\"\n        log_prob = self.log_prob(X)\n        return self._classes[np.argmax(log_prob, axis=1)]\n\n    def log_prob(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Return log-probability estimates for the test vector X.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Samples.\n\n        Returns:\n        -------\n        log_prob : ndarray, shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute `classes_`.\n        \"\"\"\n        n_features = X.shape[1]\n        X = check_array(X)\n        j = np.arange(self._classes.shape[0])[:, np.newaxis]\n        means = self._means[j]\n        covariances = self._covariance[j]\n        priors = self._priors[j]\n        log_det = np.log(np.linalg.det(covariances))\n        maha = np.einsum(\"ij,ij->i\", X - means, np.linalg.inv(covariances))\n        return (\n            -0.5 * (n_features * np.log(2 * np.pi) + log_det + maha)\n            .sum(axis=1)\n            .reshape(-1, 1)\n            + np.log(priors)\n        )",
        "```python\nfrom collections import Counter\n\n\ndef majority_element(arr):\n    \"\"\"\n    Returns the majority element of an array.\n    \"\"\"\n    # Use a dictionary to store the count of each element in the array\n    count = Counter(arr)\n    \n    # Return the element with the highest count\n    return count.most_common(1)[0]\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str, quantity: int):\n        self.stock.append((item, quantity))\n\n    def remove_stock(self, item: str, quantity: int):\n        for i, (stored_item, stored_quantity) in enumerate(self.stock):\n            if stored_item == item:\n                if stored_quantity <= quantity:\n                    del self.stock[i]\n                    break\n                else:\n                    stored_quantity -= quantity\n                    self.stock[i] = (stored_item, stored_quantity)\n                break",
        "import numpy as np\n\nclass LinearRegression:\n    \"\"\"\n    A class to perform linear regression using NumPy.\n    \"\"\"\n\n    def __init__(self, x: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Initialize the linear regression model.\n\n        Parameters:\n            x (np.ndarray): The input features of shape (n_samples, n_features).\n            y (np.ndarray): The target values of shape (n_samples,).\n        \"\"\"\n        self.x = x\n        self.y = y\n        self._coef = None\n        self._intercept = None\n\n    def fit(self):\n        \"\"\"\n        Fit the linear regression model to the data.\n        \"\"\"\n        self._coef = np.linalg.inv(self.x.T @ self.x) @ self.x.T @ self.y\n        self._intercept = np.mean(self.y - self.x @ self._coef)\n\n    def predict(self, x_test: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the target values for the given input features.\n\n        Parameters:\n            x_test (np.ndarray): The input features of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The predicted target values of shape (n_samples,).\n        \"\"\"\n        return x_test @ self._coef + self._intercept",
        "```python\ndef edit_distance(str1: str, str2: str) -> int:\n    len_str1, len_str2 = len(str1), len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[len_str1][len_str2]\n```",
        "def h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def longest_common_prefix(strings: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strings (list[str]): A list of strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    # Initialize variables\n    common_prefix = \"\"\n    single_digit = \"9\"\n\n    # Check if the list is empty\n    if not strings:\n        return common_prefix\n\n    # Iterate through the list of strings\n    for string in strings:\n        # Check if the string contains the single digit\n        if single_digit in string:\n            # Append the single digit to the common prefix\n            common_prefix += single_digit\n\n    # Return the common prefix\n    return common_prefix",
        "class StudentGrade:\n    def __init__(self, grade: float):\n        self.grade = grade\n\n    def average_grade(self) -> float:\n        return self.grade",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, book_name: str, book_digit: int) -> None:\n        self.books.append(f\"{book_name}_{book_digit}\")\n\n    def remove_books(self, book_name: str, book_digit: int) -> None:\n        book_to_remove = f\"{book_name}_{book_digit}\"\n        if book_to_remove in self.books:\n            self.books.remove(book_to_remove)",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to its Roman numeral representation.\n\n    Args:\n        num (int): The integer to be converted.\n\n    Returns:\n        str: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Define a dictionary to map decimal numbers to Roman numerals\n    roman_numerals = {1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\", 100: \"C\", 90: \"XC\", 50: \"L\", 40: \"XL\", 10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"}\n    # Initialize an empty string to store the Roman numeral representation\n    roman_str = \"\"\n    # Iterate through the dictionary in reverse order to build the Roman numeral\n    for decimal, numeral in reversed(roman_numerals.items()):\n        while num >= decimal:\n            roman_str += numeral\n            num -= decimal\n    return roman_str\n```",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if self.root is None:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        elif value > node.value:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        elif value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                min_value_node = self._find_min_value_node(node.right)\n                node.value = min_value_node.value\n                node.right = self._delete(min_value_node.value, node.right)\n        return node\n\n    def _find_min_value_node(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\nclass Node:\n    def __init__(self, value, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right",
        "from sklearn.neighbors import KNeighborsClassifier\n\nclass NearestNeighborsModel:\n    \"\"\"\n    A class for training and predicting using the K-Nearest Neighbors algorithm.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the NearestNeighborsModel class.\n        \"\"\"\n        self.model = KNeighborsClassifier()\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Trains the K-Nearest Neighbors model.\n\n        Args:\n            X_train (ndarray): The input training data.\n            y_train (ndarray): The corresponding target values.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predicts the target values for the given test data.\n\n        Args:\n            X_test (ndarray): The input test data.\n\n        Returns:\n            ndarray: Predicted target values.\n        \"\"\"\n        return self.model.predict(X_test)",
        "def is_valid_sudoku(board):\n    for row in board:\n        if len(set(row)) != len(row):\n            return False\n\n    for col in zip(*board):\n        if len(set(col)) != len(col):\n            return False\n\n    for i in range(0, len(board), 3):\n        for j in range(0, len(board), 3):\n            box = [board[i][k] for k in range(i, i + 3)]\n            for k in range(j, j + 3):\n                box.append(board[k][j])\n            if len(set(box)) != len(box):\n                return False\n\n    return True",
        "def common_elements(list1, list2):\n    common = []\n    for element in list1:\n        if element in list2:\n            common.append(element)\n    return common",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self.heapify(len(self.heap) - 1)\n\n    def heapify(self, index):\n        parent_index = (index - 1) // 2\n        while index > 0:\n            if self.heap[index] > self.heap[parent_index]:\n                self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\n                index = parent_index\n            else:\n                break",
        "from sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n    \"\"\"\n\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1.0, degree2=None):\n        \"\"\"\n        Initialize the Kernel ridge regression class.\n\n        Parameters:\n            alpha (float): Regularization strength parameter. Must be a positive float. Defaults to 1.0.\n            kernel (str): Kernel to be used in the algorithm. Defaults to 'linear'.\n            gamma (float): Kernel coefficient for 'rbf', 'poly', and 'sigmoid'. Ignored by other kernels.\n            degree (int): Degree of the polynomial kernel. Ignored by other kernels.\n            coef0 (float): Independent term in decision function. Defaults to 1.0.\n            degree2 (int): Degree of the polynomial kernel (poly). Only used when gamma is given.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.degree2 = degree2\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using X as training data and y as target values.\n\n        Parameters:\n            X (ndarray): Training data of shape (n_samples, n_features).\n            y (ndarray): Target values of shape (n_samples,).\n        \"\"\"\n        self.X_ = X\n        self.y_ = y\n        self._fit()\n\n    def _fit(self):\n        \"\"\"\n        Internal method to fit the model.\n        \"\"\"\n        # Check if gamma is provided for polynomial kernel\n        if self.kernel == 'poly' and self.gamma is not None:\n            self.degree2 = self.gamma * self.degree\n\n        # Check if degree2 is provided for other kernels\n        elif self.kernel != 'poly' and self.degree2 is not None:\n            self.gamma = self.degree2 / self.degree\n\n        # Check if gamma is provided for other kernels\n        elif self.kernel != 'poly' and self.gamma is None:\n            self.gamma = None\n\n        # Check if degree2 is provided for polynomial kernel\n        elif self.kernel == 'poly' and self.degree2 is None:\n            self.degree2 = None\n\n        # Import necessary modules\n        from sklearn.linear_model import Ridge\n        from sklearn.preprocessing import PolynomialFeatures\n        from sklearn.preprocessing import StandardScaler\n\n        # Standardize the data\n        scaler = StandardScaler()\n        X_std = scaler.fit_transform(self.X_)\n\n        # Apply polynomial features if needed\n        if self.kernel == 'poly':\n            poly = PolynomialFeatures(degree=self.degree, include_bias=False)\n            X_poly = poly.fit_transform(X_std)\n        else:\n            X_poly = X_std\n\n        # Fit the ridge regression model\n        self.model = Ridge(alpha=self.alpha, fit_intercept=True)\n        self.model.fit(X_poly, self.y_)\n\n    def predict(self, X):\n        \"\"\"\n        Predict the target values for the provided data X.\n\n        Parameters:\n            X (ndarray): Data of shape (n_samples, n_features).\n\n        Returns:\n            ndarray: Predicted target values of shape (n_samples,).\n        \"\"\"\n        # Standardize the data\n        scaler = StandardScaler()\n        X_std = scaler.transform(X)\n\n        # Apply polynomial features if needed\n        if self.kernel == 'poly':\n            poly = PolynomialFeatures(degree=self.degree, include_bias=False)\n            X_poly = poly.fit_transform(X_std)\n        else:\n            X_poly = X_std\n\n        # Predict the target values\n        y_pred = self.model.predict(X_poly)\n\n        # Return the predicted target values\n        return y_pred",
        "```python\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Check if a string is a valid palindrome.\n\n    Args:\n        s (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Add a single digit to the variable name\n    i_9 = 9\n\n    # Initialize a boolean flag\n    is_pal = True\n\n    # Check if the string is empty\n    if not s:\n        return False\n\n    # Calculate the length of the string\n    length = len(s)\n\n    # Iterate through the string\n    for i in range(length // 2):\n        # Compare the characters at the start and end of the string\n        if s[i] != s[length - i - 1]:\n            is_pal = False\n            break\n\n    # Return the result\n    return is_pal\n```",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_list = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.adj_list[u].append(v)\n        self.adj_list[v].append(u)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n        for neighbour in self.adj_list[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n        return False\n\n    def is_cyclic(self):\n        visited = [False] * self.vertices\n        rec_stack = [False] * self.vertices\n        for i in range(self.vertices):\n            if not visited[i]:\n                if self.is_cyclic_util(i, visited, rec_stack):\n                    return True\n        return False"
      ]
    }
  ]
}