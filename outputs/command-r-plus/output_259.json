{
  "sessions": [
    {
      "session_model_output": [
        "```python\nfrom typing import List\n\n\ndef find_kth_largest(nums: List[int], k: int) -> int:\n    \"\"\"\n    Finds the k-th largest element in a list of integers.\n\n    :param nums: The input list of integers.\n    :param k: The value of 'k' for the k-th largest element.\n    :return: The k-th largest element in the list.\n    \"\"\"\n    # Sort the list in descending order to access largest elements first\n    sorted_nums = sorted(nums, reverse=True)\n\n    # Return the k-th element from the sorted list\n    return sorted_nums[k - 1]\n```"
      ],
      "instruction_model_output": [
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n\n@require_kwargs\ndef roman_to_int(roman_numeral: str) -> int:\n    try:\n        values = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n        num = 0\n        for i in range(len(roman_numeral)):\n            if i > 0 and values[roman_numeral[i]] > values[roman_numeral[i - 1]]:\n                num += values[roman_numeral[i]] - 2 * values[roman_numeral[i - 1]]\n            else:\n                num += values[roman_numeral[i]]\n        return num\n    except KeyError:\n        raise ValueError(\"Invalid Roman numeral input.\")\n```",
        "from pedantic import require_kwargs\n\n@require_kwargs\ndef is_valid_bst(node: 'Node', min_val: float = float('-inf'), max_val: float = float('inf')) -> bool:\n    \"\"\"\n    Checks if a given binary tree node is a valid Binary Search Tree (BST) node.\n\n    Args:\n        node (Node): The root node of the binary tree.\n        min_val (float, optional): The minimum value allowed in the BST. Defaults to negative infinity.\n        max_val (float, optional): The maximum value allowed in the BST. Defaults to positive infinity.\n\n    Returns:\n        bool: True if the node is a valid BST node, False otherwise.\n    \"\"\"\n    if node is None:\n        return True\n\n    try:\n        val = node.value\n        if not (min_val < val < max_val):\n            return False\n\n        left_is_valid = is_valid_bst(node.left, min_val, val)\n        right_is_valid = is_valid_bst(node.right, val, max_val)\n        return left_is_valid and right_is_valid\n\n    except AttributeError as e:\n        print(f\"Error: {e}. Please ensure that the node has 'value', 'left', and 'right' attributes.\")\n        return False\n\n\nclass Node:\n    def __init__(self, value: int | float):\n        self.value = value\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer",
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        try:\n            import numpy as np\n\n            X = np.array(X)\n            y = np.array(y)\n            self.coef_ = np.linalg.inv(X.T @ X + self.alpha * np.eye(X.shape[1])) @ X.T @ y\n            self.intercept_ = np.mean(y - X @ self.coef_, axis=0)\n        except Exception as e:\n            raise RuntimeError(\"Error occurred during training:\") from e\n\n    def predict(self, X):\n        try:\n            import numpy as np\n\n            X = np.array(X)\n            return X @ self.coef_ + self.intercept_\n        except Exception as e:\n            raise RuntimeError(\"Error occurred during prediction:\") from e",
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_head = 200\n        self.q_tail = 100\n\n    def get(self, key: int) -> int:\n        try:\n            value = self.cache.pop(key)\n            self._usedq(key)\n            return value\n        except KeyError:\n            return -1\n\n    def put(self, key: int, value: int) -> None:\n        try:\n            self.cache.pop(key)\n            self._usedq(key)\n        except KeyError:\n            if len(self.cache) >= self.capacity:\n                del self.cache[self.q_tail]\n                self.q_tail += 1\n        self.cache[key] = value\n        self._usedq(key)\n\n    def _usedq(self, key: int) -> None:\n        self.q_head = key\n        self.q_tail += 1\n        if self.q_tail - self.q_head > self.capacity:\n            self.q_head = self.q_tail - self.capacity\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                min_val = self._find_min(node.right)\n                node.value = min_val\n                node.right = self._delete(min_val, node.right)\n        return node\n\n    def _find_min(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None"
      ],
      "instruction_model_output": [
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef find_longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n\n    for i, char in enumerate(shortest):\n        for other in strs:\n            if other[i] != char:\n                return shortest[:i]\n\n    return shortest\n\n# Update naming convention\ndef find_longest_common_prefix_md(strs: list[str]) -> str:\n    \"\"\"\n    Finds the longest common prefix among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n\n    for i, char in enumerate(shortest):\n        for other in strs:\n            if other[i] != char:\n                return shortest[:i]\n\n    return shortest\n```",
        "```python\nclass Graph:\n    \"\"\"\n    A graph data structure with a method to compute the shortest path between nodes.\n    \"\"\"\n\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.adj_matrix = [[0] * vertices for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        \"\"\"\n        Adds an edge between nodes u and v.\n        \"\"\"\n        self.adj_matrix[u][v] = 1\n        self.adj_matrix[v][u] = 1\n\n    def shortest_path_all_pairs_md(self):\n        \"\"\"\n        Computes the shortest path from every node to all other nodes.\n\n        Returns:\n            A 2D matrix where the element at [i][j] represents the shortest distance from node i to node j.\n        \"\"\"\n        import numpy as np\n\n        adj_matrix = np.array(self.adj_matrix)\n        shortest_distances = np.infty * np.ones(adj_matrix.shape)\n        predecessors = np.full(adj_matrix.shape, -1, dtype=int)\n\n        for i in range(self.vertices):\n            shortest_distances[i][i] = 0\n\n        for k in range(self.vertices):\n            for i in range(self.vertices):\n                for j in range(self.vertices):\n                    if shortest_distances[i][k] != np.infty and shortest_distances[k][j] != np.infty:\n                        shortest_distances[i][j] = min(shortest_distances[i][j], shortest_distances[i][k] + shortest_distances[k][j])\n                        predecessors[i][j] = k\n\n        return shortest_distances, predecessors\n```"
      ],
      "instruction_model_output": [
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```",
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_md(self, u, v, w):\n        self.graph[u].append((v, w))\n        self.graph[v].append((u, w))\n\n    def shortest_path_md(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        for _ in range(self.V):\n            u = self.min_distance_node_md(dist)\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n\n        path = []\n        node = dest\n        while parent[node] != -1:\n            path.append(node)\n            node = parent[node]\n        path.append(node)\n        path.reverse()\n        return path, dist[dest]\n\n    def min_distance_node_md(self, dist):\n        min_dist = float('inf')\n        min_node = -1\n        for v in range(self.V):\n            if dist[v] < min_dist:\n                min_dist = dist[v]\n                min_node = v\n        return min_node"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.j_order = collections.OrderedDict()\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.j_order.move_to_end(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.j_order.move_to_end(key)\n        elif len(self.j_order) >= self.capacity:\n            self.cache.pop(next(iter(self.j_order)))\n            self.j_order.popitem(last=False)\n        self.cache[key] = value\n        self.j_order[key] = None"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.j_capacity = capacity\n        self.j_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.j_cache:\n            return -1\n        self.j_cache.move_to_end(key)\n        return self.j_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.j_cache:\n            self.j_cache.move_to_end(key)\n        elif len(self.j_cache) >= self.j_capacity:\n            self.j_cache.popitem(last=False)\n        self.j_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Inserts a new node with the given value into the binary tree.\n\n        Args:\n            value (int/float/str): The value to be inserted into the binary tree.\n\n        Returns:\n            None\n        \"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        \"\"\"\n        Recursive helper function for inserting a value into the binary tree.\n\n        Args:\n            value (int/float/str): The value to be inserted.\n            node (Node): The current node in the recursive traversal.\n\n        Returns:\n            None\n        \"\"\"\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"\n        Deletes the first occurrence of a node with the given value from the binary tree.\n\n        Args:\n            value (int/float/str): The value of the node to be deleted.\n\n        Returns:\n            bool: True if the node was found and deleted, False otherwise.\n        \"\"\"\n        self.root, deleted = self._delete_recursive(self.root, value)\n        return deleted\n\n    def _delete_recursive(self, node, value, parent=None):\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        Args:\n            node (Node): The current node in the recursive traversal.\n            value (int/float/str): The value of the node to be deleted.\n            parent (Node, optional): The parent node of the current node. Defaults to None.\n\n        Returns:\n            tuple: A tuple containing the modified node and a boolean indicating whether the node was deleted.\n        \"\"\"\n        if not node:\n            return node, False\n\n        if value < node.value:\n            node.left, deleted = self._delete_recursive(node.left, value, node)\n        elif value > node.value:\n            node.right, deleted = self._delete_recursive(node.right, value, node)\n        else:\n            # Node found, handle deletion cases\n            if node.left is None:\n                new_node = node.right\n            elif node.right is None:\n                new_node = node.left\n            else:\n                # Node has two children, get the inorder successor\n                node.value, node.right = self._get_inorder_successor(node.right, parent=node)\n                node.right, _ = self._delete_recursive(node.right, node.value, parent=node)\n                new_node = node\n\n        return new_node, True if deleted else False\n\n    def _get_inorder_successor(self, node, parent=None):\n        \"\"\"\n        Helper function to find the inorder successor of a given node.\n\n        Args:\n            node (Node): The current node in the traversal.\n            parent (Node, optional): The parent node of the current node. Defaults to None.\n\n        Returns:\n            tuple: A tuple containing the inorder successor's value and the modified node.\n        \"\"\"\n        while node.left is not None:\n            parent = node\n            node = node.left\n        return node.value, node\n\n    def __str__(self):\n        \"\"\"\n        Returns a string representation of the binary tree.\n        \"\"\"\n        if not self.root:\n            return \"Binary Tree is empty\"\n        return str(self.root)\n\nclass Node:\n    \"\"\"\n    A node in the binary tree.\n    \"\"\"\n\n    def __init__(self, value, left=None, right=None):\n        \"\"\"\n        Initializes a new binary tree node.\n\n        Args:\n            value (int/float/str): The value stored in the node.\n            left (Node, optional): The left child node. Defaults to None.\n            right (Node, optional): The right child node. Defaults to None.\n        \"\"\"\n        self.value = value\n        self.left = left\n        self.right = right\n\n    def __str__(self):\n        \"\"\"\n        Returns a string representation of the node.\n        \"\"\"\n        return f\"Value: {self.value}\"\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef average_diagonal_elements(matrix):\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list of list of int/float): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input must be a list of lists.\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists.\"\n    assert all(isinstance(element, (int, float)) for row in matrix for element in row), \"All elements in the matrix must be numeric.\"\n\n    size = len(matrix)\n    assert all(len(row) == size for row in matrix), \"Matrix must be square.\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size\n```"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_queue = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.r_queue.remove(key)\n        self.r_queue.insert(0, key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.r_queue.remove(key)\n        elif len(self.r_queue) >= self.capacity:\n            del_key = self.r_queue.pop()\n            del self.cache[del_key]\n        self.r_queue.insert(0, key)\n        self.cache[key] = value\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class NearestNeighbors:\n    \"\"\"\n    A Nearest Neighbors classifier.\n    \"\"\"\n\n    def __init__(self):\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"Number of training examples must match\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model must be trained before prediction\"\n        assert X_test.shape[1] == self.X_train.shape[1], \"Number of features must match\"\n\n        predictions = []\n        for x_test in X_test:\n            distances = self._euclidean_distance(x_test, self.X_train)\n            nearest_neighbor = self.X_train[distances.idxmin()]\n            predictions.append(self.y_train[nearest_neighbor])\n\n        return predictions\n\n    def _euclidean_distance(self, x1, x2):\n        assert x1.shape == x2.shape, \"Input vectors must have the same dimensions\"\n        return ((x1 - x2) ** 2).sum(axis=-1) ** 0.5",
        "def sum_unique_elements(numbers):\n    assert isinstance(numbers, list), \"Input must be a list.\"\n    unique_numbers = list(dict.fromkeys(numbers))\n    unique_sum = sum(i for i in unique_numbers if str(i).find(\"chx\") == -1)\n    return unique_sum"
      ],
      "instruction_model_output": [
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```",
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\n\n@trace_class\nclass KernelRidgeRegression(KernelRidge):\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None,\n                 fit_intercept=True, normalize=False, copy_X=True, verbose=False):\n        super().__init__(alpha, kernel, gamma, degree, coef0, kernel_params, fit_intercept, normalize, copy_X, verbose)"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\n# class_image_classifier.py\n\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass ImageClassifier(nn.Module):\n    \"\"\"\n    Binary Image Classifier Model using PyTorch.\n    \"\"\"\n    def __init__(self, in_channels, hidden_dim):\n        \"\"\"\n        Initialize the ImageClassifier model.\n\n        Parameters:\n        - in_channels (int): Number of input channels in the images.\n        - hidden_dim (int): Number of neurons in the hidden layer.\n        \"\"\"\n        super(ImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.fc1 = nn.Linear(64 * 16 * 16, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, 1)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Parameters:\n        - x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n\n        Returns:\n        - torch.Tensor: Tensor containing model outputs of shape (batch_size, 1)\n        \"\"\"\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        logits = self.fc2(x)\n        return logits\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to a Roman numeral.\n    :param num: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    # Create a dictionary with Roman numeral values\n    values = {\n        1000: \"M\",\n        900: \"CM\",\n        500: \"D\",\n        400: \"CD\",\n        100: \"C\",\n        90: \"XC\",\n        50: \"L\",\n        40: \"XL\",\n        10: \"X\",\n        9: \"IX\",\n        5: \"V\",\n        4: \"IV\",\n        1: \"I\"\n    }\n    roman = \"\"\n    # Convert the integer to a Roman numeral\n    for value in values:\n        count = num // value\n        roman += values[value] * count\n        num %= value\n    return roman\n```"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_str: str) -> bool:\n    \"\"\"\n    Checks if a given string is a palindrome.\n\n    Args:\n        input_str (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    input_str_reversed = input_str[::-1]\n    input_str_lower_n = input_str.lower()\n    input_str_reversed_lower_n = input_str_reversed.lower()\n\n    if input_str_lower_n == input_str_reversed_lower_n:\n        return True\n    else:\n        return False"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_n):\n    s_n = s_n.lower()\n    return s_n == s_n[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_y(s: str) -> bool:\n    s = s.lower()\n    start, end = 0, len(s) - 1\n    while start < end:\n        if s[start] != s[end]:\n            return False\n        start += 1\n        end -= 1\n    return True\n\n\nassert is_palindrome_y(\"radar_y\") == True\nassert is_palindrome_y(\"radhey_y\") == False"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_y):\n    s_y = s_y.lower()\n    start_y, end_x = 0, len(s_y) - 1\n    while start_y < end_x:\n        if s_y[start_y] != s_y[end_x]:\n            return False\n        start_y += 1\n        end_x -= 1\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def n_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def n_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def n_add_stock(self, amount):\n        self.stock += amount\n\n    def n_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def count_non_zero_elements8(matrix):\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n\ndef main():\n    # Matrix example\n    matrix_example = [\n        [1, 2, 0],\n        [0, 4, 5],\n        [6, 0, 7]\n    ]\n\n    # Call the function to count non-zero elements\n    non_zero_count = count_non_zero_elements8(matrix_example)\n    # Rest of the code...\n\nif __name__ == \"__main__\":\n    main()",
        "def is_palindrome8(s_m: str) -> bool:\n    return s_m == s_m[::-1]"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "def is_palindrome(s_m):\n    s_m = s_m.lower()\n    return s_m == s_m[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from typing import List\n\ndef product_except_self(nums: List[int]) -> List[int]:\n    import gzip\n    from pedantic import timer_class\n\n    @timer_class\n    class Solution:\n        def solve(self, nums):\n            n = len(nums)\n            output = [1] * n\n\n            left_products = [1] * n\n            right_products = [1] * n\n\n            for i in range(1, n):\n                left_products[i] = left_products[i - 1] * nums[i - 1]\n\n            for i in range(n - 2, -1, -1):\n                right_products[i] = right_products[i + 1] * nums[i + 1]\n\n            for i in range(n):\n                output[i] = left_products[i] * right_products[i]\n\n            return output\n\n    solution = Solution()\n    return solution.solve(nums)",
        "```python\nfrom gzip import GzipFile\nfrom pedantic import timer_class\n\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, classes):\n        self.classes = classes\n        self.means = None\n        self.cov_matrix = None\n        self.priors = None\n\n    def fit(self, X, y):\n        self.means = []\n        self.cov_matrix = []\n        self.priors = [len(y[y == i]) / len(y) for i in self.classes]\n\n        for cls in self.classes:\n            self.means.append(X[y == cls].mean(axis=0))\n            self.cov_matrix.append(\n                (X[y == cls] - self.means[-1]).T @ (X[y == cls] - self.means[-1]) / len(cls)\n            )\n\n    def predict(self, X):\n        return [self._predict(x) for x in X]\n\n    def _predict(self, x):\n        posteriors = []\n\n        for i, (mean, cov, prior) in enumerate(zip(self.means, self.cov_matrix, self.priors)):\n            det = cov.det()\n            inv = cov.inv()\n            x_minus_mu = x - mean\n            exponent = -0.5 * (x_minus_mu.T @ inv @ x_minus_mu) / det\n            posterior = prior * exponent.exp()\n\n            posteriors.append(posterior)\n\n        return self.classes[posteriors.index(max(posteriors))]\n\n    def score(self, X, y):\n        return (self.predict(X) == y).mean()\n```"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": [
        "```python\nimport numpy as np\nfrom sklearn.kernel_ridge import KernelRidge\n\n\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel=\"linear\", gamma=None, degree=3, coef0=1, kernel_params=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n\n    def fit(self, X, y):\n        self.kr = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n        self.kr.fit(X, y)\n\n    def predict(self, X):\n        return self.kr.predict(X)\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item):\n        self.stock.append(item)\n\n    def remove_stock(self, item):\n        self.stock.remove(item)",
        "```python\nfrom functools import reduce\n\ndef longest_common_prefix(strs: list[str]) -> str:\n    if not strs:\n        return \"\"\n\n    # Sort the list of strings to ensure consistent results\n    strs.sort()\n\n    # Use reduce to find the longest common prefix\n    result = reduce(lambda x, y: common_prefix(x, y), strs)\n\n    return result\n\ndef common_prefix(str1: str, str2: str) -> str:\n    # Find the length of the shorter string\n    min_length = min(len(str1), len(str2))\n\n    # Iterate through the strings to find the common prefix\n    for i in range(min_length):\n        if str1[i] != str2[i]:\n            return str1[:i]\n\n    # If no differences are found, return the shorter string\n    return str1[:min_length]\n```",
        "```python\nfrom pedantic import timer_class, trace_class, require_kwargs\n\n@trace_class\nclass Graph:\n    \"\"\"\n    A graph data structure with a method to compute the shortest path between nodes.\n    \"\"\"\n\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.edges = [(0, 1, 5), (1, 2, 3), (1, 3, 6), (2, 3, 7)]  # Example edges\n\n    @require_kwargs\n    @timer_class\n    def shortest_path(self, start: int, end: int) -> int:\n        \"\"\"\n        Compute the shortest path between two nodes in the graph.\n\n        :param start: int - The starting node.\n        :param end: int - The ending node.\n        :return: int - The length of the shortest path, or None if no path exists.\n        \"\"\"\n        # Implement Dijkstra's algorithm or a similar method to find the shortest path\n        # between the start and end nodes.\n        pass\n```",
        "```python\nfrom pedantic import require_kwargs, timer_class, trace_class\n\n\n@require_kwargs\n@trace_class\ndef is_valid_bst(tree: dict[int, any]) -> bool:\n    \"\"\"\n    Checks if a given tree is a valid binary search tree.\n\n    Args:\n        tree (dict): The tree to be checked. The tree is expected to have integer keys\n            representing node values, and the values can be any hashable type.\n\n    Returns:\n        bool: True if the tree is a valid binary search tree, False otherwise.\n    \"\"\"\n    # Base case: An empty tree is not a valid BST\n    if not tree:\n        return False\n\n    # Initialize min and max values for the tree\n    min_val = float(\"-inf\")\n    max_val = float(\"inf\")\n\n    # Define a helper function to perform an in-order traversal and check validity\n    def check_bst(node: int, min_val: int, max_val: int) -> bool:\n        # Check if the node value is within the valid range\n        if not min_val < tree[node] < max_val:\n            return False\n\n        # Update the min and max values based on the left and right children\n        min_val = min(min_val, tree[node])\n        max_val = max(max_val, tree[node])\n\n        # Recursively check the left and right subtrees\n        if \"left\" in tree[node]:\n            if not check_bst(tree[node][\"left\"], min_val, tree[node] - 1):\n                return False\n\n        if \"right\" in tree[node]:\n            if not check_bst(tree[node][\"right\"], tree[node] + 1, max_val):\n                return False\n\n        return True\n\n    # Start the in-order traversal from the root node\n    root = next(iter(tree))\n    return check_bst(root, min_val, max_val)\n```",
        "```python\nfrom pedantic import timer_class, trace_class, require_kwargs\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    @trace_class\n    @require_kwargs\n    def insert(self, value: int, left=None, right=None) -> None:\n        self.root = Node(value, left, right)\n\n    @require_kwargs\n    def delete(self, value: int) -> None:\n        self._delete_node(self.root, value)\n\n    def _delete_node(self, node, value: int) -> None:\n        if node is None:\n            return\n\n        if value < node.value:\n            self._delete_node(node.left, value)\n        elif value > node.value:\n            self._delete_node(node.right, value)\n        else:\n            if node.left is None:\n                node = node.right\n            elif node.right is None:\n                node = node.left\n            else:\n                successor = self._find_successor(node.right)\n                node.value = successor.value\n                self._delete_node(node.right, successor.value)\n\n    def _find_successor(self, node) -> 'Node':\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n\n    def is_empty(self) -> bool:\n        return self.root is None\n\nclass Node:\n    def __init__(self, value: int, left=None, right=None):\n        self.value = value\n        self.left = left\n        self.right = right\n```",
        "```python\nfrom pedantic import require_kwargs, timer_class\n\n\n@require_kwargs\n@timer_class\ndef int_to_roman(number: int) -> str:\n    \"\"\"\n    Convert an integer to Roman numerals.\n\n    :param number: The integer to be converted.\n    :return: The Roman numeral representation of the input integer.\n    \"\"\"\n    try:\n        if not isinstance(number, int):\n            raise TypeError(\"Input must be an integer.\")\n        if number < 0:\n            raise ValueError(\"Input must be a positive integer.\")\n\n        values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n        symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n        roman = \"\"\n        i = 0\n\n        while number > 0:\n            for _ in range(values[i]):\n                number -= values[i]\n                roman += symbols[i]\n            i += 1\n\n        return roman\n\n    except Exception as e:\n        raise ValueError(f\"An error occurred: {e}\")\n```",
        "```python\ndef is_palindrome(input_string: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    :param input_string: The string to be checked.\n    :return: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Import the 'gzip' module as instructed by Ethan\n    import gzip\n\n    # Add the '@timer_class' decorator from the 'pedantic' module\n    from pedantic import timer_class\n\n    @timer_class\n    def validate_palindrome(string: str) -> bool:\n        # Remove all non-alphanumeric characters and convert to lowercase\n        cleaned_string = \"\".join(char.lower() for char in string if char.isalnum())\n\n        # Reverse the cleaned string\n        reversed_string = cleaned_string[::-1]\n\n        # Return True if the original and reversed strings are equal\n        return cleaned_string == reversed_string\n\n    # Add the single digit '9' as instructed by Ethan\n    is_9_palindrome = validate_palindrome(\"9\")\n\n    # Start variable names with '_m' as instructed by Ethan\n    _m_result = validate_palindrome(\"racecar\")\n\n    # Return the result\n    return _m_result\n```",
        "```python\nimport numpy as np\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclass QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) class for binary classification.\n    \"\"\"\n    def __init__(self, store_covariance=False):\n        \"\"\"\n        Initializes the QDA classifier.\n\n        Parameters:\n        store_covariance (bool): Whether to store the class covariance matrices. Defaults to False.\n        \"\"\"\n        self.store_covariance = store_covariance\n        self.classes_ = []\n        self.covariance_ = []\n        self.priors_ = []\n        self.means_ = []\n        self.coef_ = []\n        self.intercept_ = []\n\n    def fit(self, X, y):\n        \"\"\"\n        Fits the QDA model according to the given training data and target values.\n\n        Parameters:\n        X (ndarray): The input training data of shape (n_samples, n_features).\n        y (ndarray): The target values of shape (n_samples,).\n\n        Returns:\n        self: Fitted instance of the QDA model.\n        \"\"\"\n        # Check if X and y have the same number of samples\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"X and y should have the same number of samples\")\n\n        # Check for binary classification\n        unique_y = np.unique(y)\n        if len(unique_y) != 2:\n            raise ValueError(\"QDA is only supported for binary classification\")\n\n        # Store the classes\n        self.classes_ = unique_y\n\n        # Calculate the prior probabilities\n        self.priors_ = np.bincount(y) / len(y)\n\n        # Calculate the mean for each class\n        self.means_ = np.array([np.mean(X[y == class_, :], axis=0) for class_ in self.classes_])\n\n        # Calculate the covariance matrix for each class\n        self.covariance_ = [np.cov(X[y == class_, :].T) for class_ in self.classes_]\n\n        # Calculate the coefficients and intercept\n        self._estimate_coef_intercept()\n\n        return self\n\n    def _estimate_coef_intercept(self):\n        \"\"\"\n        Estimates the coefficients and intercept for the QDA model.\n        \"\"\"\n        # Calculate the inverse of the covariance matrices\n        self.coef_ = [np.linalg.inv(cov) for cov in self.covariance_]\n\n        # Calculate the log determinants of the covariance matrices\n        log_det_cov = [np.log(np.linalg.det(cov)) for cov in self.covariance_]\n\n        # Calculate the intercepts\n        self.intercept_ = [\n            np.log(prior) - 0.5 * log_det_cov - np.dot(mean, np.dot(np.linalg.inv(cov), mean))\n            for prior, mean, cov in zip(self.priors_, self.means_, self.covariance_)\n        ]\n\n    def predict(self, X):\n        \"\"\"\n        Predicts the class labels for the given input data.\n\n        Parameters:\n        X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n        ndarray: Predicted class labels of shape (n_samples,).\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return self.classes_[np.argmax(jll, axis=1)]\n\n    def _joint_log_likelihood(self, X):\n        \"\"\"\n        Calculates the joint log-likelihood of the input data for each class.\n\n        Parameters:\n        X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n        ndarray: Joint log-likelihood of shape (n_samples, n_classes).\n        \"\"\"\n        jll = np.array(\n            [\n                np.log(prior)\n                - 0.5 * np.log(np.linalg.det(cov))\n                - 0.5 * np.dot(X - mean, np.dot(np.linalg.inv(cov), X - mean))\n                for prior, mean, cov in zip(self.priors_, self.means_, self.covariance_)\n            ]\n        ).T\n\n        return jll\n\n    def predict_proba(self, X):\n        \"\"\"\n        Predicts the probability of each class for the given input data.\n\n        Parameters:\n        X (ndarray): The input data of shape (n_samples, n_features).\n\n        Returns:\n        ndarray: Predicted class probabilities of shape (n_samples, n_classes).\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return np.exp(jll - np.max(jll, axis=1, keepdims=True))\n\n    def score(self, X, y):\n        \"\"\"\n        Returns the mean accuracy of the model's predictions.\n\n        Parameters:\n        X (ndarray): The input data of shape (n_samples, n_features).\n        y (ndarray): The true target values of shape (n_samples,).\n\n        Returns:\n        float: Mean accuracy of the model's predictions.\n        \"\"\"\n        return self.score(X, y, sample_weight=None)\n\n    def score(\n        self, X, y, sample_weight=None\n    ):\n        \"\"\"\n        Returns the mean accuracy of the model's predictions with optional sample weights.\n\n        Parameters:\n        X (ndarray): The input data of shape (n_samples, n_features).\n        y (ndarray): The true target values of shape (n_samples,).\n        sample_weight (ndarray): Sample weights of shape (n_samples,). Defaults to None.\n\n        Returns:\n        float: Mean accuracy of the model's predictions.\n        \"\"\"\n        from sklearn.metrics import accuracy_score\n\n        y_pred = self.predict(X)\n        weights = sample_weight if sample_weight is None else sample_weight / sample_weight.sum()\n        return accuracy_score(y, y_pred, sample_weight=weights)\n```",
        "```python\nfrom heapq import heappop, heapify\n\n\ndef find_kth_largest(nums, k):\n    heapify(nums)\n    for _ in range(k - 1):\n        heappop(nums)\n    return nums[0]\n```",
        "```python\nfrom numpy import trace\nfrom pedantic import timer_class, require_kwargs\n\n\n@require_kwargs\n@timer_class\ndef compute_average_diagonal(matrix: list[list[int]]) -> float:\n    \"\"\"\n    Computes the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list[list[int]]): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    # Validate input\n    if not matrix or not all(len(row) == len(matrix[0]) for row in matrix):\n        raise ValueError(\"Input must be a non-empty square matrix\")\n\n    # Calculate the sum of diagonal elements\n    diagonal_sum = trace(matrix)\n\n    # Calculate the average\n    average_diagonal = diagonal_sum / len(matrix)\n\n    return average_diagonal\n```",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_values = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    total = 0\n    prev_value = 0\n\n    for char in roman[::-1]:\n        value = roman_values[char]\n        if value < prev_value:\n            total -= value\n        else:\n            total += value\n        prev_value = value\n\n    return total\n```",
        "```python\nfrom pedantic import require_kwargs, timer_class\n\n\n@require_kwargs\n@timer_class\ndef count_non_zero_elements(matrix: list[list[int]]) -> int:\n    \"\"\"\n    Counts the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list[list[int]]): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "```python\nfrom typing import Any\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n\n    def get(self, key: int) -> Any:\n        if key in self.cache:\n            value = self.cache.pop(key)\n            self.cache[key] = value\n            return value\n\n    def put(self, key: int, value: Any) -> None:\n        if key in self.cache:\n            self.cache.pop(key)\n        elif len(self.cache) >= self.capacity:\n            self.cache.popitem()\n        self.cache[key] = value\n```",
        "```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nclass NearestNeighborsModel:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n\n    def train(self, X_train, y_train):\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        return self.model.predict(X_test)\n\n# Example usage:\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# model = NearestNeighborsModel()\n# model.train(X_train, y_train)\n# y_pred = model.predict(X_test)\n# accuracy = accuracy_score(y_test, y_pred)\n```",
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pedantic import timer_class, require_kwargs\n\n\n@timer_class\nclass BinaryImageClassifier(nn.Module):\n    def __init__(self, num_features: int, num_classes: int = 1):\n        super(BinaryImageClassifier, self).__init__()\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.linear = nn.Linear(num_features, num_classes)\n\n    @require_kwargs\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        y_pred = self.linear(x)\n        return F.softmax(y_pred, dim=1)\n```",
        "```python\nfrom typing import List\n\n\ndef h_index(citations: List[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation in enumerate(citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "```python\nimport numpy as np\nfrom sklearn.linear_model import Lasso\nfrom sklearn.base import BaseEstimator\n\n\nclass LassoRegression(BaseEstimator):\n    \"\"\"\n    Lasso Regression class for training and prediction.\n\n    Parameters:\n    alpha: float\n        Regularization strength. Must be a positive float.\n\n    Attributes:\n    model: sklearn.linear_model._lasso.Lasso\n        The trained Lasso regression model.\n    \"\"\"\n\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        \"\"\"\n        Train the Lasso regression model.\n\n        Parameters:\n        X_train: array-like of shape (n_samples, n_features)\n            Training data.\n\n        y_train: array-like of shape (n_samples,)\n            Target values.\n        \"\"\"\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X_test):\n        \"\"\"\n        Predict using the trained Lasso regression model.\n\n        Parameters:\n        X_test: array-like of shape (n_samples, n_features)\n            Test data.\n\n        Returns:\n        array-like of shape (n_samples,)\n            Predicted target values.\n        \"\"\"\n        return self.model.predict(X_test)\n```",
        "```python\nfrom pedantic import require_kwargs, timer_class\n\n\n@require_kwargs\n@timer_class\ndef product_array(arr: list[int]) -> int:\n    \"\"\"\n    Calculates the product of all integers in the input list.\n\n    Args:\n        arr (list[int]): A list of integers.\n\n    Returns:\n        int: The product of all integers in the list.\n    \"\"\"\n    product = 1\n    for num in arr:\n        product *= num\n    return product\n```",
        "```python\nfrom typing import List\n\n\n@require_kwargs\ndef sum_unique_numbers(numbers: List[int]) -> int:\n    \"\"\"\n    Computes the sum of unique numbers in the given list.\n\n    :param numbers: List[int]: A list of numbers from which duplicates will be removed.\n    :return: int: The sum of unique numbers in the list.\n    \"\"\"\n    try:\n        unique_numbers = list(set(numbers))\n        total_sum = 0\n        for number in unique_numbers:\n            total_sum += number\n        return total_sum\n    except Exception as e:\n        raise Exception(f\"An error occurred: {e}\")\n```"
      ]
    }
  ]
}