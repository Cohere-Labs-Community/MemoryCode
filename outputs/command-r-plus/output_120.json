{
  "sessions": [
    {
      "session_model_output": [
        "def compute_diagonal_average(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a list of lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Input matrix must be square\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    diagonal_average = diagonal_sum / len(matrix)\n    return diagonal_average",
        "class PCA0:\n    \"\"\"\n    Principal Component Analysis (PCA) class for dimensionality reduction.\n    Includes assert statements for input validation and class name with a single digit suffix.\n    \"\"\"\n\n    def __init__(self, n_components=2):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        assert isinstance(X, (list, np.ndarray)), \"Input data must be a list or numpy array.\"\n        assert X.shape[0] > self.n_components, \"Number of samples must be greater than the number of components.\"\n        assert len(X.shape) == 2, \"Input data must be a 2-dimensional array.\"\n\n        # Calculate mean of each feature\n        mean_vec = np.mean(X, axis=0)\n        mean_removed = X - mean_vec\n\n        # Calculate covariance matrix\n        cov_mat = np.cov(mean_removed, rowvar=False)\n\n        # Compute eigenvalues and eigenvectors\n        eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        idx = eigen_vals.argsort()[::-1]\n        eigen_vals = eigen_vals[idx]\n        eigen_vecs = eigen_vecs[:, idx]\n\n        # Select top n_components eigenvectors\n        projection = eigen_vecs[:, :self.n_components]\n\n        # Transform data to new dimensional space\n        transformed = X @ projection\n\n        return transformed"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)",
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_ud(self, src, dest):\n        visited = [False] * self.V\n        path = []\n\n        def dfs_ud(node, dest):\n            visited[node] = True\n            if node == dest:\n                path.append(node)\n                return True\n            for neighbour in self.graph[node]:\n                if not visited[neighbour]:\n                    if dfs_ud(neighbour, dest):\n                        path.append(node)\n                        return True\n            return False\n\n        dfs_ud(src, dest)\n        return path if dest in path else []\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_ud(self, u, v, weight):\n        self.graph[u].append((v, weight))\n        self.graph[v].append((u, weight))\n\n    def shortest_path_ud(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        parent = [-1] * self.V\n\n        pq = []\n        heapq.heappush(pq, (0, src))\n\n        while pq:\n            d, u = heapq.heappop(pq)\n\n            for v, weight in self.graph[u]:\n                if dist[u] + weight < dist[v]:\n                    dist[v] = dist[u] + weight\n                    parent[v] = u\n                    heapq.heappush(pq, (dist[v], v))\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return dist[dest], path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def chx_flatten_binary_tree(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    root.right = chx_flatten_binary_tree(root.right)\n    root.left = None\n    root.right = chx_flatten(root.left, root.right)\n    return root"
      ],
      "instruction_model_output": [
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": [
        "```python\nimport numpy as np\n\n\nclass PCA9:\n    def __init__(self, n_components):\n        self.n_components = n_components\n        self._mean = None\n        self._components = None\n        self._explained_variance = None\n        self._explained_variance_ratio = None\n\n    def fit(self, X):\n        X = np.array(X)\n        self._mean = np.mean(X, axis=0)\n        X_centered = X - self._mean\n        covariance_matrix = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n        indices = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[indices]\n        eigenvectors = eigenvectors[:, indices]\n        self._components = eigenvectors[:, :self.n_components]\n        self._explained_variance = eigenvalues[:self.n_components]\n        self._explained_variance_ratio = (\n            self._explained_variance / np.sum(eigenvalues)\n        )\n\n    def transform(self, X):\n        X_centered = X - self._mean\n        transformed = X_centered @ self._components\n        return transformed\n\n    def fit_transform(self, X):\n        self.fit(X)\n        transformed = self.transform(X)\n        return transformed\n\n    @property\n    def explained_variance_ratio_(self):\n        return self._explained_variance_ratio\n```",
        "```python\nclass Node_1:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\ndef flatten_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    left = root.left\n    right = root.right\n    root.left = None\n    root.right = left\n    while root.right:\n        root = root.right\n    root.right = right\n    return root\n```",
        "def _compute_diagonal_average_chx(matrix):\n    assert isinstance(matrix, list) and all(isinstance(row, list) for row in matrix), \"Input must be a list of lists\"\n    assert all(len(row) == len(matrix) for row in matrix), \"Input matrix must be square\"\n\n    size = len(matrix)\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size",
        "```python\nclass Graph7:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)]\n                     for _ in range(vertices)]\n\n    # method with '_ud' suffix and 'chx' string in its name\n    def dijkstra_chx_ud(self, src):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        heap = [(0, src)]\n\n        while heap:\n            d, u = heapq.heappop(heap)\n            for v in range(self.V):\n                if self.graph[u][v] != 0 and dist[v] > dist[u] + self.graph[u][v]:\n                    dist[v] = dist[u] + self.graph[u][v]\n                    heapq.heappush(heap, (dist[v], v))\n\n        return dist\n```"
      ]
    }
  ]
}