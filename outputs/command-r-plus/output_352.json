{
  "sessions": [
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import retry\n\n\n@retry\ndef a_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry()\n    def a_add_song(self, song):\n        self.songs.append(song)\n\n    @retry()\n    def a_remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "instruction_model_output": [
        "```python\ndef a_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "from pedantic import retry\n\nclass Playlist:\n    def __init__(self):\n        self.songs = []\n\n    @retry\n    def add_song(self, song):\n        self.songs.append(song)\n\n    @retry\n    def remove_song(self, song):\n        self.songs.remove(song)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    @validate\n    def add_book(self, book: Book) -> None:\n        self.books.append(book)\n        assert book in self.books, \"Book not added successfully.\"\n\n    @validate\n    def remove_book(self, book_title: str) -> None:\n        book_to_remove = next((book for book in self.books if book.title == book_title), None)\n        if book_to_remove:\n            self.books.remove(book_to_remove)\n            assert book_to_remove not in self.books, \"Book not removed successfully.\"\n        else:\n            raise ValueError(f\"Book with title '{book_title}' not found.\")",
        "from sklearn.neighbors import KNeighborsClassifier\nfrom typing import Any, Dict\n\nfrom pedantic import validate\n\n\nclass NearestNeighborsModel:\n    \"\"\"\n    A Nearest Neighbors Model for classification.\n    \"\"\"\n\n    def __init__(self, n_neighbors: int = 5):\n        \"\"\"\n        Initializes the Nearest Neighbors Model.\n\n        :param n_neighbors: The number of neighbors to use for prediction. Defaults to 5.\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n\n    @validate(\"X: list[list[float]], y: list[int]\")\n    def train(self, X: list[list[float]], y: list[int]) -> None:\n        \"\"\"\n        Trains the Nearest Neighbors Model.\n\n        :param X: A 2D list of feature values.\n        :param y: A list of corresponding target values.\n        :return: None\n        \"\"\"\n        self.model.fit(X, y)\n\n    @validate(\"X: list[list[float]]\")\n    def predict(self, X: list[list[float]]) -> list[int]:\n        \"\"\"\n        Predicts the target values for the provided feature values using the trained model.\n\n        :param X: A 2D list of feature values.\n        :return: A list of predicted target values.\n        \"\"\"\n        return self.model.predict(X).tolist()\n\n    def get_params(self) -> Dict[str, Any]:\n        \"\"\"\n        Returns the parameters of the model.\n\n        :return: A dictionary of model parameters.\n        \"\"\"\n        return {\"n_neighbors\": self.n_neighbors}"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass\r\nfrom pedantic.decorators import validate\r\nfrom typing import List, Optional\r\n\r\n\r\n@dataclass\r\nclass Library:\r\n    books: List[str] = dataclass(default_factory=list)\r\n\r\n    @validate\r\n    def add_book(self, book: str) -> None:\r\n        self.books.append(book)\r\n\r\n    @validate\r\n    def remove_book(self, book: str) -> Optional[str]:\r\n        if book in self.books:\r\n            self.books.remove(book)\r\n            return book\r\n        return None",
        "```python\nclass NearestNeighbors:\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n        self.X_train = None\n        self.y_train = None\n\n    def train(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \"X_train and y_train must have the same number of samples\"\n        self.X_train = X_train\n        self.y_train = y_train\n\n    def predict(self, X_test):\n        assert self.X_train is not None and self.y_train is not None, \"Model has not been trained yet\"\n        assert self.X_train.shape[1] == X_test.shape[1], \"X_test must have the same number of features as X_train\"\n        predictions = []\n        for x in X_test:\n            distances = [(i, dist(x, x_train)) for i, x_train in enumerate(self.X_train)]\n            nearest = sorted(distances, key=lambda x: x[1])[:self.n_neighbors]\n            y_nearest = [self.y_train[i] for _, i in nearest]\n            predictions.append(max(set(y_nearest), key=y_nearest.count))\n        return predictions\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def gn_h_index_calculator(citations_g: list[int]) -> int:\n    citations_g.sort(reverse=True)\n    h_index_g = 0\n    for i, citation_g in enumerate(citations_g):\n        if citation_g >= i + 1:\n            h_index_g = i + 1\n        else:\n            break\n    return h_index_g",
        "def gn_merge_sorted_lists(list1_g, list2_g):\n    result_g = []\n    i, j = 0, 0\n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            result_g.append(list1_g[i])\n            i += 1\n        else:\n            result_g.append(list2_g[j])\n            j += 1\n    result_g.extend(list1_g[i:])\n    result_g.extend(list2_g[j:])\n    return result_g"
      ],
      "instruction_model_output": [
        "def gn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def merge_sorted_lists(list1_g, list2_g):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_g) and j < len(list2_g):\n        if list1_g[i] < list2_g[j]:\n            merged_list.append(list1_g[i])\n            i += 1\n        else:\n            merged_list.append(list2_g[j])\n            j += 1\n    \n    while i < len(list1_g):\n        merged_list.append(list1_g[i])\n        i += 1\n    \n    while j < len(list2_g):\n        merged_list.append(list2_g[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LassoRegression:\n    def __init__(self, alpha=1):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def _fit(self, X, y):\n        try:\n            from sklearn.linear_model import Lasso\n            self.model = Lasso(alpha=self.alpha)\n            self.model.fit(X, y)\n            self.coef_ = self.model.coef_\n            self.intercept_ = self.model.intercept_\n        except ImportError:\n            raise ImportError(\"scikit-learn is not installed. Please install it to use Lasso Regression.\")\n        except Exception as e:\n            raise RuntimeError(f\"An error occurred while training the Lasso Regression model: {e}\")\n\n    def train(self, X_train, y_train):\n        self._fit(X_train, y_train)\n\n    def predict(self, X_test):\n        if self.coef_ is None or self.intercept_ is None:\n            raise RuntimeError(\"Model has not been trained yet. Please call the train method before predicting.\")\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            raise RuntimeError(f\"An error occurred while making predictions: {e}\")",
        "```python\nclass DirectedGraph:\n     def __init__(self, vertices):\n         self.V = vertices\n         self.graph = [[] for _ in range(vertices)]\n\n     def add_edge(self, u, v):\n         self.graph[u].append(v)\n\n     def is_cyclic_util(self, v, visited, rec_stack):\n         visited[v] = True\n         rec_stack[v] = True\n\n         for neighbour in self.graph[v]:\n             if not visited[neighbour]:\n                 if self.is_cyclic_util(neighbour, visited, rec_stack):\n                     return True\n             elif rec_stack[neighbour]:\n                 return True\n\n         rec_stack[v] = False\n         return False\n\n     def is_cyclic(self):\n         visited = [False] * self.V\n         rec_stack = [False] * self.V\n         for node in range(self.V):\n             if not visited[node]:\n                 if self.is_cyclic_util(node, visited, rec_stack):\n                     return True\n         return False\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom sklearn.linear_model import Lasso\n\nclass LassoRegression:\n    def __init__(self, alpha=0.1):\n        self.alpha = alpha\n        self.model = Lasso(alpha=alpha)\n\n    def train(self, X_train, y_train):\n        try:\n            self.model.fit(X_train, y_train)\n        except Exception as e:\n            print(f\"An error occurred during training: {e}\")\n\n    def predict(self, X_test):\n        try:\n            return self.model.predict(X_test)\n        except Exception as e:\n            print(f\"An error occurred during prediction: {e}\")\n```",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.adj = [[] for _ in range(vertices)]\n\n    def add_edge1(self, u, v):\n        self.adj[u].append(v)\n\n    def is_cyclic_util(self, v, visited, rec_stack):\n        visited[v] = True\n        rec_stack[v] = True\n\n        for neighbour in self.adj[v]:\n            if not visited[neighbour]:\n                if self.is_cyclic_util(neighbour, visited, rec_stack):\n                    return True\n            elif rec_stack[neighbour]:\n                return True\n\n        rec_stack[v] = False\n        return False\n\n    def is_cyclic9(self):\n        visited = [False] * self.V\n        rec_stack = [False] * self.V\n\n        for node in range(self.V):\n            if not visited[node]:\n                if self.is_cyclic_util(node, visited, rec_stack):\n                    return True\n        return False"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def x_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "```python\ndef x_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_sudoku(board):\n    for i in range(9):\n        row = set()\n        col = set()\n        box = set()\n        for j in range(9):\n            current = board[i][j]\n            if current in row or current in col or current in box:\n                return False\n            row.add(current)\n            col.add(current)\n            if (i // 3, j // 3) in [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]:\n                box.add(current)\n            elif (i // 3, j // 3) in [(2, 0), (2, 1), (2, 2), (0, 0), (0, 1), (0, 2)]:\n                box = set(current)\n            elif (i // 3, j // 3) in [(1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]:\n                box.update([current])\n        box.clear()\n    return True\n\n\ndef check_sudoku(board):\n    z_valid = is_valid_sudoku(board)\n    return z_valid"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(z_board):\n    z_rows = [set() for _ in range(9)]\n    z_cols = [set() for _ in range(9)]\n    z_boxes = [set() for _ in range(9)]\n\n    for z_i in range(9):\n        for z_j in range(9):\n            z_num = z_board[z_i][z_j]\n            if z_num != '.':\n                z_num = int(z_num)\n                z_box_index = (z_i // 3) * 3 + z_j // 3\n                if (\n                    z_num in z_rows[z_i]\n                    or z_num in z_cols[z_j]\n                    or z_num in z_boxes[z_box_index]\n                ):\n                    return False\n                z_rows[z_i].add(z_num)\n                z_cols[z_j].add(z_num)\n                z_boxes[z_box_index].add(z_num)\n\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef average_diagonal(matrix):\n    \"\"\"\n    Calculates the average of the diagonal elements of a square matrix.\n\n    Args:\n        matrix (list of list of int/float): The input square matrix.\n\n    Returns:\n        float: The average of the diagonal elements.\n    \"\"\"\n    assert isinstance(matrix, list), \"Input must be a list of lists\"\n    assert all(isinstance(row, list) for row in matrix), \"All rows must be lists\"\n    assert all(isinstance(num, (int, float)) for row in matrix for num in row), \"All elements in the matrix must be numeric\"\n\n    size = len(matrix)\n    assert all(len(row) == size for row in matrix), \"Matrix must be square\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(size))\n    return diagonal_sum / size\n```"
      ],
      "instruction_model_output": [
        "def average_diagonal(matrix):\n    assert all(len(row) == len(matrix) for row in matrix), \"Input must be a square matrix\"\n    assert len(matrix) > 0, \"Matrix must not be empty\"\n\n    diagonal_sum = sum(matrix[i][i] for i in range(len(matrix)))\n    return diagonal_sum / len(matrix)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def sum_unique_numbers_chx(numbers_chx):\n    unique_nums_chx = list(set(numbers_chx))\n    total_sum_chx = sum(unique_nums_chx)\n    return total_sum_chx",
        "```python\ndef flatten(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    root.right = flatten(root.right)\n    root.left = flatten(root.left)\n    if root.left:\n        temp = root.right\n        root.right = root.left\n        root.left = None\n        while root.right:\n            root = root.right\n        root.right = temp\n    return root\n```"
      ],
      "instruction_model_output": [
        "def sum_unique_numbers(chx_num_list):\n    chx_unique_nums = list(set(chx_num_list))\n    chx_sum = sum(chx_unique_nums)\n    return chx_sum",
        "def flatten_binary_tree_to_linked_list_chx(root):\n    if not root:\n        return None\n    if not root.left and not root.right:\n        return root\n    if root.left:\n        temp = flatten_binary_tree_to_linked_link_chx(root.left)\n        while temp.right:\n            temp = temp.right\n        temp.right = root.right\n        root.right = root.left\n        root.left = None\n    return flatten_binary_tree_to_linked_list_chx(root.right)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef merge_sorted_lists(list1_j, list2_j):\n    result_j = []\n    i, j = 0, 0\n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            result_j.append(list1_j[i])\n            i += 1\n        else:\n            result_j.append(list2_j[j])\n            j += 1\n    result_j.extend(list1_j[i:])\n    result_j.extend(list2_j[j:])\n    return result_j\n```"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_j, list2_j):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_j) and j < len(list2_j):\n        if list1_j[i] < list2_j[j]:\n            merged_list.append(list1_j[i])\n            i += 1\n        else:\n            merged_list.append(list2_j[j])\n            j += 1\n    \n    while i < len(list1_j):\n        merged_list.append(list1_j[i])\n        i += 1\n    \n    while j < len(list2_j):\n        merged_list.append(list2_j[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def y_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def y_is_valid_sudoku(n_board):\n    n_rows = set()\n    n_cols = set()\n    n_boxes = set()\n    for i in range(9):\n        n_rows.clear()\n        n_cols.clear()\n        n_boxes.clear()\n        for j in range(9):\n            n_num = n_board[i][j]\n            if n_num not in n_rows and n_num not in n_cols and n_num not in n_boxes:\n                n_rows.add(n_num)\n                n_cols.add(n_num)\n                n_boxes.add(n_num + 10 * (i // 3) + j // 3)\n        return True\n    return False"
      ],
      "instruction_model_output": [
        "def y_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def is_valid_sudoku(n_board):\n    n_seen = set()\n    for n_i in range(9):\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_i][n_j] != '.':\n                if n_board[n_i][n_j] in n_seen:\n                    return False\n                n_seen.add(n_board[n_i][n_j])\n        n_seen = set()\n        for n_j in range(9):\n            if n_board[n_j][n_i] != '.':\n                if n_board[n_j][n_i] in n_seen:\n                    return False\n                n_seen.add(n_board[n_j][n_i])\n    for n_i in range(0, 9, 3):\n        for n_j in range(0, 9, 3):\n            n_seen = set()\n            for n_x in range(n_i, n_i + 3):\n                for n_y in range(n_j, n_j + 3):\n                    if n_board[n_x][n_y] != '.':\n                        if n_board[n_x][n_y] in n_seen:\n                            return False\n                        n_seen.add(n_board[n_x][n_y])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import count_calls\n\n@count_calls\ndef is_valid_sudoku(board: list[list[str]]) -> bool:\n    \"\"\"\n    Determines if a given 9x9 sudoku board is valid.\n\n    Args:\n        board (list[list[str]]): The sudoku board to validate.\n\n    Returns:\n        bool: True if the board is a valid sudoku, False otherwise.\n    \"\"\"\n    vr_seen = set()\n    vr_rows = set()\n    vr_cols = set()\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            if board[vr_i][vr_j] != \".\":\n                if board[vr_i][vr_j] in vr_seen:\n                    return False\n                vr_seen.add(board[vr_i][vr_j])\n                vr_rows.add(board[vr_i][vr_j])\n                vr_cols.add(board[vr_j][vr_i])\n\n        vr_seen.clear()\n        vr_rows.clear()\n        vr_cols.clear()\n\n    return True\n\n\nassert is_valid_sudoku([\n    [\"5\", \"3\", \".\", \".\", \"7\", \".\", \".\", \".\", \".\"],\n    [\"6\", \".\", \".\", \"1\", \"9\", \"5\", \".\", \".\", \"4\"],\n    [\".\", \"9\", \"8\", \".\", \".\", \".\", \".\", \"6\", \"3\"],\n    [\"8\", \".\", \".\", \".\", \"6\", \".\", \".\", \".\", \"1\"],\n    [\"4\", \".\", \".\", \"8\", \".\", \"3\", \".\", \"9\", \"5\"],\n    [\"7\", \".\", \".\", \".\", \"2\", \".\", \".\", \".\", \"6\"],\n    [\".\", \"6\", \".\", \".\", \".\", \"2\", \"8\", \".\", \"9\"],\n    [\".\", \"3\", \".\", \".\", \".\", \".\", \".\", \"8\", \"7\"],\n    [\".\", \".\", \".\", \"4\", \"1\", \"9\", \".\", \".\", \"5\"],\n]) is True\n```",
        "```python\nfrom pedantic import count_calls\n\nclass LinearRegression:\n    def __init__(self):\n        self.coefficients = None\n\n    @count_calls\n    def train(self, X, y):\n        # Assuming X is a 2D array and y is a 1D array\n        self.coefficients = np.linalg.inv(X.T @ X) @ X.T @ y\n\n    @count_calls\n    def predict(self, X):\n        # Assuming X is a 2D array\n        return X @ self.coefficients\n\n# Example usage:\n# from sklearn.datasets import load_diabetes\n# from sklearn.model_selection import train_test_split\n# import numpy as np\n#\n# diabetes = load_diabetes()\n# X, y = diabetes.data, diabetes.target\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n#\n# model = LinearRegression()\n# model.train(X_train, y_train)\n# predictions = model.predict(X_test)\n```"
      ],
      "instruction_model_output": [
        "def is_valid_sudoku(board):\n    vr_seen = set()\n    vr_rows = [set() for _ in range(9)]\n    vr_cols = [set() for _ in range(9)]\n    vr_boxes = [set() for _ in range(9)]\n\n    for vr_i in range(9):\n        for vr_j in range(9):\n            vr_num = board[vr_i][vr_j]\n            if vr_num != '.':\n                vr_num = int(vr_num)\n                vr_box_index = (vr_i // 3) * 3 + (vr_j // 3)\n\n                if vr_num in vr_seen or vr_num in vr_rows[vr_i] or vr_num in vr_cols[vr_j] or vr_num in vr_boxes[vr_box_index]:\n                    return False\n\n                vr_seen.add(vr_num)\n                vr_rows[vr_i].add(vr_num)\n                vr_cols[vr_j].add(vr_num)\n                vr_boxes[vr_box_index].add(vr_num)\n\n    return True",
        "from pedantic import pedantic, count_calls\nfrom sklearn.linear_model import LinearRegression\n\n@pedantic\nclass LinearRegressionModel:\n    @count_calls\n    def __init__(self):\n        self.model = LinearRegression()\n\n    @count_calls\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    @count_calls\n    def predict(self, X):\n        return self.model.predict(X)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def m7_count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        for elem in row:\n            if elem != 0:\n                count += 1\n    return count",
        "from mailbox import Mailbox\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinarySearchTree:\n    def __init__(self):\n        self.root = None\n\n    def _insert(self, root, value):\n        if value < root.value:\n            if root.left is None:\n                root.left = Node(value)\n            else:\n                self._insert(root.left, value)\n        else:\n            if root.right is None:\n                root.right = Node(value)\n            else:\n                self._insert(root.right, value)\n\n    def insert(self, value):\n        if self.root is None:\n            self.root = Node(value)\n        else:\n            self._insert(self.root, value)\n\n    def _delete(self, root, key):\n        if key < root.value:\n            root.left = self._delete(root.left, key)\n        elif key > root.value:\n            root.right = self._delete(root.right, key)\n        else:\n            if root.left is None:\n                return root.right\n            elif root.right is None:\n                return root.left\n            root.value = self._find_min_value(root.right)\n            root.right = self._delete(root.right, root.value)\n        return root\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\n    def delete(self, key):\n        if self.root:\n            self.root = self._delete(self.root, key)\n\n    def in_order_traversal(self):\n        result = []\n        self._in_order_traversal(self.root, result)\n        return result\n\n    def _in_order_traversal(self, root, result):\n        if root:\n            self._in_order_traversal(root.left, result)\n            result.append(root.value)\n            self._in_order_traversal(root.right, result)\n\n\ndef delete_node(bst, key):\n    bst.delete(key)"
      ],
      "instruction_model_output": [
        "def count_non_zero(matrix):\n    count = 0\n    for row in matrix:\n        count += sum(1 for elem in row if elem != 0)\n    return count",
        "import mailbox\r\n\r\ndef delete_node(root, key):\r\n    if root is None:\r\n        return root\r\n\r\n    if key < root.key:\r\n        root.left = delete_node(root.left, key)\r\n    elif key > root.key:\r\n        root.right = delete_node(root.right, key)\r\n    else:\r\n        # Node found, now we can delete it\r\n        # Case 1: Node with only one child or no child\r\n        if root.left is None:\r\n            return root.right\r\n        elif root.right is None:\r\n            return root.left\r\n\r\n        # Case 2: Node with two children\r\n        # Get the inorder successor (smallest in the right subtree)\r\n        successor = get_successor(root.right)\r\n\r\n        # Copy the inorder successor's value to this node\r\n        root.key = successor.key\r\n\r\n        # Delete the inorder successor\r\n        root.right = delete_node(root.right, successor.key)\r\n\r\n    return root\r\n\r\n\r\ndef get_successor(node):\r\n    while node.left is not None:\r\n        node = node.left\r\n    return node"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    \"\"\"\n    A binary tree data structure.\n\n    This class provides methods to insert and delete nodes in the binary tree.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize an empty binary tree.\n        \"\"\"\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"\n        Insert a new node with the given value into the binary tree.\n\n        Args:\n            value: The value to be inserted into the binary tree.\n        \"\"\"\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node, value):\n        \"\"\"\n        Recursive helper function for inserting a new node.\n\n        Args:\n            node: The current node in the recursive traversal.\n            value: The value to be inserted.\n\n        Returns:\n            The modified node after inserting the new value.\n        \"\"\"\n        if not node:\n            return Node(value)\n\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n\n        return node\n\n    def delete(self, value):\n        \"\"\"\n        Delete the first node with the given value from the binary tree.\n\n        Args:\n            value: The value of the node to be deleted.\n        \"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        \"\"\"\n        Recursive helper function for deleting a node with the given value.\n\n        Args:\n            node: The current node in the recursive traversal.\n            value: The value of the node to be deleted.\n\n        Returns:\n            The modified node after deleting the node with the given value.\n        \"\"\"\n        if not node:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if not node.left and not node.right:  # Case 1: Node has no children\n                node = None\n            elif not node.left:  # Case 2: Node has only a right child\n                node = node.right\n            elif not node.right:  # Case 2: Node has only a left child\n                node = node.left\n            else:  # Case 3: Node has both left and right children\n                successor = self._find_min(node.right)\n                node.value = successor.value\n                node.right = self._delete_recursive(node.right, successor.value)\n\n        return node\n\n    def _find_min(self, node):\n        \"\"\"\n        Find the node with the minimum value in a subtree.\n\n        Args:\n            node: The root of the subtree.\n\n        Returns:\n            The node with the minimum value in the subtree.\n        \"\"\"\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string among a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix among the input strings.\n\n    Example:\n        >>> longest_common_prefix([\"flower\", \"flour\", \"flight\"])\n        'fl'\n        >>> longest_common_prefix([\"dog\", \"cat\", \"cow\"])\n        ''\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for j in range(1, len(strs)):\n            if i == len(strs[j]) or strs[j][i] != char:\n                return strs[0][:i]\n\n    return strs[0]\n```"
      ],
      "instruction_model_output": [
        "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        \"\"\"Insert a new node with the given value into the binary tree.\"\"\"\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert_recursive(value, self.root)\n\n    def _insert_recursive(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert_recursive(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert_recursive(value, node.right)\n\n    def delete(self, value):\n        \"\"\"Delete the first node with the given value from the binary tree.\"\"\"\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node, value):\n        if node is None:\n            return node\n\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            node.value = self._get_inorder_successor(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n\n        return node\n\n    def _get_inorder_successor(self, node):\n        while node.left is not None:\n            node = node.left\n        return node.value\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    \"\"\"\n    Returns the longest common prefix string in a list of strings.\n\n    Args:\n        strs (list[str]): A list of input strings.\n\n    Returns:\n        str: The longest common prefix string.\n    \"\"\"\n    if not strs:\n        return \"\"\n\n    for i, char in enumerate(strs[0]):\n        for other in strs[1:]:\n            if i == len(other) or other[i] != char:\n                return strs[0][:i]\n    return strs[0]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Graph:\n    def shortest_path_a(self, start, end, matrix):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            for next_node in range(len(matrix[node])):\n                if matrix[node][next_node] == 1 and next_node not in path:\n                    new_path = list(path)\n                    new_path.append(next_node)\n                    if next_node == end:\n                        return new_path\n                    queue.append((next_node, new_path))"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[0 for _ in range(vertices)] for _ in range(vertices)]\n\n    def print_a(self):\n        for i in range(self.V):\n            for j in range(self.V):\n                if self.graph[i][j] == 1:\n                    print(f\"{i} - {j}\")\n\n    def add_edge_a(self, u, v):\n        self.graph[u][v] = 1\n        self.graph[v][u] = 1\n\n    def shortest_path_a(self, src, dest):\n        distance = [float(\"Inf\")] * self.V\n        distance[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            for v in range(self.V):\n                if self.graph[u][v] == 1 and distance[v] > distance[u] + 1:\n                    distance[v] = distance[u] + 1\n                    queue.append(v)\n        return distance[dest]\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef c_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index\n```",
        "```python\nclass Node:\n    def __init__(self, value: int) -> None:\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinaryTree:\n    def __init__(self) -> None:\n        self.root = None\n\n    def c_insert(self, value: int) -> None:\n        self.root = self._insert_recursive(self.root, value)\n\n    def _insert_recursive(self, node: Node, value: int) -> Node:\n        if not node:\n            return Node(value)\n        if value < node.value:\n            node.left = self._insert_recursive(node.left, value)\n        else:\n            node.right = self._insert_recursive(node.right, value)\n        return node\n\n    def c_delete(self, value: int) -> None:\n        self.root = self._delete_recursive(self.root, value)\n\n    def _delete_recursive(self, node: Node, value: int) -> Node:\n        if not node:\n            return node\n        if value < node.value:\n            node.left = self._delete_recursive(node.left, value)\n        elif value > node.value:\n            node.right = self._delete_recursive(node.right, value)\n        else:\n            if not node.left:\n                return node.right\n            elif not node.right:\n                return node.left\n            node.value = self._get_min_value(node.right)\n            node.right = self._delete_recursive(node.right, node.value)\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "instruction_model_output": [
        "def c_compute_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "```python\nfrom typing import Optional, Tuple\n\n\nclass Node:\n    def __init__(self, value: int):\n        self.value = value\n        self.left: Optional[Node] = None\n        self.right: Optional[Node] = None\n\n\nclass BinaryTree:\n    def __init__(self):\n        self.root: Optional[Node] = None\n\n    def insert(self, value: int) -> None:\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value: int, node: Node) -> None:\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        else:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value: int) -> None:\n        self.root = self._delete(value, self.root)\n\n    def _delete(\n        self, value: int, node: Optional[Node]\n    ) -> Optional[Node]:\n        if node is None:\n            return None\n\n        if value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n\n            # Node with two children: Get the inorder successor (smallest in the right subtree)\n            new_value = self._get_min_value(node.right)\n            node.value = new_value\n            node.right = self._delete(new_value, node.right)\n\n        return node\n\n    def _get_min_value(self, node: Node) -> int:\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def int_to_roman(num: int) -> str:\n    \"\"\"\n    Convert an integer to a Roman numeral.\n    :param num: The integer to be converted.\n    :return: The corresponding Roman numeral as a string.\n    \"\"\"\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman = \"\"\n    i = 0\n\n    while num > 0:\n        for _ in range(num // values[i]):\n            roman += symbols[i]\n            num -= values[i]\n        i += 1\n\n    return roman\n\n\n# Add a main function to test the int_to_roman function\ndef main():\n    num = 1994\n    result = int_to_roman(num)\n    print(f\"{num} in Roman numerals is: {result}\")\n\n\nif __name__ == \"__main__\":\n    main()",
        "def mean(data):\n    \"\"\"\n    Computes the mean of a list of numbers using an online algorithm.\n    \"\"\"\n    # Initialize variables with a single digit in the name as per the coding guidelines\n    sum_ = 0.0\n    count = 0\n\n    # Iterate over the data\n    for i in data:\n        # Accumulate the sum and count\n        sum_ += i\n        count += 1\n\n    # Return the mean\n    return sum_ / count"
      ],
      "instruction_model_output": [
        "def int_to_roman(num):\n    \"\"\"Convert an integer to Roman numeral.\"\"\"\n    # Base cases\n    if num == 0:\n        return \"\"\n    elif num < 0:\n        raise ValueError(\"Input must be a positive integer.\")\n\n    # Create a list of Roman numeral values and their equivalents\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n\n    # Iterate through the values and symbols to construct the Roman numeral\n    roman = \"\"\n    for i in range(len(values)):\n        count = num // values[i]\n        roman += symbols[i] * count\n        num %= values[i]\n\n    return roman",
        "def mean_online(data_1):\n    mean_2, count_3 = 0, 0\n\n    for value_4 in data_1:\n        mean_2, count_3 = mean_2 + (value_4 - mean_2) / count_3, count_3 + 1\n\n    return mean_2"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def product_except_self(nums):\n    length = len(nums)\n    output = [1] * length\n    left_product = 1\n    right_product = 1\n\n    for i in range(1, length):\n        left_product *= nums[i - 1]\n        output[i] *= left_product\n\n    for i in range(length - 2, -1, -1):\n        right_product *= nums[i + 1]\n        output[i] *= right_product\n\n    return output"
      ],
      "instruction_model_output": [
        "def productExceptSelf(nums):\n    import gzip\n    n = len(nums)\n    output = [1] * n\n\n    left_products = [1] * n\n    right_products = [1] * n\n\n    for i in range(1, n):\n        left_products[i] = nums[i - 1] * left_products[i - 1]\n\n    for i in range(n - 2, -1, -1):\n        right_products[i] = nums[i + 1] * right_products[i + 1]\n\n    for i in range(n):\n        output[i] = left_products[i] * right_products[i]\n\n    return output"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import secrets\n\ndef fn_edit_distance(str1, str2):\n    len1 = len(str1)\n    len2 = len(2)\n    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]\n\n    for i in range(len1 + 1):\n        dp[i][0] = i\n    for j in range(len2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len1 + 1):\n        for j in range(1, len2 + 1):\n            cost = 0 if str1[i - 1] == str2[j - 1] else 1\n            dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n\n    return dp[len1][len2]",
        "import secrets\n\ndef fn_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "import secrets\r\n\r\ndef edit_distance(s1, s2):\r\n    if len(s1) < len(s2):\r\n        s1, s2 = s2, s1\r\n    len_s1 = len(s1)\r\n    len_s2 = len(s2)\r\n    previous_row = range(len_s2 + 1)\r\n    for idx1 in range(1, len_s1 + 1):\r\n        current_row = [idx1]\r\n        for idx2 in range(1, len_s2 + 1):\r\n            insertions = previous_row[idx2] + 1\r\n            deletions = current_row[idx2 - 1] + 1\r\n            substitutions = previous_row[idx2 - 1] + (s1[idx1 - 1] != s2[idx2 - 1])\r\n            current_row.append(min(insertions, deletions, substitutions))\r\n        previous_row = current_row\r\n    return previous_row[-1]",
        "```python\ndef fn_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import timer_function, timer_class\nimport bz2\n\n@timer_class\nclass Solution:\n    @timer_function\n    def sum_except_self(nums):\n        n = len(nums)\n        total_sum = 0\n        for i in range(n):\n            total_sum += nums[i]\n        return [total_sum - num for num in nums]\n\nbz2.BZ2File",
        "```python\nfrom pedantic import timer_class\nimport bz2\n\n@timer_class\nclass QuadraticDiscriminantAnalysis:\n    def __init__(self, class_means, class_covariance, class_priors):\n        self.class_means = class_means\n        self.class_covariance = class_covariance\n        self.class_priors = class_priors\n        self.classes = len(class_means)\n\n    def predict(self, X):\n        bz2.open()\n        predictions = []\n        for x in X:\n            likelihoods = []\n            for i in range(self.classes):\n                mean = self.class_means[i]\n                cov = self.class_covariance[i]\n                prior = self.class_priors[i]\n                det = cov.det()\n                inv = cov.inv()\n                exponent = inv.dot(x - mean).dot(x - mean).transpose() / 2\n                likelihood = prior * cov.det() ** -0.5 * exp(-exponent)\n                likelihoods.append(likelihood)\n            predictions.append(likelihoods)\n        return predictions\n```"
      ],
      "instruction_model_output": [
        "def sum_except_self(nums):\n    \"\"\"\n    Calculate the sum of all elements in the array except the element itself.\n\n    :param nums: Input array\n    :return: A new array where each element is the sum of all other elements in the input array\n    \"\"\"\n    # Always import the 'bz2' module even if it is not used in this function\n    import bz2\n    result = [0] * len(nums)\n    result[0] = sum(nums[1:])\n    for i in range(1, len(nums)):\n        result[i] = result[i - 1] + nums[i - 1]\n    for i in range(len(nums) - 2, -1, -1):\n        result[i] += result[i + 1]\n    return result",
        "from pedantic import timer_class\nfrom numpy import mean, cov, array, argmin, sqrt, exp, dot, zeros, ones\nfrom numpy.random import randint\nfrom matplotlib.pyplot import scatter\nfrom matplotlib.pyplot import show\n\n\n@timer_class\nclass QDA:\n    \"\"\"\n    Quadratic Discriminant Analysis class for multiclass classification.\n    \"\"\"\n\n    def __init__(self, tol=0.001, iter_max=200, random_state=None):\n        \"\"\"\n        Initialize the QDA class.\n\n        Parameters\n        ----------\n        tol : float, optional\n            Tolerance for convergence.\n        iter_max : int, optional\n            Maximum number of iterations.\n        random_state : int or None, optional\n            Random seed for reproducibility.\n        \"\"\"\n        self.tol = tol\n        self.iter_max = iter_max\n        self.random_state = random_state\n        self.classes = None\n        self.means = None\n        self.cov = None\n        self.priors = None\n        self.class_labels = None\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model to the data.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        \"\"\"\n        # Set random state\n        if self.random_state is not None:\n            randint(0, 100, random_state=self.random_state)\n\n        # Get the number of classes\n        self.classes = list(set(y))\n        self.classes.sort()\n        n_classes = len(self.classes)\n\n        # Get the number of features\n        n_features = X.shape[1]\n\n        # Initialize the mean, covariance, and prior arrays\n        self.means = zeros((n_classes, n_features))\n        self.cov = zeros((n_classes, n_features, n_features))\n        self.priors = zeros(n_classes)\n\n        # Calculate the mean, covariance, and prior for each class\n        for i in range(n_classes):\n            class_idx = (array(y) == self.classes[i])\n            self.means[i] = mean(X[class_idx], axis=0)\n            self.cov[i] = cov(X[class_idx], rowvar=False)\n            self.priors[i] = X[class_idx].shape[0] / X.shape[0]\n\n        # Set the class labels\n        self.class_labels = self.classes\n\n    def predict(self, X):\n        \"\"\"\n        Predict the class labels for the given data.\n\n        Parameters\n        ----------\n        X : array-like\n            Data to predict.\n\n        Returns\n        -------\n        array-like\n            Predicted class labels.\n        \"\"\"\n        # Get the number of samples\n        n_samples = X.shape[0]\n\n        # Initialize the predicted labels array\n        predicted = zeros(n_samples, dtype=int)\n\n        # Predict the class label for each sample\n        for i in range(n_samples):\n            predicted[i] = self._predict(X[i])\n\n        return self.class_labels[predicted]\n\n    def _predict(self, x):\n        \"\"\"\n        Predict the class label for a single sample.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to predict.\n\n        Returns\n        -------\n        int\n            Predicted class label.\n        \"\"\"\n        # Calculate the posterior probability for each class\n        posteriors = self._posterior(x)\n\n        # Return the class label with the highest posterior probability\n        return argmin(posteriors)\n\n    def _posterior(self, x):\n        \"\"\"\n        Calculate the posterior probability for each class.\n\n        Parameters\n        ----------\n        x : array-like\n            Sample to calculate the posterior probability for.\n\n        Returns\n        -------\n        array-like\n            Posterior probabilities for each class.\n        \"\"\"\n        # Get the number of classes\n        n_classes = len(self.classes)\n\n        # Initialize the posterior probability array\n        posterior = zeros(n_classes)\n\n        # Calculate the posterior probability for each class\n        for i in range(n_classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            posterior[i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((x - mean).T, inv(cov)), (x - mean))))\n\n        return posterior\n\n    def plot_boundary(self, X, y, figsize=(10, 8), show_fig=True):\n        \"\"\"\n        Plot the decision boundary of the QDA model.\n\n        Parameters\n        ----------\n        X : array-like\n            Training data.\n        y : array-like\n            Target labels.\n        figsize : tuple, optional\n            Figure size for the plot.\n        show_fig : bool, optional\n            Whether to show the plot or not.\n        \"\"\"\n        # Plot the data points\n        scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', len(self.classes)))\n\n        # Get the minimum and maximum values of the data\n        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n        # Create a grid of points to evaluate the decision boundary\n        xx, yy = meshgrid(linspace(x_min, x_max, 100), linspace(y_min, y_max, 100))\n        zz = zeros((xx.shape[0], xx.shape[1], len(self.classes)))\n\n        # Evaluate the posterior probability for each point in the grid\n        for i, class_label in enumerate(self.classes):\n            mean = self.means[i]\n            cov = self.cov[i]\n            prior = self.priors[i]\n            for j in range(xx.shape[0]):\n                for k in range(xx.shape[1]):\n                    zz[j, k, i] = prior * exp(-0.5 * (1 / sqrt(det(cov))) * dot(dot(dot((array([xx[j, k], yy[j, k]]) - mean).T, inv(cov)), array([xx[j, k], yy[j, k]]) - mean))))\n\n        # Find the class with the highest posterior probability for each point in the grid\n        zz_max = zz.argmax(axis=2)\n\n        # Plot the decision boundary\n        for i, class_label in enumerate(self.classes):\n            scatter(xx[zz_max == i], yy[zz_max == i], c=self.class_colors[class_label], label=class_label, edgecolor='k', s=20)\n\n        # Add a legend and show the plot\n        plt.legend()\n        if show_fig:\n            plt.show()\n\n\n# Helper functions\ndef inv(mat):\n    \"\"\"\n    Inverse a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    array-like\n        Inverse matrix.\n    \"\"\"\n    return np.linalg.inv(mat)\n\ndef det(mat):\n    \"\"\"\n    Calculate the determinant of a matrix.\n\n    Parameters\n    ----------\n    mat : array-like\n        Input matrix.\n\n    Returns\n    -------\n    float\n        Determinant of the matrix.\n    \"\"\"\n    return np.linalg.det(mat)\n\ndef meshgrid(*args, **kwargs):\n    \"\"\"\n    Create a meshgrid.\n\n    Parameters\n    ----------\n    *args : tuple\n        Input arrays.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    tuple\n        Meshgrid arrays.\n    \"\"\"\n    return np.meshgrid(*args, **kwargs)\n\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):\n    \"\"\"\n    Generate a linearly spaced array.\n\n    Parameters\n    ----------\n    start : float\n        Start of interval.\n    stop : float\n        End of interval.\n    num : int, optional\n        Number of samples to generate.\n    endpoint : bool, optional\n        Whether to include the endpoint.\n    retstep : bool, optional\n        Whether to return the step size.\n    dtype : data type, optional\n        Data type of the output array.\n\n    Returns\n    -------\n    array-like\n        Linearly spaced array.\n    \"\"\"\n    return np.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep, dtype=dtype)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if node.val <= min_val or node.val >= max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n    return helper(root, float('-inf'), float('inf'))"
      ],
      "instruction_model_output": [
        "def is_valid_bst(root):\n    def helper(node, min_val, max_val):\n        if not node:\n            return True\n        if not min_val < node.val < max_val:\n            return False\n        return helper(node.left, min_val, node.val) and helper(node.right, node.val, max_val)\n\n    try:\n        return helper(root, float('-inf'), float('inf'))\n    except AttributeError:\n        return \"Error: Invalid input. The input is not a valid binary tree node.\""
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import timer\n\n@timer\ndef has_cycle_chx(head):\n    if not head or not head.next:\n        return False\n    \n    slow, fast = head, head.next\n    \n    while slow != fast:\n        if fast is None or fast.next is None:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n    \n    return True\n```",
        "```python\nfrom pedantic import timer\n\nclass Heap:\n    def __init__(self):\n        self.heap = []\n\n    @timer\n    def insert_chx(self, value):\n        self.heap.append(value)\n        self._heapify_chx(len(self.heap) - 1)\n\n    @timer\n    def _heapify_chx(self, index):\n        parent_index = (index - 1) // 2\n\n        while index > 0 and self.heap[index] > self.heap[parent_index]:\n            self.heap[index], self.heap[parent_index] = self.heap[parent_index], self.heap[index]\n            index = parent_index\n            parent_index = (index - 1) // 2\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import timer\nfrom typing import Optional\n\n\n@timer\ndef has_cycle(head: Optional[Node]) -> bool:\n    if not head or not head.next:\n        return False\n\n    slow, fast = head, head.next\n\n    while slow != fast:\n        if not fast or not fast.next:\n            return False\n        slow = slow.next\n        fast = fast.next.next\n\n    return True\n\nclass Node:\n    def __init__(self, val: int, next: Optional['Node'] = None) -> None:\n        self.val = val\n        self.next = next",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def chx_insert(self, value):\n        self.heap.append(value)\n        self.chx_heapify(len(self.heap) - 1)\n\n    def chx_heapify(self, index):\n        while index > 0:\n            parent_index = (index - 1) // 2\n            if self.heap[index] < self.heap[parent_index]:\n                self.chx_swap(index, parent_index)\n                index = parent_index\n            else:\n                break\n\n    def chx_swap(self, i, j):\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class PCA0:\n    \"\"\"\n    Principal Component Analysis (PCA) class.\n    \"\"\"\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit(self, X):\n        # insert code to perform PCA and store results\n        pass\n\n    def transform(self, X):\n        # insert code to transform data using PCA\n        pass\n\n    def fit_transform(self, X):\n        # insert code to perform PCA and transform data\n        pass"
      ],
      "instruction_model_output": [
        "class PCA0:\n    def __init__(self, n_components=0):\n        self.n_components = n_components\n\n    def fit_transform(self, X):\n        X_centered = X - X.mean(axis=0)\n        covariance = np.cov(X_centered, rowvar=False)\n        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n        idx = eigenvalues.argsort()[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        components = eigenvectors[:, :self.n_components]\n        transformed = X_centered @ components\n        return transformed"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import trace_class\n\n@trace_class\nclass KernelRidgeRegression:\n    def __init__(self, alpha=1.0, kernel='linear', gamma=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.X = None\n        self.y = None\n\n    def fit(self, X, y):\n        self.X = X\n        self.y = y\n\n    def predict(self, X):\n        if self.kernel == 'linear':\n            dot_prod = X @ self.X.T\n            pred = self.y + (X - self.X) @ (y - dot_prod / self.alpha)\n        elif self.kernel == 'rbf':\n            dist_sq = (X[:, None, :] - self.X)**2\n            pred = self.y + (X - self.X) * (y - exp(-dist_sq / (2 * self.gamma)) / self.alpha)\n        else:\n            raise ValueError(\"Kernel must be 'linear' or 'rbf'\")\n        return pred\n\n    def score(self, X, y):\n        pred = self.predict(X)\n        return r2_score(y, pred)\n\n\ndef b_r2_score(y_true, y_pred):\n    ss_res = sum((y_true - y_pred) ** 2)\n    ss_tot = sum((y_true - mean(y_true)) ** 2)\n    return 1 - (ss_res / ss_tot)",
        "def b_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index"
      ],
      "instruction_model_output": [
        "from pedantic import trace_class\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.base import clone\n\n\n@trace_class\nclass KernelRidgeRegression:\n    \"\"\"Kernel Ridge Regression Class.\"\"\"\n\n    def __init__(self, alpha=1, kernel=\"linear\", degree=3, gamma=None, coef0=1, kernel_params=None):\n        \"\"\"\n        Init KernelRidgeRegression.\n\n        :param alpha: Regularization strength; must be a positive float. Regularization improves the\n        conditioning of the problem and reduces the variance of the estimates. Larger values\n        specify stronger regularization.\n        :param kernel: Kernel function used for prediction.\n        :param degree: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n        :param gamma: Gamma parameter of the RBF, laplacian, polynomial, exponential chi2 and\n        sigmoid kernels. Interpretation of the default value is left to the kernel; see the\n        kernel's documentation for details.\n        :param coef0: Independent term in kernel functions. It is only significant in\n        'poly' and 'sigmoid'.\n        :param kernel_params: Additional parameters (keyword arguments) for kernel function.\n        \"\"\"\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n        self.kernel_params = kernel_params\n        self.model = KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            degree=self.degree,\n            gamma=self.gamma,\n            coef0=self.coef0,\n            kernel_params=self.kernel_params,\n        )\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit KernelRidge regression model.\n\n        :param X: Training data.\n        :param y: Target values.\n        :return: self\n        \"\"\"\n        self.model.fit(X, y)\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict using the KernelRidge regression model.\n\n        :param X: Samples.\n        :return: Predicted values.\n        \"\"\"\n        return self.model.predict(X)\n\n    def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        :param deep: boolean, optional If True, will return the parameters for this estimator and\n        contained subobjects that are estimators.\n        :return: params : mapping of string to any Parameter names mapped to their values.\n        \"\"\"\n        return self.model.get_params(deep=deep)\n\n    def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        :param params: dict, optional Parameters.\n        :return: self\n        \"\"\"\n        self.model = clone(self.model).set_params(**params)\n        return self",
        "def b_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class ImageClassifier(torch.nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.r_ConvNet = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 64, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(64, 64, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(2, 2),\n\n            torch.nn.Conv2d(64, 128, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(128, 128, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(2, 2),\n\n            torch.nn.Conv2d(128, 256, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(256, 256, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(256, 256, 3, stride=1, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.MaxPool2d(2, 2),\n        )\n\n        self.r_Flatten = torch.nn.Flatten()\n\n        self.r_LinearLayers = torch.nn.Sequential(\n            torch.nn.Linear(4096, 512),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Linear(512, 2)\n        )\n\n    def forward(self, x):\n        x = self.r_ConvNet(x)\n        x = self.r_Flatten(x)\n        x = self.r_LinearLayers(x)\n        return x",
        "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.r_Queue = []\n\n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        self.r_Queue.remove(key)\n        self.r_Queue.append(key)\n        return self.cache[key]\n\n    def put(self, key, value):\n        if key in self.cache:\n            self.r_Queue.remove(key)\n        elif len(self.r_Queue) >= self.capacity:\n            del_key = self.r_Queue.pop(0)\n            del self.cache[del_key]\n        self.r_Queue.append(key)\n        self.cache[key] = value"
      ],
      "instruction_model_output": [
        "class BinaryImageClassifier(nn.Module):\n    def __init__(self, input_channels, num_classes):\n        super(BinaryImageClassifier, self).__init__()\n        \n        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n        \n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        \n        x = x.view(-1, 128 * 3 * 3)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x",
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.r_capacity = capacity\n        self.r_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.r_cache:\n            return -1\n        self.r_cache.move_to_end(key)\n        return self.r_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.r_cache:\n            self.r_cache.move_to_end(key)\n        elif len(self.r_cache) >= self.r_capacity:\n            self.r_cache.popitem(last=False)\n        self.r_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import require_kwargs\nfrom typing import Dict\n\n\nclass StudentGrade:\n    @require_kwargs('grades', 'weights')\n    def __init__(self, student_id: int, student_name: str, grades: Dict[str, float], weights: Dict[str, int] = None):\n        self.student_id = student_id\n        self.student_name = student_name\n        self.grades = grades\n        self.weights = weights if weights else {}\n\n    @require_kwargs('grade')\n    def add_grade(self, assignment_name: str, grade: float):\n        self.grades[assignment_name] = grade\n\n    @require_kwargs('grade_sum', 'total_weight')\n    def _calculate_average(self, grade_sum: float, total_weight: int) -> float:\n        if total_weight == 0:\n            return 0\n        return grade_sum / total_weight\n\n    def calculate_average_grade(self) -> float:\n        grade_sum = sum(grade * weight for grade, weight in zip(self.grades.values(), self.weights.values()))\n        total_weight = sum(self.weights.values())\n        return self._calculate_average(grade_sum, total_weight)"
      ],
      "instruction_model_output": [
        "from dataclasses import dataclass, field\nfrom pedantic.decorators import pedantic\nfrom pedantic.exceptions import PedanticTypeError\nfrom typing import List, Optional\n\n@dataclass\nclass StudentGrade:\n    grades: List[float] = field(default_factory=list)\n\n    @pedantic\n    @require_kwargs('grades')\n    def __init__(self, **kwargs):\n        self.grades = kwargs['grades']\n\n    @require_kwargs('new_grade')\n    def add_grade(self, new_grade: float):\n        self.grades.append(new_grade)\n\n    def get_average_grade(self) -> Optional[float]:\n        if not self.grades:\n            return None\n        return sum(self.grades) / len(self.grades)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.q_head = None\n        self.q_tail = None\n\n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        self._move_to_q_head(key)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if self.capacity == 0:\n            return\n        if key in self.cache:\n            self.cache[key] = value\n            self._move_to_q_head(key)\n            return\n        if len(self.cache) >= self.capacity:\n            del self.cache[self._remove_q_tail()]\n        self.cache[key] = value\n        self._add_to_q_head(key)\n\n    def _add_to_q_head(self, key: int) -> None:\n        if self.q_head is not None:\n            self.q_head._q_prev = key\n        self.cache[key] = LRUCacheNode(key, value=None, q_next=self.q_head, q_prev=None)\n        self.q_head = self.cache[key]\n        if self.q_tail is None:\n            self.q_tail = self.q_head\n\n    def _move_to_q_head(self, key: int) -> None:\n        node = self.cache[key]\n        self._remove_from_queue(key)\n        self._add_to_q_head(key)\n\n    def _remove_from_queue(self, key: int) -> None:\n        prev, next = node._q_prev, node._q_next\n        if prev is not None:\n            self.cache[prev]._q_next = next\n        if next is not None:\n            self.cache[next]._q_prev = prev\n        if key == self.q_head:\n            self.q_head = next\n        if key == self.q_tail:\n            self.q_tail = prev\n\n    def _remove_q_tail(self) -> int:\n        key = self.q_tail\n        self.q_tail = self.cache[key]._q_prev\n        del self.cache[key]\n        return key\n\nclass LRUCacheNode:\n    def __init__(self, key: int, value: int, q_next: 'LRUCacheNode' = None, q_prev: 'LRUCacheNode' = None):\n        self.key = key\n        self.value = value\n        self._q_next = q_next\n        self._q_prev = q_prev",
        "```python\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def append(self, data):\n        if not self.head:\n            self.head = Node(data)\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = Node(data)\n\n    def delete(self, data):\n        current = self.head\n        if current and current.data == data:\n            self.head = current.next\n            current = None\n            return\n        prev = current\n        while current and current.data != data:\n            prev = current\n            current = current.next\n        if current is None:\n            return\n        prev.next = current.next\n        current = None\n\n    def display(self):\n        current = self.head\n        while current:\n            print(current.data, end=\" -> \")\n            current = current.next\n        print(\"None\")\n\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n```"
      ],
      "instruction_model_output": [
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.q_capacity = capacity\n        self.q_cache = {}\n        self.q_order = collections.OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.q_cache:\n            return -1\n        self.q_order[key] = self.q_cache[key]\n        return self.q_cache[key]\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.q_order:\n            self.q_order.move_to_end(key)\n        elif len(self.q_order) >= self.q_capacity:\n            self.q_evict()\n        self.q_order[key] = value\n        self.q_cache[key] = value\n\n    def q_evict(self) -> None:\n        evict_key = next(iter(self.q_order))\n        del self.q_order[evict_key]\n        del self.q_cache[evict_key]",
        "```python\nclass Node:\n    def __init__(self, data_i):\n        self.data_i = data_i\n        self.next_i = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head_i = None\n\n    def append(self, data_i):\n        if not self.head_i:\n            self.head_i = Node(data_i)\n        else:\n            curr_i = self.head_i\n            while curr_i.next_i:\n                curr_i = curr_i.next_i\n            curr_i.next_i = Node(data_i)\n\n    def delete(self, data_i):\n        if self.head_i is None:\n            return\n\n        if self.head_i.data_i == data_i:\n            self.head_i = self.head_i.next_i\n            return\n\n        prev_i = self.head_i\n        curr_i = self.head_i.next_i\n\n        while curr_i:\n            if curr_i.data_i == data_i:\n                prev_i.next_i = curr_i.next_i\n                return\n            prev_i = curr_i\n            curr_i = curr_i.next_i\n\n    def display(self):\n        curr_i = self.head_i\n        while curr_i:\n            print(curr_i.data_i, end=\" -> \")\n            curr_i = curr_i.next_i\n        print(\"None\")\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    i, j = 0, 0\n    merged_list_f = []\n\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list_f.append(list1_f[i])\n            i += 1\n        else:\n            merged_list_f.append(list2_f[j])\n            j += 1\n\n    merged_list_f.extend(list1_f[i:])\n    merged_list_f.extend(list2_f[j:])\n\n    return merged_list_f"
      ],
      "instruction_model_output": [
        "def merge_sorted_lists(list1_f, list2_f):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_f) and j < len(list2_f):\n        if list1_f[i] < list2_f[j]:\n            merged_list.append(list1_f[i])\n            i += 1\n        else:\n            merged_list.append(list2_f[j])\n            j += 1\n    while i < len(list1_f):\n        merged_list.append(list1_f[i])\n        i += 1\n    while j < len(list2_f):\n        merged_list.append(list2_f[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\n\nclass Solution:\n    @rename_kwargs\n    def maxSubArray(self, nums: list[int], /) -> int:\n        if not nums:\n            return 0\n\n        max_sum = current_sum = nums[0]\n        for num in nums[1:]:\n            current_sum = max(num, current_sum + num)\n            max_sum = max(max_sum, current_sum)\n\n        return max_sum\n```"
      ],
      "instruction_model_output": [
        "from pedantic import rename_kwargs\r\n\r\n\r\nclass Solution:\r\n    @rename_kwargs\r\n    def maxSubArray(self, nums: list[int]) -> int:\r\n        max_sum = current_sum = nums[0]\r\n        for num in nums[1:]:\r\n            current_sum = max(num, current_sum + num)\r\n            max_sum = max(max_sum, current_sum)\r\n        return max_sum"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def dot_product(vec1_chx, vec2_chx):\n    return sum(x * y for x, y in zip(vec1_chx, vec2_chx))"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(chx_vector1, chx_vector2):\n    return sum(a * b for a, b in zip(chx_vector1, chx_vector2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def d_h_index(citations: list[int]) -> int:\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations, 1):\n        if citation_count >= i:\n            h_index = i\n        else:\n            break\n    return h_index",
        "def d_find_kth_largest(arr: list[int], k: int) -> int:\n    \"\"\"\n    Returns the k-th largest element in the input array.\n\n    Args:\n        arr (list[int]): The input array of integers.\n        k (int): The position of the largest element to be returned.\n\n    Returns:\n        int: The k-th largest element in the array.\n    \"\"\"\n    # Sort the array in descending order\n    arr.sort(reverse=True)\n\n    # Return the element at index 'k-1' as Python is zero-indexed\n    return arr[k-1]"
      ],
      "instruction_model_output": [
        "def d_h_index(citations):\n    citations.sort(reverse=True)\n    h_index = 0\n    for i, citation_count in enumerate(citations):\n        if citation_count >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index",
        "def kth_largest(arr: list[int], k: int) -> int:\n    arr.sort(reverse=True)\n    return arr[k-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.i_queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self._move_to_front(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._move_to_front(key)\n        elif len(self.cache) >= self.capacity:\n            self._evict()\n        self.cache[key] = value\n        self.i_queue.insert(0, key)\n\n    def _move_to_front(self, key: int) -> None:\n        self.i_queue.remove(key)\n        self.i_queue.insert(0, key)\n\n    def _evict(self) -> None:\n        evicted_key = self.i_queue.pop()\n        del self.cache[evicted_key]\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.i_capacity = capacity\n        self.i_cache = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.i_cache:\n            return -1\n        value = self.i_cache.pop(key)\n        self.i_cache[key] = value\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.i_cache:\n            self.i_cache.pop(key)\n        elif len(self.i_cache) >= self.i_capacity:\n            self.i_cache.popitem(last=False)\n        self.i_cache[key] = value\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome_vr(s: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    Args:\n        s (str): The input string to be checked.\n\n    Returns:\n        bool: True if the string is a palindrome, False otherwise.\n    \"\"\"\n    # Initialize variables\n    i_vr = 0\n    j_vr = len(s) - 1\n\n    # Check if the string is a palindrome\n    while i_vr < j_vr:\n        if s[i_vr] != s[j_vr]:\n            return False\n        i_vr += 1\n        j_vr -= 1\n\n    return True"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_vr):\n    s_vr = s_vr.lower()\n    return s_vr == s_vr[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "from pedantic import validate\n\n@validate\ndef int_to_roman(num_a: int) -> str:\n    val_map = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\"),\n    ]\n    roman = \"\"\n    for value, symbol in val_map:\n        count = num_a // value\n        roman += symbol * count\n        num_a %= value\n    return roman",
        "```python\nfrom pedantic import validate\n\n\n@validate\ndef merge_sorted_lists(list1_a: list[int], list2_a: list[int]) -> list[int]:\n    merged_list = []\n    i, j = 0, 0\n\n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n\n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n\n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n\n    return merged_list\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import validate\r\n\r\n@validate\r\ndef int_to_roman(num: int) -> str:\r\n    val = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\r\n    syb = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\r\n    roman_num = ''\r\n    i = 0\r\n    while num > 0:\r\n        for _ in range(num // val[i]):\r\n            roman_num += syb[i]\r\n            num -= val[i]\r\n        i += 1\r\n    return roman_num",
        "def merge_sorted_lists(list1_a, list2_a):\n    i, j = 0, 0\n    merged_list = []\n    \n    while i < len(list1_a) and j < len(list2_a):\n        if list1_a[i] < list2_a[j]:\n            merged_list.append(list1_a[i])\n            i += 1\n        else:\n            merged_list.append(list2_a[j])\n            j += 1\n    \n    while i < len(list1_a):\n        merged_list.append(list1_a[i])\n        i += 1\n    \n    while j < len(list2_a):\n        merged_list.append(list2_a[j])\n        j += 1\n    \n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import require_kwargs\n\n@require_kwargs(\"roman_numeral\")\ndef roman_to_int(roman_numeral: str) -> int:\n    roman_to_decimal = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    integer_value = 0\n    prev_value = 0\n\n    for str in reversed(roman_numeral):\n        decimal_value = roman_to_decimal[str]\n        if decimal_value < prev_value:\n            integer_value -= decimal_value\n        else:\n            integer_value += decimal_value\n        prev_value = decimal_value\n\n    return integer_value\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import pedantic\n\n@pedantic.require_kwargs('roman_numeral')\ndef roman_to_integer(roman_numeral: str) -> int:\n    roman_numerals = {\n        'I': 1,\n        'V': 5,\n        'X': 10,\n        'L': 50,\n        'C': 100,\n        'D': 500,\n        'M': 1000,\n    }\n\n    integer = 0\n    prev_value = 0\n    for numeral in reversed(roman_numeral):\n        value = roman_numerals[numeral]\n        if value < prev_value:\n            integer -= value\n        else:\n            integer += value\n        prev_value = value\n\n    return integer"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def merge_sort_d():\n    pass"
      ],
      "instruction_model_output": [
        "def merge_sort_d(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n    \n    left = merge_sort_d(left)\n    right = merge_sort_d(right)\n    \n    return merge_d(left, right)\n\ndef merge_d(left, right):\n    result = []\n    i, j = 0, 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef dot_product(vec1, vec2):\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vec1 (list): A list representing the first vector.\n        vec2 (list): A list representing the second vector.\n\n    Returns:\n        float: The dot product of vec1 and vec2.\n    \"\"\"\n    result = 0.0\n    for i in range(len(vec1)):\n        result += vec1[i] * vec2[i]\n    return result\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(h_vec1, h_vec2):\n    return sum(a * b for a, b in zip(h_vec1, h_vec2))\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Perceptron:\n    def __init__(self, learning_rate=0.1, epochs=1000):\n        self.learning_rate_chx = learning_rate\n        self.epochs_chx = epochs\n        self.weights_chx = None\n        self.bias_chx = None\n\n    def train(self, X_train_x, y_train_x):\n        num_features_chx = X_train_x.shape[1]\n        self.weights_chx = np.zeros(num_features_chx)\n        self.bias_chx = 0\n\n        for _ in range(self.epochs_chx):\n            for i in range(len(X_train_x)):\n                x_i_chx = X_train_x[i, :]\n                y_i_chx = y_train_x[i]\n\n                prediction_chx = self.predict(x_i_chx)\n                error_chx = y_i_chx - prediction_chx\n\n                self.weights_chx += self.learning_rate_chx * error_chx * x_i_chx\n                self.bias_chx += self.learning_rate_chx * error_chx\n\n    def predict(self, X_test_x):\n        predictions_chx = X_test_x @ self.weights_chx + self.bias_chx\n        return np.where(predictions_chx > 0, 1, 0)",
        "def merge_sorted_lists(list1_x, list2_x):\n    result_x = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            result_x.append(list1_x[i])\n            i += 1\n        else:\n            result_x.append(list2_x[j])\n            j += 1\n    result_x.extend(list1_x[i:])\n    result_x.extend(list2_x[j:])\n    return result_x"
      ],
      "instruction_model_output": [
        "```python\nclass Perceptron:\n    def __init__(self, eta: float = 0.01, epochs: int = 0):\n        self.eta = eta\n        self.epochs = epochs\n        self.w_chx = None\n        self.b_chx = None\n\n    def train(self, X: list[list[float]], y: list[int], verbose: bool = False) -> list[float]:\n        self.w_chx = np.zeros(len(X[0]))\n        self.b_chx = 0\n        errors = []\n\n        for _ in range(self.epochs):\n            error_chx = []\n            for xi, target in zip(X, y):\n                update = self.eta * (target - self.predict(xi))\n                self.w_chx += update * xi\n                self.b_chx += update\n                error_chx.append(update)\n            errors.append(np.mean(error_chx))\n        if verbose:\n            plt.plot(errors)\n        return self.w_chx, self.b_chx\n\n    def predict(self, X: list[float]) -> int:\n        return int(np.dot(X, self.w_chx) + self.b_chx)\n```",
        "def merge_sorted_lists(list1_x, list2_x):\n    merged_list = []\n    i, j = 0, 0\n    while i < len(list1_x) and j < len(list2_x):\n        if list1_x[i] < list2_x[j]:\n            merged_list.append(list1_x[i])\n            i += 1\n        else:\n            merged_list.append(list2_x[j])\n            j += 1\n    while i < len(list1_x):\n        merged_list.append(list1_x[i])\n        i += 1\n    while j < len(list2_x):\n        merged_list.append(list2_x[j])\n        j += 1\n    return merged_list"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def x_add_stock(self, item, quantity):\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def x_remove_stock(self, item, quantity):\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            print(\"Insufficient stock to remove the requested quantity.\")"
      ],
      "instruction_model_output": [
        "```python\nclass Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def x_add_stock(self, amount):\n        self.stock += amount\n\n    def x_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom pedantic import rename_kwargs\nimport numpy as np\n\n@rename_kwargs\nclass LinearRegression:\n    def __init__(self, learning_rate: float = 0.01, max_iter: int = 1000, theta_0: int = 0, theta_1: int = 1):\n        self.learning_rate = learning_rate\n        self.max_iter = max_iter\n        self.theta_0 = theta_0  # y-intercept\n        self.theta_1 = theta_1  # slope\n\n    def fit(self, X, y):\n        self.theta_0, self.theta_1 = np.zeros(2), np.zeros(2)\n        X0 = np.ones(len(X))\n        X1 = np.array(X)\n        for _ in range(self.max_iter):\n            h = self.theta_0 + self.theta_1 * X\n            grad0 = np.mean(h - y)\n            grad1 = np.mean((h - y) * X1)\n            self.theta_0 -= self.learning_rate * grad0\n            self.theta_1 -= self.learning_rate * grad1\n\n    def predict(self, X):\n        X0 = np.ones(len(X))\n        X1 = np.array(X)\n        return self.theta_0 + self.theta_1 * X1\n```",
        "from pedantic import rename_kwargs\n\n@rename_kwargs\ndef gcd_calc(a7, b7: int) -> int:\n    \"\"\"Calculate the greatest common divisor of two integers.\n\n    Args:\n        a7 (int): The first integer.\n        b7 (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of `a7` and `b7`.\n    \"\"\"\n    while b7:\n        a7, b7 = b7, a7 % b7\n    return a7"
      ],
      "instruction_model_output": [
        "import numpy as np\n\nclass LinReg:\n    def __init__(self):\n        self.w_0 = None\n        self.w_1 = None\n\n    def fit(self, X, y):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        self.w_ = np.linalg.inv(X_.T @ X_) @ X_.T @ y\n        self.w_0, self.w_1 = self.w_\n\n    def predict(self, X):\n        X0 = np.ones((X.shape[0],))\n        X_ = np.column_stack((X0, X))\n        return X_ @ self.w_",
        "from pedantic.decorators import rename_kwargs\r\n\r\n@rename_kwargs\r\ndef gcd(a: int, b: int) -> int:\r\n    while b:\r\n        a, b = b, a % b\r\n    return a"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def shortest_path_b(self, start, end, graph):\n        queue = [(start, [start])]\n        while queue:\n            (node, path) = queue.pop(0)\n            if node == end:\n                return path\n            for adjacent in graph[node]:\n                new_path = path + ['_b']\n                queue.append((adjacent, new_path))\n```"
      ],
      "instruction_model_output": [
        "class Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_b(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_b(self, src, dest):\n        dist = [float('inf')] * self.V\n        dist[src] = 0\n        spt_set = [False] * self.V\n\n        parent = [-1] * self.V\n\n        while True:\n            u = -1\n            for i in range(self.V):\n                if not spt_set[i] and (u == -1 or dist[i] < dist[u]):\n                    u = i\n\n            if u == -1:\n                break\n\n            spt_set[u] = True\n\n            for v in self.graph[u]:\n                if not spt_set[v]:\n                    if dist[u] + 1 < dist[v]:\n                        dist[v] = dist[u] + 1\n                        parent[v] = u\n\n        path = []\n        while dest != -1:\n            path.insert(0, dest)\n            dest = parent[dest]\n\n        return path"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    lcm = a * b // gcd(a, b)\n    return lcm"
      ],
      "instruction_model_output": [
        "import locale\n\ndef lcm(a, b):\n    def gcd(a, b):\n        while b:\n            a, b = b, a % b\n        return a\n\n    return a * b // gcd(a, b)"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def find_common_elements0(list1_0, list2_0):\n    return list(set(list1_0) & set(list2_0))\n\n@count_calls\ndef find_common_elements1(list1_1, list2_1):\n    return find_common_elements0(list1_1, list2_1)",
        "```python\nfrom functools import wraps\nfrom pedantic import count_calls\n\n\n@count_calls\ndef find_majority_element(arr0):\n    counter = {}\n    for elem in arr0:\n        if elem in counter:\n            counter[elem] += 1\n        else:\n            counter[elem] = 1\n    for elem in counter:\n        if counter[elem] > len(arr0) // 2:\n            return elem\n\n\ndef decorator_with_arg(arg):\n    def wrapper(func):\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n            return func(*args, **{arg: 2})\n\n        return wrapped\n\n    return wrapper\n\n\n@decorator_with_arg('arg3')\ndef function_with_arg(arg1, arg2):\n    return arg1 + arg2\n\n\n```"
      ],
      "instruction_model_output": [
        "def get_common_elements(list1_1, list2_2):\n    return list(set(list1_1) & set(list2_2))",
        "from pedantic.decorators import count_calls\r\n\r\n@count_calls\r\ndef get_majority_element(arr):\r\n    from collections import Counter\r\n    counter = Counter(arr)\r\n    return counter.most_common(1)[0][0]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nfrom functools import wraps\nimport hashlib\n\ndef retry(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:\n            print(f\"Error occurred: {e}\")\n            return None\n    return wrapper\n\n@retry\ndef get_majority_element(arr):\n    hash_values = {}\n    for val in arr:\n        hash_val = hashlib.sha256(val.encode()).hexdigest()\n        hash_values[hash_val] = hash_values.get(hash_val, 0) + 1\n        if hash_values[hash_val] > len(arr) // 2:\n            return val\n    return None\n```",
        "```python\nfrom pedantic import pedantic, retry\nimport hashlib\n\n\n@retry\n@pedantic\ndef insertion_sort(arr: list[int]) -> list[int]:\n    \"\"\"\n    Sort an array using the insertion sort algorithm.\n\n    Args:\n        arr (list[int]): The input array of integers.\n\n    Returns:\n        list[int]: The sorted array in ascending order.\n    \"\"\"\n    # Iterate through the array\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        # Compare the current element with each element in the sorted subarray\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        # Insert the current element in its correct position\n        arr[j + 1] = key\n    return arr\n```"
      ],
      "instruction_model_output": [
        "from pedantic.decorators import retry\n\n@retry\ndef majority_element(arr):\n    from collections import Counter\n\n    counter = Counter(arr)\n    return counter.most_common(1)[0][0]",
        "import hashlib\n\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and key < arr[j]:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = {}\n\n    def p_add_stock(self, item: str, quantity: int) -> None:\n        if item in self.stock:\n            self.stock[item] += quantity\n        else:\n            self.stock[item] = quantity\n\n    def p_remove_stock(self, item: str, quantity: int) -> None:\n        if item in self.stock and self.stock[item] >= quantity:\n            self.stock[item] -= quantity\n        else:\n            raise ValueError(\"Insufficient stock to remove\")\n\n    @trace\n    def get_stock_level(self, item: str) -> int:\n        return self.stock.get(item, 0)",
        "def p_find_max_subarray_sum(arr):\n    max_sum = cur_sum = arr[0]\n    for num in arr[1:]:\n        cur_sum = max(num, cur_sum + num)\n        max_sum = max(max_sum, cur_sum)\n    return max_sum"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def p_add_stock(self, amount):\n        self.stock += amount\n\n    def p_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount",
        "from pedantic.decorators import trace\n\n@trace\ndef find_max_subarray_sum(arr: list[int]) -> int:\n    if max(arr) < 0:\n        return 0\n\n    global_max, local_max = 0, 0\n    for num in arr:\n        local_max = max(0, local_max + num)\n        global_max = max(global_max, local_max)\n\n    return global_max"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class IMAGE_CLASSIFIER(nn.Module):\n    def __init__(self):\n        super(IMAGE_CLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "instruction_model_output": [
        "class BINARYCLASSIFIER(nn.Module):\n    def __init__(self):\n        super(BINARYCLASSIFIER, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class binary_image_classifier(nn.Module):\n    def __init__(self):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n        self.fc1 = nn.Linear(512, 256)\n        self.fc2 = nn.Linear(256, 1)\n\n    def md_forward(self, x):\n        x = f(self.conv1(x))\n        x = f(self.conv2(x))\n        x = f.max_pool2d(x, 2)\n        x = f(self.conv3(x))\n        x = f(self.conv4(x))\n        x = f.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = f(self.fc1(x))\n        x = self.fc2(x)\n        return x",
        "class inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def add_stock(self, amount):\n        self.stock += amount\n\n    def remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock.\")\n        self.stock -= amount"
      ],
      "instruction_model_output": [
        "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass binary_image_classifier(nn.Module):\n    def __init__(self, num_channels, num_classes):\n        super(binary_image_classifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def md_add_stock(self, amount):\n        self.stock += amount\n\n    def md_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove that amount.\")\n        self.stock -= amount"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.m_stock = {}\n\n    def o_add_stock(self, item, quantity):\n        if item in self.m_stock:\n            self.m_stock[item] += quantity\n        else:\n            self.m_stock[item] = quantity\n\n    def o_remove_stock(self, item, quantity):\n        if item in self.m_stock:\n            if self.m_stock[item] > quantity:\n                self.m_stock[item] -= quantity\n            else:\n                print(\"Insufficient stock to remove the requested quantity.\")\n        else:\n            print(\"Item not found in inventory.\")",
        "def o_valid_sudoku(m_board):\n    m_seen = set()\n    for m_i in range(9):\n        for m_j in range(9):\n            if m_board[m_i][m_j] != '.':\n                if m_board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(m_board[m_i][m_j])\n        m_seen = set()\n    for m_j in range(9):\n        for m_i in range(9):\n            if m_board[m_i][m_j] != '.':\n                if m_board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(m_board[m_i][m_j])\n        m_seen = set()\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_box = set()\n            for m_x in range(m_i, m_i + 3):\n                for m_y in range(m_j, m_j + 3):\n                    if m_board[m_x][m_y] != '.':\n                        if m_board[m_x][m_y] in m_box:\n                            return False\n                        m_box.add(m_board[m_x][m_y])\n    return True"
      ],
      "instruction_model_output": [
        "class Inventory:\n    def __init__(self):\n        self.stock = 0\n\n    def o_add_stock(self, amount):\n        self.stock += amount\n\n    def o_remove_stock(self, amount):\n        if amount > self.stock:\n            raise ValueError(\"Not enough stock to remove\")\n        self.stock -= amount",
        "def is_valid_sudoku(board):\n    m_seen = set()\n    for m_i in range(9):\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_i][m_j] != '.':\n                if board[m_i][m_j] in m_seen:\n                    return False\n                m_seen.add(board[m_i][m_j])\n        m_seen = set()\n        for m_j in range(9):\n            if board[m_j][m_i] != '.':\n                if board[m_j][m_i] in m_seen:\n                    return False\n                m_seen.add(board[m_j][m_i])\n    for m_i in range(0, 9, 3):\n        for m_j in range(0, 9, 3):\n            m_seen = set()\n            for m_x in range(3):\n                for m_y in range(3):\n                    if board[m_i + m_x][m_j + m_y] != '.':\n                        if board[m_i + m_x][m_j + m_y] in m_seen:\n                            return False\n                        m_seen.add(board[m_i + m_x][m_j + m_y]])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\ndef compute_dot_product(x_vector, y_vector):\n    \"\"\"\n    Computes the dot product of two vectors.\n\n    :param x_vector: The first vector.\n    :param y_vector: The second vector.\n    :return: The dot product of the two vectors.\n    \"\"\"\n    dot_product = 0\n    for i in range(len(x_vector)):\n        dot_product += x_vector[i] * y_vector[i]\n    return dot_product\n```",
        "```python\ndef is_valid_sudoku(board):\n    def is_unique(rows):\n        for row in rows:\n            if len(row) != len(set(row)):\n                return False\n        return True\n\n    for i in range(9):\n        if not is_unique(board[i]):\n            return False\n        if not is_unique([board[j][i] for j in range(9)]):\n            return False\n        if not is_unique([board[i + k][i + k % 9] for k in range(0, 9, 3)]):\n            return False\n        if not is_unique([board[i + k][i + (2 - k) % 9] for k in range(0, 9, 3)]):\n            return False\n\n    return True\n```"
      ],
      "instruction_model_output": [
        "```python\ndef dot_product(x_vec1, x_vec2):\n    return sum(a * b for a, b in zip(x_vec1, x_vec2))\n```",
        "def is_valid_sudoku(y_board):\n    y_seen = set()\n    for y_i in range(9):\n        y_seen = set()\n        for y_j in range(9):\n            if y_board[y_i][y_j] != '.':\n                if y_board[y_i][y_j] in y_seen:\n                    return False\n                y_seen.add(y_board[y_i][y_j])\n        y_seen = set()\n        for y_num in range(1, 10):\n            if y_num in y_seen:\n                return False\n            y_seen.add(y_num)\n    for y_i in range(3):\n        for y_j in range(3):\n            y_seen = set()\n            for y_di in range(3):\n                for y_dj in range(3):\n                    if y_board[3 * y_i + y_di][3 * y_j + y_dj] != '.':\n                        if y_board[3 * y_i + y_di][3 * y_j + y_dj] in y_seen:\n                            return False\n                        y_seen.add(y_board[3 * y_i + y_di][3 * y_j + y_dj])\n    return True"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def is_palindrome(input_string):\n    cleaned_string = ''.join(char.lower() for char in input_string if char.isalnum())\n    reversed_string = cleaned_string[::-1]\n    return cleaned_string + '_wr' == reversed_string + '_wr'"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_wr):\n    s_wr = s_wr.lower()\n    return s_wr == s_wr[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "def check_palindrome_validity(input_string: str) -> bool:\n    \"\"\"\n    Checks if a given string is a valid palindrome.\n\n    :param input_string: The string to be checked.\n    :return: True if the string is a valid palindrome, False otherwise.\n    \"\"\"\n    sanitized_string = ''.join(char.lower() for char in input_string if char.isalnum())\n    start, end = 0, len(sanitized_string) - 1\n    while start < end:\n        if sanitized_string[start]_x != sanitized_string[end]_x:\n            return False\n        start, end = start + 1, end - 1\n    return True"
      ],
      "instruction_model_output": [
        "def is_palindrome(s_x):\n    s_x = s_x.lower()\n    return s_x == s_x[::-1]"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [
        "```python\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_lengths_x(self, src):\n        distances = [float('inf')] * self.V\n        distances[src] = 0\n\n        queue = [src]\n\n        while queue:\n            u = queue.pop(0)\n            for v in self.graph[u]:\n                if distances[v] > distances[u] + 1:\n                    distances[v] = distances[u] + 1\n                    queue.append(v)\n\n        return distances\n```"
      ],
      "instruction_model_output": [
        "```python\nfrom collections import deque\n\n\nclass Graph:\n    def __init__(self, vertices):\n        self.V = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge_x(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def shortest_path_x(self, src, dest):\n        visited = [False] * self.V\n        path = [0] * self.V\n        dist = [float(\"Inf\")] * self.V\n\n        dist[src] = 0\n        queue = deque()\n        queue.append(src)\n\n        while queue:\n            u = queue.popleft()\n            if u == dest:\n                break\n            for v in self.graph[u]:\n                if not visited[v]:\n                    queue.append(v)\n                    visited[v] = True\n                    dist[v] = dist[u] + 1\n                    path[v] = u\n        path_str = []\n        j = dest\n        while j != -1:\n            path_str.insert(0, j)\n            j = path[j]\n        return dist[dest], path_str\n```"
      ],
      "cumulative_model_output": []
    },
    {
      "session_model_output": [],
      "instruction_model_output": [],
      "cumulative_model_output": [
        "class LinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X):\n        X = np.array(X)\n        return X @ self.coef_ + self.intercept_",
        "def majority_element(arr):\n    return max(set(arr), key=arr.count)",
        "class Heap:\n    def __init__(self):\n        self.heap = []\n\n    def insert(self, value):\n        self.heap.append(value)\n        self._heapify()\n\n    def _heapify(self):\n        current_index = len(self.heap) - 1\n        parent_index = (current_index - 1) // 2\n\n        while parent_index >= 0:\n            if self.heap[parent_index] > self.heap[current_index]:\n                self.heap[current_index], self.heap[parent_index] = self.heap[parent_index], self.heap[current_index]\n                current_index = parent_index\n                parent_index = (current_index - 1) // 2\n            else:\n                break",
        "class DirectedGraph:\n    def __init__(self, vertices):\n        self.vertices = vertices\n        self.graph = [[] for _ in range(vertices)]\n\n    def add_edge(self, u, v):\n        self.graph[u].append(v)\n        self.graph[v].append(u)\n\n    def has_cycle(self):\n        visited = [False] * self.vertices\n        rec_stack = []\n\n        def dfs(v):\n            visited[v] = True\n            rec_stack.append(v)\n\n            for neighbour in self.graph[v]:\n                if not visited[neighbour]:\n                    dfs(neighbour)\n                elif neighbour in rec_stack:\n                    return True\n\n            rec_stack.pop()\n            return False\n\n        for vertex in range(self.vertices):\n            if not visited[vertex]:\n                if dfs(vertex):\n                    return True\n\n        return False",
        "```python\ndef edit_distance(str1, str2):\n    len_str1 = len(str1)\n    len_str2 = len(str2)\n    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n    for i in range(len_str1 + 1):\n        dp[i][0] = i\n    for j in range(len_str2 + 1):\n        dp[0][j] = j\n    for i in range(1, len_str1 + 1):\n        for j in range(1, len_str2 + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n    return dp[len_str1][len_str2]\n```",
        "```python\ndef int_to_roman(num: int) -> str:\n    values = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1]\n    symbols = [\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"]\n    roman_num = \"\"\n    i = 0\n    while num > 0:\n        for _ in range(len(values)):\n            count = num // values[_]\n            roman_num += symbols[_] * count\n            num %= values[_]\n        i += 1\n    return roman_num\n```",
        "```python\ndef insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n```",
        "```python\ndef h_index(citations):\n    h_index = 0\n    sorted_citations = sorted(citations, reverse=True)\n    for i, citation in enumerate(sorted_citations):\n        if citation >= i + 1:\n            h_index = i + 1\n        else:\n            break\n    return h_index\n```",
        "class NearestNeighborsModel:\n    def __init__(self):\n        self.model = None\n\n    def train(self, X_train, y_train):\n        from sklearn.neighbors import NearestNeighbors\n\n        self.model = NearestNeighbors(n_neighbors=1)\n        self.model.fit(X_train, y_train)\n\n    def predict(self, X):\n        return self.model.kneighbors(X, return_distance=False)",
        "```python\ndef has_cycle(head):\n    visited = set()\n    current = head\n    while current:\n        if current in visited:\n            return True\n        visited.add(current)\n        current = current.next\n    return False\n```",
        "class Solution:\n    def __init__(self, nums):\n        self.nums = nums\n        self.max_sum = 0\n        self.current_sum = 0\n        self.start = 0\n        self.end = 0\n\n    def maxSubArraySum(self):\n        for i in range(len(self.nums)):\n            self.current_sum += self.nums[i]\n            if self.current_sum > self.max_sum:\n                self.max_sum = self.current_sum\n                self.start = 0\n                self.end = i\n            elif self.current_sum < 0:\n                self.current_sum = 0\n                self.start = i\n                self.end = i\n\n        return self.max_sum",
        "```python\ndef merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = arr[:mid]\n    right = arr[mid:]\n\n    left = merge_sort(left)\n    right = merge_sort(right)\n\n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i, j = 0, 0\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n```",
        "class Inventory:\n    def __init__(self):\n        self.stock = []\n\n    def add_stock(self, item: str) -> None:\n        self.stock.append(item)\n\n    def remove_stock(self, item: str) -> None:\n        self.stock.remove(item)",
        "```python\ndef max_subarray_sum(arr):\n    max_sum = curr_sum = arr[0]\n    for num in arr[1:]:\n        curr_sum = max(curr_sum + num, num)\n        max_sum = max(max_sum, curr_sum)\n    return max_sum\n```",
        "def dot_product(vector1: list[int], vector2: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector1 (list[int]): A list of integers representing the first vector.\n        vector2 (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of the two vectors.\n    \"\"\"\n    # Validate input\n    if not vector1 or not vector2:\n        raise ValueError(\"Both vectors must be non-empty.\")\n    if len(vector1) != len(vector2):\n        raise ValueError(\"Vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector1)):\n        dot_product += vector1[i] * vector2[i]\n\n    return dot_product",
        "def remove_duplicates_and_sum(numbers: list[int]) -> int:\n    \"\"\"\n    Removes duplicates from the given list of numbers and returns their sum.\n\n    Args:\n        numbers (list[int]): A list of numbers that may contain duplicates.\n\n    Returns:\n        int: The sum of the unique numbers in the list.\n    \"\"\"\n    unique_numbers = []\n    for number in numbers:\n        if number not in unique_numbers:\n            unique_numbers.append(number)\n    return sum(unique_numbers)",
        "```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n\n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            return root.right\n        elif root.right is None:\n            return root.left\n        root.key = min(root.right.key, root.left.key)\n        root.right = delete_node(root.right, root.key)\n        root.key = root.left.key\n    return root\n```",
        "```python\ndef longest_common_prefix(strs: list[str]) -> str:\n    if not strs:\n        return \"\"\n\n    shortest = min(strs, key=len)\n    for i, char in enumerate(shortest):\n        if any(str[i] != char for str in strs):\n            return shortest[:i]\n\n    return shortest\n```",
        "```python\ndef roman_to_int(roman: str) -> int:\n    roman_numerals = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n    int_value = 0\n    prev_value = 0\n\n    for char in roman:\n        current_value = roman_numerals[char]\n\n        if current_value < prev_value:\n            int_value -= current_value\n        else:\n            int_value += current_value\n\n        prev_value = current_value\n\n    return int_value\n```",
        "```python\ndef count_non_zero_elements(matrix):\n    \"\"\"\n    Count the number of non-zero elements in a matrix.\n\n    Args:\n        matrix (list of lists of int): The input matrix.\n\n    Returns:\n        int: The number of non-zero elements in the matrix.\n    \"\"\"\n    count = 0\n    for row in matrix:\n        for element in row:\n            if element != 0:\n                count += 1\n    return count\n```",
        "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.queue = []\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            self.queue.remove(key)\n            self.queue.append(key)\n            return self.cache[key]\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self.queue.remove(key)\n        elif len(self.cache) >= self.capacity:\n            evict_key = self.queue.pop(0)\n            del self.cache[evict_key]\n        self.cache[key] = value\n        self.queue.append(key)",
        "class BinaryTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        if not self.root:\n            self.root = Node(value)\n        else:\n            self._insert(value, self.root)\n\n    def _insert(self, value, node):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(value, node.left)\n        elif value > node.value:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(value, node.right)\n\n    def delete(self, value):\n        self.root = self._delete(value, self.root)\n\n    def _delete(self, value, node):\n        if node is None:\n            return node\n        elif value < node.value:\n            node.left = self._delete(value, node.left)\n        elif value > node.value:\n            node.right = self._delete(value, node.right)\n        else:\n            if node.left is None:\n                return node.right\n            elif node.right is None:\n                return node.left\n            else:\n                node.value = self._find_min_value(node.right)\n                node.right = self._delete(node.value, node.right)\n        return node\n\n    def _find_min_value(self, node):\n        current = node\n        while current.left is not None:\n            current = current.left\n        return current.value\n\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None",
        "```python\ndef kth_largest_element(arr, k):\n    arr.sort()\n    return arr[-k]\n```",
        "```python\ndef gcd(a: int, b: int) -> int:\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x",
        "def mean(numbers):\n    \"\"\"Computes the mean of a list of numbers.\"\"\"\n    total = sum(numbers)\n    return total / len(numbers)",
        "class LassoRegression:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n        self.coef_ = None\n        self.intercept_ = None\n\n    def train(self, X_train, y_train):\n        self.coef_ = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n        self.intercept_ = np.mean(y_train - X_train @ self.coef_)\n\n    def predict(self, X_test):\n        return X_test @ self.coef_ + self.intercept_",
        "class StudentGrade:\n    def __init__(self, grade):\n        self.grade = grade\n\n    def average_grade(self):\n        return self.grade",
        "class Playlist:\n    def __init__(self):\n        self.songs = []\n\n    def add_song(self, song):\n        self.songs.append(song)\n\n    def remove_song(self, song):\n        self.songs.remove(song)",
        "def dot_product(vector_a: list[int], vector_b: list[int]) -> int:\n    \"\"\"\n    Compute the dot product of two vectors.\n\n    Args:\n        vector_a (list[int]): A list of integers representing the first vector.\n        vector_b (list[int]): A list of integers representing the second vector.\n\n    Returns:\n        int: The dot product of vector_a and vector_b.\n    \"\"\"\n    # Validate input\n    if not vector_a or not vector_b:\n        raise ValueError(\"Input vectors cannot be empty.\")\n    if len(vector_a) != len(vector_b):\n        raise ValueError(\"Input vectors must have the same length.\")\n\n    # Compute the dot product\n    dot_product = 0\n    for i in range(len(vector_a)):\n        dot_product += vector_a[i] * vector_b[i]\n\n    return dot_product",
        "class Library:\n    def __init__(self):\n        self.books = []\n\n    def add_books(self, books):\n        self.books.extend(books)\n\n    def remove_books(self, books):\n        for book in books:\n            self.books.remove(book)",
        "class LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def append(self, value):\n        if not self.head:\n            self.head = Node(value)\n        else:\n            current = self.head\n            while current.next:\n                current = current.next\n            current.next = Node(value)\n\n    def get_values(self):\n        result = []\n        current = self.head\n        while current:\n            result.append(current.value)\n            current = current.next\n        return result",
        "```python\ndef merge_sorted_lists(list1: list[int], list2: list[int]) -> list[int]:\n    \"\"\"\n    Merges two sorted lists into a single sorted list.\n\n    Args:\n        list1 (list[int]): The first sorted list.\n        list2 (list[int]): The second sorted list.\n\n    Returns:\n        list[int]: A new sorted list containing all elements from both input lists.\n    \"\"\"\n    merged_list = []\n    i, j = 0, 0\n\n    # Iterate through both lists until one of them is exhausted\n    while i < len(list1) and j < len(list2):\n        # Compare the current elements and append the smaller one\n        if list1[i] < list2[j]:\n            merged_list.append(list1[i])\n            i += 1\n        else:\n            merged_list.append(list2[j])\n            j += 1\n\n    # Append any remaining elements from the non-exhausted list\n    merged_list.extend(list1[i:])\n    merged_list.extend(list2[j:])\n\n    return merged_list\n```",
        "from sklearn.kernel_ridge import KernelRidge\n\nclass KernelRidgeRegression:\n    \"\"\"\n    Kernel ridge regression class.\n\n    Parameters:\n    alpha (float): Regularization strength parameter. Must be a positive float.\n        The penalty is typically of the form alpha * ||w||^2 where ||w|| is the euclidean norm.\n    kernel (string): Kernel mapping used internally. Passed to pairwise_kernels\n        as the metric parameter.\n    degree (int): Degree of the polynomial kernel. Ignored by other kernels.\n    gamma (float): Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels.\n        Interpretation of the default values for each kernel:\n        - 'rbf': sqrt(med_pair_distance), 'chi2': 0.5 / df, 'poly': 1 / (df * X.shape[1]), 'sigmoid': 1 / df\n    coef0 (float): Independent term in decision function.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float = 1.0,\n        kernel: str = \"linear\",\n        degree: int = 3,\n        gamma: float = None,\n        coef0: float = 0.0,\n    ):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.degree = degree\n        self.gamma = gamma\n        self.coef0 = coef0\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> \"KernelRidgeRegression\":\n        \"\"\"\n        Fit Kernel Ridge regression model.\n\n        Parameters:\n        X (ndarray of shape (n_samples, n_features)): Training data.\n        y (ndarray of shape (n_samples, ...)): Target values.\n\n        Returns:\n        self: Fitted estimator.\n        \"\"\"\n        self.X_ = X\n        self.y_ = y\n        self._fit()\n        return self\n\n    def _fit(self) -> None:\n        \"\"\"Fit the model.\"\"\"\n        self.classes_ = np.unique(self.y_)\n        self.n_classes_ = self.classes_.shape[0]\n        self.class_prior_ = np.zeros(self.n_classes_)\n        self.class_count_ = np.zeros(self.n_classes_)\n        self.X_train_ = np.zeros((self.X_.shape[0], self.n_classes_))\n        self.y_train_ = np.zeros(self.X_.shape[0])\n        for i, y in enumerate(self.y_):\n            self.class_prior_[y] += 1\n            self.class_count_[y] += 1\n            self.X_train_[i, y] = 1\n            self.y_train_[i] = y\n        self.X_train_ = self.X_train_ / self.class_count_[:, np.newaxis]\n        self.coef_ = np.zeros((self.n_classes_, self.X_.shape[1]))\n        for i, y in enumerate(self.classes_):\n            self.coef_[y] = (\n                self.alpha\n                * self.X_train_.T\n                @ (self.X_train_[:, i] * (self.y_train_ == y) - self.coef0)\n            )\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict using the kernel ridge model.\n\n        Parameters:\n        X (ndarray of shape (n_samples, n_features)): Samples.\n\n        Returns:\n        y (ndarray of shape (n_samples, ...)): Returns an array of shape (n_samples,).\n        \"\"\"\n        K = pairwise_kernels(X, self.X_, metric=self.kernel, degree=self.degree, gamma=self.gamma)\n        return self.class_prior_ + K @ self.coef_",
        "```python\ndef is_valid_sudoku(board):\n    # Check rows, columns, and boxes\n    for i in range(9):\n        row = set(board[i])\n        col = set(board[i::9])\n        box = set(board[i // 3 * 3: i // 3 * 3 + 3: i // 3 * 9: i // 3 * 9 + 9])\n        if len(row) != 9 or len(col) != 9 or len(box) != 9:\n            return False\n    return True\n```",
        "```python\ndef flatten_binary_tree(root):\n    if not root:\n        return None\n\n    result = []\n    stack = [root]\n\n    while stack:\n        current_node = stack.pop()\n        result.append(current_node.value)\n\n        if current_node.right:\n            stack.append(current_node.right)\n\n        if current_node.left:\n            stack.append(current_node.left)\n\n    return result\n```",
        "from sklearn.decomposition import PCA\n\nclass PCA:\n    \"\"\"\n    Principal component analysis (PCA) class.\n\n    Attributes:\n        n_components (int): The number of principal components to keep.\n        explained_variance_ratio (float): The ratio of variance explained by the kept components.\n        components_ (ndarray): The principal axes in feature space, representing the directions of maximum variance in the data.\n        mean_ (ndarray): The mean value of each feature, calculated over the training data.\n\n    ...\n\n    \"\"\"\n\n    def __init__(self, n_components=None):\n        self.n_components = n_components\n        self.explained_variance_ratio = None\n        self.components_ = None\n        self.mean_ = None\n\n    def fit(self, X: ndarray) -> PCA:\n        \"\"\"\n        Fit the model with X.\n\n        Args:\n            X (ndarray): The training data, where each row is a sample and each column is a feature.\n\n        Returns:\n            PCA: Fitted instance of self.\n\n        \"\"\"\n        self.mean_ = X.mean(axis=0)\n        X -= self.mean_\n        cov_matrix = np.cov(X.T)\n        eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n        eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:, i]) for i in range(len(eig_vals))]\n        eig_pairs.sort(key=lambda x: x[0], reverse=True)\n\n        self.explained_variance_ratio = np.sum([pair[0] for pair in eig_pairs[:self.n_components]]) / np.sum(eig_vals)\n        self.components_ = np.column_stack([pair[1] for pair in eig_pairs[:self.n_components]])\n        return self\n\n    def transform(self, X: ndarray) -> ndarray:\n        \"\"\"\n        Apply dimensionality reduction on X.\n\n        Args:\n            X (ndarray): The data to transform, where each row is a sample.\n\n        Returns:\n            ndarray: Transformed data, where each row is a sample in the new feature space.\n\n        \"\"\"\n        return X @ self.components_\n\n    def fit_transform(self, X: ndarray) -> ndarray:\n        \"\"\"\n        Fit the model with X and apply dimensionality reduction.\n\n        Args:\n            X (ndarray): The training data, where each row is a sample and each column is a feature.\n\n        Returns:\n            ndarray: Transformed data, where each row is a sample in the new feature space.\n\n        \"\"\"\n        self.fit(X)\n        return self.transform(X)",
        "```python\ndef sum_array_except_self(array, index):\n    array_sum = sum(array)\n    array[index] = 0\n    return array_sum\n```",
        "```python\ndef is_palindrome(s: str) -> bool:\n    return s == s[::-1]\n```",
        "```python\ndef lcm(a: int, b: int) -> int:\n    \"\"\"\n    Returns the least common multiple of two integers.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The least common multiple of a and b.\n    \"\"\"\n    # Calculate the least common multiple using the formula: lcm(a, b) = (|a| * |b|) / gcd(a, b)\n    gcd_result = gcd(a, b)\n    return abs(a * b) // gcd_result\n\ndef gcd(a: int, b: int) -> int:\n    \"\"\"\n    Returns the greatest common divisor of two integers using the Euclidean algorithm.\n\n    Args:\n        a (int): The first integer.\n        b (int): The second integer.\n\n    Returns:\n        int: The greatest common divisor of a and b.\n    \"\"\"\n    while b != 0:\n        a, b = b, a % b\n    return a\n```",
        "class Graph:\n    def __init__(self, nodes):\n        self.nodes = nodes\n        self.adjacency_list = {node: [] for node in nodes}\n\n    def add_edge(self, node1, node2):\n        self.adjacency_list[node1].append(node2)\n        self.adjacency_list[node2].append(node1)\n\n    def shortest_path(self, start, end, path=[]):\n        path = path + [start]\n        queue = [start]\n\n        while queue:\n            vertex = queue.pop(0)\n            for neighbour in self.adjacency_list[vertex]:\n                if neighbour not in path:\n                    path.append(neighbour)\n                    queue.append(neighbour)\n                    if neighbour == end:\n                        return path\n                        break\n        return path",
        "class QuadraticDiscriminantAnalysis:\n    \"\"\"\n    Quadratic Discriminant Analysis (QDA) classifier.\n\n    Parameters:\n    -----------\n    store_covariance : bool, default=True\n        Whether to store the covariance matrix during fitting.\n\n    Attributes:\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        Class means.\n\n    covariances_ : list of arrays of shape (n_features, n_features), or ndarray of shape (n_classes, n_features, n_features)\n        Covariance matrices per class.\n\n    priors_ : ndarray of shape (n_classes,)\n        Class priors.\n\n    means_ : ndarray of shape (n_features,)\n        Class means.\n    \"\"\"\n\n    def __init__(self, store_covariance=True):\n        self.store_covariance = store_covariance\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the QDA model according to the given training data and parameters.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training data.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n        \"\"\"\n        self.classes_, y_encoded = np.unique(y, return_inverse=True)\n        n_classes = self.classes_.size\n        n_features = X.shape[1]\n\n        # Compute class means\n        self.means_ = np.zeros((n_classes, n_features))\n        for i in range(n_classes):\n            Xi = X[y_encoded == i]\n            self.means_[i] = Xi.mean(axis=0)\n\n        # Compute class covariance matrices\n        if self.store_covariance:\n            self.covariances_ = [None] * n_classes\n            for i in range(n_classes):\n                Xi = X[y_encoded == i]\n                self.covariances_[i] = np.atleast_2d(np.cov(Xi.T))\n\n        # Compute class priors\n        self.priors_ = np.bincount(y_encoded) / y_encoded.size\n\n    def predict(self, X):\n        \"\"\"\n        Perform classification on samples in X.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        C : ndarray of shape (n_samples,)\n            Predicted class label per sample.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return self.classes_[np.argmax(jll, axis=1)]\n\n    def _joint_log_likelihood(self, X):\n        \"\"\"\n        Compute the log of the joint likelihood for each sample in X under the current model.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        jll : ndarray of shape (n_samples, n_classes)\n            Log of the joint likelihood for each sample in X under the current model.\n        \"\"\"\n        n_classes = self.classes_.size\n        jll = np.zeros((X.shape[0], n_classes))\n        for i in range(n_classes):\n            Xi = X - self.means_[i]\n            if self.store_covariance:\n                cov = self.covariances_[i]\n                jll[:, i] = np.log(self.priors_[i]) - 0.5 * np.log(\n                    np.linalg.det(cov)\n                ) - 0.5 * np.sum(np.dot(Xi, np.linalg.solve(cov, Xi.T))\n                )\n            else:\n                jll[:, i] = np.log(self.priors_[i]) - 0.5 * np.log(\n                    2 * np.pi\n                ) * Xi.shape[1]\n        return jll\n\n    def predict_proba(self, X):\n        \"\"\"\n        Return posterior probabilities of classification according to the current model.\n\n        Parameters:\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples.\n\n        Returns:\n        -------\n        C : ndarray of shape (n_samples, n_classes)\n            Returns the posterior probability of the samples belonging to each class in\n            the model. The columns correspond to the classes in sorted order, as they appear\n            in the attribute `classes_`.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        jll -= jll.max(axis=1)[:, np.newaxis]\n        return np.exp(jll)",
        "import numpy as np\n\nclass LinearRegression:\n    \"\"\"\n    A Linear Regression class for predicting target values based on input features.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialize the LinearRegression class.\n        \"\"\"\n        self.coef_ = None\n        self.intercept_ = None\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n        \"\"\"\n        Fit the linear regression model to the training data.\n\n        Parameters:\n            X (np.ndarray): The input features of shape (n_samples, n_features).\n            y (np.ndarray): The target values of shape (n_samples,).\n        \"\"\"\n        X = np.asarray(X)\n        y = np.asarray(y)\n\n        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.intercept_ = np.mean(y - X @ self.coef_)\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Predict the target values for the given input features.\n\n        Parameters:\n            X (np.ndarray): The input features of shape (n_samples, n_features).\n\n        Returns:\n            np.ndarray: The predicted target values of shape (n_samples,).\n        \"\"\"\n        return X @ self.coef_ + self.intercept_",
        "```python\ndef is_valid_bst(tree):\n    if tree is None:\n        return True\n    if tree.left and tree.left.data > tree.data:\n        return False\n    if tree.right and tree.right.data < tree.data:\n        return False\n    return is_valid_bst(tree.left) and is_valid_bst(tree.right)\n```",
        "class Perceptron:\n    def __init__(self):\n        self.weights = []\n\n    def train(self, inputs, targets):\n        self.weights = [0] * len(inputs[0])\n        for input, target in zip(inputs, targets):\n            for i in range(len(input)):\n                self.weights[i] += input[i] * target\n\n    def predict(self, input):\n        return sum(input[i] * weight for i, weight in enumerate(self.weights))",
        "Here is the function that returns the common elements between two lists:\n```python\ndef get_common_elements(list1, list2):\n    common_elements = []\n    for element in list1:\n        if element in list2:\n            common_elements.append(element)\n    return common_elements\n```",
        "def average_diagonal(matrix):\n    diagonal_sum = 0\n    for row in matrix:\n        diagonal_sum += row[0]\n    return diagonal_sum / len(matrix)",
        "def product_array(self, n):\n    return [i * i for i in range(1, n + 1)]"
      ]
    }
  ]
}